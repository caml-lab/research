{"title": "HyperShot: Few-Shot Learning by Kernel HyperNetworks", "abstract": "Few-shot models aim at making predictions using a minimal number of labeled\nexamples from a given task. The main challenge in this area is the one-shot\nsetting where only one element represents each class. We propose HyperShot -\nthe fusion of kernels and hypernetwork paradigm. Compared to reference\napproaches that apply a gradient-based adjustment of the parameters, our model\naims to switch the classification module parameters depending on the task's\nembedding. In practice, we utilize a hypernetwork, which takes the aggregated\ninformation from support data and returns the classifier's parameters\nhandcrafted for the considered problem. Moreover, we introduce the kernel-based\nrepresentation of the support examples delivered to hypernetwork to create the\nparameters of the classification module. Consequently, we rely on relations\nbetween embeddings of the support examples instead of direct feature values\nprovided by the backbone models. Thanks to this approach, our model can adapt\nto highly different tasks.", "authors": ["Marcin Sendera", "Marcin Przewi\u0119\u017alikowski", "Konrad Karanowski", "Maciej Zi\u0119ba", "Jacek Tabor", "Przemys\u0142aw Spurek"], "published_date": "2022_03_21", "pdf_url": "http://arxiv.org/pdf/2203.11378v1", "list_table_and_caption": [{"table": "<table><tr><td>Method</td><td>CUB</td><td>mini-ImageNet</td></tr><tr><td>ML-LSTM (Ravi &amp; Larochelle, 2017)</td><td>\u2013</td><td>43.44\\pm 0.77</td></tr><tr><td>SNAIL (Mishra et al., 2018)</td><td>\u2013</td><td>45.10</td></tr><tr><td>iMAML-HF (Rajeswaran et al., 2019)</td><td>\u2013</td><td>49.30\\pm 1.88</td></tr><tr><td>LLAMA (Grant et al., 2018)</td><td>\u2013</td><td>49.40\\pm 1.83</td></tr><tr><td>VERSA (Gordon et al., 2018)</td><td>\u2013</td><td>48.53\\pm 1.84</td></tr><tr><td>Amortized VI (Gordon et al., 2018)</td><td>\u2013</td><td>44.13\\pm 1.78</td></tr><tr><td>Meta-Mixture (Jerfel et al., 2019)</td><td>\u2013</td><td>49.60\\pm 1.50</td></tr><tr><td>SimpleShot (Wang et al., 2019)</td><td>\u2013</td><td>49.69\\pm 0.19</td></tr><tr><td>Feature Transfer (Zhuang et al., 2020)</td><td>46.19\\pm 0.64</td><td>39.51\\pm 0.23</td></tr><tr><td>Baseline++ (Chen et al., 2019)</td><td>61.75\\pm 0.95</td><td>47.15\\pm 0.49</td></tr><tr><td>MatchingNet (Vinyals et al., 2016)</td><td>60.19\\pm 1.02</td><td>48.25\\pm 0.65</td></tr><tr><td>ProtoNet (Snell et al., 2017)</td><td>52.52\\pm 1.90</td><td>44.19\\pm 1.30</td></tr><tr><td>MAML (Finn et al., 2017)</td><td>56.11\\pm 0.69</td><td>45.39\\pm 0.49</td></tr><tr><td>RelationNet (Sung et al., 2018)</td><td>62.52\\pm 0.34</td><td>48.76\\pm 0.17</td></tr><tr><td>DKT + CosSim (Patacchiola et al., 2020)</td><td>63.37\\pm 0.19</td><td>48.64\\pm 0.45</td></tr><tr><td>DKT + BNCosSim (Patacchiola et al., 2020)</td><td>62.96\\pm 0.62</td><td>49.73\\pm 0.07</td></tr><tr><td>GPLDLA (Kim &amp; Hospedales, 2021)</td><td>63.40\\pm 0.14</td><td>52.58\\pm 0.19</td></tr><tr><td>amortized Bayesianprototype meta-learning (Sun et al., 2021) </td><td>63.46\\pm 0.98</td><td>53.28\\pm 0.91</td></tr><tr><td>VAMPIRE (Nguyen et al., 2020)</td><td>\u2013</td><td>51.54\\pm 0.74</td></tr><tr><td>PLATIPUS (Finn et al., 2018)</td><td>\u2013</td><td>50.13\\pm 1.86</td></tr><tr><td>ABML (Ravi &amp; Beatson, 2018)</td><td>49.57\\pm 0.42</td><td>45.00\\pm 0.60</td></tr><tr><td>Bayesian MAML (Yoon et al., 2018)</td><td>55.93\\pm 0.71</td><td>53.80\\pm 1.46</td></tr><tr><td>OVE PG GP + Cosine (ML) (Snell &amp; Zemel, 2020)</td><td>63.98\\pm 0.43</td><td>50.02\\pm 0.35</td></tr><tr><td>OVE PG GP + Cosine (PL) (Snell &amp; Zemel, 2020)</td><td>60.11\\pm 0.26</td><td>48.00\\pm 0.24</td></tr><tr><td>Reptile (Nichol et al., 2018)</td><td>\u2013</td><td>49.97\\pm 0.32</td></tr><tr><td>R2-D2 (Bertinetto et al., 2018)</td><td>\u2013</td><td>48.70\\pm 0.60</td></tr><tr><td>VSM (Zhen et al., 2020)</td><td>\u2013</td><td>\\mathit{54.73\\pm 1.60}</td></tr><tr><td>PPA (Qiao et al., 2017)</td><td>\u2013</td><td>54.53\\pm 0.40</td></tr><tr><td>DFSVLwF (Gidaris &amp; Komodakis, 2018)</td><td>\u2013</td><td>\\mathbf{56.20\\pm 0.86}</td></tr><tr><td>HyperShot (ours)</td><td>\\mathit{65.27\\pm 0.24}</td><td>52.42\\pm 0.46</td></tr><tr><td>HyperShot + finetuning (ours)</td><td>\\mathbf{66.13\\pm 0.26}</td><td>53.18\\pm 0.45</td></tr></table>", "caption": "Table 1: The classification accuracy results for the inference tasks on CUB and mini-ImageNet datasets in the 1-shot setting. The highest results are bold and second-highest in italic (the larger, the better).", "list_citation_info": ["Chen et al. (2019) Chen, W.-Y., Liu, Y.-C., Kira, Z., Wang, Y.-C. F., and Huang, J.-B. A closer look at few-shot classification. arXiv preprint arXiv:1904.04232, 2019.", "Finn et al. (2017) Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-learning for fast adaptation of deep networks. In International Conference on Machine Learning, pp. 1126\u20131135. PMLR, 2017.", "Grant et al. (2018) Grant, E., Finn, C., Levine, S., Darrell, T., and Griffiths, T. Recasting gradient-based meta-learning as hierarchical bayes. In International Conference on Learning Representations, 2018.", "Ravi & Larochelle (2017) Ravi, S. and Larochelle, H. Optimization as a model for few-shot learning. In ICLR, 2017.", "Ravi & Beatson (2018) Ravi, S. and Beatson, A. Amortized bayesian meta-learning. In International Conference on Learning Representations, 2018.", "Snell et al. (2017) Snell, J., Swersky, K., and Zemel, R. S. Prototypical networks for few-shot learning. arXiv preprint arXiv:1703.05175, 2017.", "Yoon et al. (2018) Yoon, J., Kim, T., Dia, O., Kim, S., Bengio, Y., and Ahn, S. Bayesian model-agnostic meta-learning. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 7343\u20137353, 2018.", "Snell & Zemel (2020) Snell, J. and Zemel, R. Bayesian few-shot classification with one-vs-each p\u00f3lya-gamma augmented gaussian processes. In International Conference on Learning Representations, 2020.", "Nguyen et al. (2020) Nguyen, C., Do, T.-T., and Carneiro, G. Uncertainty in model-agnostic meta-learning using variational inference. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 3090\u20133100, 2020.", "Finn et al. (2018) Finn, C., Xu, K., and Levine, S. Probabilistic model-agnostic meta-learning. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 9537\u20139548, 2018.", "Qiao et al. (2017) Qiao, S., Liu, C., Shen, W., and Yuille, A. Few-shot image recognition by predicting parameters from activations, 2017.", "Wang et al. (2019) Wang, Y., Chao, W.-L., Weinberger, K. Q., and van der Maaten, L. Simpleshot: Revisiting nearest-neighbor classification for few-shot learning. arXiv preprint arXiv:1911.04623, 2019.", "Vinyals et al. (2016) Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. Advances in neural information processing systems, 29:3630\u20133638, 2016.", "Patacchiola et al. (2020) Patacchiola, M., Turner, J., Crowley, E. J., O\u2019Boyle, M., and Storkey, A. J. Bayesian meta-learning for the few-shot setting via deep kernels. Advances in Neural Information Processing Systems, 33, 2020.", "Sung et al. (2018) Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H., and Hospedales, T. M. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1199\u20131208, 2018.", "Gidaris & Komodakis (2018) Gidaris, S. and Komodakis, N. Dynamic few-shot visual learning without forgetting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4367\u20134375, 2018.", "Gordon et al. (2018) Gordon, J., Bronskill, J., Bauer, M., Nowozin, S., and Turner, R. Meta-learning probabilistic inference for prediction. In International Conference on Learning Representations, 2018.", "Zhen et al. (2020) Zhen, X., Du, Y.-J., Xiong, H., Qiu, Q., Snoek, C., and Shao, L. Learning to learn variational semantic memory. In NeurIPS, 2020.", "Zhuang et al. (2020) Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., and He, Q. A comprehensive survey on transfer learning, 2020.", "Mishra et al. (2018) Mishra, N., Rohaninejad, M., Chen, X., and Abbeel, P. A simple neural attentive meta-learner. In International Conference on Learning Representations, 2018.", "Sun et al. (2021) Sun, Z., Wu, J., Li, X., Yang, W., and Xue, J.-H. Amortized bayesian prototype meta-learning: A new probabilistic meta-learning approach to few-shot image classification. In International Conference on Artificial Intelligence and Statistics, pp. 1414\u20131422. PMLR, 2021.", "Rajeswaran et al. (2019) Rajeswaran, A., Finn, C., Kakade, S. M., and Levine, S. Meta-learning with implicit gradients. Advances in Neural Information Processing Systems, 32:113\u2013124, 2019.", "Bertinetto et al. (2018) Bertinetto, L., Henriques, J. F., Torr, P., and Vedaldi, A. Meta-learning with differentiable closed-form solvers. In International Conference on Learning Representations, 2018.", "Nichol et al. (2018) Nichol, A., Achiam, J., and Schulman, J. On first-order meta-learning algorithms. arXiv preprint arXiv:1803.02999, 2018.", "Kim & Hospedales (2021) Kim, M. and Hospedales, T. Gaussian process meta few-shot classifier learning via linear discriminant laplace approximation. arXiv preprint arXiv:2111.05392, 2021.", "Jerfel et al. (2019) Jerfel, G., Grant, E., Griffiths, T. L., and Heller, K. Reconciling meta-learning and continual learning with online mixtures of tasks. In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 9122\u20139133, 2019."]}, {"table": "<table><tr><td>Method</td><td>CUB</td><td>mini-ImageNet</td></tr><tr><td>ML-LSTM (Ravi &amp; Larochelle, 2017)</td><td>\u2013</td><td>60.60\\pm 0.71</td></tr><tr><td>SNAIL (Mishra et al., 2018)</td><td>\u2013</td><td>55.20</td></tr><tr><td>VERSA (Gordon et al., 2018)</td><td>\u2013</td><td>67.37\\pm 0.86</td></tr><tr><td>Amortized VI (Gordon et al., 2018)</td><td>\u2013</td><td>55.68\\pm 0.91</td></tr><tr><td>Meta-Mixture (Jerfel et al., 2019)</td><td>\u2013</td><td>64.60\\pm 0.92</td></tr><tr><td>SimpleShot (Wang et al., 2019)</td><td>\u2013</td><td>66.92\\pm 0.17</td></tr><tr><td>Feature Transfer</td><td>68.40\\pm 0.79</td><td>60.51\\pm 0.55</td></tr><tr><td>Baseline++ (Chen et al., 2019)</td><td>78.51\\pm 0.59</td><td>66.18\\pm 0.18</td></tr><tr><td>MatchingNet (Vinyals et al., 2016)</td><td>75.11\\pm 0.35</td><td>62.71\\pm 0.44</td></tr><tr><td>ProtoNet (Snell et al., 2017)</td><td>75.93\\pm 0.46</td><td>64.07\\pm 0.65</td></tr><tr><td>MAML (Finn et al., 2017)</td><td>74.84\\pm 0.62</td><td>61.58\\pm 0.53</td></tr><tr><td>RelationNet (Sung et al., 2018)</td><td>78.22\\pm 0.07</td><td>64.20\\pm 0.28</td></tr><tr><td>DKT + CosSim (Patacchiola et al., 2020)</td><td>77.73\\pm 0.26</td><td>62.85\\pm 0.37</td></tr><tr><td>DKT + BNCosSim (Patacchiola et al., 2020)</td><td>77.76\\pm 0.62</td><td>64.00\\pm 0.09</td></tr><tr><td>GPLDLA (Kim &amp; Hospedales, 2021)</td><td>78.86\\pm 0.35</td><td>\u2013</td></tr><tr><td>amortized Bayesianprototype meta-learning (Sun et al., 2021) </td><td>\\mathbf{80.94\\pm 0.62}</td><td>\\mathbf{70.44\\pm 0.72}</td></tr><tr><td>VAMPIRE (Nguyen et al., 2020)</td><td>\u2013</td><td>64.31\\pm 0.74</td></tr><tr><td>ABML (Ravi &amp; Beatson, 2018)</td><td>68.94\\pm 0.16</td><td>\u2013</td></tr><tr><td>Bayesian MAML (Yoon et al., 2018)</td><td>\u2013</td><td>64.23\\pm 0.69</td></tr><tr><td>OVE PG GP + Cosine (ML) (Snell &amp; Zemel, 2020)</td><td>77.44\\pm 0.18</td><td>64.58\\pm 0.31</td></tr><tr><td>OVE PG GP + Cosine (PL) (Snell &amp; Zemel, 2020)</td><td>79.07\\pm 0.05</td><td>67.14\\pm 0.23</td></tr><tr><td>Reptile (Nichol et al., 2018)</td><td>\u2013</td><td>65.99\\pm 0.58</td></tr><tr><td>R2-D2 (Bertinetto et al., 2018)</td><td>\u2013</td><td>65.50\\pm 0.60</td></tr><tr><td>VSM (Zhen et al., 2020)</td><td>\u2013</td><td>68.01\\pm 0.90</td></tr><tr><td>HyperShot</td><td>79.80\\pm 0.16</td><td>68.78\\pm 0.29</td></tr><tr><td>HyperShot + finetuning</td><td>\\mathit{80.07\\pm 0.22}</td><td>\\mathit{69.62\\pm 0.28}</td></tr></table>", "caption": "Table 2: The classification accuracy results for the inference tasks on CUB and mini-ImageNet datasets in the 5-shot setting. The highest results are bold and second-highest in italic (the larger, the better). ", "list_citation_info": ["Chen et al. (2019) Chen, W.-Y., Liu, Y.-C., Kira, Z., Wang, Y.-C. F., and Huang, J.-B. A closer look at few-shot classification. arXiv preprint arXiv:1904.04232, 2019.", "Finn et al. (2017) Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-learning for fast adaptation of deep networks. In International Conference on Machine Learning, pp. 1126\u20131135. PMLR, 2017.", "Ravi & Larochelle (2017) Ravi, S. and Larochelle, H. Optimization as a model for few-shot learning. In ICLR, 2017.", "Ravi & Beatson (2018) Ravi, S. and Beatson, A. Amortized bayesian meta-learning. In International Conference on Learning Representations, 2018.", "Snell et al. (2017) Snell, J., Swersky, K., and Zemel, R. S. Prototypical networks for few-shot learning. arXiv preprint arXiv:1703.05175, 2017.", "Yoon et al. (2018) Yoon, J., Kim, T., Dia, O., Kim, S., Bengio, Y., and Ahn, S. Bayesian model-agnostic meta-learning. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 7343\u20137353, 2018.", "Snell & Zemel (2020) Snell, J. and Zemel, R. Bayesian few-shot classification with one-vs-each p\u00f3lya-gamma augmented gaussian processes. In International Conference on Learning Representations, 2020.", "Nguyen et al. (2020) Nguyen, C., Do, T.-T., and Carneiro, G. Uncertainty in model-agnostic meta-learning using variational inference. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 3090\u20133100, 2020.", "Wang et al. (2019) Wang, Y., Chao, W.-L., Weinberger, K. Q., and van der Maaten, L. Simpleshot: Revisiting nearest-neighbor classification for few-shot learning. arXiv preprint arXiv:1911.04623, 2019.", "Vinyals et al. (2016) Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. Advances in neural information processing systems, 29:3630\u20133638, 2016.", "Patacchiola et al. (2020) Patacchiola, M., Turner, J., Crowley, E. J., O\u2019Boyle, M., and Storkey, A. J. Bayesian meta-learning for the few-shot setting via deep kernels. Advances in Neural Information Processing Systems, 33, 2020.", "Sung et al. (2018) Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H., and Hospedales, T. M. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1199\u20131208, 2018.", "Gordon et al. (2018) Gordon, J., Bronskill, J., Bauer, M., Nowozin, S., and Turner, R. Meta-learning probabilistic inference for prediction. In International Conference on Learning Representations, 2018.", "Zhen et al. (2020) Zhen, X., Du, Y.-J., Xiong, H., Qiu, Q., Snoek, C., and Shao, L. Learning to learn variational semantic memory. In NeurIPS, 2020.", "Mishra et al. (2018) Mishra, N., Rohaninejad, M., Chen, X., and Abbeel, P. A simple neural attentive meta-learner. In International Conference on Learning Representations, 2018.", "Sun et al. (2021) Sun, Z., Wu, J., Li, X., Yang, W., and Xue, J.-H. Amortized bayesian prototype meta-learning: A new probabilistic meta-learning approach to few-shot image classification. In International Conference on Artificial Intelligence and Statistics, pp. 1414\u20131422. PMLR, 2021.", "Bertinetto et al. (2018) Bertinetto, L., Henriques, J. F., Torr, P., and Vedaldi, A. Meta-learning with differentiable closed-form solvers. In International Conference on Learning Representations, 2018.", "Nichol et al. (2018) Nichol, A., Achiam, J., and Schulman, J. On first-order meta-learning algorithms. arXiv preprint arXiv:1803.02999, 2018.", "Kim & Hospedales (2021) Kim, M. and Hospedales, T. Gaussian process meta few-shot classifier learning via linear discriminant laplace approximation. arXiv preprint arXiv:2111.05392, 2021.", "Jerfel et al. (2019) Jerfel, G., Grant, E., Griffiths, T. L., and Heller, K. Reconciling meta-learning and continual learning with online mixtures of tasks. In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 9122\u20139133, 2019."]}, {"table": "<table><tr><td></td><td colspan=\"2\">Omni\\rightarrowEMNIST</td><td colspan=\"2\">mini-ImageNet\\rightarrowCUB</td></tr><tr><td>Method</td><td>1-shot</td><td>5-shot</td><td>1-shot</td><td>5-shot</td></tr><tr><td>Feature Transfer</td><td>64.22 \\pm 1.24</td><td>86.10 \\pm 0.84</td><td>32.77 \\pm 0.35</td><td>50.34 \\pm 0.27</td></tr><tr><td>Baseline++ (Chen et al., 2019)</td><td>56.84 \\pm 0.91</td><td>80.01 \\pm 0.92</td><td>39.19 \\pm 0.12</td><td>57.31\\pm 0.11</td></tr><tr><td>MatchingNet (Vinyals et al., 2016)</td><td>75.01 \\pm 2.09</td><td>87.41 \\pm 1.79</td><td>36.98 \\pm 0.06</td><td>50.72 \\pm 0.36</td></tr><tr><td>ProtoNet (Snell et al., 2017)</td><td>72.04 \\pm 0.82</td><td>87.22 \\pm 1.01</td><td>33.27 \\pm 1.09</td><td>52.16 \\pm 0.17</td></tr><tr><td>MAML (Finn et al., 2017)</td><td>72.68 \\pm 1.85</td><td>83.54 \\pm 1.79</td><td>34.01 \\pm 1.25</td><td>48.83 \\pm 0.62</td></tr><tr><td>RelationNet (Sung et al., 2018)</td><td>75.62 \\pm 1.00</td><td>87.84 \\pm 0.27</td><td>37.13 \\pm 0.20</td><td>51.76 \\pm 1.48</td></tr><tr><td>DKT (Patacchiola et al., 2020)</td><td>75.40 \\pm 1.10</td><td>\\mathit{90.30\\pm 0.49}</td><td>\\mathbf{40.14\\pm{0.18}}</td><td>56.40 \\pm 1.34</td></tr><tr><td>Bayesian MAML (Yoon et al., 2018)</td><td>63.94\\pm 0.47</td><td>65.26\\pm 0.30</td><td>33.52\\pm 0.36</td><td>51.35\\pm 0.16</td></tr><tr><td>OVE PG GP + Cosine (ML) (Snell &amp; Zemel, 2020)</td><td>68.43\\pm 0.67</td><td>86.22\\pm 0.20</td><td>39.66\\pm 0.18</td><td>55.71\\pm 0.31</td></tr><tr><td>OVE PG GP + Cosine (PL) (Snell &amp; Zemel, 2020)</td><td>77.00\\pm 0.50</td><td>87.52\\pm 0.19</td><td>37.49\\pm 0.11</td><td>57.23\\pm 0.31</td></tr><tr><td>HyperShot</td><td>\\mathit{78.06\\pm 0.24}</td><td>89.04\\pm 0.18</td><td>39.09\\pm 0.28</td><td>\\mathit{57.77\\pm 0.33}</td></tr><tr><td>HyperShot + finetuning</td><td>\\mathbf{80.65\\pm 0.30}</td><td>\\mathbf{90.81\\pm 0.16}</td><td>\\mathit{40.03\\pm 0.41}</td><td>\\mathbf{58.86\\pm 0.38}</td></tr></table>", "caption": "Table 3: The classification accuracy results for the inference tasks on cross-domain tasks (Omniglot\\rightarrowEMNIST and mini-ImageNet\\rightarrowCUB) datasets in the 1-shot setting. The highest results are bold and second-highest in italic (the larger, the better). ", "list_citation_info": ["Chen et al. (2019) Chen, W.-Y., Liu, Y.-C., Kira, Z., Wang, Y.-C. F., and Huang, J.-B. A closer look at few-shot classification. arXiv preprint arXiv:1904.04232, 2019.", "Finn et al. (2017) Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-learning for fast adaptation of deep networks. In International Conference on Machine Learning, pp. 1126\u20131135. PMLR, 2017.", "Vinyals et al. (2016) Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. Advances in neural information processing systems, 29:3630\u20133638, 2016.", "Snell et al. (2017) Snell, J., Swersky, K., and Zemel, R. S. Prototypical networks for few-shot learning. arXiv preprint arXiv:1703.05175, 2017.", "Yoon et al. (2018) Yoon, J., Kim, T., Dia, O., Kim, S., Bengio, Y., and Ahn, S. Bayesian model-agnostic meta-learning. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 7343\u20137353, 2018.", "Patacchiola et al. (2020) Patacchiola, M., Turner, J., Crowley, E. J., O\u2019Boyle, M., and Storkey, A. J. Bayesian meta-learning for the few-shot setting via deep kernels. Advances in Neural Information Processing Systems, 33, 2020.", "Sung et al. (2018) Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H., and Hospedales, T. M. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1199\u20131208, 2018.", "Snell & Zemel (2020) Snell, J. and Zemel, R. Bayesian few-shot classification with one-vs-each p\u00f3lya-gamma augmented gaussian processes. In International Conference on Learning Representations, 2020."]}, {"table": "<table><tr><td>Method</td><td>1-shot</td><td>5-shot</td></tr><tr><td>Feature Transfer</td><td>63.64\\pm 0.91</td><td>81.27\\pm 0.57</td></tr><tr><td>Baseline++ (Chen et al., 2019)</td><td>69.55\\pm 0.89</td><td>85.17\\pm 0.50</td></tr><tr><td>MatchingNet (Vinyals et al., 2016)</td><td>71.29\\pm 0.87</td><td>83.47\\pm 0.58</td></tr><tr><td>ProtoNet (Snell et al., 2017)</td><td>\\mathbf{73.22\\pm 0.92}</td><td>85.01\\pm 0.52</td></tr><tr><td>MAML (Finn et al., 2017)</td><td>70.32\\pm 0.99</td><td>80.93\\pm 0.71</td></tr><tr><td>RelationNet (Sung et al., 2018)</td><td>70.47\\pm 0.99</td><td>83.70\\pm 0.55</td></tr><tr><td>DKT + CosSim (Patacchiola et al., 2020)</td><td>70.81\\pm 0.52</td><td>83.26\\pm 0.50</td></tr><tr><td>DKT + BNCosSim (Patacchiola et al., 2020)</td><td>\\mathit{72.27\\pm 0.30}</td><td>85.64\\pm 0.29</td></tr><tr><td>SimpleShot (Wang et al., 2019)</td><td>53.78\\pm 0.21</td><td>71.41\\pm 0.17</td></tr><tr><td>GPLDLA (Kim &amp; Hospedales, 2021)</td><td>71.30\\pm 0.16</td><td>\\mathbf{86.38\\pm 0.15}</td></tr><tr><td>HyperShot</td><td>71.99\\pm 0.70</td><td>86.28\\pm 0.29</td></tr><tr><td>HyperShot + finetuning</td><td>71.60\\pm 0.59</td><td>\\mathit{86.22\\pm 0.30}</td></tr></table>", "caption": "Table 5:  The classification accuracy results for the inference tasks in the CUB dataset in the 5-way (1-shot and 5-shot) scenarios. We consider models using the ResNet-10 backbone. The highest results are bold and second-highest in italic (the larger, the better).", "list_citation_info": ["Chen et al. (2019) Chen, W.-Y., Liu, Y.-C., Kira, Z., Wang, Y.-C. F., and Huang, J.-B. A closer look at few-shot classification. arXiv preprint arXiv:1904.04232, 2019.", "Finn et al. (2017) Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-learning for fast adaptation of deep networks. In International Conference on Machine Learning, pp. 1126\u20131135. PMLR, 2017.", "Wang et al. (2019) Wang, Y., Chao, W.-L., Weinberger, K. Q., and van der Maaten, L. Simpleshot: Revisiting nearest-neighbor classification for few-shot learning. arXiv preprint arXiv:1911.04623, 2019.", "Vinyals et al. (2016) Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. Advances in neural information processing systems, 29:3630\u20133638, 2016.", "Snell et al. (2017) Snell, J., Swersky, K., and Zemel, R. S. Prototypical networks for few-shot learning. arXiv preprint arXiv:1703.05175, 2017.", "Patacchiola et al. (2020) Patacchiola, M., Turner, J., Crowley, E. J., O\u2019Boyle, M., and Storkey, A. J. Bayesian meta-learning for the few-shot setting via deep kernels. Advances in Neural Information Processing Systems, 33, 2020.", "Sung et al. (2018) Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H., and Hospedales, T. M. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1199\u20131208, 2018.", "Kim & Hospedales (2021) Kim, M. and Hospedales, T. Gaussian process meta few-shot classifier learning via linear discriminant laplace approximation. arXiv preprint arXiv:2111.05392, 2021."]}, {"table": "<table><tr><td>Method</td><td>1-shot</td><td>5-shot</td></tr><tr><td>Baseline++ (Chen et al., 2019)</td><td>54.35\\pm 0.34</td><td>\\mathbf{75.26\\pm 0.16}</td></tr><tr><td>MatchingNet (Vinyals et al., 2016)</td><td>54.18\\pm 0.09</td><td>67.71\\pm 0.20</td></tr><tr><td>ProtoNet (Snell et al., 2017)</td><td>53.28\\pm 0.17</td><td>73.04\\pm 0.15</td></tr><tr><td>RelationNet (Sung et al., 2018)</td><td>51.88\\pm 0.45</td><td>67.21\\pm 0.16</td></tr><tr><td>DKT + BNCosSim (Patacchiola et al., 2020)</td><td>\\mathbf{56.03\\pm 0.50}</td><td>71.28\\pm 0.12</td></tr><tr><td>HyperShot</td><td>55.36\\pm 0.64</td><td>\\mathit{73.06\\pm 0.30}</td></tr><tr><td>HyperShot + finetuning</td><td>\\mathit{55.99\\pm 0.63}</td><td>72.87\\pm 0.33</td></tr></table>", "caption": "Table 6: The classification accuracy results for the inference tasks in the mini-ImageNet dataset in the 5-way (1-shot and 5-shot) scenarios. We consider models using the ResNet-10 backbone. The highest results are bold and second-highest in italic (the larger, the better).", "list_citation_info": ["Chen et al. (2019) Chen, W.-Y., Liu, Y.-C., Kira, Z., Wang, Y.-C. F., and Huang, J.-B. A closer look at few-shot classification. arXiv preprint arXiv:1904.04232, 2019.", "Vinyals et al. (2016) Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. Advances in neural information processing systems, 29:3630\u20133638, 2016.", "Snell et al. (2017) Snell, J., Swersky, K., and Zemel, R. S. Prototypical networks for few-shot learning. arXiv preprint arXiv:1703.05175, 2017.", "Patacchiola et al. (2020) Patacchiola, M., Turner, J., Crowley, E. J., O\u2019Boyle, M., and Storkey, A. J. Bayesian meta-learning for the few-shot setting via deep kernels. Advances in Neural Information Processing Systems, 33, 2020.", "Sung et al. (2018) Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H., and Hospedales, T. M. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1199\u20131208, 2018."]}], "citation_info_to_title": {"Nguyen et al. (2020) Nguyen, C., Do, T.-T., and Carneiro, G. Uncertainty in model-agnostic meta-learning using variational inference. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 3090\u20133100, 2020.": "Uncertainty in model-agnostic meta-learning using variational inference", "Chen et al. (2019) Chen, W.-Y., Liu, Y.-C., Kira, Z., Wang, Y.-C. F., and Huang, J.-B. A closer look at few-shot classification. arXiv preprint arXiv:1904.04232, 2019.": "A closer look at few-shot classification", "Bertinetto et al. (2018) Bertinetto, L., Henriques, J. F., Torr, P., and Vedaldi, A. Meta-learning with differentiable closed-form solvers. In International Conference on Learning Representations, 2018.": "Meta-learning with differentiable closed-form solvers", "Rajeswaran et al. (2019) Rajeswaran, A., Finn, C., Kakade, S. M., and Levine, S. Meta-learning with implicit gradients. Advances in Neural Information Processing Systems, 32:113\u2013124, 2019.": "Meta-learning with implicit gradients", "Qiao et al. (2017) Qiao, S., Liu, C., Shen, W., and Yuille, A. Few-shot image recognition by predicting parameters from activations, 2017.": "Few-shot image recognition by predicting parameters from activations", "Ravi & Beatson (2018) Ravi, S. and Beatson, A. Amortized bayesian meta-learning. In International Conference on Learning Representations, 2018.": "Amortized Bayesian Meta-Learning", "Snell et al. (2017) Snell, J., Swersky, K., and Zemel, R. S. Prototypical networks for few-shot learning. arXiv preprint arXiv:1703.05175, 2017.": "Prototypical networks for few-shot learning", "Sung et al. (2018) Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H., and Hospedales, T. M. Learning to compare: Relation network for few-shot learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1199\u20131208, 2018.": "Learning to compare: Relation network for few-shot learning", "Ravi & Larochelle (2017) Ravi, S. and Larochelle, H. Optimization as a model for few-shot learning. In ICLR, 2017.": "Optimization as a model for few-shot learning", "Vinyals et al. (2016) Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al. Matching networks for one shot learning. Advances in neural information processing systems, 29:3630\u20133638, 2016.": "Matching Networks for One Shot Learning", "Patacchiola et al. (2020) Patacchiola, M., Turner, J., Crowley, E. J., O\u2019Boyle, M., and Storkey, A. J. Bayesian meta-learning for the few-shot setting via deep kernels. Advances in Neural Information Processing Systems, 33, 2020.": "Bayesian meta-learning for the few-shot setting via deep kernels", "Gidaris & Komodakis (2018) Gidaris, S. and Komodakis, N. Dynamic few-shot visual learning without forgetting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4367\u20134375, 2018.": "Dynamic Few-Shot Visual Learning Without Forgetting", "Kim & Hospedales (2021) Kim, M. and Hospedales, T. Gaussian process meta few-shot classifier learning via linear discriminant laplace approximation. arXiv preprint arXiv:2111.05392, 2021.": "Gaussian process meta few-shot classifier learning via linear discriminant Laplace approximation", "Zhuang et al. (2020) Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., and He, Q. A comprehensive survey on transfer learning, 2020.": "A comprehensive survey on transfer learning", "Zhen et al. (2020) Zhen, X., Du, Y.-J., Xiong, H., Qiu, Q., Snoek, C., and Shao, L. Learning to learn variational semantic memory. In NeurIPS, 2020.": "Learning to learn variational semantic memory", "Jerfel et al. (2019) Jerfel, G., Grant, E., Griffiths, T. L., and Heller, K. Reconciling meta-learning and continual learning with online mixtures of tasks. In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 9122\u20139133, 2019.": "Reconciling meta-learning and continual learning with online mixtures of tasks", "Nichol et al. (2018) Nichol, A., Achiam, J., and Schulman, J. On first-order meta-learning algorithms. arXiv preprint arXiv:1803.02999, 2018.": "On first-order meta-learning algorithms", "Finn et al. (2017) Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-learning for fast adaptation of deep networks. In International Conference on Machine Learning, pp. 1126\u20131135. PMLR, 2017.": "Model-agnostic meta-learning for fast adaptation of deep networks", "Finn et al. (2018) Finn, C., Xu, K., and Levine, S. Probabilistic model-agnostic meta-learning. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 9537\u20139548, 2018.": "Probabilistic Model-Agnostic Meta-Learning", "Yoon et al. (2018) Yoon, J., Kim, T., Dia, O., Kim, S., Bengio, Y., and Ahn, S. Bayesian model-agnostic meta-learning. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 7343\u20137353, 2018.": "Bayesian model-agnostic meta-learning", "Sun et al. (2021) Sun, Z., Wu, J., Li, X., Yang, W., and Xue, J.-H. Amortized bayesian prototype meta-learning: A new probabilistic meta-learning approach to few-shot image classification. In International Conference on Artificial Intelligence and Statistics, pp. 1414\u20131422. PMLR, 2021.": "Amortized Bayesian Prototype Meta-Learning: A New Probabilistic Meta-Learning Approach to Few-Shot Image Classification", "Gordon et al. (2018) Gordon, J., Bronskill, J., Bauer, M., Nowozin, S., and Turner, R. Meta-learning probabilistic inference for prediction. In International Conference on Learning Representations, 2018.": "Meta-learning probabilistic inference for prediction", "Snell & Zemel (2020) Snell, J. and Zemel, R. Bayesian few-shot classification with one-vs-each p\u00f3lya-gamma augmented gaussian processes. In International Conference on Learning Representations, 2020.": "Bayesian Few-Shot Classification with One-vs-Each P\u00f3lya-Gamma Augmented Gaussian Processes", "Mishra et al. (2018) Mishra, N., Rohaninejad, M., Chen, X., and Abbeel, P. A simple neural attentive meta-learner. In International Conference on Learning Representations, 2018.": "A Simple Neural Attentive Meta-Learner", "Grant et al. (2018) Grant, E., Finn, C., Levine, S., Darrell, T., and Griffiths, T. Recasting gradient-based meta-learning as hierarchical bayes. In International Conference on Learning Representations, 2018.": "Recasting Gradient-Based Meta-Learning as Hierarchical Bayes", "Wang et al. (2019) Wang, Y., Chao, W.-L., Weinberger, K. Q., and van der Maaten, L. Simpleshot: Revisiting nearest-neighbor classification for few-shot learning. arXiv preprint arXiv:1911.04623, 2019.": "Simpleshot: Revisiting nearest-neighbor classification for few-shot learning"}, "source_title_to_arxiv_id": {"Gaussian process meta few-shot classifier learning via linear discriminant Laplace approximation": "2111.05392", "Learning to learn variational semantic memory": "2010.10341"}}