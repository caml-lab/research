{"title": "PROB: Probabilistic Objectness for Open World Object Detection", "abstract": "Open World Object Detection (OWOD) is a new and challenging computer vision\ntask that bridges the gap between classic object detection (OD) benchmarks and\nobject detection in the real world. In addition to detecting and classifying\nseen/labeled objects, OWOD algorithms are expected to detect novel/unknown\nobjects - which can be classified and incrementally learned. In standard OD,\nobject proposals not overlapping with a labeled object are automatically\nclassified as background. Therefore, simply applying OD methods to OWOD fails\nas unknown objects would be predicted as background. The challenge of detecting\nunknown objects stems from the lack of supervision in distinguishing unknown\nobjects and background object proposals. Previous OWOD methods have attempted\nto overcome this issue by generating supervision using pseudo-labeling -\nhowever, unknown object detection has remained low. Probabilistic/generative\nmodels may provide a solution for this challenge. Herein, we introduce a novel\nprobabilistic framework for objectness estimation, where we alternate between\nprobability distribution estimation and objectness likelihood maximization of\nknown objects in the embedded feature space - ultimately allowing us to\nestimate the objectness probability of different proposals. The resulting\nProbabilistic Objectness transformer-based open-world detector, PROB,\nintegrates our framework into traditional object detection models, adapting\nthem for the open-world setting. Comprehensive experiments on OWOD benchmarks\nshow that PROB outperforms all existing OWOD methods in both unknown object\ndetection ($\\sim 2\\times$ unknown recall) and known object detection ($\\sim\n10\\%$ mAP). Our code will be made available upon publication at\nhttps://github.com/orrzohar/PROB.", "authors": ["Orr Zohar", "Kuan-Chieh Wang", "Serena Yeung"], "published_date": "2022_12_02", "pdf_url": "http://arxiv.org/pdf/2212.01424v1", "list_table_and_caption": [{"table": "<p>Task IDs (\\rightarrow)Task 1Task 2Task 3Task 4U-RecallmAP (\\uparrow)U-RecallmAP (\\uparrow)U-RecallmAP (\\uparrow)mAP (\\uparrow)(\\uparrow)Currentknown(\\uparrow)PreviouslyknownCurrentknownBoth(\\uparrow)PreviouslyknownCurrentknownBothPreviouslyknownCurrentknownBothORE* [11]4.956.02.952.726.039.43.938.212.729.729.612.425.3UC-OWOD [32]2.450.73.433.130.531.88.728.816.324.625.615.923.2OCPL [33]8.2656.67.6550.627.539.111.938.714.730.730.714.426.72B-OCD [31]12.156.49.451.625.338.511.637.213.229.230.013.325.8OW-DETR [9]7.559.26.253.633.542.95.738.315.830.831.417.127.8Ours: PROB19.459.517.455.732.244.019.643.022.236.035.718.931.5ORE* [11]1.561.43.956.526.140.63.638.723.733.733.626.331.8OW-DETR [9]5.771.56.262.827.543.86.945.224.938.538.228.133.1Ours: PROB17.673.422.366.336.050.424.847.830.442.042.631.739.9</p>", "caption": "Table 1: State-of-the-art comparison for OWOD on M-OWODB (top) and S-OWODB (bottom). The comparison is shown in terms of unknown class recall (U-Recall) and known class mAP@0.5 (for previously, currently, and all known objects).For a fair comparison in the OWOD setting, we compare with the recently introduced ORE [11] not employing EBUI (EBUI relies on a held-out set of unknown images, violating the OWOD objective, as shown in [36, 9]).PROB outperforms all existing OWOD models across all tasks both in terms of U-Recall and known mAP, indicating our models improved unknown and known detection capabilities.The smaller drops in mAP between \u201cPreviously known\u201d and \u201cCurrent known\u201d from the previous task exemplify that the exemplar selection improved our models\u2019 incremental learning performance.Note that since all 80 classes are known in Task 4, U-Recall is not computed. Only ORE and OW-DETR are compared in S-OWODB, as other methods have not reported results on this benchmark. See Sec. 5.1 for more details. ", "list_citation_info": ["[31] Yan Wu, Xiaowei Zhao, Yuqing Ma, Duorui Wang, and Xianglong Liu. Two-branch objectness-centric open world detection. In Proceedings of the 3rd International Workshop on Human-Centric Multimedia Analysis, HCMA \u201922, page 35\u201340, New York, NY, USA, 2022. Association for Computing Machinery.", "[11] K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Vineeth N Balasubramanian. Towards open world object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 5830\u20135840, June 2021.", "[32] Zhiheng Wu, Yue Lu, Xingyu Chen, Zhengxing Wu, Liwen Kang, and Junzhi Yu. Uc-owod: Unknown-classified open world object detection, 2022.", "[33] Jinan Yu, Liyan Ma, Zhenglin Li, Yan Peng, and Shaorong Xie. Open-world object detection via discriminative class prototype learning. In 2022 IEEE International Conference on Image Processing (ICIP), pages 626\u2013630. IEEE, 2022.", "[36] Xiaowei Zhao, Xianglong Liu, Yifan Shen, Yixuan Qiao, Yuqing Ma, and Duorui Wang. Revisiting open world object detection, 2022.", "[9] Akshita Gupta, Sanath Narayan, K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Mubarak Shah. Ow-detr: Open-world detection transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 9235\u20139244, June 2022."]}, {"table": "<p>Task IDs (\\rightarrow)Task 1Task 2Task 3Task 4U-RecallmAP (\\uparrow)U-RecallmAP (\\uparrow)U-RecallmAP (\\uparrow)mAP (\\uparrow)(\\uparrow)Currentknown(\\uparrow)PreviouslyknownCurrentknownBoth(\\uparrow)PreviouslyknownCurrentknownBothPreviouslyknownCurrentknownBothUpper Bound31.662.540.555.838.146.942.642.429.333.935.623.132.5D-DETR [37]-60.3-54.534.444.7-40.017.733.332.520.029.4PROB-Obj21.139.318.941.023.532.322.234.716.328.629.213.425.2PROB-IL19.459.515.954.732.243.518.442.620.735.334.717.430.4Final: PROB19.459.517.455.732.244.019.643.022.236.035.718.931.5</p>", "caption": "Table 2: Impact of progressively integrating our contributions into the baseline. The comparison is shown in terms of known class average precision (mAP) and unknown class recall (U-Recall) on M-OWODB. All models shown include a finetuning step to mitigate catastrophic forgetting.PROB-Obj is our model without objectness likelihood maximization.PROB-IL is our model without active exemplar selection.For context, we also include the performance of deformable DETR and an upper bound (D-DETR trained with ground-truth unknown class annotations) as reported by Gupta et al. [9]. As all classes are known in Task 4, U-Recall is not computed.", "list_citation_info": ["[9] Akshita Gupta, Sanath Narayan, K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Mubarak Shah. Ow-detr: Open-world detection transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 9235\u20139244, June 2022.", "[37] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai. Deformable detr: Deformable transformers for end-to-end object detection. In ICLR, 2021."]}, {"table": "<p>10 + 10 settingold classesnew classesfinal mAPILOD [26]63.263.263.2Faster ILOD [21]69.854.562.1ORE - EBUI [11]60.468.864.5OW-DETR[9]63.567.965.7Ours: PROB66.067.266.515 + 5 settingold classesnew classesfinal mAPILOD [26]68.358.465.8Faster ILOD [21]71.656.967.9ORE - EBUI [11]71.858.768.5OW-DETR [9]72.259.869.4Ours: PROB73.260.870.119 + 1 settingold classesnew classefinal mAPILOD [26]68.562.768.2Faster ILOD [21]68.961.168.5ORE - EBUI [11]69.460.168.8OW-DETR [9]70.262.070.2Ours: PROB73.948.572.6</p>", "caption": "Table 3: State-of-the-art comparison for incremental object detection (iOD) on PASCAL VOC.The comparison is shown in terms of new, old, and overall mAP. In each setting, the model is first trained on 10, 15 or 19 classes, and then the additional 10, 5, and 1 class(es) are introduced. PROB achieves favorable performance in comparison to existing approaches in all three settings. See Sec. 5.3 for additional details.", "list_citation_info": ["[11] K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Vineeth N Balasubramanian. Towards open world object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 5830\u20135840, June 2021.", "[21] Can Peng, Kun Zhao, and Brian C Lovell. Faster ilod: Incremental learning for object detectors based on faster rcnn. PRL, 2020.", "[9] Akshita Gupta, Sanath Narayan, K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Mubarak Shah. Ow-detr: Open-world detection transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 9235\u20139244, June 2022.", "[26] Konstantin Shmelkov, Cordelia Schmid, and Karteek Alahari. Incremental learning of object detectors without catastrophic forgetting. In ICCV, 2017."]}, {"table": "<p>Task IDs (\\rightarrow)Task 1Task 2Task 3U-RecallWIA-OSEU-RecallWIA-OSEU-RecallWIA-OSE(\\uparrow)(\\downarrow)(\\downarrow)(\\uparrow)(\\downarrow)(\\downarrow)(\\uparrow)(\\downarrow)(\\downarrow)ORE - EBUI  [11]4.90.0621104592.90.0282104453.90.021179902B-OCD  [31]12.10.0481-9.40.160-11.60.0137-OW-DETR [9]7.50.0571102406.20.027884415.70.01566803OCPL  [33]8.30.041356707.60.0220569011.90.01625166Ours: PROB19.40.0569519517.40.0344645219.60.01512641Ours: PROB(\\tau=0.5)19.30.0415142817.70.013356219.70.0082387</p>", "caption": "Table 4:  Uknown Object Confusion on M-OWODB. The comparison is shown in terms of wilderness impact (WI), absolute open set error (A-OSE) and unknown class recall (U-Recall). The unknown recall (U-Recall) metric quantifies a model\u2019s ability to retrieve the unknown object instances.PROB achieves improved WI, A-OSE and U-Recall over OW-DETR across tasks, thereby indicating less confusion in detecting unknown instances as known classes with higher unknown instance detection capabilities. See Sec. A.1 for additional details.", "list_citation_info": ["[11] K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Vineeth N Balasubramanian. Towards open world object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 5830\u20135840, June 2021.", "[9] Akshita Gupta, Sanath Narayan, K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Mubarak Shah. Ow-detr: Open-world detection transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 9235\u20139244, June 2022.", "[31] Yan Wu, Xiaowei Zhao, Yuqing Ma, Duorui Wang, and Xianglong Liu. Two-branch objectness-centric open world detection. In Proceedings of the 3rd International Workshop on Human-Centric Multimedia Analysis, HCMA \u201922, page 35\u201340, New York, NY, USA, 2022. Association for Computing Machinery.", "[33] Jinan Yu, Liyan Ma, Zhenglin Li, Yan Peng, and Shaorong Xie. Open-world object detection via discriminative class prototype learning. In 2022 IEEE International Conference on Image Processing (ICIP), pages 626\u2013630. IEEE, 2022."]}, {"table": "<p>10 + 10 settingaerocyclebirdboatbottlebuscarcatchaircowtabledoghorsebikepersonplantsheepsofatraintvmAPILOD [26]69.970.469.454.34868.778.968.445.558.159.772.773.573.266.329.563.461.669.362.263.2Faster ILOD [21]72.875.771.260.561.770.483.376.653.172.336.770.966.867.666.124.763.148.157.143.662.1ORE - (CC + EBUI) [11]53.369.262.451.852.973.683.771.742.866.846.859.965.566.168.629.855.151.665.351.559.4ORE - EBUI [11]63.570.958.942.934.176.280.776.334.166.156.170.480.272.381.842.771.668.17767.764.5OW-DETR[9]61.869.167.845.847.378.378.478.636.271.557.575.376.277.479.540.166.866.375.664.165.7Ours: PROB70.475.467.348.155.973.578.575.442.872.264.273.876.074.875.340.266.273.364.464.066.515 + 5 settingaerocyclebirdboatbottlebuscarcatchaircowtabledoghorsebikepersonplantsheepsofatraintvmAPILOD [26]70.579.268.859.153.275.479.478.846.659.45975.871.878.669.633.761.563.171.762.265.8Faster ILOD [21]66.578.171.854.661.468.482.682.752.174.363.178.680.578.480.436.761.759.367.959.167.9ORE - (CC + EBUI) [11]65.174.657.939.536.775.18073.337.169.848.86977.572.876.534.462.656.580.365.762.6ORE - EBUI [11]75.48167.151.955.777.285.681.746.176.255.476.786.278.582.132.863.654.777.764.668.5OW-DETR [9]77.176.569.251.361.379.884.281.049.779.658.179.083.167.885.433.265.162.073.965.069.4Ours: PROB77.977.077.556.763.975.085.582.350.078.563.175.880.078.377.238.469.857.173.764.970.119 + 1 settingaerocyclebirdboatbottlebuscarcatchaircowtabledoghorsebikepersonplantsheepsofatraintvmAPILOD [26]69.479.369.557.445.478.479.180.545.776.364.877.280.877.570.142.367.564.476.762.768.2Faster ILOD [21]64.274.773.255.553.770.882.982.651.679.758.778.881.875.377.443.173.861.769.861.168.5ORE - (CC + EBUI) [11]60.778.661.84543.275.182.575.542.475.156.772.980.875.477.737.872.364.570.749.964.9ORE - EBUI [11]67.376.86048.458.881.186.575.841.579.654.672.885.981.782.444.875.868.275.760.168.8OW-DETR [9]70.577.273.854.055.679.080.880.643.280.453.577.589.582.074.743.371.966.679.462.070.2Ours: PROB80.378.977.659.763.775.286.083.953.782.866.582.780.683.877.948.974.569.977.648.572.6</p>", "caption": "Table 5: State-of-the-art comparison for incremental object detection (iOD) on PASCAL VOC. We experiment on 3 different settings. The comparison is shown in terms of per-class AP and overall mAP. The 10, 5 and 1 class(es) in gray background are introduced to a detector trained on the remaining 10, 15 and 19 classes, respectively. PROB achieves favorable performance in comparison to existing OWOD approaches in all three settings. See Sec. A.2 for additional details.", "list_citation_info": ["[11] K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Vineeth N Balasubramanian. Towards open world object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 5830\u20135840, June 2021.", "[21] Can Peng, Kun Zhao, and Brian C Lovell. Faster ilod: Incremental learning for object detectors based on faster rcnn. PRL, 2020.", "[9] Akshita Gupta, Sanath Narayan, K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Mubarak Shah. Ow-detr: Open-world detection transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 9235\u20139244, June 2022.", "[26] Konstantin Shmelkov, Cordelia Schmid, and Karteek Alahari. Incremental learning of object detectors without catastrophic forgetting. In ICCV, 2017."]}], "citation_info_to_title": {"[32] Zhiheng Wu, Yue Lu, Xingyu Chen, Zhengxing Wu, Liwen Kang, and Junzhi Yu. Uc-owod: Unknown-classified open world object detection, 2022.": "Uc-owod: Unknown-classified open world object detection", "[33] Jinan Yu, Liyan Ma, Zhenglin Li, Yan Peng, and Shaorong Xie. Open-world object detection via discriminative class prototype learning. In 2022 IEEE International Conference on Image Processing (ICIP), pages 626\u2013630. IEEE, 2022.": "Open-world object detection via discriminative class prototype learning", "[31] Yan Wu, Xiaowei Zhao, Yuqing Ma, Duorui Wang, and Xianglong Liu. Two-branch objectness-centric open world detection. In Proceedings of the 3rd International Workshop on Human-Centric Multimedia Analysis, HCMA \u201922, page 35\u201340, New York, NY, USA, 2022. Association for Computing Machinery.": "Two-branch objectness-centric open world detection", "[37] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai. Deformable detr: Deformable transformers for end-to-end object detection. In ICLR, 2021.": "Deformable DETR: Deformable Transformers for End-to-End Object Detection", "[9] Akshita Gupta, Sanath Narayan, K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Mubarak Shah. Ow-detr: Open-world detection transformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 9235\u20139244, June 2022.": "Ow-detr: Open-world detection transformer", "[21] Can Peng, Kun Zhao, and Brian C Lovell. Faster ilod: Incremental learning for object detectors based on faster rcnn. PRL, 2020.": "Faster ilod: Incremental learning for object detectors based on faster rcnn", "[11] K J Joseph, Salman Khan, Fahad Shahbaz Khan, and Vineeth N Balasubramanian. Towards open world object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 5830\u20135840, June 2021.": "Towards open world object detection", "[36] Xiaowei Zhao, Xianglong Liu, Yifan Shen, Yixuan Qiao, Yuqing Ma, and Duorui Wang. Revisiting open world object detection, 2022.": "Revisiting open world object detection", "[26] Konstantin Shmelkov, Cordelia Schmid, and Karteek Alahari. Incremental learning of object detectors without catastrophic forgetting. In ICCV, 2017.": "Incremental learning of object detectors without catastrophic forgetting"}, "source_title_to_arxiv_id": {"Towards open world object detection": "2103.02603"}}