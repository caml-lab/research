{"title": "Point2Seq: Detecting 3D Objects as Sequences", "abstract": "We present a simple and effective framework, named Point2Seq, for 3D object\ndetection from point clouds. In contrast to previous methods that normally\n{predict attributes of 3D objects all at once}, we expressively model the\ninterdependencies between attributes of 3D objects, which in turn enables a\nbetter detection accuracy. Specifically, we view each 3D object as a sequence\nof words and reformulate the 3D object detection task as decoding words from 3D\nscenes in an auto-regressive manner. We further propose a lightweight\nscene-to-sequence decoder that can auto-regressively generate words conditioned\non features from a 3D scene as well as cues from the preceding words. The\npredicted words eventually constitute a set of sequences that completely\ndescribe the 3D objects in the scene, and all the predicted sequences are then\nautomatically assigned to the respective ground truths through similarity-based\nsequence matching. Our approach is conceptually intuitive and can be readily\nplugged upon most existing 3D-detection backbones without adding too much\ncomputational overhead; the sequential decoding paradigm we proposed, on the\nother hand, can better exploit information from complex 3D scenes with the aid\nof preceding predicted words. Without bells and whistles, our method\nsignificantly outperforms previous anchor- and center-based 3D object detection\nframeworks, yielding the new state of the art on the challenging ONCE dataset\nas well as the Waymo Open Dataset. Code is available at\n\\url{https://github.com/ocNflag/point2seq}.", "authors": ["Yujing Xue", "Jiageng Mao", "Minzhe Niu", "Hang Xu", "Michael Bi Mi", "Wei Zhang", "Xiaogang Wang", "Xinchao Wang"], "published_date": "2022_03_25", "pdf_url": "http://arxiv.org/pdf/2203.13394v1", "list_table_and_caption": [{"table": "<table><tbody><tr><th rowspan=\"2\">Method</th><td rowspan=\"2\">Backbone</td><td rowspan=\"2\">Head</td><td colspan=\"2\">Vehicle LEVEL 1</td><td colspan=\"2\">Vehicle LEVEL 2</td></tr><tr><td>3D mAP(%)</td><td>3D mAPH(%)</td><td>3D mAP(%)</td><td>3D mAPH(%)</td></tr><tr><th>LaserNet [20]</th><td>Range</td><td>Anchor</td><td>52.1</td><td>50.1</td><td>-</td><td>-</td></tr><tr><th>RCD [1]</th><td>Range</td><td>Center</td><td>69.0</td><td>68.5</td><td>-</td><td>-</td></tr><tr><th>RangeDet [8]</th><td>Range</td><td>Center</td><td>72.85</td><td>-</td><td>-</td><td>-</td></tr><tr><th>RSN [31]</th><td>Range</td><td>Center</td><td>75.1</td><td>74.6</td><td>66.0</td><td>65.6</td></tr><tr><th>PointPillars [13]</th><td>Pillar</td><td>Anchor</td><td>63.3</td><td>62.7</td><td>55.2</td><td>54.7</td></tr><tr><th>Pillar-OD [35]</th><td>Pillar</td><td>Anchor</td><td>69.8</td><td>-</td><td>-</td><td>-</td></tr><tr><th>MVF [43]</th><td>Voxel</td><td>Anchor</td><td>62.93</td><td>-</td><td>-</td><td>-</td></tr><tr><th>PV-RCNN [25]</th><td>Voxel</td><td>Anchor</td><td>77.51</td><td>76.89</td><td>68.98</td><td>68.41</td></tr><tr><th>VoTr-TSD [19]</th><td>Voxel</td><td>Anchor</td><td>74.95</td><td>74.25</td><td>65.91</td><td>65.29</td></tr><tr><th>Voxel R-CNN [6]</th><td>Voxel</td><td>Anchor</td><td>75.59</td><td>-</td><td>66.59</td><td>-</td></tr><tr><th>Pyramid-RCNN [16]</th><td>Voxel</td><td>Anchor</td><td>76.3</td><td>75.68</td><td>67.23</td><td>66.68</td></tr><tr><th>CT3D [24]</th><td>Voxel</td><td>Anchor</td><td>76.3</td><td>-</td><td>69.04</td><td>-</td></tr><tr><th>CVCNet [4]</th><td>Voxel</td><td>Center</td><td>65.20</td><td>-</td><td>-</td><td>-</td></tr><tr><th>AFDet [9]</th><td>Voxel</td><td>Center</td><td>63.69</td><td>-</td><td>-</td><td>-</td></tr><tr><th>CenterPoints [42]</th><td>Voxel</td><td>Center</td><td>76.7</td><td>76.2</td><td>68.8</td><td>68.3</td></tr><tr><th>SECOND{}^{{\\dagger}} [38]</th><td>Voxel</td><td>Anchor</td><td>73.62</td><td>73.14</td><td>64.86</td><td>64.40</td></tr><tr><th>CenterPoints{}^{{\\dagger}} [42]</th><td>Voxel</td><td>Center</td><td>75.58</td><td>75.01</td><td>67.00</td><td>66.52</td></tr><tr><th>Point2Seq (Ours)</th><td>Voxel</td><td>Sequence</td><td>77.52</td><td>77.03</td><td>68.80</td><td>68.36</td></tr></tbody></table>", "caption": "Table 1: Performance comparison on the Waymo Open Dataset with 202 validation sequences for vehicle detection. {\\dagger}: re-implemented using the official code. Point2Seq maintains the same backbone, data augmentations, and training epochs with the re-implemented baselines.", "list_citation_info": ["[25] Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li. Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10529\u201310538, 2020.", "[8] Lue Fan, Xuan Xiong, Feng Wang, Naiyan Wang, and Zhaoxiang Zhang. Rangedet: In defense of range view for lidar-based 3d object detection. arXiv preprint arXiv:2103.10039, 2021.", "[6] Jiajun Deng, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, and Houqiang Li. Voxel r-cnn: Towards high performance voxel-based 3d object detection. arXiv:2012.15712, 2020.", "[20] Gregory P. Meyer, Ankita Gajanan Laddha, Eric Kee, Carlos Vallespi-Gonzalez, and Carl K. Wellington. Lasernet: An efficient probabilistic 3d object detector for autonomous driving. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 12669\u201312678, 2019.", "[1] Alex Bewley, Pei Sun, Thomas Mensink, Dragomir Anguelov, and Cristian Sminchisescu. Range conditioned dilated convolutions for scale invariant 3d object detection. arXiv preprint arXiv:2005.09927, 2020.", "[38] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018.", "[43] Yin Zhou, Pei Sun, Yu Zhang, Dragomir Anguelov, Jiyang Gao, Tom Ouyang, James Guo, Jiquan Ngiam, and Vijay Vasudevan. End-to-end multi-view fusion for 3d object detection in lidar point clouds. In Conference on Robot Learning, pages 923\u2013932. PMLR, 2020.", "[19] Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang, Hang Xu, and Chunjing Xu. Voxel transformer for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3164\u20133173, 2021.", "[9] Runzhou Ge, Zhuangzhuang Ding, Yihan Hu, Yu Wang, Sijia Chen, Li Huang, and Yuan Li. Afdet: Anchor free one stage 3d object detection. arXiv preprint arXiv:2006.12671, 2020.", "[13] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019.", "[35] Yue Wang, Alireza Fathi, Abhijit Kundu, David A Ross, Caroline Pantofaru, Tom Funkhouser, and Justin Solomon. Pillar-based object detection for autonomous driving. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXII 16, pages 18\u201334. Springer, 2020.", "[31] Pei Sun, Weiyue Wang, Yuning Chai, Gamaleldin Elsayed, Alex Bewley, Xiao Zhang, Cristian Sminchisescu, and Dragomir Anguelov. Rsn: Range sparse net for efficient, accurate lidar 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5725\u20135734, 2021.", "[4] Qi Chen, Lin Sun, Ernest Cheung, and Alan L Yuille. Every view counts: Cross-view consistency in 3d object detection with hybrid-cylindrical-spherical voxelization. Advances in Neural Information Processing Systems, 2020.", "[16] Jiageng Mao, Minzhe Niu, Haoyue Bai, Xiaodan Liang, Hang Xu, and Chunjing Xu. Pyramid r-cnn: Towards better performance and adaptability for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2723\u20132732, 2021.", "[42] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11784\u201311793, 2021.", "[24] Hualian Sheng, Sijia Cai, Yuan Liu, Bing Deng, Jianqiang Huang, Xian-Sheng Hua, and Min-Jian Zhao. Improving 3d object detection with channel-wise transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 2743\u20132752, October 2021."]}, {"table": "<table><thead><tr><th rowspan=\"2\">Method</th><th rowspan=\"2\">mAP(%)</th><th colspan=\"4\">Vehicle mAP(%)</th><th colspan=\"4\">Pedestrian mAP(%)</th><th colspan=\"4\">Cyclist mAP(%)</th></tr><tr><th>overall</th><th>0-30m</th><th>30-50m</th><th>50m-inf</th><th>overall</th><th>0-30m</th><th>30-50m</th><th>50m-inf</th><th>overall</th><th>0-30m</th><th>30-50m</th><th>50m-inf</th></tr></thead><tbody><tr><th>PointRCNN [25]</th><th>28.74</th><td>52.09</td><td>74.45</td><td>40.89</td><td>16.81</td><td>4.28</td><td>6.17</td><td>2.4</td><td>0.91</td><td>29.84</td><td>46.03</td><td>20.94</td><td>5.46</td></tr><tr><th>PointPillars [13]</th><th>44.34</th><td>68.57</td><td>80.86</td><td>62.07</td><td>47.04</td><td>17.63</td><td>19.74</td><td>15.15</td><td>10.23</td><td>46.81</td><td>58.33</td><td>40.32</td><td>25.86</td></tr><tr><th>PV-RCNN [25]</th><th>53.55</th><td>77.77</td><td>89.39</td><td>72.55</td><td>58.64</td><td>23.50</td><td>25.61</td><td>22.84</td><td>17.27</td><td>59.37</td><td>71.66</td><td>52.58</td><td>36.17</td></tr><tr><th>SECOND [38]</th><th>51.89</th><td>71.19</td><td>84.04</td><td>63.02</td><td>47.25</td><td>26.44</td><td>29.33</td><td>24.05</td><td>18.05</td><td>58.04</td><td>69.96</td><td>52.43</td><td>34.61</td></tr><tr><th>CenterPoints [42]</th><th>60.05</th><td>66.79</td><td>80.10</td><td>59.55</td><td>43.39</td><td>49.90</td><td>56.24</td><td>42.61</td><td>26.27</td><td>63.45</td><td>74.28</td><td>57.94</td><td>41.48</td></tr><tr><th>Point2Seq (Ours)</th><th>66.16</th><td>73.43</td><td>85.16</td><td>66.21</td><td>50.76</td><td>57.53</td><td>68.21</td><td>47.15</td><td>25.18</td><td>67.53</td><td>77.95</td><td>62.14</td><td>46.06</td></tr></tbody></table>", "caption": "Table 2: Performance comparison on the ONCE dataset validation split. Point2Seq maintains the same backbone architecture and training configurations with the baselines on the ONCE benchmark.", "list_citation_info": ["[42] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11784\u201311793, 2021.", "[38] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018.", "[25] Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li. Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10529\u201310538, 2020.", "[13] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019."]}, {"table": "<table><tbody><tr><td rowspan=\"2\">Method</td><td>Vehicle</td><td rowspan=\"2\">#Param</td><td rowspan=\"2\">Latency (ms)</td></tr><tr><td>L1/L2 mAP(%)</td></tr><tr><td>PV-RCNN [25]</td><td>77.51/68.98</td><td>13.05M</td><td>300</td></tr><tr><td>CenterPoints [42]</td><td>76.7/68.8</td><td>8.74M</td><td>77</td></tr><tr><td>SECOND{}^{{\\dagger}} [38]</td><td>73.62/64.86</td><td>7.28M</td><td>66.5</td></tr><tr><td>CenterPoints{}^{{\\dagger}} [42]</td><td>75.58/67.00</td><td>7.76M</td><td>69.5</td></tr><tr><td>Point2Seq{}^{{\\dagger}} (Ours)</td><td>77.52/68.80</td><td>7.86M</td><td>70.4</td></tr></tbody></table>", "caption": "Table 3: Inference speed and parameters amount. {\\dagger}: tested under the same environment using a single model on a V100 GPU.", "list_citation_info": ["[38] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018.", "[25] Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li. Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10529\u201310538, 2020.", "[42] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11784\u201311793, 2021."]}], "citation_info_to_title": {"[8] Lue Fan, Xuan Xiong, Feng Wang, Naiyan Wang, and Zhaoxiang Zhang. Rangedet: In defense of range view for lidar-based 3d object detection. arXiv preprint arXiv:2103.10039, 2021.": "Rangedet: In defense of range view for lidar-based 3d object detection", "[20] Gregory P. Meyer, Ankita Gajanan Laddha, Eric Kee, Carlos Vallespi-Gonzalez, and Carl K. Wellington. Lasernet: An efficient probabilistic 3d object detector for autonomous driving. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 12669\u201312678, 2019.": "Lasernet: An efficient probabilistic 3d object detector for autonomous driving", "[31] Pei Sun, Weiyue Wang, Yuning Chai, Gamaleldin Elsayed, Alex Bewley, Xiao Zhang, Cristian Sminchisescu, and Dragomir Anguelov. Rsn: Range sparse net for efficient, accurate lidar 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5725\u20135734, 2021.": "RSN: Range Sparse Net for Efficient, Accurate LiDAR 3D Object Detection", "[42] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11784\u201311793, 2021.": "Center-based 3d object detection and tracking", "[4] Qi Chen, Lin Sun, Ernest Cheung, and Alan L Yuille. Every view counts: Cross-view consistency in 3d object detection with hybrid-cylindrical-spherical voxelization. Advances in Neural Information Processing Systems, 2020.": "Every view counts: Cross-view consistency in 3d object detection with hybrid-cylindrical-spherical voxelization", "[13] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019.": "Pointpillars: Fast Encoders for Object Detection from Point Clouds", "[25] Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li. Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10529\u201310538, 2020.": "Pv-rcnn: Point-voxel feature set abstraction for 3d object detection", "[38] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018.": "Second: Sparsely embedded convolutional detection", "[19] Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang, Hang Xu, and Chunjing Xu. Voxel transformer for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3164\u20133173, 2021.": "Voxel Transformer for 3D Object Detection", "[6] Jiajun Deng, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, and Houqiang Li. Voxel r-cnn: Towards high performance voxel-based 3d object detection. arXiv:2012.15712, 2020.": "Voxel R-CNN: Towards High Performance Voxel-Based 3D Object Detection", "[9] Runzhou Ge, Zhuangzhuang Ding, Yihan Hu, Yu Wang, Sijia Chen, Li Huang, and Yuan Li. Afdet: Anchor free one stage 3d object detection. arXiv preprint arXiv:2006.12671, 2020.": "Afdet: Anchor free one stage 3d object detection", "[35] Yue Wang, Alireza Fathi, Abhijit Kundu, David A Ross, Caroline Pantofaru, Tom Funkhouser, and Justin Solomon. Pillar-based object detection for autonomous driving. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXII 16, pages 18\u201334. Springer, 2020.": "Pillar-based object detection for autonomous driving", "[1] Alex Bewley, Pei Sun, Thomas Mensink, Dragomir Anguelov, and Cristian Sminchisescu. Range conditioned dilated convolutions for scale invariant 3d object detection. arXiv preprint arXiv:2005.09927, 2020.": "Range Conditioned Dilated Convolutions for Scale Invariant 3D Object Detection", "[43] Yin Zhou, Pei Sun, Yu Zhang, Dragomir Anguelov, Jiyang Gao, Tom Ouyang, James Guo, Jiquan Ngiam, and Vijay Vasudevan. End-to-end multi-view fusion for 3d object detection in lidar point clouds. In Conference on Robot Learning, pages 923\u2013932. PMLR, 2020.": "End-to-end multi-view fusion for 3d object detection in lidar point clouds", "[16] Jiageng Mao, Minzhe Niu, Haoyue Bai, Xiaodan Liang, Hang Xu, and Chunjing Xu. Pyramid r-cnn: Towards better performance and adaptability for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2723\u20132732, 2021.": "Pyramid R-CNN: Towards Better Performance and Adaptability for 3D Object Detection", "[24] Hualian Sheng, Sijia Cai, Yuan Liu, Bing Deng, Jianqiang Huang, Xian-Sheng Hua, and Min-Jian Zhao. Improving 3d object detection with channel-wise transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 2743\u20132752, October 2021.": "Improving 3D Object Detection with Channel-wise Transformer"}, "source_title_to_arxiv_id": {"Lasernet: An efficient probabilistic 3d object detector for autonomous driving": "1903.08701", "Improving 3D Object Detection with Channel-wise Transformer": "2108.10723"}}