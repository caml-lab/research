{"title": "muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems", "abstract": "Most uses of machine learning today involve training a model from scratch for\na particular task, or sometimes starting with a model pretrained on a related\ntask and then fine-tuning on a downstream task. Both approaches offer limited\nknowledge transfer between different tasks, time-consuming human-driven\ncustomization to individual tasks and high computational costs especially when\nstarting from randomly initialized models. We propose a method that uses the\nlayers of a pretrained deep neural network as building blocks to construct an\nML system that can jointly solve an arbitrary number of tasks. The resulting\nsystem can leverage cross tasks knowledge transfer, while being immune from\ncommon drawbacks of multitask approaches such as catastrophic forgetting,\ngradients interference and negative transfer. We define an evolutionary\napproach designed to jointly select the prior knowledge relevant for each task,\nchoose the subset of the model parameters to train and dynamically auto-tune\nits hyperparameters. Furthermore, a novel scale control method is employed to\nachieve quality/size trade-offs that outperform common fine-tuning techniques.\nCompared with standard fine-tuning on a benchmark of 10 diverse image\nclassification tasks, the proposed model improves the average accuracy by 2.39%\nwhile using 47% less parameters per task.", "authors": ["Andrea Gesmundo", "Jeff Dean"], "published_date": "2022_05_22", "pdf_url": "http://arxiv.org/pdf/2205.10937v2", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Name</td><td>Reference</td><td>License</td></tr><tr><td colspan=\"3\">Multitask Character Classification Benchmark</td></tr><tr><td>emnist/digits</td><td>(Cohen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>emnist/letters</td><td>(Cohen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>kmnist</td><td>(Clanuwat et al., 2018)</td><td>Attribution-ShareAlike 4.0 International</td></tr><tr><td>mnist</td><td>(LeCun et al., 1998)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>omniglot</td><td>(Lake et al., 2015)</td><td>The MIT License</td></tr><tr><td>cmaterdb/bangla</td><td>(Das et al., 2012b, a)</td><td>Apache License 2.0</td></tr><tr><td>cmaterdb/devanagari</td><td>(Das et al., 2012b, a)</td><td>Apache License 2.0</td></tr><tr><td>cmaterdb/telugu</td><td>(Das et al., 2012b, a)</td><td>Apache License 2.0</td></tr><tr><td colspan=\"3\">Visual Domain Decathlon Benchmark</td></tr><tr><td>aircraft</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>cifar100</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>daimlerpedcls</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>dtd</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>gtsrb</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>imagenet12</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>omniglot</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>svhn</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>ucf101</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr><tr><td>vgg-flowers</td><td>(Bilen et al., 2017)</td><td>Creative Commons Attribution 4.0 License</td></tr></tbody></table>", "caption": "Table 5: Datasets reference and license.", "list_citation_info": ["Lake et al. [2015] B. M. Lake, R. Salakhutdinov, and J. B. Tenenbaum. Human-level concept learning through probabilistic program induction. Science, 350:1332 \u2013 1338, 2015.", "LeCun et al. [1998] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proc. IEEE, 86:2278\u20132324, 1998.", "Bilen et al. [2017] H. Bilen, S. Rebuffi, and T. Jakab. Visual domain decathlon. 2017.", "Cohen et al. [2017] G. Cohen, S. Afshar, J. C. Tapson, and A. van Schaik. Emnist: Extending mnist to handwritten letters. 2017 International Joint Conference on Neural Networks (IJCNN), pages 2921\u20132926, 2017.", "Das et al. [2012b] N. Das, R. Sarkar, S. Basu, M. Kundu, M. Nasipuri, and D. K. Basu. A genetic algorithm based region sampling for selection of local features in handwritten digit recognition application. Appl. Soft Comput., 12:1592\u20131606, 2012b.", "Clanuwat et al. [2018] T. Clanuwat, M. Bober-Irizar, A. Kitamoto, A. Lamb, K. Yamamoto, and D. Ha. Deep learning for classical japanese literature. ArXiv, abs/1812.01718, 2018."]}], "citation_info_to_title": {"Das et al. [2012b] N. Das, R. Sarkar, S. Basu, M. Kundu, M. Nasipuri, and D. K. Basu. A genetic algorithm based region sampling for selection of local features in handwritten digit recognition application. Appl. Soft Comput., 12:1592\u20131606, 2012b.": "A genetic algorithm based region sampling for selection of local features in handwritten digit recognition application", "Bilen et al. [2017] H. Bilen, S. Rebuffi, and T. Jakab. Visual domain decathlon. 2017.": "Visual Domain Decathlon", "Lake et al. [2015] B. M. Lake, R. Salakhutdinov, and J. B. Tenenbaum. Human-level concept learning through probabilistic program induction. Science, 350:1332 \u2013 1338, 2015.": "Human-level concept learning through probabilistic program induction", "LeCun et al. [1998] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proc. IEEE, 86:2278\u20132324, 1998.": "Gradient-based learning applied to document recognition", "Clanuwat et al. [2018] T. Clanuwat, M. Bober-Irizar, A. Kitamoto, A. Lamb, K. Yamamoto, and D. Ha. Deep learning for classical japanese literature. ArXiv, abs/1812.01718, 2018.": "Deep learning for classical Japanese literature", "Cohen et al. [2017] G. Cohen, S. Afshar, J. C. Tapson, and A. van Schaik. Emnist: Extending mnist to handwritten letters. 2017 International Joint Conference on Neural Networks (IJCNN), pages 2921\u20132926, 2017.": "Emnist: Extending mnist to handwritten letters"}, "source_title_to_arxiv_id": {"Deep learning for classical Japanese literature": "1812.01718"}}