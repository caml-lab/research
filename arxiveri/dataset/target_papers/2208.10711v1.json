{"title": "A Constrained Deformable Convolutional Network for Efficient Single Image Dynamic Scene Blind Deblurring with Spatially-Variant Motion Blur Kernels Estimation", "abstract": "Most existing deep-learning-based single image dynamic scene blind deblurring\n(SIDSBD) methods usually design deep networks to directly remove the\nspatially-variant motion blurs from one inputted motion blurred image, without\nblur kernels estimation. In this paper, inspired by the Projective Motion Path\nBlur (PMPB) model and deformable convolution, we propose a novel constrained\ndeformable convolutional network (CDCN) for efficient single image dynamic\nscene blind deblurring, which simultaneously achieves accurate\nspatially-variant motion blur kernels estimation and the high-quality image\nrestoration from only one observed motion blurred image. In our proposed CDCN,\nwe first construct a novel multi-scale multi-level multi-input multi-output\n(MSML-MIMO) encoder-decoder architecture for more powerful features extraction\nability. Second, different from the DLVBD methods that use multiple consecutive\nframes, a novel constrained deformable convolution reblurring (CDCR) strategy\nis proposed, in which the deformable convolution is first applied to blurred\nfeatures of the inputted single motion blurred image for learning the sampling\npoints of motion blur kernel of each pixel, which is similar to the estimation\nof the motion density function of the camera shake in the PMPB model, and then\na novel PMPB-based reblurring loss function is proposed to constrain the\nlearned sampling points convergence, which can make the learned sampling points\nmatch with the relative motion trajectory of each pixel better and promote the\naccuracy of the spatially-variant motion blur kernels estimation.", "authors": ["Shu Tang", "Yang Wu", "Hongxing Qin", "Xianzhong Xie", "Shuli Yang", "Jing Wang"], "published_date": "2022_08_23", "pdf_url": "http://arxiv.org/pdf/2208.10711v1", "list_table_and_caption": [{"table": "<table><tbody><tr><td rowspan=\"2\">Method</td><td colspan=\"2\">GOPRO</td><td colspan=\"2\">HIDE</td></tr><tr><td>PSNR</td><td>SSIM</td><td>PSNR</td><td>SSIM</td></tr><tr><td>Xu et al.[5]</td><td>21.00</td><td>0.741</td><td>-</td><td>-</td></tr><tr><td>DeblurGAN[15]</td><td>28.70</td><td>0.858</td><td>24.51</td><td>0.871</td></tr><tr><td>Nah et al.[14]</td><td>29.08</td><td>0.914</td><td>25.73</td><td>0.874</td></tr><tr><td>Zhang et al.[17]</td><td>29.19</td><td>0.931</td><td>-</td><td>-</td></tr><tr><td>DeblurGAN-v2[46]</td><td>29.55</td><td>0.934</td><td>26.61</td><td>0.875</td></tr><tr><td>SRN[16]</td><td>30.26</td><td>0.934</td><td>28.36</td><td>0.915</td></tr><tr><td>Gao et al.[19]</td><td>30.90</td><td>0.935</td><td>29.11</td><td>0.913</td></tr><tr><td>DBGAN[29]</td><td>31.10</td><td>0.942</td><td>28.94</td><td>0.915</td></tr><tr><td>MT-RNN[30]</td><td>31.15</td><td>0.945</td><td>29.15</td><td>0.918</td></tr><tr><td>DMPHN[18]</td><td>31.20</td><td>0.940</td><td>29.09</td><td>0.924</td></tr><tr><td>MSCAN[27]</td><td>31.24</td><td>0.945</td><td>29.63</td><td>0.921</td></tr><tr><td>Suin et al.[31]</td><td>31.85</td><td>0.948</td><td>29.98</td><td>0.930</td></tr><tr><td>SPAIR[24]</td><td>32.06</td><td>0.953</td><td>30.29</td><td>0.931</td></tr><tr><td>MIMO-UNet+[23]</td><td>32.45</td><td>0.957</td><td>29.99</td><td>0.930</td></tr><tr><td>CDCN</td><td>32.59</td><td>0.958</td><td>30.55</td><td>0.935</td></tr></tbody></table>", "caption": "TABLE II: ALL THE MODELS. ALL MODELS ARE TRAINED ONLY ON THE GOPRO[14] TRAINING IMAGE PAIRS AND DIRECTLY APPLIED TO THE HIDE[44] TESTING DATASETS.", "list_citation_info": ["[16] X. Tao, H. Gao, X. Shen, J. Wang, and J. Jia, \u201cScale-recurrent network for deep image deblurring,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8174\u20138182.", "[15] O. Kupyn, V. Budzan, M. Mykhailych, D. Mishkin, and J. Matas, \u201cDeblurgan: Blind motion deblurring using conditional adversarial networks,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8183\u20138192.", "[30] D. Park, D. U. Kang, J. Kim, and S. Y. Chun, \u201cMulti-temporal recurrent neural networks for progressive non-uniform single image deblurring with incremental temporal training,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 327\u2013343.", "[27] S. Wan, S. Tang, X. Xie, J. Gu, R. Huang, B. Ma, and L. Luo, \u201cDeep convolutional-neural-network-based channel attention for single image dynamic scene blind deblurring,\u201d IEEE Transactions on Circuits and Systems for Video Technology, vol. 31, no. 8, pp. 2994\u20133009, 2021.", "[14] S. Nah, T. Hyun Kim, and K. Mu Lee, \u201cDeep multi-scale convolutional neural network for dynamic scene deblurring,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 3883\u20133891.", "[29] K. Zhang, W. Luo, Y. Zhong, L. Ma, B. Stenger, W. Liu, and H. Li, \u201cDeblurring by realistic blurring,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 2737\u20132746.", "[17] J. Zhang, J. Pan, J. Ren, Y. Song, L. Bao, R. W. Lau, and M.-H. Yang, \u201cDynamic scene deblurring using spatially variant recurrent neural networks,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 2521\u20132529.", "[18] H. Zhang, Y. Dai, H. Li, and P. Koniusz, \u201cDeep stacked hierarchical multi-patch network for image deblurring,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 5978\u20135986.", "[5] L. Xu, S. Zheng, and J. Jia, \u201cUnnatural l0 sparse representation for natural image deblurring,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2013, pp. 1107\u20131114.", "[19] H. Gao, X. Tao, X. Shen, and J. Jia, \u201cDynamic scene deblurring with parameter selective sharing and nested skip connections,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 3848\u20133856.", "[31] M. Suin, K. Purohit, and A. Rajagopalan, \u201cSpatially-attentive patch-hierarchical network for adaptive motion deblurring,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 3606\u20133615.", "[44] Z. Shen, W. Wang, J. Shen, H. Ling, T. Xu, and L. Shao, \u201cHuman-aware motion deblurring,\u201d in IEEE International Conference on Computer Vision, 2019.", "[23] S.-J. Cho, S.-W. Ji, J.-P. Hong, S.-W. Jung, and S.-J. Ko, \u201cRethinking coarse-to-fine approach in single image deblurring,\u201d in Proceedings of the IEEE/CVF international conference on computer vision, 2021, pp. 4641\u20134650.", "[46] O. Kupyn, T. Martyniuk, J. Wu, and Z. Wang, \u201cDeblurgan-v2: Deblurring (orders-of-magnitude) faster and better,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019, pp. 8878\u20138887.", "[24] K. Purohit, M. Suin, A. Rajagopalan, and V. N. Boddeti, \u201cSpatially-adaptive image restoration using distortion-guided networks,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 2309\u20132319."]}], "citation_info_to_title": {"[14] S. Nah, T. Hyun Kim, and K. Mu Lee, \u201cDeep multi-scale convolutional neural network for dynamic scene deblurring,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 3883\u20133891.": "Deep multi-scale convolutional neural network for dynamic scene deblurring", "[5] L. Xu, S. Zheng, and J. Jia, \u201cUnnatural l0 sparse representation for natural image deblurring,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2013, pp. 1107\u20131114.": "Unnatural l0 sparse representation for natural image deblurring", "[18] H. Zhang, Y. Dai, H. Li, and P. Koniusz, \u201cDeep stacked hierarchical multi-patch network for image deblurring,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 5978\u20135986.": "Deep stacked hierarchical multi-patch network for image deblurring", "[46] O. Kupyn, T. Martyniuk, J. Wu, and Z. Wang, \u201cDeblurgan-v2: Deblurring (orders-of-magnitude) faster and better,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019, pp. 8878\u20138887.": "Deblurgan-v2: Deblurring (orders-of-magnitude) faster and better", "[24] K. Purohit, M. Suin, A. Rajagopalan, and V. N. Boddeti, \u201cSpatially-adaptive image restoration using distortion-guided networks,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 2309\u20132319.": "Spatially-adaptive image restoration using distortion-guided networks", "[30] D. Park, D. U. Kang, J. Kim, and S. Y. Chun, \u201cMulti-temporal recurrent neural networks for progressive non-uniform single image deblurring with incremental temporal training,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 327\u2013343.": "Multi-temporal recurrent neural networks for progressive non-uniform single image deblurring with incremental temporal training", "[19] H. Gao, X. Tao, X. Shen, and J. Jia, \u201cDynamic scene deblurring with parameter selective sharing and nested skip connections,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 3848\u20133856.": "Dynamic Scene Deblurring with Parameter Selective Sharing and Nested Skip Connections", "[15] O. Kupyn, V. Budzan, M. Mykhailych, D. Mishkin, and J. Matas, \u201cDeblurgan: Blind motion deblurring using conditional adversarial networks,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8183\u20138192.": "Deblurgan: Blind motion deblurring using conditional adversarial networks", "[23] S.-J. Cho, S.-W. Ji, J.-P. Hong, S.-W. Jung, and S.-J. Ko, \u201cRethinking coarse-to-fine approach in single image deblurring,\u201d in Proceedings of the IEEE/CVF international conference on computer vision, 2021, pp. 4641\u20134650.": "Rethinking coarse-to-fine approach in single image deblurring", "[17] J. Zhang, J. Pan, J. Ren, Y. Song, L. Bao, R. W. Lau, and M.-H. Yang, \u201cDynamic scene deblurring using spatially variant recurrent neural networks,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 2521\u20132529.": "Dynamic scene deblurring using spatially variant recurrent neural networks", "[29] K. Zhang, W. Luo, Y. Zhong, L. Ma, B. Stenger, W. Liu, and H. Li, \u201cDeblurring by realistic blurring,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 2737\u20132746.": "Deblurring by realistic blurring", "[27] S. Wan, S. Tang, X. Xie, J. Gu, R. Huang, B. Ma, and L. Luo, \u201cDeep convolutional-neural-network-based channel attention for single image dynamic scene blind deblurring,\u201d IEEE Transactions on Circuits and Systems for Video Technology, vol. 31, no. 8, pp. 2994\u20133009, 2021.": "Deep Convolutional-Neural-Network-Based Channel Attention for Single Image Dynamic Scene Blind Deblurring", "[16] X. Tao, H. Gao, X. Shen, J. Wang, and J. Jia, \u201cScale-recurrent network for deep image deblurring,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 8174\u20138182.": "Scale-recurrent network for deep image deblurring", "[31] M. Suin, K. Purohit, and A. Rajagopalan, \u201cSpatially-attentive patch-hierarchical network for adaptive motion deblurring,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 3606\u20133615.": "Spatially-attentive patch-hierarchical network for adaptive motion deblurring", "[44] Z. Shen, W. Wang, J. Shen, H. Ling, T. Xu, and L. Shao, \u201cHuman-aware motion deblurring,\u201d in IEEE International Conference on Computer Vision, 2019.": "Human-aware motion deblurring"}, "source_title_to_arxiv_id": {"Spatially-adaptive image restoration using distortion-guided networks": "2108.08617"}}