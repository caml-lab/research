{"title": "Audio-Visual Object Classification for Human-Robot Collaboration", "abstract": "Human-robot collaboration requires the contactless estimation of the physical\nproperties of containers manipulated by a person, for example while pouring\ncontent in a cup or moving a food box. Acoustic and visual signals can be used\nto estimate the physical properties of such objects, which may vary\nsubstantially in shape, material and size, and also be occluded by the hands of\nthe person. To facilitate comparisons and stimulate progress in solving this\nproblem, we present the CORSMAL challenge and a dataset to assess the\nperformance of the algorithms through a set of well-defined performance scores.\nThe tasks of the challenge are the estimation of the mass, capacity, and\ndimensions of the object (container), and the classification of the type and\namount of its content. A novel feature of the challenge is our\nreal-to-simulation framework for visualising and assessing the impact of\nestimation errors in human-to-robot handovers.", "authors": ["A. Xompero", "Y. L. Pang", "T. Patten", "A. Prabhakar", "B. Calli", "A. Cavallaro"], "published_date": "2022_03_03", "pdf_url": "http://arxiv.org/pdf/2203.01977v1", "list_table_and_caption": [{"table": "<table><tbody><tr><td>T1</td><td>T2</td><td>T3</td><td>T4</td><td>T5</td><td>Description</td><td>Unit</td><td>Measure</td><td>Score</td><td>Weight</td><td>Type</td><td>R2S</td><td>RAN</td><td>AVG</td><td>[14]</td><td>[15]</td><td>[16]</td><td>[17]</td><td>[18]</td><td>[19]</td><td>[20]</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Filling level</td><td></td><td>\\lambda^{j}</td><td>s_{1}=\\bar{F}_{1}(\\lambda^{1},\\ldots,\\lambda^{J},\\hat{\\lambda}^{1},\\ldots,\\hat{\\lambda}^{J})</td><td>\\pi_{1}=1/8</td><td>D</td><td><svg><g><path></path></g></svg></td><td>37.62</td><td>33.15</td><td>80.84</td><td>43.53</td><td>78.56</td><td>79.65</td><td>\u2013</td><td>65.73</td><td>77.40</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Filling type</td><td></td><td>\\tau^{j}</td><td>s_{2}=\\bar{F}_{1}(\\tau^{1},\\ldots,\\tau^{J},\\hat{\\tau}^{1},\\ldots,\\hat{\\tau}^{J})</td><td>\\pi_{2}=1/8</td><td>D</td><td><svg><g><path></path></g></svg></td><td>24.38</td><td>23.01</td><td>94.50</td><td>41.83</td><td>96.95</td><td>94.26</td><td>\u2013</td><td>80.72</td><td>99.13</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Capacity</td><td>mL</td><td>\\gamma^{j}</td><td>s_{3}=\\frac{1}{J}\\sum_{j=1}^{J}\\mathds{1}_{j}e^{-\\varepsilon^{j}(\\gamma^{j},\\hat{\\gamma}^{j})}</td><td>\\pi_{3}=1/8</td><td>D</td><td><svg><g><path></path></g></svg></td><td>24.58</td><td>40.73</td><td>\u2013</td><td>62.57</td><td>54.79</td><td>60.57</td><td>\u2013</td><td>72.26</td><td>59.51</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Container mass</td><td>g</td><td>m_{c}^{j}</td><td>s_{4}=\\frac{1}{J}\\sum_{j=1}^{J}\\mathds{1}_{j}e^{-\\varepsilon^{j}(m_{c}^{j},\\hat{m}_{c}^{j})}</td><td>\\pi_{4}=1/8</td><td>D</td><td><svg><g><path></path></g></svg></td><td>29.42</td><td>22.06</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>49.64</td><td>40.19</td><td>58.78</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Width at top</td><td>mm</td><td>w_{t}^{j}</td><td>s_{5}=\\frac{1}{J}\\sum_{j=1}^{J}{\\mathds{1}_{j}\\sigma_{1}(w_{t}^{j},\\hat{w_{t}}^{j})}</td><td>\\pi_{5}=1/24</td><td>D</td><td><svg><g><path></path></g></svg></td><td>32.33</td><td>76.89</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>69.09</td><td>80.01</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Width at bottom</td><td>mm</td><td>w_{b}^{j}</td><td>s_{6}=\\frac{1}{J}\\sum_{j=1}^{J}{\\mathds{1}_{j}\\sigma_{1}(w_{b}^{j},\\hat{w_{b}}^{j})}</td><td>\\pi_{6}=1/24</td><td>D</td><td><svg><g><path></path></g></svg></td><td>25.36</td><td>58.19</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>59.74</td><td>76.09</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Height</td><td>mm</td><td>h^{j}</td><td>s_{7}=\\frac{1}{J}\\sum_{j=1}^{J}{\\mathds{1}_{j}\\sigma_{1}(h^{j},\\hat{h}^{j})}</td><td>\\pi_{7}=1/24</td><td>D</td><td><svg><g><path></path></g></svg></td><td>42.48</td><td>64.32</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>70.07</td><td>74.33</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Filling mass</td><td>g</td><td>m_{f}^{j}</td><td>s_{8}=\\frac{1}{J}\\sum_{j=1}^{J}\\mathds{1}_{j}e^{-\\epsilon^{j}(m_{f}^{j},\\hat{m}_{f}^{j})}</td><td>\\pi_{8}=1/8*</td><td>I</td><td><svg><g><path></path></g></svg></td><td>35.06</td><td>42.31</td><td>25.07</td><td>53.47</td><td>62.16</td><td>65.06</td><td>\u2013</td><td>70.50</td><td>65.25</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Object mass</td><td>g</td><td>m^{j}</td><td>s_{9}=\\frac{1}{J}\\sum_{j=1}^{J}{\\mathds{1}_{j}\\psi^{j}(m^{j},\\hat{F}^{j})}</td><td>\\pi_{9}=1/8*</td><td>I</td><td><svg><g><path></path></g></svg></td><td>56.31</td><td>58.30</td><td>55.22</td><td>64.13</td><td>66.84</td><td>65.04</td><td>53.54</td><td>60.41</td><td>71.19</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Pose at delivery</td><td>(mm, {}^{\\circ})</td><td>(\\alpha^{j},\\beta^{j})</td><td>s_{10}=\\frac{1}{J}\\sum_{j=1}^{J}{\\Delta_{j}(\\alpha^{j},\\beta^{j},\\eta,\\phi)}</td><td>\\pi_{10}=1/8*</td><td>I</td><td><svg><g><path></path></g></svg></td><td>72.11</td><td>70.01</td><td>73.94</td><td>78.76</td><td>72.91</td><td>80.40</td><td>60.54</td><td>73.17</td><td>79.32</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td colspan=\"3\">Joint filling type and level</td><td>s_{11}=\\bar{F}_{1}(\\lambda^{1},\\tau^{1},\\ldots,\\hat{\\lambda}^{1},\\hat{\\tau}^{1},\\ldots)</td><td>\u2013</td><td>D</td><td><svg><g><path></path></g></svg></td><td>10.49</td><td>8.88</td><td>77.15</td><td>24.32</td><td>77.81</td><td>76.45</td><td>\u2013</td><td>59.32</td><td>78.16</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td colspan=\"3\">Container capacity and dimensions</td><td>s_{12}={s_{3}}/{2}+(s4+s5+s6)/{6}</td><td>\u2013</td><td>D</td><td><svg><g><path></path></g></svg></td><td>28.99</td><td>53.60</td><td>\u2013</td><td>31.28</td><td>27.39</td><td>30.28</td><td>\u2013</td><td>69.28</td><td>68.16</td></tr><tr><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td><svg><g><path></path></g></svg></td><td>Overall score</td><td></td><td></td><td>S=\\sum_{l=1}^{10}\\pi_{l}s_{l}</td><td>\u2013</td><td>I</td><td>\u2013</td><td>39.11</td><td>44.51</td><td>31.52</td><td>35.89</td><td>47.04</td><td>48.35</td><td>9.05</td><td>66.16</td><td>73.43</td></tr><tr><td colspan=\"21\">Best performing results for each row highlighted in bold. Results of tasks not addressed shown with a hyphen (\u2013).</td></tr><tr><td colspan=\"21\">For s_{9} and s_{10}, configurations with failures in grasping and/or delivering the containers in simulation using true physical properties as input are annotated and discarded.</td></tr><tr><td colspan=\"21\">For fairness, the residual between 100 and the scores obtained with true measures of the physical properties are added to s_{9} and s_{10} to remove the impact of the simulator.</td></tr><tr><td colspan=\"21\">KEY \u2013 T: task, D: direct score, I: indirect score, R2S: measured in the real-to-simulation framework, RAN: random estimation, AVG: average from the training set.</td></tr><tr><td colspan=\"21\">* weighted by the number of performed tasks.</td></tr></tbody></table>", "caption": "Table 1: Results of the CORSMAL challenge entries on the combination of the public and private CCM test sets [8, 12]. For a measure a, its corresponding ground-truth value is \\hat{a}. All scores are normalised and presented in percentages. \\bar{F}_{1}(\\cdot) is the weighted average F1-score. Filling amount and type are sets of classes (no unit).", "list_citation_info": ["[8] A. Xompero, S. Donaher, V. Iashin, F. Palermo, G. Solak, C. Coppola, R. Ishikawa, Y. Nagao, R. Hachiuma, Q. Liu, F. Feng, C. Lan, R. H. M. Chan, G. Christmann, J.-T. Song, G. Neeharika, C. K. T. Reddy, D. Jain, B. U. Rehman, and A. Cavallaro, \u201cThe CORSMAL benchmark for the prediction of the properties of containers,\u201d arXiv:2107.12719v2 [cs.MM], 2021.", "[17] V. Iashin, F. Palermo, G. Solak, and C. Coppola, \u201cTop-1 CORSMAL challenge 2020 submission: Filling mass estimation using multi-modal observations of human-robot handovers,\u201d in Proc. IEEE Conf. Pattern Recognit. Workshops and Challenges, Virtual, 10\u201315 Jan. 2021.", "[18] T. Apicella, G. Slavic, R. Ragusa, P. Gastaldo, and L. Marcenaro, \u201cContainer localisation and mass estimation with an RGB-D camera,\u201d in Proc. IEEE Int. Conf. Acoustics, Speech and, Signal Process., Grand Challenges: Audio-Visual Object Classification For Human-Robot Collaboration, Singapore, 22\u201327 May 2022.", "[15] Q. Liu, F. Feng, C. Lan, and R. H. M. Chan, \u201cVA2Mass: Towards the fluid filling mass estimation via integration of vision & audio learning,\u201d in Proc. IEEE Conf. Pattern Recognit. Workshops and Challenges, Virtual, 10\u201315 Jan. 2021.", "[14] S. Donaher, A. Xompero, and A. Cavallaro, \u201cAudio classification of the content of food containers and drinking glasses,\u201d in Europ. Signal Process. Conf., Virtual, 23\u201327 Aug. 2021.", "[16] R. Ishikawa, Y. Nagao, R. Hachiuma, and H. Saito, \u201cAudio-visual hybrid approach for filling mass estimation,\u201d in Proc. IEEE Conf. Pattern Recognit. Workshops and Challenges, Virtual, 10\u201315 Jan. 2021.", "[20] H. Wang, C. Zhu, Z. Ma, and C. Oh, \u201cImproving generalization of deep networks for estimating physical properties of containers and fillings,\u201d in Proc. IEEE Int. Conf. Acoustics, Speech and, Signal Process., Grand Challenges: Audio-Visual Object Classification For Human-Robot Collaboration, Singapore, 22\u201327 May 2022.", "[19] T. Matsubara, S. Otsuki, Y. Wada, H. Matsuo, T. Komatsu, Y. Iioka, K. Sugiura, and H. Saito, \u201cShared transformer encoder with mask-based 3D model estimation for container mass estimation,\u201d in Proc. IEEE Int. Conf. Acoustics, Speech and, Signal Process., Grand Challenges: Audio-Visual Object Classification For Human-Robot Collaboration, Singapore, 22\u201327 May 2022."]}], "citation_info_to_title": {"[19] T. Matsubara, S. Otsuki, Y. Wada, H. Matsuo, T. Komatsu, Y. Iioka, K. Sugiura, and H. Saito, \u201cShared transformer encoder with mask-based 3D model estimation for container mass estimation,\u201d in Proc. IEEE Int. Conf. Acoustics, Speech and, Signal Process., Grand Challenges: Audio-Visual Object Classification For Human-Robot Collaboration, Singapore, 22\u201327 May 2022.": "Shared transformer encoder with mask-based 3D model estimation for container mass estimation", "[17] V. Iashin, F. Palermo, G. Solak, and C. Coppola, \u201cTop-1 CORSMAL challenge 2020 submission: Filling mass estimation using multi-modal observations of human-robot handovers,\u201d in Proc. IEEE Conf. Pattern Recognit. Workshops and Challenges, Virtual, 10\u201315 Jan. 2021.": "Top-1 CORSMAL challenge 2020 submission: Filling mass estimation using multi-modal observations of human-robot handovers", "[8] A. Xompero, S. Donaher, V. Iashin, F. Palermo, G. Solak, C. Coppola, R. Ishikawa, Y. Nagao, R. Hachiuma, Q. Liu, F. Feng, C. Lan, R. H. M. Chan, G. Christmann, J.-T. Song, G. Neeharika, C. K. T. Reddy, D. Jain, B. U. Rehman, and A. Cavallaro, \u201cThe CORSMAL benchmark for the prediction of the properties of containers,\u201d arXiv:2107.12719v2 [cs.MM], 2021.": "The CORSMAL benchmark for the prediction of the properties of containers", "[18] T. Apicella, G. Slavic, R. Ragusa, P. Gastaldo, and L. Marcenaro, \u201cContainer localisation and mass estimation with an RGB-D camera,\u201d in Proc. IEEE Int. Conf. Acoustics, Speech and, Signal Process., Grand Challenges: Audio-Visual Object Classification For Human-Robot Collaboration, Singapore, 22\u201327 May 2022.": "Container localisation and mass estimation with an RGB-D camera", "[15] Q. Liu, F. Feng, C. Lan, and R. H. M. Chan, \u201cVA2Mass: Towards the fluid filling mass estimation via integration of vision & audio learning,\u201d in Proc. IEEE Conf. Pattern Recognit. Workshops and Challenges, Virtual, 10\u201315 Jan. 2021.": "VA2Mass: Towards the fluid filling mass estimation via integration of vision & audio learning", "[20] H. Wang, C. Zhu, Z. Ma, and C. Oh, \u201cImproving generalization of deep networks for estimating physical properties of containers and fillings,\u201d in Proc. IEEE Int. Conf. Acoustics, Speech and, Signal Process., Grand Challenges: Audio-Visual Object Classification For Human-Robot Collaboration, Singapore, 22\u201327 May 2022.": "Improving Generalization of Deep Networks for Estimating Physical Properties of Containers and Fillings", "[14] S. Donaher, A. Xompero, and A. Cavallaro, \u201cAudio classification of the content of food containers and drinking glasses,\u201d in Europ. Signal Process. Conf., Virtual, 23\u201327 Aug. 2021.": "Audio classification of the content of food containers and drinking glasses", "[16] R. Ishikawa, Y. Nagao, R. Hachiuma, and H. Saito, \u201cAudio-visual hybrid approach for filling mass estimation,\u201d in Proc. IEEE Conf. Pattern Recognit. Workshops and Challenges, Virtual, 10\u201315 Jan. 2021.": "Audio-visual hybrid approach for filling mass estimation"}, "source_title_to_arxiv_id": {"The CORSMAL benchmark for the prediction of the properties of containers": "2107.12719", "Audio classification of the content of food containers and drinking glasses": "2103.15999"}}