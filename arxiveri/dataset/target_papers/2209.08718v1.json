{"title": "Density-aware NeRF Ensembles: Quantifying Predictive Uncertainty in Neural Radiance Fields", "abstract": "We show that ensembling effectively quantifies model uncertainty in Neural\nRadiance Fields (NeRFs) if a density-aware epistemic uncertainty term is\nconsidered. The naive ensembles investigated in prior work simply average\nrendered RGB images to quantify the model uncertainty caused by conflicting\nexplanations of the observed scene. In contrast, we additionally consider the\ntermination probabilities along individual rays to identify epistemic model\nuncertainty due to a lack of knowledge about the parts of a scene unobserved\nduring training. We achieve new state-of-the-art performance across established\nuncertainty quantification benchmarks for NeRFs, outperforming methods that\nrequire complex changes to the NeRF architecture and training regime. We\nfurthermore demonstrate that NeRF uncertainty can be utilised for next-best\nview selection and model refinement.", "authors": ["Niko S\u00fcnderhauf", "Jad Abou-Chakra", "Dimity Miller"], "published_date": "2022_09_19", "pdf_url": "http://arxiv.org/pdf/2209.08718v1", "list_table_and_caption": [{"table": "<table><tbody><tr><td></td><td>Training</td><td colspan=\"6\">Negative Log-Likelihood \\downarrow</td><td colspan=\"4\">Ablation Ensemble Size (NLL \\downarrow)</td></tr><tr><td></td><td>Views</td><td>MC-DO\\dagger</td><td>Naive Ens\\dagger</td><td>NeRF-W\\dagger</td><td>S-NeRF\\dagger</td><td>CF-NeRF\\ddagger</td><td>Ours</td><td></td><td></td><td></td><td></td></tr><tr><td>Dataset</td><td>(Ours)</td><td>M=5</td><td>M=5</td><td>[29]</td><td>[20]</td><td>[21]</td><td>M=5</td><td>M=2</td><td>M=4</td><td>M=8</td><td>M=10</td></tr><tr><td>Flower</td><td>7</td><td>4.63</td><td>1.63</td><td>1.71</td><td>1.27</td><td>\u2013</td><td>1.00</td><td>1.88</td><td>1.13</td><td>0.90</td><td>0.85</td></tr><tr><td>Fortress</td><td>8</td><td>5.19</td><td>2.29</td><td>1.04</td><td>-0.03</td><td>\u2013</td><td>-1.30</td><td>-1.28</td><td>-1.29</td><td>-1.30</td><td>-1.30</td></tr><tr><td>Leaves</td><td>5</td><td>2.72</td><td>2.66</td><td>0.79</td><td>0.68</td><td>\u2013</td><td>0.97</td><td>2.32</td><td>1.10</td><td>0.80</td><td>0.73</td></tr><tr><td>Horns</td><td>12</td><td>4.18</td><td>2.17</td><td>0.78</td><td>0.60</td><td>\u2013</td><td>-0.55</td><td>0.06</td><td>-0.50</td><td>-0.64</td><td>-0.66</td></tr><tr><td>T-Rex</td><td>11</td><td>4.10</td><td>2.28</td><td>1.91</td><td>1.37</td><td>\u2013</td><td>-0.31</td><td>2.69</td><td>0.00</td><td>-0.65</td><td>-0.69</td></tr><tr><td>Fern</td><td>4</td><td>4.90</td><td>2.47</td><td>2.16</td><td>2.01</td><td>\u2013</td><td>-0.98</td><td>-0.89</td><td>-0.97</td><td>-0.99</td><td>-1.00</td></tr><tr><td>Orchids</td><td>5</td><td>5.74</td><td>2.23</td><td>2.24</td><td>1.95</td><td>\u2013</td><td>-0.28</td><td>0.06</td><td>-0.17</td><td>-0.29</td><td>-0.31</td></tr><tr><td>Room</td><td>8</td><td>5.06</td><td>2.13</td><td>4.93</td><td>2.35</td><td>\u2013</td><td>-1.35</td><td>-1.29</td><td>-1.34</td><td>-1.35</td><td>-1.35</td></tr><tr><td>Average</td><td></td><td>4.57</td><td>2.23</td><td>1.95</td><td>1.27</td><td>0.57</td><td>-0.35</td><td>0.44</td><td>-0.26</td><td>-0.44</td><td>-0.47</td></tr></tbody></table>", "caption": "TABLE I: Measuring uncertainty quantification with Negative Log Likelihood (NLL) for baselines and different ensemble sizes of our proposed method.Considered baselines are Monte Carlo Dropout (MC-DO), a naive ensembles approach implemented by [20], NeRF in the Wild (NeRF-W) [29], S-NeRF [20], and CF-NeRF [21]. The latter paper only published average NLL over all scenes instead of individual results. A \\dagger indicates results taken from [20], \\ddagger from [21].", "list_citation_info": ["[29] R. Martin-Brualla, N. Radwan, M. S. M. Sajjadi, J. T. Barron, A. Dosovitskiy, and D. Duckworth, \u201cNeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections,\u201d in CVPR, 2021.", "[20] J. Shen, A. Ruiz, A. Agudo, and F. Moreno-Noguer, \u201cStochastic neural radiance fields: Quantifying uncertainty in implicit 3d representations,\u201d in International Conference on 3D Vision (3DV), 2021.", "[21] J. Shen, A. Agudo, F. Moreno-Noguer, and A. Ruiz, \u201cConditional-flow nerf: Accurate 3d modelling with reliable uncertainty quantification,\u201d arXiv preprint arXiv:2203.10192, 2022."]}], "citation_info_to_title": {"[29] R. Martin-Brualla, N. Radwan, M. S. M. Sajjadi, J. T. Barron, A. Dosovitskiy, and D. Duckworth, \u201cNeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections,\u201d in CVPR, 2021.": "NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections", "[21] J. Shen, A. Agudo, F. Moreno-Noguer, and A. Ruiz, \u201cConditional-flow nerf: Accurate 3d modelling with reliable uncertainty quantification,\u201d arXiv preprint arXiv:2203.10192, 2022.": "Conditional-flow nerf: Accurate 3d modelling with reliable uncertainty quantification", "[20] J. Shen, A. Ruiz, A. Agudo, and F. Moreno-Noguer, \u201cStochastic neural radiance fields: Quantifying uncertainty in implicit 3d representations,\u201d in International Conference on 3D Vision (3DV), 2021.": "Stochastic neural radiance fields: Quantifying uncertainty in implicit 3d representations"}, "source_title_to_arxiv_id": {"Stochastic neural radiance fields: Quantifying uncertainty in implicit 3d representations": "2109.02123"}}