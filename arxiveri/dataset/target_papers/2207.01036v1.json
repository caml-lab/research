{"title": "Memory-Based Label-Text Tuning for Few-Shot Class-Incremental Learning", "abstract": "Few-shot class-incremental learning(FSCIL) focuses on designing learning\nalgorithms that can continually learn a sequence of new tasks from a few\nsamples without forgetting old ones. The difficulties are that training on a\nsequence of limited data from new tasks leads to severe overfitting issues and\ncauses the well-known catastrophic forgetting problem. Existing researches\nmainly utilize the image information, such as storing the image knowledge of\nprevious tasks or limiting classifiers updating. However, they ignore analyzing\nthe informative and less noisy text information of class labels. In this work,\nwe propose leveraging the label-text information by adopting the memory prompt.\nThe memory prompt can learn new data sequentially, and meanwhile store the\nprevious knowledge. Furthermore, to optimize the memory prompt without\nundermining the stored knowledge, we propose a stimulation-based training\nstrategy. It optimizes the memory prompt depending on the image embedding\nstimulation, which is the distribution of the image embedding elements.\nExperiments show that our proposed method outperforms all prior\nstate-of-the-art approaches, significantly mitigating the catastrophic\nforgetting and overfitting problems.", "authors": ["Jinze Li", "Yan Bai", "Yihang Lou", "Xiongkun Linghu", "Jianzhong He", "Shaoyun Xu", "Tao Bai"], "published_date": "2022_07_03", "pdf_url": "http://arxiv.org/pdf/2207.01036v1", "list_table_and_caption": [{"table": "<table><thead><tr><th></th><th colspan=\"9\">Sessions</th></tr><tr><th>Models</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th></tr></thead><tbody><tr><th>iCaRL[30]</th><td>61.31</td><td>46.32</td><td>42.94</td><td>37.63</td><td>30.49</td><td>24.00</td><td>20.89</td><td>18.80</td><td>17.21</td></tr><tr><th>TOPIC[38]</th><td>61.31</td><td>50.09</td><td>45.17</td><td>41.16</td><td>37.48</td><td>35.52</td><td>32.19</td><td>29.46</td><td>24.42</td></tr><tr><th>IDLVQ-C[4]</th><td>64.77</td><td>59.87</td><td>55.93</td><td>52.62</td><td>49.88</td><td>47.55</td><td>44.83</td><td>43.14</td><td>41.84</td></tr><tr><th>F2M[34]</th><td>67.28</td><td>63.80</td><td>60.38</td><td>57.06</td><td>54.08</td><td>51.39</td><td>48.82</td><td>46.58</td><td>44.65</td></tr><tr><th>CEC[45]</th><td>72.00</td><td>66.83</td><td>62.97</td><td>59.43</td><td>56.70</td><td>53.73</td><td>51.19</td><td>49.24</td><td>47.63</td></tr><tr><th>C-FSCIL Mode3[14]</th><td>76.40</td><td>71.14</td><td>66.46</td><td>63.29</td><td>60.42</td><td>57.46</td><td>54.78</td><td>53.11</td><td>51.41</td></tr><tr><th>FACT[49]</th><td>72.56</td><td>69.63</td><td>66.38</td><td>62.77</td><td>60.6</td><td>57.33</td><td>54.34</td><td>52.16</td><td>50.49</td></tr><tr><th>M-FSCIL(ours)</th><td>93.45</td><td>91.82</td><td>87.09</td><td>88.07</td><td>86.75</td><td>87.15</td><td>85.68</td><td>84.80</td><td>85.37</td></tr></tbody></table>", "caption": "Table 1: Comparative results on the miniImageNet dataset for a 5-way 5-shot class incremental learning. In each session, we test the accuracy on all learned classes.", "list_citation_info": ["[45] Chi Zhang et al. \u201cFew-shot incremental learning with continually evolved classifiers\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 12455\u201312464", "[30] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl and Christoph H Lampert \u201cicarl: Incremental classifier and representation learning\u201d In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2017, pp. 2001\u20132010", "[49] Da-Wei Zhou et al. \u201cForward compatible few-shot class-incremental learning\u201d In arXiv preprint arXiv:2203.06953, 2022", "[14] Michael Hersche et al. \u201cConstrained Few-shot Class-incremental Learning\u201d In arXiv preprint arXiv:2203.16588, 2022", "[38] Xiaoyu Tao et al. \u201cFew-shot class-incremental learning\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 12183\u201312192", "[34] Guangyuan Shi et al. \u201cOvercoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima\u201d In Advances in Neural Information Processing Systems 34, 2021", "[4] Kuilin Chen and Chi-Guhn Lee \u201cIncremental few-shot learning via vector quantization in deep embedded space\u201d In International Conference on Learning Representations, 2020"]}, {"table": "<table><thead><tr><th></th><th colspan=\"9\">Sessions</th></tr><tr><th>Models</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th></tr></thead><tbody><tr><th>iCaRL[30]</th><td>66.52</td><td>57.26</td><td>54.27</td><td>50.62</td><td>47.33</td><td>44.99</td><td>43.14</td><td>41.16</td><td>39.49</td></tr><tr><th>TOPIC[38]</th><td>64.10</td><td>55.88</td><td>47.07</td><td>45.16</td><td>40.11</td><td>36.38</td><td>33.96</td><td>31.55</td><td>29.37</td></tr><tr><th>F2M[34]</th><td>64.71</td><td>62.05</td><td>59.01</td><td>55.58</td><td>52.55</td><td>49.96</td><td>48.08</td><td>46.67</td><td>44.67</td></tr><tr><th>CEC[45]</th><td>73.07</td><td>68.88</td><td>65.26</td><td>61.19</td><td>58.09</td><td>55.57</td><td>53.22</td><td>51.34</td><td>49.14</td></tr><tr><th>C-FSCIL Mode3[14]</th><td>77.47</td><td>72.40</td><td>67.47</td><td>63.25</td><td>59.84</td><td>56.95</td><td>54.42</td><td>52.47</td><td>50.47</td></tr><tr><th>FACT[49]</th><td>74.60</td><td>72.09</td><td>67.56</td><td>63.52</td><td>61.38</td><td>58.36</td><td>56.28</td><td>54.24</td><td>52.10</td></tr><tr><th>M-FSCIL(ours)</th><td>85.55</td><td>80.94</td><td>77.27</td><td>73.51</td><td>69.16</td><td>66.44</td><td>62.01</td><td>59.04</td><td>55.06</td></tr></tbody></table>", "caption": "Table 2: Comparative results on the CIFAR100 dataset for a 5-way 5-shot class incremental learning. In each session, we test the accuracy on all learned classes.", "list_citation_info": ["[45] Chi Zhang et al. \u201cFew-shot incremental learning with continually evolved classifiers\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 12455\u201312464", "[30] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl and Christoph H Lampert \u201cicarl: Incremental classifier and representation learning\u201d In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2017, pp. 2001\u20132010", "[49] Da-Wei Zhou et al. \u201cForward compatible few-shot class-incremental learning\u201d In arXiv preprint arXiv:2203.06953, 2022", "[14] Michael Hersche et al. \u201cConstrained Few-shot Class-incremental Learning\u201d In arXiv preprint arXiv:2203.16588, 2022", "[38] Xiaoyu Tao et al. \u201cFew-shot class-incremental learning\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 12183\u201312192", "[34] Guangyuan Shi et al. \u201cOvercoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima\u201d In Advances in Neural Information Processing Systems 34, 2021"]}, {"table": "<table><thead><tr><th></th><th colspan=\"11\">Sessions</th></tr><tr><th>Models</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th></tr></thead><tbody><tr><th>iCaRL[30]</th><td>68.68</td><td>52.65</td><td>48.61</td><td>44.16</td><td>36.62</td><td>29.52</td><td>27.83</td><td>26.26</td><td>24.01</td><td>23.89</td><td>21.16</td></tr><tr><th>TOPIC[38]</th><td>68.68</td><td>62.49</td><td>54.81</td><td>49.99</td><td>45.25</td><td>41.40</td><td>38.35</td><td>35.36</td><td>32.22</td><td>28.31</td><td>26.28</td></tr><tr><th>F2M[34]</th><td>81.07</td><td>78.16</td><td>75.57</td><td>72.89</td><td>70.86</td><td>68.17</td><td>67.01</td><td>65.26</td><td>63.36</td><td>61.76</td><td>60.26</td></tr><tr><th>CEC[45]</th><td>75.85</td><td>71.94</td><td>68.50</td><td>63.50</td><td>62.43</td><td>58.27</td><td>57.73</td><td>55.81</td><td>54.83</td><td>53.52</td><td>52.28</td></tr><tr><th>M-FSCIL(ours)</th><td>81.04</td><td>79.73</td><td>76.62</td><td>73.30</td><td>71.22</td><td>68.90</td><td>66.87</td><td>65.02</td><td>63.90</td><td>62.49</td><td>60.40</td></tr></tbody></table>", "caption": "Table 3: Comparative results on the CUB200 dataset for a 10-way 5-shot class incremental learning. In each session, we test the accuracy on all learned classes.", "list_citation_info": ["[38] Xiaoyu Tao et al. \u201cFew-shot class-incremental learning\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 12183\u201312192", "[45] Chi Zhang et al. \u201cFew-shot incremental learning with continually evolved classifiers\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 12455\u201312464", "[34] Guangyuan Shi et al. \u201cOvercoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima\u201d In Advances in Neural Information Processing Systems 34, 2021", "[30] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl and Christoph H Lampert \u201cicarl: Incremental classifier and representation learning\u201d In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2017, pp. 2001\u20132010"]}, {"table": "<table><thead><tr><th></th><th colspan=\"2\">Sessions</th></tr><tr><th>Models</th><th>Base session</th><th>Final session</th></tr></thead><tbody><tr><th>ViT-L/16[8]</th><td>92.80</td><td>15.65</td></tr><tr><th>ViT-L/32[8]</th><td>91.80</td><td>15.08</td></tr><tr><th>M-FSCIL(ours)</th><td>85.55</td><td>51.36</td></tr></tbody></table>", "caption": "Table 4: Ablation study of the model scale for 5-way 5-shot incremental learning on CIFAR100.", "list_citation_info": ["[8] Alexey Dosovitskiy et al. \u201cAn image is worth 16x16 words: Transformers for image recognition at scale\u201d In arXiv preprint arXiv:2010.11929, 2020"]}], "citation_info_to_title": {"[45] Chi Zhang et al. \u201cFew-shot incremental learning with continually evolved classifiers\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 12455\u201312464": "Few-shot incremental learning with continually evolved classifiers", "[30] Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl and Christoph H Lampert \u201cicarl: Incremental classifier and representation learning\u201d In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, 2017, pp. 2001\u20132010": "icarl: Incremental classifier and representation learning", "[49] Da-Wei Zhou et al. \u201cForward compatible few-shot class-incremental learning\u201d In arXiv preprint arXiv:2203.06953, 2022": "Forward compatible few-shot class-incremental learning", "[8] Alexey Dosovitskiy et al. \u201cAn image is worth 16x16 words: Transformers for image recognition at scale\u201d In arXiv preprint arXiv:2010.11929, 2020": "An image is worth 16x16 words: Transformers for image recognition at scale", "[38] Xiaoyu Tao et al. \u201cFew-shot class-incremental learning\u201d In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 12183\u201312192": "Few-shot class-incremental learning", "[34] Guangyuan Shi et al. \u201cOvercoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima\u201d In Advances in Neural Information Processing Systems 34, 2021": "Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima", "[4] Kuilin Chen and Chi-Guhn Lee \u201cIncremental few-shot learning via vector quantization in deep embedded space\u201d In International Conference on Learning Representations, 2020": "Incremental few-shot learning via vector quantization in deep embedded space", "[14] Michael Hersche et al. \u201cConstrained Few-shot Class-incremental Learning\u201d In arXiv preprint arXiv:2203.16588, 2022": "Constrained Few-shot Class-incremental Learning"}, "source_title_to_arxiv_id": {"Constrained Few-shot Class-incremental Learning": "2203.16588"}}