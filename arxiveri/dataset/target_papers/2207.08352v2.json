{"title": "Show Me What I Like: Detecting User-Specific Video Highlights Using Content-Based Multi-Head Attention", "abstract": "We propose a method to detect individualized highlights for users on given\ntarget videos based on their preferred highlight clips marked on previous\nvideos they have watched. Our method explicitly leverages the contents of both\nthe preferred clips and the target videos using pre-trained features for the\nobjects and the human activities. We design a multi-head attention mechanism to\nadaptively weigh the preferred clips based on their object- and\nhuman-activity-based contents, and fuse them using these weights into a single\nfeature representation for each user. We compute similarities between these\nper-user feature representations and the per-frame features computed from the\ndesired target videos to estimate the user-specific highlight clips from the\ntarget videos. We test our method on a large-scale highlight detection dataset\ncontaining the annotated highlights of individual users. Compared to current\nbaselines, we observe an absolute improvement of 2-4% in the mean average\nprecision of the detected highlights. We also perform extensive ablation\nexperiments on the number of preferred highlight clips associated with each\nuser as well as on the object- and human-activity-based feature representations\nto validate that our method is indeed both content-based and user-specific.", "authors": ["Uttaran Bhattacharya", "Gang Wu", "Stefano Petrangeli", "Viswanathan Swaminathan", "Dinesh Manocha"], "published_date": "2022_07_18", "pdf_url": "http://arxiv.org/pdf/2207.08352v2", "list_table_and_caption": [{"table": "<table><tr><td></td><td>Method</td><td>mAP</td><td>nMSD</td></tr><tr><td rowspan=\"3\">User-Agnostic</td><td>Random</td><td>0.112</td><td>0.536</td></tr><tr><td>FCSN [37]</td><td>0.152</td><td>-</td></tr><tr><td>HighlightMe [2]</td><td>0.200</td><td>-</td></tr><tr><td rowspan=\"6\">User-Specific</td><td>Personalized Summ. [32]</td><td>0.216<sup>*</sup></td><td>0.288<sup>*</sup></td></tr><tr><td>Video2GIF [16]</td><td>0.158</td><td>0.420</td></tr><tr><td>PHD-GIF [11]</td><td>0.166</td><td>0.402</td></tr><tr><td>Adaptive-FCSN [35]</td><td>0.168</td><td>-</td></tr><tr><td>PR-Net [5]</td><td>0.187</td><td>-</td></tr><tr><td>MHA+Fusion (Ours)</td><td>0.228</td><td>0.271</td></tr></table><ul><li>*<p>Numbers reported for a subset of the test set consisting of at least 5 selected highlights per user. For a similar test subset, our method has mAP of 0.262 and nMSD of 0.223.</p></li></ul>", "caption": "Table 1: Mean Average Precision (mAP) and normalized Meaningful Summary Duration (nMSD) for Highlight Detection. We report the numbers of all methods on PHD{}^{2} [11]. Bold indicates best.", "list_citation_info": ["[35] Mrigank Rochan, Mahesh Kumar Krishna Reddy, Linwei Ye, and Yang Wang. Adaptive video highlight detection by learning from user history. In Proceedings of the European Conference on Computer Vision (ECCV), August 2020.", "[16] Michael Gygli, Yale Song, and Liangliang Cao. Video2gif: Automatic generation of animated gifs from video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.", "[5] Runnan Chen, Penghao Zhou, Wenzhe Wang, Nenglun Chen, Pai Peng, Xing Sun, and Wenping Wang. Pr-net: Preference reasoning for personalized video highlight detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 7980\u20137989, October 2021.", "[32] Costas Panagiotakis, Harris Papadakis, and Paraskevi Fragopoulou. Personalized video summarization based exclusively on user preferences. In Joemon M. Jose, Emine Yilmaz, Jo\u00e3o Magalh\u00e3es, Pablo Castells, Nicola Ferro, M\u00e1rio J. Silva, and Fl\u00e1vio Martins, editors, Advances in Information Retrieval, pages 305\u2013311, Cham, 2020. Springer International Publishing.", "[37] Mrigank Rochan, Linwei Ye, and Yang Wang. Video summarization using fully convolutional sequence networks. In Proceedings of the European Conference on Computer Vision (ECCV), September 2018.", "[2] Uttaran Bhattacharya, Gang Wu, Stefano Petrangeli, Viswanathan Swaminathan, and Dinesh Manocha. Highlightme: Detecting highlights from human-centric videos. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 8157\u20138167, October 2021.", "[11] Ana Garcia del Molino and Michael Gygli. Phd-gifs: Personalized highlight detection for automatic gif creation. In Proceedings of the 26th ACM International Conference on Multimedia, MM \u201918, page 600\u2013608, New York, NY, USA, 2018. Association for Computing Machinery."]}, {"table": "<table><tr><td>Method</td><td>F-Score</td></tr><tr><td>SumMe baseline [14]</td><td>0.394</td></tr><tr><td>Submodular mixtures [15]</td><td>0.397</td></tr><tr><td>DPP-LSTM [58]</td><td>0.386</td></tr><tr><td>Unsup. Adversarial LSTM [31]</td><td>0.417</td></tr><tr><td>Sup. Deep RL [62]</td><td>0.421</td></tr><tr><td>S{}^{2}N [47]</td><td>0.433</td></tr><tr><td>Adaptive-FCSN [35]</td><td>0.444</td></tr><tr><td>HighlightMe [2]</td><td>0.480</td></tr><tr><td>MHA+Fusion (Ours)</td><td>0.526</td></tr></table>", "caption": "Table 2: F-Score for Video Summarization. We report the F-scores of all methods on the SumMe dataset [14]. Bold indicates best.", "list_citation_info": ["[31] Behrooz Mahasseni, Michael Lam, and Sinisa Todorovic. Unsupervised video summarization with adversarial lstm networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 202\u2013211, 2017.", "[58] Ke Zhang, Wei-Lun Chao, Fei Sha, and Kristen Grauman. Video summarization with long short-term memory. In Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling, editors, Computer Vision \u2013 ECCV 2016, pages 766\u2013782, Cham, 2016. Springer International Publishing.", "[35] Mrigank Rochan, Mahesh Kumar Krishna Reddy, Linwei Ye, and Yang Wang. Adaptive video highlight detection by learning from user history. In Proceedings of the European Conference on Computer Vision (ECCV), August 2020.", "[47] Zijun Wei, Boyu Wang, Minh Hoai Nguyen, Jianming Zhang, Zhe Lin, Xiaohui Shen, Radomir Mech, and Dimitris Samaras. Sequence-to-segment networks for segment detection. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31, pages 3507\u20133516. Curran Associates, Inc., 2018.", "[15] Michael Gygli, Helmut Grabner, and Luc Van Gool. Video summarization by learning submodular mixtures of objectives. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.", "[14] Michael Gygli, Helmut Grabner, Hayko Riemenschneider, and Luc Van Gool. Creating summaries from user videos. In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors, Computer Vision \u2013 ECCV 2014, pages 505\u2013520, Cham, 2014. Springer International Publishing.", "[62] Kaiyang Zhou, Yu Qiao, and Tao Xiang. Deep reinforcement learning for unsupervised video summarization with diversity-representativeness reward. pages 7582\u20137589, 2018.", "[2] Uttaran Bhattacharya, Gang Wu, Stefano Petrangeli, Viswanathan Swaminathan, and Dinesh Manocha. Highlightme: Detecting highlights from human-centric videos. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 8157\u20138167, October 2021."]}, {"table": "<table><tr><td># preferred Highlight Clips</td><td>0</td><td>5</td><td>10</td><td>15 (max)</td></tr><tr><td>mAP</td><td>0.151</td><td>0.197</td><td>0.211</td><td>0.228</td></tr></table>", "caption": "Table 3: Ablation 1: Changing the Number of Preferred Highlights. We report the mAPs of all ablated versions on PHD{}^{2} [11]. Bold indicates best.", "list_citation_info": ["[11] Ana Garcia del Molino and Michael Gygli. Phd-gifs: Personalized highlight detection for automatic gif creation. In Proceedings of the 26th ACM International Conference on Multimedia, MM \u201918, page 600\u2013608, New York, NY, USA, 2018. Association for Computing Machinery."]}, {"table": "<table><tr><td>Using backbone</td><td>YOLOv5 [20]</td><td>Detectron2 [48]</td><td>both</td></tr><tr><td>mAP</td><td>0.164</td><td>0.193</td><td>0.228</td></tr></table>", "caption": "Table 4: Ablation 2: Using Only One Pre-Trained Backbone for Highlight Detection. We report the mAPs of all ablated versions on PHD{}^{2} [11]. Bold indicates best.", "list_citation_info": ["[48] Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick. Detectron2. https://github.com/facebookresearch/detectron2, 2019.", "[11] Ana Garcia del Molino and Michael Gygli. Phd-gifs: Personalized highlight detection for automatic gif creation. In Proceedings of the 26th ACM International Conference on Multimedia, MM \u201918, page 600\u2013608, New York, NY, USA, 2018. Association for Computing Machinery.", "[20] Glenn Jocher, Ayush Chaurasia, Alex Stoken, Jirka Borovec, NanoCode012, Yonghye Kwon, TaoXie, Jiacong Fang, imyhxy, Kalen Michael, Lorna, Abhiram V, Diego Montes, Jebastin Nadar, Laughing, tkianai, yxNONG, Piotr Skalski, Zhiqiang Wang, Adam Hogan, Cristi Fati, Lorenzo Mammana, AlexWang1900, Deep Patel, Ding Yiwei, Felix You, Jan Hajek, Laurentiu Diaconu, and Mai Thanh Minh. ultralytics/yolov5: v6.1 - TensorRT, TensorFlow Edge TPU and OpenVINO Export and Inference, Feb. 2022."]}, {"table": "<table><tr><td>Excluding loss</td><td>label</td><td>margin</td><td>sparsity</td><td>none</td></tr><tr><td>mAP</td><td>0.155</td><td>0.192</td><td>0.163</td><td>0.228</td></tr></table>", "caption": "Table 5: Ablation 3: Ablating the Training Loss Functions. We report the mAPs of all ablated versions on PHD{}^{2} [11]. Bold indicates best.", "list_citation_info": ["[11] Ana Garcia del Molino and Michael Gygli. Phd-gifs: Personalized highlight detection for automatic gif creation. In Proceedings of the 26th ACM International Conference on Multimedia, MM \u201918, page 600\u2013608, New York, NY, USA, 2018. Association for Computing Machinery."]}, {"table": "<table><tr><td>Domain</td><td>RRAE [53]</td><td>Video2 GIF [16]</td><td>LSVM [42]</td><td>Less is More [49]</td><td>HighlightMe [2]</td><td>Ours</td></tr><tr><td>dog show</td><td>0.49</td><td>0.31</td><td>0.60</td><td>0.58</td><td>0.63</td><td>0.60</td></tr><tr><td>gymnastics</td><td>0.35</td><td>0.34</td><td>0.41</td><td>0.44</td><td>0.73</td><td>0.73</td></tr><tr><td>parkour</td><td>0.50</td><td>0.54</td><td>0.61</td><td>0.67</td><td>0.72</td><td>0.71</td></tr><tr><td>skating</td><td>0.25</td><td>0.55</td><td>0.62</td><td>0.58</td><td>0.64</td><td>0.62</td></tr><tr><td>skiing</td><td>0.22</td><td>0.33</td><td>0.36</td><td>0.49</td><td>0.52</td><td>0.61</td></tr><tr><td>surfing</td><td>0.49</td><td>0.54</td><td>0.61</td><td>0.65</td><td>0.62</td><td>0.58</td></tr><tr><td>Mean</td><td>0.38</td><td>0.46</td><td>0.54</td><td>0.57</td><td>0.64</td><td>0.62</td></tr></table>", "caption": "Table 6: Mean average precision on the DSH dataset [42]. Bold indicates best, underline indicates second-best.", "list_citation_info": ["[16] Michael Gygli, Yale Song, and Liangliang Cao. Video2gif: Automatic generation of animated gifs from video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.", "[53] Huan Yang, Baoyuan Wang, Stephen Lin, David Wipf, Minyi Guo, and Baining Guo. Unsupervised extraction of video highlights via robust recurrent auto-encoders. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), December 2015.", "[42] Min Sun, Ali Farhadi, and Steve Seitz. Ranking domain-specific highlights by analyzing edited videos. In European conference on computer vision, pages 787\u2013802. Springer, 2014.", "[49] Bo Xiong, Yannis Kalantidis, Deepti Ghadiyaram, and Kristen Grauman. Less is more: Learning highlight detection from video duration. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1258\u20131267, 2019.", "[2] Uttaran Bhattacharya, Gang Wu, Stefano Petrangeli, Viswanathan Swaminathan, and Dinesh Manocha. Highlightme: Detecting highlights from human-centric videos. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 8157\u20138167, October 2021."]}, {"table": "<table><tr><td>Domain</td><td>MBF [7]</td><td>KVS [34]</td><td>CVS [33]</td><td>Adv-LSTM [31]</td><td>Less is More [49]</td><td>HighlightMe [2]</td><td>Ours</td></tr><tr><td>BK</td><td>0.31</td><td>0.34</td><td>0.33</td><td>0.42</td><td>0.66</td><td>0.57</td><td>0.60</td></tr><tr><td>BT</td><td>0.37</td><td>0.42</td><td>0.40</td><td>0.48</td><td>0.69</td><td>0.93</td><td>0.85</td></tr><tr><td>DS</td><td>0.36</td><td>0.39</td><td>0.38</td><td>0.47</td><td>0.63</td><td>0.60</td><td>0.62</td></tr><tr><td>FM</td><td>0.37</td><td>0.40</td><td>0.37</td><td>0.46</td><td>0.43</td><td>0.88</td><td>0.77</td></tr><tr><td>GA</td><td>0.33</td><td>0.40</td><td>0.38</td><td>0.48</td><td>0.61</td><td>0.50</td><td>0.63</td></tr><tr><td>MS</td><td>0.41</td><td>0.42</td><td>0.40</td><td>0.49</td><td>0.54</td><td>0.50</td><td>0.55</td></tr><tr><td>PR</td><td>0.33</td><td>0.40</td><td>0.38</td><td>0.47</td><td>0.53</td><td>0.84</td><td>0.70</td></tr><tr><td>PK</td><td>0.32</td><td>0.38</td><td>0.35</td><td>0.46</td><td>0.60</td><td>0.76</td><td>0.68</td></tr><tr><td>VT</td><td>0.30</td><td>0.35</td><td>0.33</td><td>0.42</td><td>0.56</td><td>0.65</td><td>0.61</td></tr><tr><td>VU</td><td>0.36</td><td>0.44</td><td>0.41</td><td>0.47</td><td>0.50</td><td>0.77</td><td>0.75</td></tr><tr><td>Mean</td><td>0.35</td><td>0.40</td><td>0.37</td><td>0.46</td><td>0.58</td><td>0.70</td><td>0.68</td></tr></table>", "caption": "Table 7: Mean average precision on the TVSum dataset [41]. Bold indicates best, underline indicates second-best.", "list_citation_info": ["[31] Behrooz Mahasseni, Michael Lam, and Sinisa Todorovic. Unsupervised video summarization with adversarial lstm networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 202\u2013211, 2017.", "[34] Danila Potapov, Matthijs Douze, Zaid Harchaoui, and Cordelia Schmid. Category-specific video summarization. In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors, Computer Vision \u2013 ECCV 2014, pages 540\u2013555, Cham, 2014. Springer International Publishing.", "[33] Rameswar Panda and Amit K. Roy-Chowdhury. Collaborative summarization of topic-related videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.", "[49] Bo Xiong, Yannis Kalantidis, Deepti Ghadiyaram, and Kristen Grauman. Less is more: Learning highlight detection from video duration. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1258\u20131267, 2019.", "[2] Uttaran Bhattacharya, Gang Wu, Stefano Petrangeli, Viswanathan Swaminathan, and Dinesh Manocha. Highlightme: Detecting highlights from human-centric videos. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 8157\u20138167, October 2021.", "[41] Yale Song, Jordi Vallmitjana, Amanda Stent, and Alejandro Jaimes. Tvsum: Summarizing web videos using titles. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.", "[7] Wen-Sheng Chu, Yale Song, and Alejandro Jaimes. Video co-summarization: Video summarization by visual co-occurrence. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015."]}], "citation_info_to_title": {"[47] Zijun Wei, Boyu Wang, Minh Hoai Nguyen, Jianming Zhang, Zhe Lin, Xiaohui Shen, Radomir Mech, and Dimitris Samaras. Sequence-to-segment networks for segment detection. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31, pages 3507\u20133516. Curran Associates, Inc., 2018.": "Sequence-to-Segment Networks for Segment Detection", "[37] Mrigank Rochan, Linwei Ye, and Yang Wang. Video summarization using fully convolutional sequence networks. In Proceedings of the European Conference on Computer Vision (ECCV), September 2018.": "Video summarization using fully convolutional sequence networks", "[62] Kaiyang Zhou, Yu Qiao, and Tao Xiang. Deep reinforcement learning for unsupervised video summarization with diversity-representativeness reward. pages 7582\u20137589, 2018.": "Deep reinforcement learning for unsupervised video summarization with diversity-representativeness reward", "[33] Rameswar Panda and Amit K. Roy-Chowdhury. Collaborative summarization of topic-related videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.": "Collaborative summarization of topic-related videos", "[53] Huan Yang, Baoyuan Wang, Stephen Lin, David Wipf, Minyi Guo, and Baining Guo. Unsupervised extraction of video highlights via robust recurrent auto-encoders. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), December 2015.": "Unsupervised extraction of video highlights via robust recurrent auto-encoders", "[14] Michael Gygli, Helmut Grabner, Hayko Riemenschneider, and Luc Van Gool. Creating summaries from user videos. In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors, Computer Vision \u2013 ECCV 2014, pages 505\u2013520, Cham, 2014. Springer International Publishing.": "Creating summaries from user videos", "[20] Glenn Jocher, Ayush Chaurasia, Alex Stoken, Jirka Borovec, NanoCode012, Yonghye Kwon, TaoXie, Jiacong Fang, imyhxy, Kalen Michael, Lorna, Abhiram V, Diego Montes, Jebastin Nadar, Laughing, tkianai, yxNONG, Piotr Skalski, Zhiqiang Wang, Adam Hogan, Cristi Fati, Lorenzo Mammana, AlexWang1900, Deep Patel, Ding Yiwei, Felix You, Jan Hajek, Laurentiu Diaconu, and Mai Thanh Minh. ultralytics/yolov5: v6.1 - TensorRT, TensorFlow Edge TPU and OpenVINO Export and Inference, Feb. 2022.": "ultralytics/yolov5: v61 - TensorRT, TensorFlow Edge TPU and OpenVINO Export and Inference", "[58] Ke Zhang, Wei-Lun Chao, Fei Sha, and Kristen Grauman. Video summarization with long short-term memory. In Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling, editors, Computer Vision \u2013 ECCV 2016, pages 766\u2013782, Cham, 2016. Springer International Publishing.": "Video Summarization with Long Short-Term Memory", "[32] Costas Panagiotakis, Harris Papadakis, and Paraskevi Fragopoulou. Personalized video summarization based exclusively on user preferences. In Joemon M. Jose, Emine Yilmaz, Jo\u00e3o Magalh\u00e3es, Pablo Castells, Nicola Ferro, M\u00e1rio J. Silva, and Fl\u00e1vio Martins, editors, Advances in Information Retrieval, pages 305\u2013311, Cham, 2020. Springer International Publishing.": "Personalized video summarization based exclusively on user preferences", "[48] Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick. Detectron2. https://github.com/facebookresearch/detectron2, 2019.": "Detectron2", "[7] Wen-Sheng Chu, Yale Song, and Alejandro Jaimes. Video co-summarization: Video summarization by visual co-occurrence. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.": "Video co-summarization: Video summarization by visual co-occurrence", "[31] Behrooz Mahasseni, Michael Lam, and Sinisa Todorovic. Unsupervised video summarization with adversarial lstm networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 202\u2013211, 2017.": "Unsupervised video summarization with adversarial lstm networks", "[42] Min Sun, Ali Farhadi, and Steve Seitz. Ranking domain-specific highlights by analyzing edited videos. In European conference on computer vision, pages 787\u2013802. Springer, 2014.": "Ranking Domain-Specific Highlights by Analyzing Edited Videos", "[41] Yale Song, Jordi Vallmitjana, Amanda Stent, and Alejandro Jaimes. Tvsum: Summarizing web videos using titles. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.": "Tvsum: Summarizing web videos using titles", "[34] Danila Potapov, Matthijs Douze, Zaid Harchaoui, and Cordelia Schmid. Category-specific video summarization. In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors, Computer Vision \u2013 ECCV 2014, pages 540\u2013555, Cham, 2014. Springer International Publishing.": "Category-specific video summarization", "[11] Ana Garcia del Molino and Michael Gygli. Phd-gifs: Personalized highlight detection for automatic gif creation. In Proceedings of the 26th ACM International Conference on Multimedia, MM \u201918, page 600\u2013608, New York, NY, USA, 2018. Association for Computing Machinery.": "Phd-gifs: Personalized highlight detection for automatic gif creation", "[2] Uttaran Bhattacharya, Gang Wu, Stefano Petrangeli, Viswanathan Swaminathan, and Dinesh Manocha. Highlightme: Detecting highlights from human-centric videos. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 8157\u20138167, October 2021.": "Highlightme: Detecting highlights from human-centric videos", "[35] Mrigank Rochan, Mahesh Kumar Krishna Reddy, Linwei Ye, and Yang Wang. Adaptive video highlight detection by learning from user history. In Proceedings of the European Conference on Computer Vision (ECCV), August 2020.": "Adaptive video highlight detection by learning from user history", "[5] Runnan Chen, Penghao Zhou, Wenzhe Wang, Nenglun Chen, Pai Peng, Xing Sun, and Wenping Wang. Pr-net: Preference reasoning for personalized video highlight detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 7980\u20137989, October 2021.": "Pr-net: Preference reasoning for personalized video highlight detection", "[49] Bo Xiong, Yannis Kalantidis, Deepti Ghadiyaram, and Kristen Grauman. Less is more: Learning highlight detection from video duration. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1258\u20131267, 2019.": "Less is more: Learning highlight detection from video duration", "[15] Michael Gygli, Helmut Grabner, and Luc Van Gool. Video summarization by learning submodular mixtures of objectives. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015.": "Video summarization by learning submodular mixtures of objectives", "[16] Michael Gygli, Yale Song, and Liangliang Cao. Video2gif: Automatic generation of animated gifs from video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.": "Video2gif: Automatic generation of animated gifs from video"}, "source_title_to_arxiv_id": {"Highlightme: Detecting highlights from human-centric videos": "2110.01774"}}