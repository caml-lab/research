{"title": "S$^2$-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for Real-time Semantic Segmentation", "abstract": "Modern high-performance semantic segmentation methods employ a heavy backbone\nand dilated convolution to extract the relevant feature. Although extracting\nfeatures with both contextual and semantic information is critical for the\nsegmentation tasks, it brings a memory footprint and high computation cost for\nreal-time applications. This paper presents a new model to achieve a trade-off\nbetween accuracy/speed for real-time road scene semantic segmentation.\nSpecifically, we proposed a lightweight model named Scale-aware Strip Attention\nGuided Feature Pyramid Network (S$^2$-FPN). Our network consists of three main\nmodules: Attention Pyramid Fusion (APF) module, Scale-aware Strip Attention\nModule (SSAM), and Global Feature Upsample (GFU) module. APF adopts an\nattention mechanisms to learn discriminative multi-scale features and help\nclose the semantic gap between different levels. APF uses the scale-aware\nattention to encode global context with vertical stripping operation and models\nthe long-range dependencies, which helps relate pixels with similar semantic\nlabel. In addition, APF employs channel-wise reweighting block (CRB) to\nemphasize the channel features. Finally, the decoder of S$^2$-FPN then adopts\nGFU, which is used to fuse features from APF and the encoder. Extensive\nexperiments have been conducted on two challenging semantic segmentation\nbenchmarks, which demonstrate that our approach achieves better accuracy/speed\ntrade-off with different model settings. The proposed models have achieved a\nresults of 76.2\\%mIoU/87.3FPS, 77.4\\%mIoU/67FPS, and 77.8\\%mIoU/30.5FPS on\nCityscapes dataset, and 69.6\\%mIoU,71.0\\% mIoU, and 74.2\\% mIoU on Camvid\ndataset. The code for this work will be made available at\n\\url{https://github.com/mohamedac29/S2-FPN", "authors": ["Mohammed A. M. Elhassan", "Chenhui Yang", "Chenxi Huang", "Tewodros Legesse Munea", "Xin Hong"], "published_date": "2022_06_15", "pdf_url": "http://arxiv.org/pdf/2206.07298v2", "list_table_and_caption": [{"table": "<table><tbody><tr><th>Method</th><td>Road</td><td>S.Walk</td><td>Build</td><td>Wall</td><td>Fence</td><td>Pole</td><td>T-Light</td><td>T-Sign</td><td>Veg</td><td>Terrain</td><td>Sky</td><td>Person</td><td>Rider</td><td>Car</td><td>Truck</td><td>Bus</td><td>Tra</td><td>Motor</td><td>Bic</td><td>mIoU</td></tr><tr><th>CRF-RNN[34]</th><td>96.3</td><td>73.9</td><td>88.2</td><td>47.6</td><td>41.3</td><td>35.2</td><td>49.5</td><td>59.7</td><td>90.6</td><td>66.1</td><td>93.5</td><td>70.4</td><td>34.7</td><td>90.1</td><td>39.2</td><td>57.5</td><td>55.4</td><td>43.9</td><td>54.6</td><td>62.5</td></tr><tr><th>FCN[6]</th><td>97.4</td><td>78.4</td><td>89.2</td><td>34.9</td><td>44.2</td><td>47.4</td><td>60.1.5</td><td>65.0</td><td>91.4</td><td>69.3</td><td>93.9</td><td>77.1</td><td>51.4</td><td>92.6</td><td>35.3</td><td>48.6</td><td>46.5</td><td>51.6</td><td>66.8</td><td>65.3</td></tr><tr><th>DeepLabv2[10]</th><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>70.4</td></tr><tr><th>Dilation10[36]</th><td>97.6</td><td>79.2</td><td>89.9</td><td>37.3</td><td>47.6</td><td>53.2</td><td>58.6</td><td>65.2</td><td>91.8</td><td>69.4</td><td>93.7</td><td>78.9</td><td>55.0</td><td>3.3</td><td>45.5</td><td>53.4</td><td>47.7</td><td>52.2</td><td>66.0</td><td>67.1</td></tr><tr><th>AGLNet[64]</th><td>97.8</td><td>80.1</td><td>91.0</td><td>51.3</td><td>50.6</td><td>58.3</td><td>63.0</td><td>68.5</td><td>92.3</td><td>71.3</td><td>94.2</td><td>80.1</td><td>59.6</td><td>93.8</td><td>48.4</td><td>68.1</td><td>42.1</td><td>52.4</td><td>67.8</td><td>70.1</td></tr><tr><th>BiSeNetV2/BiSeNetV2_L[28]</th><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>73.2</td></tr><tr><th>LBN-AA[40]</th><td>98.2</td><td>84.0</td><td>91.6</td><td>50.7</td><td>49.5</td><td>60.9</td><td>69.0</td><td>73.6</td><td>92.6</td><td>70.3</td><td>94.4</td><td>83.0</td><td>65.7</td><td>94.9</td><td>62.0</td><td>70.9</td><td>53.3</td><td>62.5</td><td>71.8-</td><td>73.6</td></tr><tr><th>S<sup>2</sup>-FPN18</th><td>98.2</td><td>84.7</td><td>92.0</td><td>50.2</td><td>54.9</td><td>62.9</td><td>71.3</td><td>75.6</td><td>93.0</td><td>70.0</td><td>94.7</td><td>84.6</td><td>67.4</td><td>95.2</td><td>65.1</td><td>79.4</td><td>68.7</td><td>65.1</td><td>73.9</td><td>76.2</td></tr><tr><th>S<sup>2</sup>-FPN34</th><td>98.4</td><td>85.5</td><td>92.7</td><td>56.2</td><td>57.6</td><td>64.7</td><td>72.7</td><td>76.2</td><td>93.3</td><td>70.8</td><td>94.9</td><td>85.2</td><td>69.0</td><td>95.52</td><td>66.7</td><td>80.8</td><td>69.0</td><td>66.4</td><td>74.3</td><td>77.4</td></tr><tr><th>S<sup>2</sup>-FPN34M</th><td>98.1</td><td>84.5</td><td>92.7</td><td>51.5</td><td>57.3</td><td>68.5</td><td>76.5</td><td>79.3</td><td>93.5</td><td>71.4</td><td>94.5</td><td>86.4</td><td>68.4</td><td>95.3</td><td>61.5</td><td>80.4</td><td>72.6</td><td>68.0</td><td>76.5</td><td>77.8</td></tr></tbody></table>", "caption": "TABLE I: THE PER-CLASS, CLASS, AND CATEGORY IOU EVALUATION ON THE CITYSCAPES TEST SET.\"", "list_citation_info": ["[6] J. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networks for semantic segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 3431\u20133440.", "[64] Q. Zhou, Y. Wang, Y. Fan, X. Wu, S. Zhang, B. Kang, and L. J. Latecki, \u201cAglnet: Towards real-time semantic segmentation of self-driving images via attention-guided lightweight network,\u201d Applied Soft Computing, vol. 96, p. 106682, 2020.", "[36] F. Yu and V. Koltun, \u201cMulti-scale context aggregation by dilated convolutions (2015),\u201d arXiv preprint arXiv:1511.07122, 2016.", "[34] S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang, and P. H. Torr, \u201cConditional random fields as recurrent neural networks,\u201d in Proceedings of the IEEE international conference on computer vision, 2015, pp. 1529\u20131537.", "[28] C. Yu, C. Gao, J. Wang, G. Yu, C. Shen, and N. Sang, \u201cBisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation,\u201d International Journal of Computer Vision, pp. 1\u201318, 2021.", "[40] G. Dong, Y. Yan, C. Shen, and H. Wang, \u201cReal-time high-performance semantic image segmentation of urban street scenes,\u201d IEEE Transactions on Intelligent Transportation Systems, vol. 22, no. 6, pp. 3258\u20133274, 2020.", "[10] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, \u201cDeeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 40, no. 4, pp. 834\u2013848, 2017."]}, {"table": "<p>MethodBackboneResolutionGPUParameters(M)Flops (G)test setmIoUFPSPSPNet[5]ResNet101713 \\times713-250.8412.2\u271381.20.78DeepLab[10]VGG16512\\times1024Titan X262.1457.8\u271363.10.25ENet[34]No640 \\times360TitanX0.43.8\u271358.3135.4ICNet[35]PSPNet501024\\times2048TitanX26.528.3\u271369.530.3DABNet[6]No512\\times1024GTX 1080Ti0.7610.4\u271370.1104DFANet-A[36]XceptionA1024\\times1024Titan X7.83.4\u271371.3100DFANet-B[36]XceptionB1024\\times1024Titan X4.82.1\u271367.1120BiSeNet1[19]Xception39768\\times1536NVIDIA Titan X5.814.8\u271368.4105.8BiSeNet2[19]ResNet18768\\times1536NVIDIA Titan X4954.02\u271374.865.5FasterSeg[37]No1024\\times2048GTX 1080Ti-\u271371.5163.9TD4-Bise18[38]BiseNet181024\\times2048Titan Xp-\u271374.9-FANet-18[39]ResNet181024\\times2048Titan X-49\u271374.472FANet-34[39]ResNet341024\\times2048Titan X-65\u271375.558LBN-AA[40]LBN-AA+MobileNetV2488\\times896Titan X6.249.5\u271373.651.0AGLNet[40]No512\\times1024GTX 1080Ti1.1213.88\u271371.352.0BiSeNetV2[28]No512\\times1024GTX 1080Ti49.021.2\u271372.6156BiSeNetV2-L[28]No512\\times1024GTX 1080Ti118.5\u271375.347.3HMSeg[41]No768\\times1536GTX 1080Ti2.3\u271374.383.2TinyHMSeg[41]No768\\times1536GTX 1080Ti0.7\u271371.4172.4STDC1-Seg50[24]STDC1512\\times1924GTX 1080Ti8.4-\u271371.9250.4STDC2-Seg50[24]STDC2512\\times1024GTX 1080Ti12.5-\u271373.4188.6STDC1-Seg75[24]STDC1768\\times1536GTX 1080Ti8.4-\u271375.3126.7STDC2-Seg75[24]STDC2768\\times1536GTX 1080Ti12.5-\u271376.897.0S<sup>2</sup>-FPN18ResNet18512\\times1024GTX 1080Ti17.829.1\u271376.287.3S<sup>2</sup>-FPN34ResNet34512\\times1024GTX 1080Ti27.948.4\u271377.467S<sup>2</sup>-FPN34MResNet34512\\times1024GTX 1080Ti27.9190\u271377.830.5</p>", "caption": "TABLE VI: COMPARISON BETWEEN THE PROPOSED METHOD S<sup>2</sup>-FPN AND THE OTHER SOTA METHODS ON THE CITYSCAPES TEST DATASET. WE REPORT THE BACKBONE, INPUT RESOLUTION, GPU TYPE, NUMBER OF PARAMETERS (M), FLOPS (G), EVALUATION SPLIT (SET), ACHIEVED ACCURACY (MIOU), AND THE INFERENCE SPEED (FPS)", "list_citation_info": ["[24] M. Fan, S. Lai, J. Huang, X. Wei, Z. Chai, J. Luo, and X. Wei, \u201cRethinking bisenet for real-time semantic segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 9716\u20139725.", "[6] J. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networks for semantic segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 3431\u20133440.", "[38] P. Hu, F. Caba, O. Wang, Z. Lin, S. Sclaroff, and F. Perazzi, \u201cTemporally distributed networks for fast video semantic segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 8818\u20138827.", "[37] W. Chen, X. Gong, X. Liu, Q. Zhang, Y. Li, and Z. Wang, \u201cFasterseg: Searching for faster real-time semantic segmentation,\u201d arXiv preprint arXiv:1912.10917, 2019.", "[41] P. Li, X. Dong, X. Yu, and Y. Yang, \u201cWhen humans meet machines: Towards efficient segmentation networks.\u201d in BMVC, 2020.", "[35] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, \u201cSemantic image segmentation with deep convolutional nets and fully connected crfs,\u201d arXiv preprint arXiv:1412.7062, 2014.", "[36] F. Yu and V. Koltun, \u201cMulti-scale context aggregation by dilated convolutions (2015),\u201d arXiv preprint arXiv:1511.07122, 2016.", "[34] S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang, and P. H. Torr, \u201cConditional random fields as recurrent neural networks,\u201d in Proceedings of the IEEE international conference on computer vision, 2015, pp. 1529\u20131537.", "[39] P. Hu, F. Perazzi, F. C. Heilbron, O. Wang, Z. Lin, K. Saenko, and S. Sclaroff, \u201cReal-time semantic segmentation with fast attention,\u201d IEEE Robotics and Automation Letters, vol. 6, no. 1, pp. 263\u2013270, 2020.", "[28] C. Yu, C. Gao, J. Wang, G. Yu, C. Shen, and N. Sang, \u201cBisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation,\u201d International Journal of Computer Vision, pp. 1\u201318, 2021.", "[40] G. Dong, Y. Yan, C. Shen, and H. Wang, \u201cReal-time high-performance semantic image segmentation of urban street scenes,\u201d IEEE Transactions on Intelligent Transportation Systems, vol. 22, no. 6, pp. 3258\u20133274, 2020.", "[19] C. Yu, J. Wang, C. Peng, C. Gao, G. Yu, and N. Sang, \u201cBisenet: Bilateral segmentation network for real-time semantic segmentation,\u201d in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 325\u2013341.", "[10] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, \u201cDeeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 40, no. 4, pp. 834\u2013848, 2017.", "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890."]}, {"table": "<table><tbody><tr><th>Method</th><td>Bui</td><td>Tree</td><td>Sky</td><td>Car</td><td>Sig</td><td>Roa</td><td>Ped</td><td>Fen</td><td>Pol</td><td>Side</td><td>Bic</td><td>mIoU</td></tr><tr><th>SegNet[7]</th><td>88.8</td><td>87.3</td><td>92.4</td><td>82.1</td><td>20.5</td><td>97.2</td><td>57.1</td><td>49.3</td><td>27.5</td><td>84.4</td><td>30.7</td><td>55.6</td></tr><tr><th>ENet[45]</th><td>74.7</td><td>77.8</td><td>95.1</td><td>82.4</td><td>51.0</td><td>95.1</td><td>67.2</td><td>51.7</td><td>35.4</td><td>86.7</td><td>34.1</td><td>51.3</td></tr><tr><th>BiSeNet1[19]</th><td>82.2</td><td>74.4</td><td>91.9</td><td>80.8</td><td>42.8</td><td>93.3</td><td>53.8</td><td>49.7</td><td>25.4</td><td>77.3</td><td>50.0</td><td>65.6</td></tr><tr><th>BiSeNet2[19]</th><td>83.0</td><td>75.8</td><td>92.0</td><td>83.7</td><td>46.5</td><td>94.6</td><td>58.8</td><td>53.6</td><td>31.9</td><td>81.4</td><td>54.0</td><td>68.7</td></tr><tr><th>NDNet45-FCN8-LF[70]</th><td>85.5</td><td>84.6</td><td>94.8</td><td>82.6</td><td>39.2</td><td>97.4</td><td>60.1</td><td>37.3</td><td>17.6</td><td>86.8</td><td>53.7</td><td>57.5</td></tr><tr><th>LBN-AA[40]</th><td>83.2</td><td>70.5</td><td>92.5</td><td>81.7</td><td>51.6</td><td>93.0</td><td>55.6</td><td>53.2</td><td>36.3</td><td>82.1</td><td>47.9</td><td>68.0</td></tr><tr><th>AGLNet[64]</th><td>82.6</td><td>76.1</td><td>91.0</td><td>87.0</td><td>45.3</td><td>95.4</td><td>61.5</td><td>39.5</td><td>39.0</td><td>83.1</td><td>62.7</td><td>69.4</td></tr><tr><th>BiSeNetV2/BiSeNetV2L[28]</th><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>72.4/73.2</td></tr><tr><th>S<sup>2</sup>-FPN18</th><td>83.</td><td>77.2</td><td>91.8</td><td>88.9</td><td>48.2</td><td>95.7</td><td>56.4</td><td>43.4</td><td>32.4</td><td>84.8</td><td>62.5</td><td>69.6</td></tr><tr><th>S<sup>2</sup>-FPN34</th><td>85.3</td><td>77.4</td><td>91.7</td><td>91.2</td><td>49.6</td><td>95.7</td><td>59.1</td><td>46.8</td><td>33.2</td><td>85.4</td><td>66.5</td><td>71.0</td></tr><tr><th>S<sup>2</sup>-FPN34M</th><td>86.0</td><td>78.8</td><td>92.6</td><td>92.2</td><td>56.2</td><td>96.0</td><td>67.1</td><td>47.3</td><td>42.1</td><td>86.8</td><td>70.7</td><td>74.2</td></tr></tbody></table>", "caption": "TABLE VII: INDIVIDUAL CATEGORY RESULTS ON CAMVID TEST SET IN TERMS OF MIOU FOR 11 CLASSES", "list_citation_info": ["[45] A. Paszke, A. Chaurasia, S. Kim, and E. Culurciello, \u201cEnet: A deep neural network architecture for real-time semantic segmentation,\u201d arXiv preprint arXiv:1606.02147, 2016.", "[64] Q. Zhou, Y. Wang, Y. Fan, X. Wu, S. Zhang, B. Kang, and L. J. Latecki, \u201cAglnet: Towards real-time semantic segmentation of self-driving images via attention-guided lightweight network,\u201d Applied Soft Computing, vol. 96, p. 106682, 2020.", "[7] V. Badrinarayanan, A. Kendall, and R. Cipolla, \u201cSegnet: A deep convolutional encoder-decoder architecture for image segmentation,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 39, no. 12, pp. 2481\u20132495, 2017.", "[28] C. Yu, C. Gao, J. Wang, G. Yu, C. Shen, and N. Sang, \u201cBisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation,\u201d International Journal of Computer Vision, pp. 1\u201318, 2021.", "[40] G. Dong, Y. Yan, C. Shen, and H. Wang, \u201cReal-time high-performance semantic image segmentation of urban street scenes,\u201d IEEE Transactions on Intelligent Transportation Systems, vol. 22, no. 6, pp. 3258\u20133274, 2020.", "[19] C. Yu, J. Wang, C. Peng, C. Gao, G. Yu, and N. Sang, \u201cBisenet: Bilateral segmentation network for real-time semantic segmentation,\u201d in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 325\u2013341.", "[70] Z. Yang, H. Yu, M. Feng, W. Sun, X. Lin, M. Sun, Z.-H. Mao, and A. Mian, \u201cSmall object augmentation of urban scenes for real-time semantic segmentation,\u201d IEEE Transactions on Image Processing, vol. 29, pp. 5175\u20135190, 2020."]}, {"table": "<p>MethodYearParams MSpeed (FPS)mIoU%Deeplab[10]2017262.14.961.6PSPNet [5]2017250.85.469.1SegNet [7]201529.54655.6ENet [45]20160.36-61.3DFANet-A [27]20197.812064.7DFANet-B [27]20194.816059.3BiSeNet1 [19]20185.817565.7BiSeNet2 [19]201849.0116.368.7ICNet [50]201826.527.867.1DABNet [25]20190.7666.4AGLNet [64]20201.1290.169.4NDNet45-FCN8-LF [70]20201.1-57.5LBN-AA [40]20206.239.368.0BiSeNetV2/BiSeNetV2L [28]2021--72.4/73.2STDC1-Seg75 [24]20218.4197.673.0STDC2-Seg75 [24]202112.5152.273.9S<sup>2</sup>-FPN1817.8124.269.5S<sup>2</sup>-FPN3427.9107.271.0S<sup>2</sup>-FPN34M27.955.574.2</p>", "caption": "TABLE VIII: RESULTS OF THE MODEL ON CAMVID DATASET.* INDICATES THE MODELS PRE-TRAINED ON CITYSCAPES", "list_citation_info": ["[24] M. Fan, S. Lai, J. Huang, X. Wei, Z. Chai, J. Luo, and X. Wei, \u201cRethinking bisenet for real-time semantic segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 9716\u20139725.", "[27] H. Li, P. Xiong, H. Fan, and J. Sun, \u201cDfanet: Deep feature aggregation for real-time semantic segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 9522\u20139531.", "[45] A. Paszke, A. Chaurasia, S. Kim, and E. Culurciello, \u201cEnet: A deep neural network architecture for real-time semantic segmentation,\u201d arXiv preprint arXiv:1606.02147, 2016.", "[50] H. Zhao, X. Qi, X. Shen, J. Shi, and J. Jia, \u201cIcnet for real-time semantic segmentation on high-resolution images,\u201d in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 405\u2013420.", "[64] Q. Zhou, Y. Wang, Y. Fan, X. Wu, S. Zhang, B. Kang, and L. J. Latecki, \u201cAglnet: Towards real-time semantic segmentation of self-driving images via attention-guided lightweight network,\u201d Applied Soft Computing, vol. 96, p. 106682, 2020.", "[7] V. Badrinarayanan, A. Kendall, and R. Cipolla, \u201cSegnet: A deep convolutional encoder-decoder architecture for image segmentation,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 39, no. 12, pp. 2481\u20132495, 2017.", "[28] C. Yu, C. Gao, J. Wang, G. Yu, C. Shen, and N. Sang, \u201cBisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation,\u201d International Journal of Computer Vision, pp. 1\u201318, 2021.", "[40] G. Dong, Y. Yan, C. Shen, and H. Wang, \u201cReal-time high-performance semantic image segmentation of urban street scenes,\u201d IEEE Transactions on Intelligent Transportation Systems, vol. 22, no. 6, pp. 3258\u20133274, 2020.", "[19] C. Yu, J. Wang, C. Peng, C. Gao, G. Yu, and N. Sang, \u201cBisenet: Bilateral segmentation network for real-time semantic segmentation,\u201d in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 325\u2013341.", "[10] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, \u201cDeeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 40, no. 4, pp. 834\u2013848, 2017.", "[70] Z. Yang, H. Yu, M. Feng, W. Sun, X. Lin, M. Sun, Z.-H. Mao, and A. Mian, \u201cSmall object augmentation of urban scenes for real-time semantic segmentation,\u201d IEEE Transactions on Image Processing, vol. 29, pp. 5175\u20135190, 2020.", "[25] G. Li, I. Yun, J. Kim, and J. Kim, \u201cDabnet: Depth-wise asymmetric bottleneck for real-time semantic segmentation,\u201d arXiv preprint arXiv:1907.11357, 2019.", "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890."]}], "citation_info_to_title": {"[37] W. Chen, X. Gong, X. Liu, Q. Zhang, Y. Li, and Z. Wang, \u201cFasterseg: Searching for faster real-time semantic segmentation,\u201d arXiv preprint arXiv:1912.10917, 2019.": "Fasterseg: Searching for faster real-time semantic segmentation", "[5] H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia, \u201cPyramid scene parsing network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2881\u20132890.": "Pyramid Scene Parsing Network", "[34] S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang, and P. H. Torr, \u201cConditional random fields as recurrent neural networks,\u201d in Proceedings of the IEEE international conference on computer vision, 2015, pp. 1529\u20131537.": "Conditional random fields as recurrent neural networks", "[7] V. Badrinarayanan, A. Kendall, and R. Cipolla, \u201cSegnet: A deep convolutional encoder-decoder architecture for image segmentation,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 39, no. 12, pp. 2481\u20132495, 2017.": "Segnet: A deep convolutional encoder-decoder architecture for image segmentation", "[45] A. Paszke, A. Chaurasia, S. Kim, and E. Culurciello, \u201cEnet: A deep neural network architecture for real-time semantic segmentation,\u201d arXiv preprint arXiv:1606.02147, 2016.": "Enet: A deep neural network architecture for real-time semantic segmentation", "[35] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, \u201cSemantic image segmentation with deep convolutional nets and fully connected crfs,\u201d arXiv preprint arXiv:1412.7062, 2014.": "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs", "[19] C. Yu, J. Wang, C. Peng, C. Gao, G. Yu, and N. Sang, \u201cBisenet: Bilateral segmentation network for real-time semantic segmentation,\u201d in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 325\u2013341.": "Bisenet: Bilateral segmentation network for real-time semantic segmentation", "[28] C. Yu, C. Gao, J. Wang, G. Yu, C. Shen, and N. Sang, \u201cBisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation,\u201d International Journal of Computer Vision, pp. 1\u201318, 2021.": "Bisenet v2: Bilateral network with guided aggregation for real-time semantic segmentation", "[39] P. Hu, F. Perazzi, F. C. Heilbron, O. Wang, Z. Lin, K. Saenko, and S. Sclaroff, \u201cReal-time semantic segmentation with fast attention,\u201d IEEE Robotics and Automation Letters, vol. 6, no. 1, pp. 263\u2013270, 2020.": "Real-time semantic segmentation with fast attention", "[24] M. Fan, S. Lai, J. Huang, X. Wei, Z. Chai, J. Luo, and X. Wei, \u201cRethinking bisenet for real-time semantic segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021, pp. 9716\u20139725.": "Rethinking bisenet for real-time semantic segmentation", "[10] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, \u201cDeeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 40, no. 4, pp. 834\u2013848, 2017.": "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs", "[70] Z. Yang, H. Yu, M. Feng, W. Sun, X. Lin, M. Sun, Z.-H. Mao, and A. Mian, \u201cSmall object augmentation of urban scenes for real-time semantic segmentation,\u201d IEEE Transactions on Image Processing, vol. 29, pp. 5175\u20135190, 2020.": "Small object augmentation of urban scenes for real-time semantic segmentation", "[40] G. Dong, Y. Yan, C. Shen, and H. Wang, \u201cReal-time high-performance semantic image segmentation of urban street scenes,\u201d IEEE Transactions on Intelligent Transportation Systems, vol. 22, no. 6, pp. 3258\u20133274, 2020.": "Real-time high-performance semantic image segmentation of urban street scenes", "[38] P. Hu, F. Caba, O. Wang, Z. Lin, S. Sclaroff, and F. Perazzi, \u201cTemporally distributed networks for fast video semantic segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 8818\u20138827.": "Temporally distributed networks for fast video semantic segmentation", "[50] H. Zhao, X. Qi, X. Shen, J. Shi, and J. Jia, \u201cIcnet for real-time semantic segmentation on high-resolution images,\u201d in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 405\u2013420.": "Icnet for real-time semantic segmentation on high-resolution images", "[41] P. Li, X. Dong, X. Yu, and Y. Yang, \u201cWhen humans meet machines: Towards efficient segmentation networks.\u201d in BMVC, 2020.": "When humans meet machines: Towards efficient segmentation networks", "[25] G. Li, I. Yun, J. Kim, and J. Kim, \u201cDabnet: Depth-wise asymmetric bottleneck for real-time semantic segmentation,\u201d arXiv preprint arXiv:1907.11357, 2019.": "Dabnet: Depth-wise asymmetric bottleneck for real-time semantic segmentation", "[36] F. Yu and V. Koltun, \u201cMulti-scale context aggregation by dilated convolutions (2015),\u201d arXiv preprint arXiv:1511.07122, 2016.": "Multi-scale context aggregation by dilated convolutions", "[64] Q. Zhou, Y. Wang, Y. Fan, X. Wu, S. Zhang, B. Kang, and L. J. Latecki, \u201cAglnet: Towards real-time semantic segmentation of self-driving images via attention-guided lightweight network,\u201d Applied Soft Computing, vol. 96, p. 106682, 2020.": "Aglnet: Towards Real-Time Semantic Segmentation of Self-Driving Images via Attention-Guided Lightweight Network", "[6] J. Long, E. Shelhamer, and T. Darrell, \u201cFully convolutional networks for semantic segmentation,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 3431\u20133440.": "Fully Convolutional Networks for Semantic Segmentation", "[27] H. Li, P. Xiong, H. Fan, and J. Sun, \u201cDfanet: Deep feature aggregation for real-time semantic segmentation,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 9522\u20139531.": "Dfanet: Deep feature aggregation for real-time semantic segmentation"}, "source_title_to_arxiv_id": {"Rethinking bisenet for real-time semantic segmentation": "2104.13188"}}