{"title": "Blind Users Accessing Their Training Images in Teachable Object Recognizers", "abstract": "Iteration of training and evaluating a machine learning model is an important\nprocess to improve its performance. However, while teachable interfaces enable\nblind users to train and test an object recognizer with photos taken in their\ndistinctive environment, accessibility of training iteration and evaluation\nsteps has received little attention. Iteration assumes visual inspection of the\ntraining photos, which is inaccessible for blind users. We explore this\nchallenge through MyCam, a mobile app that incorporates automatically estimated\ndescriptors for non-visual access to the photos in the users' training sets. We\nexplore how blind participants (N=12) interact with MyCam and the descriptors\nthrough an evaluation study in their homes. We demonstrate that the real-time\nphoto-level descriptors enabled blind users to reduce photos with cropped\nobjects, and that participants could add more variations by iterating through\nand accessing the quality of their training sets. Also, Participants found the\napp simple to use indicating that they could effectively train it and that the\ndescriptors were useful. However, subjective responses were not reflected in\nthe performance of their models, partially due to little variation in training\nand cluttered backgrounds.", "authors": ["Jonggi Hong", "Jaina Gandhi", "Ernest Essuah Mensah", "Farnaz Zamiri Zeraati", "Ebrima Haddy Jarjue", "Kyungjun Lee", "Hernisa Kacorri"], "published_date": "2022_08_16", "pdf_url": "http://arxiv.org/pdf/2208.07968v2", "list_table_and_caption": [{"table": "<table><tr><td></td><td></td><td>(Kacorriet al., 2017)</td><td>(Sosa-Garc\u00edaand Odone, 2017)</td><td>(Leeet al., 2019)</td><td>(Honget al., 2020)</td><td>(Ahmetovic et al., 2020)</td><td>(Vartiainenet al., 2020)</td><td>(Dwivedi et al., 2021)</td><td>(Theodorou et al., 2021)</td><td>This study</td></tr><tr><td rowspan=\"3\">Participants</td><td>Blind Adults</td><td>8</td><td>14</td><td>9</td><td></td><td>10</td><td></td><td></td><td>52</td><td>12</td></tr><tr><td>Sighted Adults</td><td>2</td><td>10</td><td>2</td><td>100</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Sighted Children</td><td></td><td></td><td></td><td></td><td></td><td>6</td><td>14</td><td></td><td></td></tr><tr><td rowspan=\"2\">Setting</td><td>Real-world</td><td>\\bullet</td><td></td><td></td><td>\\bullet</td><td>\\bullet</td><td></td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td></tr><tr><td>Controlled</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td></td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td></td><td></td></tr><tr><td rowspan=\"2\">Input</td><td>Photo</td><td>\\bullet</td><td></td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td></td><td>\\bullet</td></tr><tr><td>Video</td><td></td><td>\\bullet</td><td></td><td></td><td></td><td></td><td></td><td>\\bullet</td><td></td></tr><tr><td rowspan=\"3\">Tasks</td><td>Train</td><td>\\bullet</td><td></td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td></tr><tr><td>Test</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td><td>\\bullet</td></tr><tr><td>Iterate</td><td></td><td></td><td></td><td>\\bullet</td><td></td><td>\\bullet</td><td>\\bullet</td><td></td><td>\\bullet</td></tr><tr><td rowspan=\"2\">Access</td><td>Framing</td><td></td><td></td><td>\\bullet</td><td></td><td>\\bullet</td><td></td><td></td><td></td><td></td></tr><tr><td>Review</td><td></td><td></td><td></td><td>\\bullet</td><td></td><td>\\bullet</td><td>\\bullet</td><td></td><td>\\bullet</td></tr></table>", "caption": "Table 1. Characteristics of related studies on teachable object recognizers juxtaposed with ours.", "list_citation_info": ["Ahmetovic et al. (2020) Dragan Ahmetovic, Daisuke Sato, Uran Oh, Tatsuya Ishihara, Kris Kitani, and Chieko Asakawa. 2020. ReCog: Supporting Blind People in Recognizing Personal Objects. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3313831.3376143", "Dwivedi et al. (2021) Utkarsh Dwivedi, Jaina Gandhi, Raj Parikh, Merijke Coenraad, Elizabeth Bonsignore, and Hernisa Kacorri. 2021. Exploring Machine Teaching with Children. In 2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). 1\u201311. https://doi.org/10.1109/VL/HCC51201.2021.9576171", "Vartiainen et al. (2020) Henriikka Vartiainen, Matti Tedre, and Teemu Valtonen. 2020. Learning machine learning with very young children: Who is teaching whom? International Journal of Child-Computer Interaction 25 (Sept. 2020), 1\u201311. https://linkinghub.elsevier.com/retrieve/pii/S2212868920300155", "Sosa-Garc\u00eda and Odone (2017) Joan Sosa-Garc\u00eda and Francesca Odone. 2017. \u201cHands On\u201d Visual Recognition for Visually Impaired Users. ACM Trans. Access. Comput. 10, 3, Article 8 (Aug. 2017), 30 pages. https://doi.org/10.1145/3060056", "Theodorou et al. (2021) Lida Theodorou, Daniela Massiceti, Luisa Zintgraf, Simone Stumpf, Cecily Morrison, Edward Cutrell, Matthew Tobias Harris, and Katja Hofmann. 2021. Disability-First Dataset Creation: Lessons from Constructing a Dataset for Teachable Object Recognition with Blind and Low Vision Data Collectors. In The 23rd International ACM SIGACCESS Conference on Computers and Accessibility (Virtual Event, USA) (ASSETS \u201921). Association for Computing Machinery, New York, NY, USA, Article 27, 12 pages. https://doi.org/10.1145/3441852.3471225", "Hong et al. (2020) Jonggi Hong, Kyungjun Lee, June Xu, and Hernisa Kacorri. 2020. Crowdsourcing the Perception of Machine Teaching. Association for Computing Machinery, New York, NY, USA, 1\u201314. https://doi.org/10.1145/3313831.3376428", "Kacorri et al. (2017) Hernisa Kacorri, Kris M. Kitani, Jeffrey P. Bigham, and Chieko Asakawa. 2017. People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado, USA) (CHI \u201917). Association for Computing Machinery, New York, NY, USA, 5839\u20135849. https://doi.org/10.1145/3025453.3025899", "Lee et al. (2019) Kyungjun Lee, Jonggi Hong, Simone Pimento, Ebrima Jarjue, and Hernisa Kacorri. 2019. Revisiting Blind Photography in the Context of Teachable Object Recognizers. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility (Pittsburgh, PA, USA) (ASSETS \u201919). Association for Computing Machinery, New York, NY, USA, 83\u201395. https://doi.org/10.1145/3308561.3353799"]}, {"table": "<table><tr><td colspan=\"2\">Photo-level descriptors</td></tr><tr><td><p>Small object</p></td><td><p>The bounding box of the object is smaller than 1/8 (12.5%) of the image.</p></td></tr><tr><td><p>Cropped object</p></td><td><p>The object is partially included in the image.</p></td></tr><tr><td><p>Blurry photo</p></td><td><p>The photo is too blurry to recognize textures or texts.</p></td></tr><tr><td><p>Hand in photo</p></td><td><p>A user\u2019s hand is visible in the image.</p></td></tr><tr><td colspan=\"2\">Set-level descriptors</td></tr><tr><td><p>Variation in size</p></td><td><p>A set of images shows objects with different sizes.</p></td></tr><tr><td><p>Variation in perspective</p></td><td><p>A set of images shows different sides of objects.</p></td></tr><tr><td><p>Variation in background</p></td><td><p>A set of images show backgrounds with different textures or items.</p></td></tr></table>", "caption": "Table 2. Photo-level and set-level descriptors. The descriptors are informed by prior studies with sighted and blind people who have no machine learning expertise looking at the way they synthesize their data for training (Kacorriet al., 2017; Leeet al., 2019; Honget al., 2019, 2020; Dwivedi et al., 2021).", "list_citation_info": ["Kacorri et al. (2017) Hernisa Kacorri, Kris M. Kitani, Jeffrey P. Bigham, and Chieko Asakawa. 2017. People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado, USA) (CHI \u201917). Association for Computing Machinery, New York, NY, USA, 5839\u20135849. https://doi.org/10.1145/3025453.3025899"]}], "citation_info_to_title": {"Sosa-Garc\u00eda and Odone (2017) Joan Sosa-Garc\u00eda and Francesca Odone. 2017. \u201cHands On\u201d Visual Recognition for Visually Impaired Users. ACM Trans. Access. Comput. 10, 3, Article 8 (Aug. 2017), 30 pages. https://doi.org/10.1145/3060056": "Hands On Visual Recognition for Visually Impaired Users", "Lee et al. (2019) Kyungjun Lee, Jonggi Hong, Simone Pimento, Ebrima Jarjue, and Hernisa Kacorri. 2019. Revisiting Blind Photography in the Context of Teachable Object Recognizers. In The 21st International ACM SIGACCESS Conference on Computers and Accessibility (Pittsburgh, PA, USA) (ASSETS \u201919). Association for Computing Machinery, New York, NY, USA, 83\u201395. https://doi.org/10.1145/3308561.3353799": "Revisiting Blind Photography in the Context of Teachable Object Recognizers", "Theodorou et al. (2021) Lida Theodorou, Daniela Massiceti, Luisa Zintgraf, Simone Stumpf, Cecily Morrison, Edward Cutrell, Matthew Tobias Harris, and Katja Hofmann. 2021. Disability-First Dataset Creation: Lessons from Constructing a Dataset for Teachable Object Recognition with Blind and Low Vision Data Collectors. In The 23rd International ACM SIGACCESS Conference on Computers and Accessibility (Virtual Event, USA) (ASSETS \u201921). Association for Computing Machinery, New York, NY, USA, Article 27, 12 pages. https://doi.org/10.1145/3441852.3471225": "Disability-First Dataset Creation: Lessons from Constructing a Dataset for Teachable Object Recognition with Blind and Low Vision Data Collectors", "Dwivedi et al. (2021) Utkarsh Dwivedi, Jaina Gandhi, Raj Parikh, Merijke Coenraad, Elizabeth Bonsignore, and Hernisa Kacorri. 2021. Exploring Machine Teaching with Children. In 2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). 1\u201311. https://doi.org/10.1109/VL/HCC51201.2021.9576171": "Exploring Machine Teaching with Children", "Vartiainen et al. (2020) Henriikka Vartiainen, Matti Tedre, and Teemu Valtonen. 2020. Learning machine learning with very young children: Who is teaching whom? International Journal of Child-Computer Interaction 25 (Sept. 2020), 1\u201311. https://linkinghub.elsevier.com/retrieve/pii/S2212868920300155": "Learning machine learning with very young children: Who is teaching whom?", "Hong et al. (2020) Jonggi Hong, Kyungjun Lee, June Xu, and Hernisa Kacorri. 2020. Crowdsourcing the Perception of Machine Teaching. Association for Computing Machinery, New York, NY, USA, 1\u201314. https://doi.org/10.1145/3313831.3376428": "Crowdsourcing the Perception of Machine Teaching", "Kacorri et al. (2017) Hernisa Kacorri, Kris M. Kitani, Jeffrey P. Bigham, and Chieko Asakawa. 2017. People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (Denver, Colorado, USA) (CHI \u201917). Association for Computing Machinery, New York, NY, USA, 5839\u20135849. https://doi.org/10.1145/3025453.3025899": "People with Visual Impairment Training Personal Object Recognizers: Feasibility and Challenges", "Ahmetovic et al. (2020) Dragan Ahmetovic, Daisuke Sato, Uran Oh, Tatsuya Ishihara, Kris Kitani, and Chieko Asakawa. 2020. ReCog: Supporting Blind People in Recognizing Personal Objects. Association for Computing Machinery, New York, NY, USA, 1\u201312. https://doi.org/10.1145/3313831.3376143": "ReCog: Supporting Blind People in Recognizing Personal Objects"}, "source_title_to_arxiv_id": {"Exploring Machine Teaching with Children": "2109.11434"}}