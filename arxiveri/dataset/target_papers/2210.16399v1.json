{"title": "U-Net-based Models for Skin Lesion Segmentation: More Attention and Augmentation", "abstract": "According to WHO[1], since the 1970s, diagnosis of melanoma skin cancer has\nbeen more frequent. However, if detected early, the 5-year survival rate for\nmelanoma can increase to 99 percent. In this regard, skin lesion segmentation\ncan be pivotal in monitoring and treatment planning. In this work, ten models\nand four augmentation configurations are trained on the ISIC 2016 dataset. The\nperformance and overfitting are compared utilizing five metrics. Our results\nshow that the U-Net-Resnet50 and the R2U-Net have the highest metrics value,\nalong with two data augmentation scenarios. We also investigate CBAM and AG\nblocks in the U-Net architecture, which enhances segmentation performance at a\nmeager computational cost. In addition, we propose using pyramid, AG, and CBAM\nblocks in a sequence, which significantly surpasses the results of using the\ntwo individually. Finally, our experiments show that models that have exploited\nattention modules successfully overcome common skin lesion segmentation\nproblems. Lastly, in the spirit of reproducible research, we implement models\nand codes publicly available.", "authors": ["Pooya Mohammadi Kazaj", "MohammadHossein Koosheshi", "Ali Shahedi", "Alireza Vafaei Sadr"], "published_date": "2022_10_28", "pdf_url": "http://arxiv.org/pdf/2210.16399v1", "list_table_and_caption": [{"table": "<table><thead><tr><th>Label</th><th>Model name</th><th># parameters[M]</th><th># Model size[MB]</th></tr></thead><tbody><tr><td>R2UC</td><td>r2unet cbam</td><td>25.4</td><td>102.1</td></tr><tr><td>R2U</td><td>r2unetalom2018recurrent </td><td>96.1</td><td>384.7</td></tr><tr><td>UR50</td><td>unet res50</td><td>20.7</td><td>83.1</td></tr><tr><td>U-Net</td><td>unet conv deconvronneberger2015u </td><td>7.7</td><td>31.0</td></tr><tr><td>UAG</td><td>unet attention gateoktay2018attention </td><td>0.8</td><td>3.6</td></tr><tr><td>UC</td><td>unet cbam</td><td>7.7</td><td>31.2</td></tr><tr><td>UCG</td><td>unet cbam gate</td><td>0.9</td><td>3.7</td></tr><tr><td>UPCG</td><td>unet pyramid cbam gate</td><td>4.4</td><td>17.8</td></tr><tr><td>MCGU</td><td>mcg unetasadi2020multi </td><td>1.7</td><td>6.9</td></tr><tr><td>DU</td><td>double unetjha2020doubleu </td><td>29.3</td><td>117.7</td></tr></tbody></table>", "caption": "Table 1: Information of the models examined in this study. ", "list_citation_info": ["(17) D. Jha, M. A. Riegler, D. Johansen, P. Halvorsen, H. D. Johansen, Doubleu-net: A deep convolutional neural network for medical image segmentation, in: 2020 IEEE 33rd International symposium on computer-based medical systems (CBMS), IEEE, 2020, pp. 558\u2013564.", "(14) M. Z. Alom, M. Hasan, C. Yakopcic, T. M. Taha, V. K. Asari, Recurrent residual convolutional neural network based on u-net (r2u-net) for medical image segmentation, arXiv preprint arXiv:1802.06955 (2018).", "(24) M. Asadi-Aghbolaghi, R. Azad, M. Fathy, S. Escalera, Multi-level context gating of embedded collective knowledge for medical image segmentation, arXiv preprint arXiv:2003.05056 (2020).", "(23) O. Oktay, J. Schlemper, L. L. Folgoc, M. Lee, M. Heinrich, K. Misawa, K. Mori, S. McDonagh, N. Y. Hammerla, B. Kainz, et al., Attention u-net: Learning where to look for the pancreas, arXiv preprint arXiv:1804.03999 (2018).", "(9) O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for biomedical image segmentation, in: International Conference on Medical image computing and computer-assisted intervention, Springer, 2015, pp. 234\u2013241."]}], "citation_info_to_title": {"(17) D. Jha, M. A. Riegler, D. Johansen, P. Halvorsen, H. D. Johansen, Doubleu-net: A deep convolutional neural network for medical image segmentation, in: 2020 IEEE 33rd International symposium on computer-based medical systems (CBMS), IEEE, 2020, pp. 558\u2013564.": "Doubleu-net: A deep convolutional neural network for medical image segmentation", "(9) O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for biomedical image segmentation, in: International Conference on Medical image computing and computer-assisted intervention, Springer, 2015, pp. 234\u2013241.": "U-net: Convolutional networks for biomedical image segmentation", "(23) O. Oktay, J. Schlemper, L. L. Folgoc, M. Lee, M. Heinrich, K. Misawa, K. Mori, S. McDonagh, N. Y. Hammerla, B. Kainz, et al., Attention u-net: Learning where to look for the pancreas, arXiv preprint arXiv:1804.03999 (2018).": "Attention U-Net: Learning Where to Look for the Pancreas", "(14) M. Z. Alom, M. Hasan, C. Yakopcic, T. M. Taha, V. K. Asari, Recurrent residual convolutional neural network based on u-net (r2u-net) for medical image segmentation, arXiv preprint arXiv:1802.06955 (2018).": "Recurrent Residual Convolutional Neural Network Based on U-Net (R2U-Net) for Medical Image Segmentation", "(24) M. Asadi-Aghbolaghi, R. Azad, M. Fathy, S. Escalera, Multi-level context gating of embedded collective knowledge for medical image segmentation, arXiv preprint arXiv:2003.05056 (2020).": "Multi-level context gating of embedded collective knowledge for medical image segmentation"}, "source_title_to_arxiv_id": {"Attention U-Net: Learning Where to Look for the Pancreas": "1804.03999", "Recurrent Residual Convolutional Neural Network Based on U-Net (R2U-Net) for Medical Image Segmentation": "1802.06955"}}