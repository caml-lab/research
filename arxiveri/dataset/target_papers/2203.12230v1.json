{"title": "Negative Selection by Clustering for Contrastive Learning in Human Activity Recognition", "abstract": "Contrastive learning has been applied to Human Activity Recognition (HAR)\nbased on sensor data owing to its ability to achieve performance comparable to\nsupervised learning with a large amount of unlabeled data and a small amount of\nlabeled data. The pre-training task for contrastive learning is generally\ninstance discrimination, which specifies that each instance belongs to a single\nclass, but this will consider the same class of samples as negative examples.\nSuch a pre-training task is not conducive to human activity recognition tasks,\nwhich are mainly classification tasks. To address this problem, we follow\nSimCLR to propose a new contrastive learning framework that negative selection\nby clustering in HAR, which is called ClusterCLHAR. Compared with SimCLR, it\nredefines the negative pairs in the contrastive loss function by using\nunsupervised clustering methods to generate soft labels that mask other samples\nof the same cluster to avoid regarding them as negative samples. We evaluate\nClusterCLHAR on three benchmark datasets, USC-HAD, MotionSense, and UCI-HAR,\nusing mean F1-score as the evaluation metric. The experiment results show that\nit outperforms all the state-of-the-art methods applied to HAR in\nself-supervised learning and semi-supervised learning.", "authors": ["Jinqiang Wang", "Tao Zhu", "Liming Chen", "Huansheng Ning", "Yaping Wan"], "published_date": "2022_03_23", "pdf_url": "http://arxiv.org/pdf/2203.12230v1", "list_table_and_caption": [{"table": "<table><thead><tr><th>Method</th><th>Type</th><th>USC-HAD</th><th>MotionSense</th><th>UCI-HAR</th></tr><tr><th>TPN [33]</th><th>Sup.</th><th>55.60</th><th>93.00</th><th>94.27</th></tr></thead><tbody><tr><th>Multi-task SSL [33]</th><td>SSL</td><td>45.37</td><td>83.30</td><td>80.2</td></tr><tr><th>CAE [38]</th><td>SSL</td><td>48.82</td><td>82.50</td><td>80.26</td></tr><tr><th>Masked Reconstruction [39]</th><td>SSL</td><td>49.31</td><td>88.02</td><td>81.89</td></tr><tr><th>CPCHAR [40]</th><td>SSL</td><td>52.01</td><td>-</td><td>81.65</td></tr><tr><th>CSSHAR [31]</th><td>SSL</td><td>57.76</td><td>-</td><td>91.14</td></tr><tr><th>ClusterCLHAR (ours)</th><td>SSL</td><td>58.85</td><td>89.22</td><td>92.12</td></tr></tbody></table>", "caption": "TABLE I: Self-supervised learning", "list_citation_info": ["[40] H. Haresamudram, I. Essa, and T. Pl\u00f6tz, \u201cContrastive predictive coding for human activity recognition,\u201d Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 5, no. 2, pp. 1\u201326, 2021.", "[31] B. Khaertdinov, E. Ghaleb, and S. Asteriadis, \u201cContrastive self-supervised learning for sensor-based human activity recognition,\u201d in 2021 IEEE International Joint Conference on Biometrics (IJCB). IEEE, 2021, pp. 1\u20138.", "[38] H. Haresamudram, D. V. Anderson, and T. Pl\u00f6tz, \u201cOn the role of features in human activity recognition,\u201d in Proceedings of the 23rd International Symposium on Wearable Computers, 2019, pp. 78\u201388.", "[39] H. Haresamudram, A. Beedu, V. Agrawal, P. L. Grady, I. Essa, J. Hoffman, and T. Pl\u00f6tz, \u201cMasked reconstruction based self-supervision for human activity recognition,\u201d in Proceedings of the 2020 International Symposium on Wearable Computers, 2020, pp. 45\u201349.", "[33] A. Saeed, T. Ozcelebi, and J. Lukkien, \u201cMulti-task self-supervised learning for human activity detection,\u201d Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 3, no. 2, pp. 1\u201330, 2019."]}, {"table": "<table><thead><tr><th rowspan=\"3\"></th><th colspan=\"4\">USC-HAD</th><th colspan=\"4\">MotionSense</th><th colspan=\"4\">UCI-HAR</th></tr><tr><th colspan=\"2\">1%</th><th colspan=\"2\">10%</th><th colspan=\"2\">1%</th><th colspan=\"2\">10%</th><th colspan=\"2\">1%</th><th colspan=\"2\">10%</th></tr><tr><th>Linear.</th><th>Fine.</th><th>Linear.</th><th>Fine.</th><th>Linear.</th><th>Fine.</th><th>Linear.</th><th>Fine.</th><th>Linear.</th><th>Fine.</th><th>Linear.</th><th>Fine.</th></tr></thead><tbody><tr><th>TPN (Sup.) [33]</th><td colspan=\"2\">70.23</td><td colspan=\"2\">85.93</td><td colspan=\"2\">84.91</td><td colspan=\"2\">95.06</td><td colspan=\"2\">90.50</td><td colspan=\"2\">95.47</td></tr><tr><th>SimCLRHAR [30]</th><td>44.84</td><td>63.82</td><td>53.16</td><td>83.32</td><td>79.16</td><td>84.62</td><td>78.26</td><td>95.77</td><td>54.52</td><td>62.44</td><td>59.14</td><td>78.27</td></tr><tr><th>SimCLRHAR(resampling [32])</th><td>71.48</td><td>72.87</td><td>83.51</td><td>85.50</td><td>83.76</td><td>86.55</td><td>92.60</td><td>96.08</td><td>83.53</td><td>86.75</td><td>92.91</td><td>95.58</td></tr><tr><th>MoCoHAR [32]</th><td>68.60</td><td>69.20</td><td>78.51</td><td>85.84</td><td>77.66</td><td>85.49</td><td>91.72</td><td>96.63</td><td>83.56</td><td>87.41</td><td>91.89</td><td>95.49</td></tr><tr><th>NNCLR [23]</th><td>72.36</td><td>74.70</td><td>83.81</td><td>87.07</td><td>83.39</td><td>86.19</td><td>92.09</td><td>96.40</td><td>83.89</td><td>87.53</td><td>95.59</td><td>95.55</td></tr><tr><th>ClusterCLHAR (ours)</th><td>76.08</td><td>78.09</td><td>85.01</td><td>87.86</td><td>86.69</td><td>87.35</td><td>94.02</td><td>96.44</td><td>88.78</td><td>90.53</td><td>94.68</td><td>95.91</td></tr></tbody></table>", "caption": "TABLE II: Semi-supervised learning", "list_citation_info": ["[32] J. Wang, T. Zhu, J. Gan, H. Ning, and Y. Wan, \u201cSensor data augmentation with resampling for contrastive learning in human activity recognition,\u201d arXiv preprint arXiv:2109.02054, 2021.", "[23] D. Dwibedi, Y. Aytar, J. Tompson, P. Sermanet, and A. Zisserman, \u201cWith a little help from my friends: Nearest-neighbor contrastive learning of visual representations,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 9588\u20139597.", "[33] A. Saeed, T. Ozcelebi, and J. Lukkien, \u201cMulti-task self-supervised learning for human activity detection,\u201d Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 3, no. 2, pp. 1\u201330, 2019.", "[30] C. I. Tang, I. Perez-Pozuelo, D. Spathis, and C. Mascolo, \u201cExploring contrastive learning in human activity recognition for healthcare,\u201d arXiv preprint arXiv:2011.11542, 2020."]}], "citation_info_to_title": {"[38] H. Haresamudram, D. V. Anderson, and T. Pl\u00f6tz, \u201cOn the role of features in human activity recognition,\u201d in Proceedings of the 23rd International Symposium on Wearable Computers, 2019, pp. 78\u201388.": "On the role of features in human activity recognition", "[31] B. Khaertdinov, E. Ghaleb, and S. Asteriadis, \u201cContrastive self-supervised learning for sensor-based human activity recognition,\u201d in 2021 IEEE International Joint Conference on Biometrics (IJCB). IEEE, 2021, pp. 1\u20138.": "Contrastive self-supervised learning for sensor-based human activity recognition", "[32] J. Wang, T. Zhu, J. Gan, H. Ning, and Y. Wan, \u201cSensor data augmentation with resampling for contrastive learning in human activity recognition,\u201d arXiv preprint arXiv:2109.02054, 2021.": "Sensor data augmentation with resampling for contrastive learning in human activity recognition", "[33] A. Saeed, T. Ozcelebi, and J. Lukkien, \u201cMulti-task self-supervised learning for human activity detection,\u201d Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 3, no. 2, pp. 1\u201330, 2019.": "Multi-task self-supervised learning for human activity detection", "[40] H. Haresamudram, I. Essa, and T. Pl\u00f6tz, \u201cContrastive predictive coding for human activity recognition,\u201d Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 5, no. 2, pp. 1\u201326, 2021.": "Contrastive predictive coding for human activity recognition", "[23] D. Dwibedi, Y. Aytar, J. Tompson, P. Sermanet, and A. Zisserman, \u201cWith a little help from my friends: Nearest-neighbor contrastive learning of visual representations,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 9588\u20139597.": "With a little help from my friends: Nearest-neighbor contrastive learning of visual representations", "[30] C. I. Tang, I. Perez-Pozuelo, D. Spathis, and C. Mascolo, \u201cExploring contrastive learning in human activity recognition for healthcare,\u201d arXiv preprint arXiv:2011.11542, 2020.": "Exploring contrastive learning in human activity recognition for healthcare", "[39] H. Haresamudram, A. Beedu, V. Agrawal, P. L. Grady, I. Essa, J. Hoffman, and T. Pl\u00f6tz, \u201cMasked reconstruction based self-supervision for human activity recognition,\u201d in Proceedings of the 2020 International Symposium on Wearable Computers, 2020, pp. 45\u201349.": "Masked reconstruction based self-supervision for human activity recognition"}, "source_title_to_arxiv_id": {"Sensor data augmentation with resampling for contrastive learning in human activity recognition": "2109.02054"}}