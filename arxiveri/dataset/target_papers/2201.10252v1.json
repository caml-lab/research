{"title": "DocEnTr: An End-to-End Document Image Enhancement Transformer", "abstract": "Document images can be affected by many degradation scenarios, which cause\nrecognition and processing difficulties. In this age of digitization, it is\nimportant to denoise them for proper usage. To address this challenge, we\npresent a new encoder-decoder architecture based on vision transformers to\nenhance both machine-printed and handwritten document images, in an end-to-end\nfashion. The encoder operates directly on the pixel patches with their\npositional information without the use of any convolutional layers, while the\ndecoder reconstructs a clean image from the encoded patches. Conducted\nexperiments show a superiority of the proposed model compared to the state-of\nthe-art methods on several DIBCO benchmarks. Code and models will be publicly\navailable at: \\url{https://github.com/dali92002/DocEnTR}.", "authors": ["Mohamed Ali Souibgui", "Sanket Biswas", "Sana Khamekhem Jemni", "Yousri Kessentini", "Alicia Forn\u00e9s", "Josep Llad\u00f3s", "Umapada Pal"], "published_date": "2022_01_25", "pdf_url": "http://arxiv.org/pdf/2201.10252v1", "list_table_and_caption": [{"table": "<table><thead><tr><th>Method</th><th>Model</th><th>PSNR \\uparrow</th><th>FM \\uparrow</th><th>F{}_{ps} \\uparrow</th><th>DRD \\downarrow</th></tr></thead><tbody><tr><td>Otsu [15]</td><td>Thres.</td><td>15.70</td><td>82.10</td><td>\u2013</td><td>9.00</td></tr><tr><td>Savoula et al. [16]</td><td>Thres.</td><td>15.60</td><td>82.10</td><td>\u2013</td><td>8.50</td></tr><tr><td>Vo et al. [41]</td><td>CNN</td><td>20.10</td><td>93.30</td><td>\u2013</td><td>2.00</td></tr><tr><td>Kang et al [2]</td><td>CNN</td><td>19.90</td><td>95.50</td><td>\u2013</td><td>1.80</td></tr><tr><td>Tensmeyer et al [25]</td><td>CNN</td><td>20.11</td><td>93.60</td><td>97.70</td><td>1.85</td></tr><tr><td>Zhao et al. [41]</td><td>cGAN</td><td>20.30</td><td>93.80</td><td>\u2013</td><td>1.80</td></tr><tr><td>DocEnTr-Base{8}</td><td>Tr</td><td>20.81</td><td>94.37</td><td>96.15</td><td>1.63</td></tr><tr><td>DocEnTr-Base{16}</td><td>Tr</td><td>20.11</td><td>93.48</td><td>96.12</td><td>1.93</td></tr><tr><td>DocEnTr-Large{16}</td><td>Tr</td><td>20.62</td><td>94.24</td><td>96.71</td><td>1.69</td></tr></tbody></table>", "caption": "TABLE IV: Comparative results of our proposed method on DIBCO 2011 Dataset. Thresh: Thresholding, Tr: Transformers.", "list_citation_info": ["[41] Q.N. Vo, S.H. Kim, H.J. Yang, G. Lee, \u201cBinarization of degraded document images based on hierarchical deep supervised network,\u201d Pattern Recognition, vol. 74, pp. 568\u2013\u2013586, 2018.", "[2] S. Kang, B. K. Iwana, and S. Uchida, \u201cComplex image processing with less data document image binarization by integrating multiple pretrained u-net modules,\u201d Pattern Recognition, vol. 109, p. 107577, 2021.", "[15] N. Otsu, \u201cA threshold selection method from gray-level histograms,\u201d IEEE transactions on systems, man, and cybernetics, vol. 9, no. 1, pp. 62\u201366, 1979.", "[25] C. Tensmeyer and T. Martinez, \u201cDocument image binarization with fully convolutional neural networks,\u201d in 2017 14th IAPR international conference on document analysis and recognition (ICDAR), vol. 1. IEEE, 2017, pp. 99\u2013104.", "[16] J. Sauvola and M. Pietik\u00e4inen, \u201cAdaptive document image binarization,\u201d Pattern recognition, vol. 33, no. 2, pp. 225\u2013236, 2000."]}, {"table": "<table><thead><tr><th>Method</th><th>Model</th><th>PSNR \\uparrow</th><th>FM \\uparrow</th><th>F{}_{ps} \\uparrow</th><th>DRD \\downarrow</th></tr></thead><tbody><tr><td>Otsu [15]</td><td>Thres.</td><td>15.03</td><td>80.18</td><td>82.65</td><td>26.46</td></tr><tr><td>Savoula et al. [16]</td><td>Thres.</td><td>16.71</td><td>82.89</td><td>87.95</td><td>6.59</td></tr><tr><td>Kang et al [2]</td><td>CNN</td><td>21.37</td><td>95.16</td><td>96.44</td><td>1.13</td></tr><tr><td>Tensmeyer et al [25]</td><td>CNN</td><td>20.60</td><td>92.53</td><td>96.67</td><td>2.48</td></tr><tr><td>Zhao et al. [41]</td><td>cGAN</td><td>21.91</td><td>94.96</td><td>96.15</td><td>1.55</td></tr><tr><td>Jemni et al. [3]</td><td>cGAN</td><td>22.00</td><td>95.18</td><td>94.63</td><td>1.62</td></tr><tr><td>DocEnTr-Base{8}</td><td>Tr</td><td>22.29</td><td>95.31</td><td>96.29</td><td>1.60</td></tr><tr><td>DocEnTr-Base{16}</td><td>Tr</td><td>21.03</td><td>93.31</td><td>94.72</td><td>2.31</td></tr><tr><td>DocEnTr-Large{16}</td><td>Tr</td><td>22.04</td><td>95.09</td><td>96.00</td><td>1.64</td></tr></tbody></table>", "caption": "TABLE V: Comparative results of our proposed method on H-DIBCO 2012 Dataset. Thresh: Thresholding, Tr: Transformers.", "list_citation_info": ["[41] Q.N. Vo, S.H. Kim, H.J. Yang, G. Lee, \u201cBinarization of degraded document images based on hierarchical deep supervised network,\u201d Pattern Recognition, vol. 74, pp. 568\u2013\u2013586, 2018.", "[3] S. K. Jemni, M. A. Souibgui, Y. Kessentini, and A. Forn\u00e9s, \u201cEnhance to read better: A multi-task adversarial network for handwritten document image enhancement,\u201d Pattern Recognition, vol. 123, p. 108370, 2022.", "[2] S. Kang, B. K. Iwana, and S. Uchida, \u201cComplex image processing with less data document image binarization by integrating multiple pretrained u-net modules,\u201d Pattern Recognition, vol. 109, p. 107577, 2021.", "[15] N. Otsu, \u201cA threshold selection method from gray-level histograms,\u201d IEEE transactions on systems, man, and cybernetics, vol. 9, no. 1, pp. 62\u201366, 1979.", "[25] C. Tensmeyer and T. Martinez, \u201cDocument image binarization with fully convolutional neural networks,\u201d in 2017 14th IAPR international conference on document analysis and recognition (ICDAR), vol. 1. IEEE, 2017, pp. 99\u2013104.", "[16] J. Sauvola and M. Pietik\u00e4inen, \u201cAdaptive document image binarization,\u201d Pattern recognition, vol. 33, no. 2, pp. 225\u2013236, 2000."]}, {"table": "<table><thead><tr><th>Method</th><th>Model</th><th>PSNR \\uparrow</th><th>FM \\uparrow</th><th>F{}_{ps} \\uparrow</th><th>DRD \\downarrow</th></tr></thead><tbody><tr><td>Otsu [15]</td><td>Thres.</td><td>13.85</td><td>77.73</td><td>77.89</td><td>15.54</td></tr><tr><td>Savoula et al. [16]</td><td>Thres.</td><td>14.25</td><td>77.11</td><td>84.1</td><td>8.85</td></tr><tr><td>Kang et al [2]</td><td>CNN</td><td>15.85</td><td>91.57</td><td>93.55</td><td>2.92</td></tr><tr><td>Competition top [19]</td><td>CNN</td><td>18.28</td><td>91.04</td><td>92.86</td><td>3.40</td></tr><tr><td>Zhao et al. [41]</td><td>cGAN</td><td>17.83</td><td>90.73</td><td>92.58</td><td>3.58</td></tr><tr><td>Jemni et al. [3]</td><td>cGAN</td><td>17.45</td><td>89.8</td><td>89.95</td><td>4.03</td></tr><tr><td>DocEnTr-Base{8}</td><td>Tr</td><td>19.11</td><td>92.53</td><td>95.15</td><td>2.37</td></tr><tr><td>DocEnTr-Base{16}</td><td>Tr</td><td>18.69</td><td>91.66</td><td>94.11</td><td>2.63</td></tr><tr><td>DocEnTr-Large{16}</td><td>Tr</td><td>18.85</td><td>92.14</td><td>94.58</td><td>2.53</td></tr></tbody></table>", "caption": "TABLE VI: Comparative results of our proposed method on DIBCO 2017 Dataset. Thresh: Thresholding, Tr: Transformers.", "list_citation_info": ["[19] I. Pratikakis, K. Zagoris, G. Barlas, B. Gatos, \u201cIcdar 2017 competition on document image binarization (dibco 2017),\u201d in 2017 International Conference on Document Analysis and Recognition. IEEE, 2017, pp. 1395\u2013\u20131403.", "[41] Q.N. Vo, S.H. Kim, H.J. Yang, G. Lee, \u201cBinarization of degraded document images based on hierarchical deep supervised network,\u201d Pattern Recognition, vol. 74, pp. 568\u2013\u2013586, 2018.", "[3] S. K. Jemni, M. A. Souibgui, Y. Kessentini, and A. Forn\u00e9s, \u201cEnhance to read better: A multi-task adversarial network for handwritten document image enhancement,\u201d Pattern Recognition, vol. 123, p. 108370, 2022.", "[2] S. Kang, B. K. Iwana, and S. Uchida, \u201cComplex image processing with less data document image binarization by integrating multiple pretrained u-net modules,\u201d Pattern Recognition, vol. 109, p. 107577, 2021.", "[15] N. Otsu, \u201cA threshold selection method from gray-level histograms,\u201d IEEE transactions on systems, man, and cybernetics, vol. 9, no. 1, pp. 62\u201366, 1979.", "[16] J. Sauvola and M. Pietik\u00e4inen, \u201cAdaptive document image binarization,\u201d Pattern recognition, vol. 33, no. 2, pp. 225\u2013236, 2000."]}, {"table": "<table><thead><tr><th>Method</th><th>Model</th><th>PSNR \\uparrow</th><th>FM \\uparrow</th><th>F{}_{ps} \\uparrow</th><th>DRD \\downarrow</th></tr></thead><tbody><tr><td>Otsu [15]</td><td>Thres.</td><td>9.74</td><td>51.45</td><td>53.05</td><td>59.07</td></tr><tr><td>Savoula et al. [16]</td><td>Thres.</td><td>13.78</td><td>67.81</td><td>74.08</td><td>17.69</td></tr><tr><td>Kang et al [2]</td><td>CNN</td><td>19.39</td><td>89.71</td><td>91.62</td><td>2.51</td></tr><tr><td>Competition top [19]</td><td>CNN</td><td>19.11</td><td>88.34</td><td>90.24</td><td>4.92</td></tr><tr><td>Zhao et al. [41]</td><td>cGAN</td><td>18.37</td><td>87.73</td><td>90.60</td><td>4.58</td></tr><tr><td>Jemni et al. [3]</td><td>cGAN</td><td>20.18</td><td>92.41</td><td>94.35</td><td>2.60</td></tr><tr><td>DocEnTr-Base{8}</td><td>Tr</td><td>19.46</td><td>90.59</td><td>93.97</td><td>3.35</td></tr><tr><td>DocEnTr-Base{16}</td><td>Tr</td><td>19.33</td><td>89.97</td><td>93.5</td><td>3.68</td></tr><tr><td>DocEnTr-Large{16}</td><td>Tr</td><td>19.47</td><td>89.21</td><td>92.54</td><td>3.96</td></tr></tbody></table>", "caption": "TABLE VII: Comparative results of our proposed method on DIBCO 2018 Dataset. Thresh: Thresholding, Tr: Transformers.", "list_citation_info": ["[19] I. Pratikakis, K. Zagoris, G. Barlas, B. Gatos, \u201cIcdar 2017 competition on document image binarization (dibco 2017),\u201d in 2017 International Conference on Document Analysis and Recognition. IEEE, 2017, pp. 1395\u2013\u20131403.", "[41] Q.N. Vo, S.H. Kim, H.J. Yang, G. Lee, \u201cBinarization of degraded document images based on hierarchical deep supervised network,\u201d Pattern Recognition, vol. 74, pp. 568\u2013\u2013586, 2018.", "[3] S. K. Jemni, M. A. Souibgui, Y. Kessentini, and A. Forn\u00e9s, \u201cEnhance to read better: A multi-task adversarial network for handwritten document image enhancement,\u201d Pattern Recognition, vol. 123, p. 108370, 2022.", "[2] S. Kang, B. K. Iwana, and S. Uchida, \u201cComplex image processing with less data document image binarization by integrating multiple pretrained u-net modules,\u201d Pattern Recognition, vol. 109, p. 107577, 2021.", "[15] N. Otsu, \u201cA threshold selection method from gray-level histograms,\u201d IEEE transactions on systems, man, and cybernetics, vol. 9, no. 1, pp. 62\u201366, 1979.", "[16] J. Sauvola and M. Pietik\u00e4inen, \u201cAdaptive document image binarization,\u201d Pattern recognition, vol. 33, no. 2, pp. 225\u2013236, 2000."]}], "citation_info_to_title": {"[16] J. Sauvola and M. Pietik\u00e4inen, \u201cAdaptive document image binarization,\u201d Pattern recognition, vol. 33, no. 2, pp. 225\u2013236, 2000.": "Adaptive Document Image Binarization", "[2] S. Kang, B. K. Iwana, and S. Uchida, \u201cComplex image processing with less data document image binarization by integrating multiple pretrained u-net modules,\u201d Pattern Recognition, vol. 109, p. 107577, 2021.": "Complex Image Processing with Less Data: Document Image Binarization by Integrating Multiple Pretrained U-Net Modules", "[3] S. K. Jemni, M. A. Souibgui, Y. Kessentini, and A. Forn\u00e9s, \u201cEnhance to read better: A multi-task adversarial network for handwritten document image enhancement,\u201d Pattern Recognition, vol. 123, p. 108370, 2022.": "Enhance to read better: A multi-task adversarial network for handwritten document image enhancement", "[41] Q.N. Vo, S.H. Kim, H.J. Yang, G. Lee, \u201cBinarization of degraded document images based on hierarchical deep supervised network,\u201d Pattern Recognition, vol. 74, pp. 568\u2013\u2013586, 2018.": "Binarization of degraded document images based on hierarchical deep supervised network", "[19] I. Pratikakis, K. Zagoris, G. Barlas, B. Gatos, \u201cIcdar 2017 competition on document image binarization (dibco 2017),\u201d in 2017 International Conference on Document Analysis and Recognition. IEEE, 2017, pp. 1395\u2013\u20131403.": "Icdar 2017 competition on document image binarization (dibco 2017)", "[25] C. Tensmeyer and T. Martinez, \u201cDocument image binarization with fully convolutional neural networks,\u201d in 2017 14th IAPR international conference on document analysis and recognition (ICDAR), vol. 1. IEEE, 2017, pp. 99\u2013104.": "Document image binarization with fully convolutional neural networks", "[15] N. Otsu, \u201cA threshold selection method from gray-level histograms,\u201d IEEE transactions on systems, man, and cybernetics, vol. 9, no. 1, pp. 62\u201366, 1979.": "A threshold selection method from gray-level histograms"}, "source_title_to_arxiv_id": {"Enhance to read better: A multi-task adversarial network for handwritten document image enhancement": "2105.12710"}}