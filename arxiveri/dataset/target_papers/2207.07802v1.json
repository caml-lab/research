{"title": "Learning Granularity-Unified Representations for Text-to-Image Person Re-identification", "abstract": "Text-to-image person re-identification (ReID) aims to search for pedestrian\nimages of an interested identity via textual descriptions. It is challenging\ndue to both rich intra-modal variations and significant inter-modal gaps.\nExisting works usually ignore the difference in feature granularity between the\ntwo modalities, i.e., the visual features are usually fine-grained while\ntextual features are coarse, which is mainly responsible for the large\ninter-modal gaps. In this paper, we propose an end-to-end framework based on\ntransformers to learn granularity-unified representations for both modalities,\ndenoted as LGUR. LGUR framework contains two modules: a Dictionary-based\nGranularity Alignment (DGA) module and a Prototype-based Granularity\nUnification (PGU) module. In DGA, in order to align the granularities of two\nmodalities, we introduce a Multi-modality Shared Dictionary (MSD) to\nreconstruct both visual and textual features. Besides, DGA has two important\nfactors, i.e., the cross-modality guidance and the foreground-centric\nreconstruction, to facilitate the optimization of MSD. In PGU, we adopt a set\nof shared and learnable prototypes as the queries to extract diverse and\nsemantically aligned features for both modalities in the granularity-unified\nfeature space, which further promotes the ReID performance. Comprehensive\nexperiments show that our LGUR consistently outperforms state-of-the-arts by\nlarge margins on both CUHK-PEDES and ICFG-PEDES datasets. Code will be released\nat https://github.com/ZhiyinShao-H/LGUR.", "authors": ["Zhiyin Shao", "Xinyu Zhang", "Meng Fang", "Zhifeng Lin", "Jian Wang", "Changxing Ding"], "published_date": "2022_07_16", "pdf_url": "http://arxiv.org/pdf/2207.07802v1", "list_table_and_caption": [{"table": "<table><tbody><tr><th colspan=\"2\">Methods</th><td>Rank-1</td><td>Rank-5</td><td>Rank-10</td></tr><tr><th rowspan=\"19\">ResNet-50</th><th>Dual Path (Zheng et al., 2020b)</th><td>44.40</td><td>66.26</td><td>75.07</td></tr><tr><th>CMPM/C (Zhang and Lu, 2018)</th><td>49.37</td><td>-</td><td>79.27</td></tr><tr><th>MIA (Niu et al., 2020b)</th><td>53.10</td><td>75.00</td><td>82.90</td></tr><tr><th>A-GANet (Liu et al., 2019)</th><td>53.14</td><td>74.03</td><td>82.95</td></tr><tr><th>GALM (Jing et al., 2020)</th><td>54.12</td><td>75.45</td><td>82.97</td></tr><tr><th>TIMAM (Sarafianos et al., 2019)</th><td>54.51</td><td>77.56</td><td>84.78</td></tr><tr><th>TDE (Niu et al., 2020a)</th><td>55.25</td><td>77.46</td><td>84.56</td></tr><tr><th>VTA (Ge et al., 2019)</th><td>55.32</td><td>77.00</td><td>84.26</td></tr><tr><th>SCAN (Lee et al., 2018)</th><td>55.86</td><td>75.97</td><td>83.69</td></tr><tr><th>ViTAA (Wang et al., 2020)</th><td>55.97</td><td>75.84</td><td>83.52</td></tr><tr><th>CMAAM (Aggarwal et al., 2020)</th><td>56.68</td><td>77.18</td><td>84.86</td></tr><tr><th>HGAN (Zheng et al., 2020a)</th><td>59.00</td><td>79.49</td><td>86.62</td></tr><tr><th>NAFS (Gao et al., 2021)</th><td>59.94</td><td>79.86</td><td>86.70</td></tr><tr><th>DSSL (Zhu et al., 2021)</th><td>59.98</td><td>80.41</td><td>87.56</td></tr><tr><th>MGEL (Wang et al., 2021a)</th><td>60.27</td><td>80.01</td><td>86.74</td></tr><tr><th>SSAN (Ding et al., 2021)</th><td>61.37</td><td>80.15</td><td>86.73</td></tr><tr><th>Han et al. (Han et al., 2021)</th><td>61.65</td><td>80.98</td><td>86.78</td></tr><tr><th>LapsCore (Wu et al., 2021)</th><td>63.40</td><td>-</td><td>87.80</td></tr><tr><th>LGUR</th><td>64.21</td><td>81.94</td><td>87.93</td></tr><tr><th colspan=\"2\">LGUR ( DeiT-Small)</th><td>65.25</td><td>83.12</td><td>89.00</td></tr></tbody></table>", "caption": "Table 1. Performance comparisons on CUHK-PEDES.", "list_citation_info": ["Liu et al. (2019) Jiawei Liu, Zheng-Jun Zha, Richang Hong, Meng Wang, and Yongdong Zhang. 2019. Deep adversarial graph attention convolution network for text-based person search. In ACMMM. 665\u2013673.", "Zheng et al. (2020b) Zhedong Zheng, Liang Zheng, Michael Garrett, Yi Yang, Mingliang Xu, and Yi-Dong Shen. 2020b. Dual-Path Convolutional Image-Text Embeddings with Instance Loss. TOMM 16, 2 (2020), 1\u201323.", "Han et al. (2021) Xiao Han, Sen He, Li Zhang, and Tao Xiang. 2021. Text-Based Person Search with Limited Data. arXiv preprint arXiv:2110.10807 (2021).", "Niu et al. (2020b) Kai Niu, Yan Huang, Wanli Ouyang, and Liang Wang. 2020b. Improving description-based person re-identification by multi-granularity image-text alignments. IEEE Transactions on Image Processing 29 (2020), 5542\u20135556.", "Wang et al. (2021a) Chengji Wang, Zhiming Luo, Yaojin Lin, and Shaozi Li. 2021a. Text-based Person Search via Multi-Granularity Embedding Learning. IJCAI.", "Wu et al. (2021) Yushuang Wu, Zizheng Yan, Xiaoguang Han, Guanbin Li, Changqing Zou, and Shuguang Cui. 2021. LapsCore: Language-Guided Person Search via Color Reasoning. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 1624\u20131633.", "Jing et al. (2020) Ya Jing, Chenyang Si, Junbo Wang, Wei Wang, Liang Wang, and Tieniu Tan. 2020. Pose-Guided Multi-Granularity Attention Network for Text-Based Person Search. In AAAI.", "Ding et al. (2021) Zefeng Ding, Changxing Ding, Zhiyin Shao, and Dacheng Tao. 2021. Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification. arXiv preprint arXiv:2107.12666 (2021).", "Aggarwal et al. (2020) Surbhi Aggarwal, Venkatesh Babu RADHAKRISHNAN, and Anirban Chakraborty. 2020. Text-based person search via attribute-aided matching. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2617\u20132625.", "Zheng et al. (2020a) Kecheng Zheng, Wu Liu, Jiawei Liu, Zheng-Jun Zha, and Tao Mei. 2020a. Hierarchical gumbel attention network for text-based person search. In ACMMM. 3441\u20133449.", "Lee et al. (2018) Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, and Xiaodong He. 2018. Stacked cross attention for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 201\u2013216.", "Gao et al. (2021) Chenyang Gao, Guanyu Cai, Xinyang Jiang, Feng Zheng, Jun Zhang, Yifei Gong, Pai Peng, Xiaowei Guo, and Xing Sun. 2021. Contextual Non-Local Alignment over Full-Scale Representation for Text-Based Person Search. arXiv preprint arXiv:2101.03036 (2021).", "Zhu et al. (2021) Aichun Zhu, Zijie Wang, Yifeng Li, Xili Wan, Jing Jin, Tian Wang, Fangqiang Hu, and Gang Hua. 2021. DSSL: Deep Surroundings-person Separation Learning for Text-based Person Retrieval. In ACMMM. 209\u2013217.", "Ge et al. (2019) Jing Ge, Guangyu Gao, and Zhen Liu. 2019. Visual-Textual Association with Hardest and Semi-Hard Negative Pairs Mining for Person Search. arXiv preprint arXiv:1912.03083 (2019).", "Sarafianos et al. (2019) Nikolaos Sarafianos, Xiang Xu, and Ioannis A Kakadiaris. 2019. Adversarial Representation Learning for Text-to-Image Matching. In Proceedings of the IEEE International Conference on Computer Vision. 5814\u20135824.", "Zhang and Lu (2018) Ying Zhang and Huchuan Lu. 2018. Deep cross-modal projection learning for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 686\u2013701.", "Wang et al. (2020) Zhe Wang, Zhiyuan Fang, Jun Wang, and Yezhou Yang. 2020. ViTAA: Visual-Textual Attributes Alignment in Person Search by Natural Language. (2020).", "Niu et al. (2020a) Kai Niu, Yan Huang, and Liang Wang. 2020a. Textual dependency embedding for person search by language. In ACMMM. 4032\u20134040."]}, {"table": "<table><tbody><tr><th colspan=\"2\">Methods</th><td>Rank-1</td><td>Rank-5</td><td>Rank-10</td></tr><tr><th rowspan=\"7\">ResNet-50</th><th>Dual Path (Zheng et al., 2020b)</th><td>38.99</td><td>59.44</td><td>68.41</td></tr><tr><th>CMPM/C (Zhang and Lu, 2018)</th><td>43.51</td><td>65.44</td><td>74.26</td></tr><tr><th>MIA (Niu et al., 2020b)</th><td>46.49</td><td>67.14</td><td>75.18</td></tr><tr><th>SCAN (Lee et al., 2018)</th><td>50.05</td><td>69.65</td><td>77.21</td></tr><tr><th>ViTAA (Wang et al., 2020)</th><td>50.98</td><td>68.79</td><td>75.78</td></tr><tr><th>SSAN (Ding et al., 2021)</th><td>54.23</td><td>72.63</td><td>79.53</td></tr><tr><th>LGUR</th><td>57.42</td><td>74.97</td><td>81.45</td></tr><tr><th colspan=\"2\">LGUR ( DeiT-Small)</th><td>59.02</td><td>75.32</td><td>81.56</td></tr></tbody></table>", "caption": "Table 2. Performance comparisons on ICFG-PEDES.", "list_citation_info": ["Zheng et al. (2020b) Zhedong Zheng, Liang Zheng, Michael Garrett, Yi Yang, Mingliang Xu, and Yi-Dong Shen. 2020b. Dual-Path Convolutional Image-Text Embeddings with Instance Loss. TOMM 16, 2 (2020), 1\u201323.", "Niu et al. (2020b) Kai Niu, Yan Huang, Wanli Ouyang, and Liang Wang. 2020b. Improving description-based person re-identification by multi-granularity image-text alignments. IEEE Transactions on Image Processing 29 (2020), 5542\u20135556.", "Ding et al. (2021) Zefeng Ding, Changxing Ding, Zhiyin Shao, and Dacheng Tao. 2021. Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification. arXiv preprint arXiv:2107.12666 (2021).", "Lee et al. (2018) Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, and Xiaodong He. 2018. Stacked cross attention for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 201\u2013216.", "Zhang and Lu (2018) Ying Zhang and Huchuan Lu. 2018. Deep cross-modal projection learning for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 686\u2013701.", "Wang et al. (2020) Zhe Wang, Zhiyuan Fang, Jun Wang, and Yezhou Yang. 2020. ViTAA: Visual-Textual Attributes Alignment in Person Search by Natural Language. (2020)."]}, {"table": "<table><thead><tr><th colspan=\"2\">Methods</th><th>Rank-1</th><th>Rank-5</th><th>Rank-10</th></tr></thead><tbody><tr><th rowspan=\"6\">C \\rightarrow I</th><th>Dual Path (Zheng et al., 2020b)</th><td>15.41</td><td>29.80</td><td>38.19</td></tr><tr><th>MIA (Niu et al., 2020b)</th><td>19.35</td><td>36.78</td><td>46.42</td></tr><tr><th>SCAN (Lee et al., 2018)</th><td>21.27</td><td>39.26</td><td>48.83</td></tr><tr><th>SSAN (Ding et al., 2021)</th><td>24.72</td><td>43.43</td><td>53.01</td></tr><tr><th>SSAN(w/ BERT) (Ding et al., 2021)</th><td>29.24</td><td>49.00</td><td>58.53</td></tr><tr><th>LGUR</th><td>34.25</td><td>52.58</td><td>60.85</td></tr><tr><th rowspan=\"6\">I \\rightarrow C</th><th>Dual Path (Zheng et al., 2020b)</th><td>7.63</td><td>17.14</td><td>23.52</td></tr><tr><th>MIA (Niu et al., 2020b)</th><td>10.93</td><td>23.77</td><td>32.39</td></tr><tr><th>SCAN (Lee et al., 2018)</th><td>13.63</td><td>28.61</td><td>37.05</td></tr><tr><th>SSAN (Ding et al., 2021)</th><td>16.68</td><td>33.84</td><td>43.00</td></tr><tr><th>SSAN(w/ BERT) (Ding et al., 2021)</th><td>21.07</td><td>38.94</td><td>48.54</td></tr><tr><th>LGUR</th><td>25.44</td><td>44.48</td><td>54.39</td></tr></tbody></table>", "caption": "Table 3. Performance comparisons on the domain generalization task. \u201cC\u201d denotes CUHK-PEDES, while \u201cI\u201d represents ICFG-PEDES.", "list_citation_info": ["Niu et al. (2020b) Kai Niu, Yan Huang, Wanli Ouyang, and Liang Wang. 2020b. Improving description-based person re-identification by multi-granularity image-text alignments. IEEE Transactions on Image Processing 29 (2020), 5542\u20135556.", "Zheng et al. (2020b) Zhedong Zheng, Liang Zheng, Michael Garrett, Yi Yang, Mingliang Xu, and Yi-Dong Shen. 2020b. Dual-Path Convolutional Image-Text Embeddings with Instance Loss. TOMM 16, 2 (2020), 1\u201323.", "Lee et al. (2018) Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, and Xiaodong He. 2018. Stacked cross attention for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 201\u2013216.", "Ding et al. (2021) Zefeng Ding, Changxing Ding, Zhiyin Shao, and Dacheng Tao. 2021. Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification. arXiv preprint arXiv:2107.12666 (2021)."]}, {"table": "<table><thead><tr><th></th><th>CAM</th><th>Methods</th><th>Train</th><th>Inference</th><th>Rank-1</th></tr></thead><tbody><tr><th rowspan=\"7\">CUHK-PEDES</th><th>\u2713</th><th>MIA (Niu et al., 2020b)</th><td>680ms</td><td>42ms</td><td>53.10</td></tr><tr><th>\u2713</th><th>SCAN (Lee et al., 2018)</th><td>718ms</td><td>46ms</td><td>55.86</td></tr><tr><th>\u2713</th><th>NAFS (Gao et al., 2021)</th><td>1,284ms</td><td>42ms</td><td>59.94</td></tr><tr><th>\\times</th><th>Dual Path (Zheng et al., 2020b)</th><td>321ms</td><td>10ms</td><td>44.40</td></tr><tr><th>\\times</th><th>CMPM/C (Zhang and Lu, 2018)</th><td>338ms</td><td>27ms</td><td>49.37</td></tr><tr><th>\\times</th><th>SSAN (Ding et al., 2021)</th><td>901ms</td><td>76ms</td><td>61.37</td></tr><tr><th>\\times</th><th>LGUR (Ours)</th><td>886ms</td><td>26ms</td><td>64.21</td></tr><tr><th rowspan=\"7\">ICFG-PEDES</th><th>\u2713</th><th>MIA (Niu et al., 2020b)</th><td>711ms</td><td>113ms</td><td>46.49</td></tr><tr><th>\u2713</th><th>SCAN (Lee et al., 2018)</th><td>738ms</td><td>114ms</td><td>50.05</td></tr><tr><th>\u2713</th><th>NAFS (Gao et al., 2021)</th><td>1,304ms</td><td>116ms</td><td>-</td></tr><tr><th>\\times</th><th>Dual Path (Zheng et al., 2020b)</th><td>342ms</td><td>11ms</td><td>38.99</td></tr><tr><th>\\times</th><th>CMPM/C (Zhang and Lu, 2018)</th><td>356ms</td><td>31ms</td><td>43.51</td></tr><tr><th>\\times</th><th>SSAN (Ding et al., 2021)</th><td>973ms</td><td>77ms</td><td>54.23</td></tr><tr><th>\\times</th><th>LGUR (Ours)</th><td>910ms</td><td>31ms</td><td>57.42</td></tr></tbody></table>", "caption": "Table 4. Performance comparisons in terms of time complexity. \u201cCAM\u201d refers to the cross-modal attention mechanism (Lee et al., 2018).", "list_citation_info": ["Zheng et al. (2020b) Zhedong Zheng, Liang Zheng, Michael Garrett, Yi Yang, Mingliang Xu, and Yi-Dong Shen. 2020b. Dual-Path Convolutional Image-Text Embeddings with Instance Loss. TOMM 16, 2 (2020), 1\u201323.", "Niu et al. (2020b) Kai Niu, Yan Huang, Wanli Ouyang, and Liang Wang. 2020b. Improving description-based person re-identification by multi-granularity image-text alignments. IEEE Transactions on Image Processing 29 (2020), 5542\u20135556.", "Ding et al. (2021) Zefeng Ding, Changxing Ding, Zhiyin Shao, and Dacheng Tao. 2021. Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification. arXiv preprint arXiv:2107.12666 (2021).", "Gao et al. (2021) Chenyang Gao, Guanyu Cai, Xinyang Jiang, Feng Zheng, Jun Zhang, Yifei Gong, Pai Peng, Xiaowei Guo, and Xing Sun. 2021. Contextual Non-Local Alignment over Full-Scale Representation for Text-Based Person Search. arXiv preprint arXiv:2101.03036 (2021).", "Lee et al. (2018) Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, and Xiaodong He. 2018. Stacked cross attention for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 201\u2013216.", "Zhang and Lu (2018) Ying Zhang and Huchuan Lu. 2018. Deep cross-modal projection learning for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 686\u2013701."]}, {"table": "<table><thead><tr><th rowspan=\"2\">Type of reconstruction</th><th colspan=\"2\">CUHK-PEDES</th><th colspan=\"2\">ICFG-PEDES</th></tr><tr><th>Rank-1</th><th>Rank-5</th><th>Rank-1</th><th>Rank-5</th></tr></thead><tbody><tr><th>w/o reconstruction</th><td>63.26</td><td>81.17</td><td>56.34</td><td>73.58</td></tr><tr><th>w/ SA</th><td>63.39</td><td>82.28</td><td>56.34</td><td>74.09</td></tr><tr><th>w/ unshared {\\bf{D}}</th><td>61.55</td><td>80.69</td><td>55.96</td><td>73.23</td></tr><tr><th>w/ shared {\\bf{D}} (Ours)</th><td>64.28</td><td>81.95</td><td>57.52</td><td>74.84</td></tr></tbody></table>", "caption": "Table 6. Comparisons with variants of MSD, including without reconstruction (w/o reconstruction), reconstruction with a self-attention layer (w/ SA) (Vaswani et al., 2017), reconstruction with modality unshared dictionary (w/ unshared {\\bf{D}}).", "list_citation_info": ["Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998\u20136008."]}], "citation_info_to_title": {"Ding et al. (2021) Zefeng Ding, Changxing Ding, Zhiyin Shao, and Dacheng Tao. 2021. Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification. arXiv preprint arXiv:2107.12666 (2021).": "Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification", "Jing et al. (2020) Ya Jing, Chenyang Si, Junbo Wang, Wei Wang, Liang Wang, and Tieniu Tan. 2020. Pose-Guided Multi-Granularity Attention Network for Text-Based Person Search. In AAAI.": "Pose-Guided Multi-Granularity Attention Network for Text-Based Person Search", "Liu et al. (2019) Jiawei Liu, Zheng-Jun Zha, Richang Hong, Meng Wang, and Yongdong Zhang. 2019. Deep adversarial graph attention convolution network for text-based person search. In ACMMM. 665\u2013673.": "Deep Adversarial Graph Attention Convolution Network for Text-Based Person Search", "Niu et al. (2020a) Kai Niu, Yan Huang, and Liang Wang. 2020a. Textual dependency embedding for person search by language. In ACMMM. 4032\u20134040.": "Textual Dependency Embedding for Person Search by Language", "Zhu et al. (2021) Aichun Zhu, Zijie Wang, Yifeng Li, Xili Wan, Jing Jin, Tian Wang, Fangqiang Hu, and Gang Hua. 2021. DSSL: Deep Surroundings-person Separation Learning for Text-based Person Retrieval. In ACMMM. 209\u2013217.": "DSSL: Deep Surroundings-person Separation Learning for Text-based Person Retrieval", "Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998\u20136008.": "Attention is all you need", "Sarafianos et al. (2019) Nikolaos Sarafianos, Xiang Xu, and Ioannis A Kakadiaris. 2019. Adversarial Representation Learning for Text-to-Image Matching. In Proceedings of the IEEE International Conference on Computer Vision. 5814\u20135824.": "Adversarial Representation Learning for Text-to-Image Matching", "Zheng et al. (2020a) Kecheng Zheng, Wu Liu, Jiawei Liu, Zheng-Jun Zha, and Tao Mei. 2020a. Hierarchical gumbel attention network for text-based person search. In ACMMM. 3441\u20133449.": "Hierarchical Gumbel Attention Network for Text-Based Person Search", "Lee et al. (2018) Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, and Xiaodong He. 2018. Stacked cross attention for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 201\u2013216.": "Stacked cross attention for image-text matching", "Gao et al. (2021) Chenyang Gao, Guanyu Cai, Xinyang Jiang, Feng Zheng, Jun Zhang, Yifei Gong, Pai Peng, Xiaowei Guo, and Xing Sun. 2021. Contextual Non-Local Alignment over Full-Scale Representation for Text-Based Person Search. arXiv preprint arXiv:2101.03036 (2021).": "Contextual Non-Local Alignment over Full-Scale Representation for Text-Based Person Search", "Han et al. (2021) Xiao Han, Sen He, Li Zhang, and Tao Xiang. 2021. Text-Based Person Search with Limited Data. arXiv preprint arXiv:2110.10807 (2021).": "Text-Based Person Search with Limited Data", "Niu et al. (2020b) Kai Niu, Yan Huang, Wanli Ouyang, and Liang Wang. 2020b. Improving description-based person re-identification by multi-granularity image-text alignments. IEEE Transactions on Image Processing 29 (2020), 5542\u20135556.": "Improving description-based person re-identification by multi-granularity image-text alignments", "Ge et al. (2019) Jing Ge, Guangyu Gao, and Zhen Liu. 2019. Visual-Textual Association with Hardest and Semi-Hard Negative Pairs Mining for Person Search. arXiv preprint arXiv:1912.03083 (2019).": "Visual-Textual Association with Hardest and Semi-Hard Negative Pairs Mining for Person Search", "Wang et al. (2021a) Chengji Wang, Zhiming Luo, Yaojin Lin, and Shaozi Li. 2021a. Text-based Person Search via Multi-Granularity Embedding Learning. IJCAI.": "Text-based Person Search via Multi-Granularity Embedding Learning", "Zheng et al. (2020b) Zhedong Zheng, Liang Zheng, Michael Garrett, Yi Yang, Mingliang Xu, and Yi-Dong Shen. 2020b. Dual-Path Convolutional Image-Text Embeddings with Instance Loss. TOMM 16, 2 (2020), 1\u201323.": "Dual-Path Convolutional Image-Text Embeddings with Instance Loss", "Wu et al. (2021) Yushuang Wu, Zizheng Yan, Xiaoguang Han, Guanbin Li, Changqing Zou, and Shuguang Cui. 2021. LapsCore: Language-Guided Person Search via Color Reasoning. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 1624\u20131633.": "LapsCore: Language-Guided Person Search via Color Reasoning", "Wang et al. (2020) Zhe Wang, Zhiyuan Fang, Jun Wang, and Yezhou Yang. 2020. ViTAA: Visual-Textual Attributes Alignment in Person Search by Natural Language. (2020).": "ViTAA: Visual-Textual Attributes Alignment in Person Search by Natural Language", "Aggarwal et al. (2020) Surbhi Aggarwal, Venkatesh Babu RADHAKRISHNAN, and Anirban Chakraborty. 2020. Text-based person search via attribute-aided matching. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2617\u20132625.": "Text-based person search via attribute-aided matching", "Zhang and Lu (2018) Ying Zhang and Huchuan Lu. 2018. Deep cross-modal projection learning for image-text matching. In Proceedings of the European Conference on Computer Vision (ECCV). 686\u2013701.": "Deep cross-modal projection learning for image-text matching"}, "source_title_to_arxiv_id": {"Text-Based Person Search with Limited Data": "2110.10807"}}