{"title": "Learning Quality-aware Representation for Multi-person Pose Regression", "abstract": "Off-the-shelf single-stage multi-person pose regression methods generally\nleverage the instance score (i.e., confidence of the instance localization) to\nindicate the pose quality for selecting the pose candidates. We consider that\nthere are two gaps involved in existing paradigm:~1) The instance score is not\nwell interrelated with the pose regression quality.~2) The instance feature\nrepresentation, which is used for predicting the instance score, does not\nexplicitly encode the structural pose information to predict the reasonable\nscore that represents pose regression quality. To address the aforementioned\nissues, we propose to learn the pose regression quality-aware representation.\nConcretely, for the first gap, instead of using the previous instance\nconfidence label (e.g., discrete {1,0} or Gaussian representation) to denote\nthe position and confidence for person instance, we firstly introduce the\nConsistent Instance Representation (CIR) that unifies the pose regression\nquality score of instance and the confidence of background into a pixel-wise\nscore map to calibrates the inconsistency between instance score and pose\nregression quality. To fill the second gap, we further present the Query\nEncoding Module (QEM) including the Keypoint Query Encoding (KQE) to encode the\npositional and semantic information for each keypoint and the Pose Query\nEncoding (PQE) which explicitly encodes the predicted structural pose\ninformation to better fit the Consistent Instance Representation (CIR). By\nusing the proposed components, we significantly alleviate the above gaps. Our\nmethod outperforms previous single-stage regression-based even bottom-up\nmethods and achieves the state-of-the-art result of 71.7 AP on MS COCO test-dev\nset.", "authors": ["Yabo Xiao", "Dongdong Yu", "Xiaojuan Wang", "Lei Jin", "Guoli Wang", "Qian Zhang"], "published_date": "2022_01_04", "pdf_url": "http://arxiv.org/pdf/2201.01087v1", "list_table_and_caption": [{"table": "<br/><table><tbody><tr><th>Methods</th><th>Params</th><th>Input size</th><th>GFLOPs</th><td>AP</td><td>AP_{50}</td><td>AP_{75}</td><td>AP_{M}</td><td>AP_{L}</td><td>AR</td></tr><tr><th>Personlab (Papandreou et al. 2018)</th><th>68.7</th><th>1401</th><th>405.5</th><td>66.5</td><td>86.2</td><td>71.9</td><td>62.3</td><td>73.2</td><td>70.7</td></tr><tr><th>PifPaf (Kreiss, Bertoni, and Alahi 2019)</th><th>-</th><th>-</th><th>-</th><td>67.4</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>CenterNet-DLA (Zhou, Wang, and Kr\u00e4henb\u00fchl 2019)</th><th>-</th><th>512</th><th>-</th><td>58.9</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>CenterNet-HG (Zhou, Wang, and Kr\u00e4henb\u00fchl 2019)</th><th>-</th><th>512</th><th>-</th><td>64.0</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>HrHRNet-W32(Cheng et al. 2020)</th><th>28.5</th><th>512</th><th>47.9</th><td>67.1</td><td>86.2</td><td>73.0</td><td>-</td><td>-</td><td>-</td></tr><tr><th>HrHRNet-W48(Cheng et al. 2020)</th><th>63.8</th><th>640</th><th>154.3</th><td>69.9</td><td>87.2</td><td>76.1</td><td>-</td><td>-</td><td>-</td></tr><tr><th>DEKR-W32(Geng et al. 2021)</th><th>29.6</th><th>512</th><th>45.4</th><td>68.0</td><td>86.7</td><td>74.5</td><td>62.1</td><td>77.7</td><td>73.0</td></tr><tr><th>DEKR-W48(Geng et al. 2021)</th><th>65.7</th><th>640</th><th>141.5</th><td>71.0</td><td>88.3</td><td>77.4</td><td>66.7</td><td>78.5</td><td>76.0</td></tr><tr><th>Ours (HRNet-W32)</th><th>29.7</th><th>512</th><th>46.4</th><td>69.8</td><td>88.1</td><td>76.2</td><td>63.8</td><td>78.9</td><td>73.8</td></tr><tr><th>Ours (HRNet-W48)</th><th>65.8</th><th>640</th><th>143.4</th><td>72.4</td><td>89.1</td><td>79.0</td><td>67.3</td><td>80.4</td><td>76.4</td></tr></tbody></table>", "caption": "Table 1: Comparisons with the previous state-of-the-art methods on the COCO mini-val set (single-scale testing). ", "list_citation_info": ["Geng et al. (2021) Geng, Z.; Sun, K.; Xiao, B.; Zhang, Z.; and Wang, J. 2021. Bottom-Up Human Pose Estimation Via Disentangled Keypoint Regression. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 14676\u201314686.", "Kreiss, Bertoni, and Alahi (2019) Kreiss, S.; Bertoni, L.; and Alahi, A. 2019. Pifpaf: Composite fields for human pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 11977\u201311986.", "Zhou, Wang, and Kr\u00e4henb\u00fchl (2019) Zhou, X.; Wang, D.; and Kr\u00e4henb\u00fchl, P. 2019. Objects as points. arXiv preprint arXiv:1904.07850.", "Cheng et al. (2020) Cheng, B.; Xiao, B.; Wang, J.; Shi, H.; Huang, T. S.; and Zhang, L. 2020. HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 5386\u20135395.", "Papandreou et al. (2018) Papandreou, G.; Zhu, T.; Chen, L.-C.; Gidaris, S.; Tompson, J.; and Murphy, K. 2018. Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model. In Proceedings of the European Conference on Computer Vision (ECCV), 269\u2013286."]}, {"table": "<br/><table><tbody><tr><th>Methods</th><th>Input size</th><td>AP</td><td>AP_{50}</td><td>AP_{75}</td><td>AP_{M}</td><td>AP_{L}</td><td>AR</td></tr><tr><th colspan=\"8\">Bottom-up Methods</th></tr><tr><th>CMU-Pose{}^{*{\\dagger}} (Cao et al. 2017)</th><th>-</th><td>61.8</td><td>84.9</td><td>67.5</td><td>57.1</td><td>68.2</td><td>66.5</td></tr><tr><th>AE{}^{*{\\dagger}} (Newell, Huang, and Deng 2017)</th><th>512</th><td>65.5</td><td>86.8</td><td>72.3</td><td>60.6</td><td>72.6</td><td>70.2</td></tr><tr><th>CenterNet-DLA (Zhou, Wang, and Kr\u00e4henb\u00fchl 2019)</th><th>512</th><td>57.9</td><td>84.7</td><td>63.1</td><td>52.5</td><td>67.4</td><td>-</td></tr><tr><th>CenterNet-HG (Zhou, Wang, and Kr\u00e4henb\u00fchl 2019)</th><th>512</th><td>63.0</td><td>86.8</td><td>69.6</td><td>58.9</td><td>70.4</td><td>-</td></tr><tr><th>PifPaf (Kreiss, Bertoni, and Alahi 2019)</th><th>801</th><td>66.7</td><td>-</td><td>-</td><td>62.4</td><td>72.9</td><td>-</td></tr><tr><th>HrHRNet-w48{}^{*} (Cheng et al. 2020)</th><th>512</th><td>68.4</td><td>88.2</td><td>75.1</td><td>64.4</td><td>74.2</td><td>-</td></tr><tr><th>SWAHR(HrHRNet-W48){}^{*} (Luo et al. 2021)</th><th>640</th><td>70.2</td><td>89.9</td><td>76.9</td><td>65.2</td><td>77.0</td><td>-</td></tr><tr><th colspan=\"8\">Single-stage Regression Methods</th></tr><tr><th>SPM {}^{*{\\dagger}} (Nie et al. 2019)</th><th>-</th><td>66.9</td><td>88.5</td><td>72.9</td><td>62.6</td><td>73.1</td><td>-</td></tr><tr><th>DirectPose {}^{{\\dagger}} (Tian, Chen, and Shen 2019)</th><th>800*1333</th><td>64.8</td><td>87.8</td><td>71.1</td><td>60.4</td><td>71.5</td><td>-</td></tr><tr><th>MDN{}_{3}  (Varamesh and Tuytelaars 2020)</th><th>-</th><td>62.9</td><td>85.1</td><td>69.4</td><td>58.8</td><td>71.4</td><td>-</td></tr><tr><th>PointSetNet {}^{*{\\dagger}} (Wei et al. 2020)</th><th>640</th><td>68.7</td><td>89.9</td><td>76.3</td><td>64.8</td><td>75.3</td><td>74.8</td></tr><tr><th>DEkR-W48{}^{*}(Geng et al. 2021)</th><th>640</th><td>70.0</td><td>89.4</td><td>77.3</td><td>65.7</td><td>76.9</td><td>75.4</td></tr><tr><th>DEkR-W48 {}^{*{\\dagger}}(Geng et al. 2021)</th><th>640</th><td>71.0</td><td>89.2</td><td>78.0</td><td>67.1</td><td>76.9</td><td>76.7</td></tr><tr><th>Ours (HRNet-W32)</th><th>512</th><td>69.0</td><td>89.3</td><td>76.0</td><td>62.8</td><td>77.0</td><td>73.6</td></tr><tr><th>Ours (HRNet-W32){}^{{\\dagger}}</th><th>512</th><td>70.5</td><td>89.6</td><td>77.5</td><td>64.8</td><td>78.0</td><td>75.1</td></tr><tr><th>Ours (HRNet-W48)</th><th>640</th><td>71.0</td><td>90.2</td><td>78.2</td><td>66.2</td><td>77.8</td><td>76.0</td></tr><tr><th>Ours (HRNet-W48){}^{{\\dagger}}</th><th>640</th><td>71.7</td><td>90.4</td><td>78.7</td><td>67.3</td><td>78.5</td><td>76.5</td></tr></tbody></table>", "caption": "Table 4: Comparisons with the state-of-the-art methods on COCO test-dev set. {*} indicates using additional post-process(e.g., single-person model refinement used in CMU-Pose, AE, SPM and pose scoring net in DEKR). {\\dagger} refers to multi-scale testing.", "list_citation_info": ["Geng et al. (2021) Geng, Z.; Sun, K.; Xiao, B.; Zhang, Z.; and Wang, J. 2021. Bottom-Up Human Pose Estimation Via Disentangled Keypoint Regression. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 14676\u201314686.", "Kreiss, Bertoni, and Alahi (2019) Kreiss, S.; Bertoni, L.; and Alahi, A. 2019. Pifpaf: Composite fields for human pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 11977\u201311986.", "Nie et al. (2019) Nie, X.; Feng, J.; Zhang, J.; and Yan, S. 2019. Single-stage multi-person pose machines. In Proceedings of the IEEE International Conference on Computer Vision, 6951\u20136960.", "Wei et al. (2020) Wei, F.; Sun, X.; Li, H.; Wang, J.; and Lin, S. 2020. Point-set anchors for object detection, instance segmentation and pose estimation. In European Conference on Computer Vision, 527\u2013544. Springer.", "Luo et al. (2021) Luo, Z.; Wang, Z.; Huang, Y.; Wang, L.; Tan, T.; and Zhou, E. 2021. Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 13264\u201313273.", "Zhou, Wang, and Kr\u00e4henb\u00fchl (2019) Zhou, X.; Wang, D.; and Kr\u00e4henb\u00fchl, P. 2019. Objects as points. arXiv preprint arXiv:1904.07850.", "Varamesh and Tuytelaars (2020) Varamesh, A.; and Tuytelaars, T. 2020. Mixture dense regression for object detection and human pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 13086\u201313095.", "Newell, Huang, and Deng (2017) Newell, A.; Huang, Z.; and Deng, J. 2017. Associative embedding: End-to-end learning for joint detection and grouping. In Advances in neural information processing systems, 2277\u20132287.", "Cheng et al. (2020) Cheng, B.; Xiao, B.; Wang, J.; Shi, H.; Huang, T. S.; and Zhang, L. 2020. HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 5386\u20135395.", "Tian, Chen, and Shen (2019) Tian, Z.; Chen, H.; and Shen, C. 2019. DirectPose: Direct End-to-End Multi-Person Pose Estimation. arXiv preprint arXiv:1911.07451.", "Cao et al. (2017) Cao, Z.; Simon, T.; Wei, S.-E.; and Sheikh, Y. 2017. Realtime multi-person 2d pose estimation using part affinity fields. In Proceedings of the IEEE conference on computer vision and pattern recognition, 7291\u20137299."]}], "citation_info_to_title": {"Wei et al. (2020) Wei, F.; Sun, X.; Li, H.; Wang, J.; and Lin, S. 2020. Point-set anchors for object detection, instance segmentation and pose estimation. In European Conference on Computer Vision, 527\u2013544. Springer.": "Point-set anchors for object detection, instance segmentation and pose estimation", "Papandreou et al. (2018) Papandreou, G.; Zhu, T.; Chen, L.-C.; Gidaris, S.; Tompson, J.; and Murphy, K. 2018. Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model. In Proceedings of the European Conference on Computer Vision (ECCV), 269\u2013286.": "Personlab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model", "Cao et al. (2017) Cao, Z.; Simon, T.; Wei, S.-E.; and Sheikh, Y. 2017. Realtime multi-person 2d pose estimation using part affinity fields. In Proceedings of the IEEE conference on computer vision and pattern recognition, 7291\u20137299.": "Realtime multi-person 2d pose estimation using part affinity fields", "Newell, Huang, and Deng (2017) Newell, A.; Huang, Z.; and Deng, J. 2017. Associative embedding: End-to-end learning for joint detection and grouping. In Advances in neural information processing systems, 2277\u20132287.": "Associative Embedding: End-to-End Learning for Joint Detection and Grouping", "Varamesh and Tuytelaars (2020) Varamesh, A.; and Tuytelaars, T. 2020. Mixture dense regression for object detection and human pose estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 13086\u201313095.": "Mixture dense regression for object detection and human pose estimation", "Geng et al. (2021) Geng, Z.; Sun, K.; Xiao, B.; Zhang, Z.; and Wang, J. 2021. Bottom-Up Human Pose Estimation Via Disentangled Keypoint Regression. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 14676\u201314686.": "Bottom-Up Human Pose Estimation Via Disentangled Keypoint Regression", "Cheng et al. (2020) Cheng, B.; Xiao, B.; Wang, J.; Shi, H.; Huang, T. S.; and Zhang, L. 2020. HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 5386\u20135395.": "HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human Pose Estimation", "Zhou, Wang, and Kr\u00e4henb\u00fchl (2019) Zhou, X.; Wang, D.; and Kr\u00e4henb\u00fchl, P. 2019. Objects as points. arXiv preprint arXiv:1904.07850.": "Objects as Points", "Nie et al. (2019) Nie, X.; Feng, J.; Zhang, J.; and Yan, S. 2019. Single-stage multi-person pose machines. In Proceedings of the IEEE International Conference on Computer Vision, 6951\u20136960.": "Single-stage multi-person pose machines", "Kreiss, Bertoni, and Alahi (2019) Kreiss, S.; Bertoni, L.; and Alahi, A. 2019. Pifpaf: Composite fields for human pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 11977\u201311986.": "Pifpaf: Composite fields for human pose estimation", "Tian, Chen, and Shen (2019) Tian, Z.; Chen, H.; and Shen, C. 2019. DirectPose: Direct End-to-End Multi-Person Pose Estimation. arXiv preprint arXiv:1911.07451.": "DirectPose: Direct End-to-End Multi-Person Pose Estimation", "Luo et al. (2021) Luo, Z.; Wang, Z.; Huang, Y.; Wang, L.; Tan, T.; and Zhou, E. 2021. Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 13264\u201313273.": "Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation"}, "source_title_to_arxiv_id": {"Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation": "2012.15175"}}