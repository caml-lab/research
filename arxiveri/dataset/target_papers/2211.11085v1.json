{"title": "R2-MLP: Round-Roll MLP for Multi-View 3D Object Recognition", "abstract": "Recently, vision architectures based exclusively on multi-layer perceptrons\n(MLPs) have gained much attention in the computer vision community. MLP-like\nmodels achieve competitive performance on a single 2D image classification with\nless inductive bias without hand-crafted convolution layers. In this work, we\nexplore the effectiveness of MLP-based architecture for the view-based 3D\nobject recognition task. We present an MLP-based architecture termed as\nRound-Roll MLP (R$^2$-MLP). It extends the spatial-shift MLP backbone by\nconsidering the communications between patches from different views. R$^2$-MLP\nrolls part of the channels along the view dimension and promotes information\nexchange between neighboring views. We benchmark MLP results on ModelNet10 and\nModelNet40 datasets with ablations in various aspects. The experimental results\nshow that, with a conceptually simple structure, our R$^2$-MLP achieves\ncompetitive performance compared with existing state-of-the-art methods.", "authors": ["Shuo Chen", "Tan Yu", "Ping Li"], "published_date": "2022_11_20", "pdf_url": "http://arxiv.org/pdf/2211.11085v1", "list_table_and_caption": [{"table": "<table><thead><tr><th>Method</th><th>Views</th><th>ModelNet40</th><th>ModelNet10</th></tr></thead><tbody><tr><th>MVCNN (Su et al., 2015)</th><th>80</th><td>90.1</td><td>-</td></tr><tr><th>RotationNet (Kanezaki et al., 2018)</th><th>12</th><td>91.0</td><td>94.0</td></tr><tr><th>GVCNN (Feng et al., 2018)</th><th>12</th><td>93.1</td><td>-</td></tr><tr><th>Relation Network (Yang and Wang, 2019)</th><th>12</th><td>94.3</td><td>95.3</td></tr><tr><th>3D2SeqViews (Han et al., 2019a)</th><th>12</th><td>93.4</td><td>94.7</td></tr><tr><th>SeqViews2SeqLabels (Han et al., 2019b)</th><th>12</th><td>93.4</td><td>94.8</td></tr><tr><th>MLVCNN (Jiang et al., 2019)</th><th>12</th><td>94.2</td><td>-</td></tr><tr><th>CAR-Net (Xu et al., 2021)</th><th>12</th><td>95.2</td><td>95.8</td></tr><tr><th>MVT-small (Chen et al., 2021)</th><th>12</th><td>94.4</td><td>95.3</td></tr><tr><th>R{}^{2}-MLP-36 (Ours)</th><th>6</th><td>94.7</td><td>95.9</td></tr><tr><th>R{}^{2}-MLP-36 (Ours)</th><th>12</th><td>95.0</td><td>97.4</td></tr><tr><th>RotationNet (Kanezaki et al., 2018)</th><th>20</th><td>97.4</td><td>98.5</td></tr><tr><th>View-GCN (Wei et al., 2020)</th><th>20</th><td>97.6</td><td>-</td></tr><tr><th>CAR-Net (Xu et al., 2021)</th><th>20</th><td>97.7</td><td>99.0</td></tr><tr><th>MVT-small (Chen et al., 2021)</th><th>20</th><td>97.5</td><td>99.3</td></tr><tr><th>R{}^{2}-MLP-36 (Ours)</th><th>20</th><td>97.7</td><td>99.6</td></tr></tbody></table>", "caption": "Table 8: Comparison with the present state-of-the-art methods on the ModelNet40 dataset. The best accuracy is bold.", "list_citation_info": ["Kanezaki et al. [2018] Asako Kanezaki, Yasuyuki Matsushita, and Yoshifumi Nishida. RotationNet: Joint object categorization and pose estimation using multiviews from unsupervised viewpoints. In Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5010\u20135019, Salt Lake City, UT, 2018.", "Han et al. [2019a] Zhizhong Han, Honglei Lu, Zhenbao Liu, Chi-Man Vong, Yu-Shen Liu, Matthias Zwicker, Junwei Han, and C. L. Philip Chen. 3D2SeqViews: Aggregating sequential views for 3d global feature learning by CNN with hierarchical attention aggregation. IEEE Trans. Image Process., 28(8):3986\u20133999, 2019a.", "Xu et al. [2021] Yong Xu, Chaoda Zheng, Ruotao Xu, Yuhui Quan, and Haibin Ling. Multi-view 3d shape recognition via correspondence-aware deep learning. IEEE Trans. Image Process., 30:5299\u20135312, 2021.", "Su et al. [2015] Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik G. Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition. In Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), pages 945\u2013953, Santiago, Chile, 2015.", "Chen et al. [2021] Shuo Chen, Tan Yu, and Ping Li. MVT: multi-view vision transformer for 3D object recognition. In Proceedings of the 32nd British Machine Vision Conference (BMVC), page 349, Online, 2021.", "Jiang et al. [2019] Jianwen Jiang, Di Bao, Ziqiang Chen, Xibin Zhao, and Yue Gao. MLVCNN: multi-loop-view convolutional neural network for 3d shape retrieval. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI), pages 8513\u20138520, Honolulu, HI, 2019.", "Yang and Wang [2019] Ze Yang and Liwei Wang. Learning relationships for multi-view 3d object recognition. In Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pages 7504\u20137513, Seoul, Korea, 2019.", "Feng et al. [2018] Yifan Feng, Zizhao Zhang, Xibin Zhao, Rongrong Ji, and Yue Gao. GVCNN: group-view convolutional neural networks for 3d shape recognition. In Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 264\u2013272, Salt Lake City, UT, 2018.", "Wei et al. [2020] Xin Wei, Ruixuan Yu, and Jian Sun. View-GCN: View-based graph convolutional network for 3d shape analysis. In Proceedings of the 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1847\u20131856, Seattle, WA, 2020.", "Han et al. [2019b] Zhizhong Han, Mingyang Shang, Zhenbao Liu, Chi-Man Vong, Yu-Shen Liu, Matthias Zwicker, Junwei Han, and C. L. Philip Chen. SeqViews2SeqLabels: Learning 3D global features via aggregating sequential views by RNN with attention. IEEE Trans. Image Process., 28(2):658\u2013672, 2019b."]}, {"table": "<table><thead><tr><th>Model</th><th>CAR-Net (Xu et al., 2021)</th><th>R{}^{2}-MLP-36 (Ours)</th></tr></thead><tbody><tr><th>inference</th><td>0.20 s</td><td>0.07 s</td></tr></tbody></table>", "caption": "Table 9: Comparison of inference time on ModelNet40.Our model\u2019s inference speed is faster by a large margin.", "list_citation_info": ["Xu et al. [2021] Yong Xu, Chaoda Zheng, Ruotao Xu, Yuhui Quan, and Haibin Ling. Multi-view 3d shape recognition via correspondence-aware deep learning. IEEE Trans. Image Process., 30:5299\u20135312, 2021."]}, {"table": "<table><thead><tr><th>Method</th><th>Views</th><th>mAP</th></tr></thead><tbody><tr><th>LFD (Chen et al., 2003)</th><td>Volume</td><td>40.0</td></tr><tr><th>3DShapeNets (Chang et al., 2015)</th><td>Volume</td><td>49.2</td></tr><tr><th>PVNet (You et al., 2018)</th><td>Point</td><td>89.5</td></tr><tr><th>MVCNN (Su et al., 2015)</th><td>12</td><td>80.2</td></tr><tr><th>MLVCNN (Jiang et al., 2019)</th><td>24</td><td>92.2</td></tr><tr><th>MVTN (Hamdi et al., 2021)</th><td>12</td><td>92.9</td></tr><tr><th>R{}^{2}-MLP (Ours)</th><td>12</td><td>93.0</td></tr><tr><th>R{}^{2}-MLP (Ours)</th><td>20</td><td>93.1</td></tr></tbody></table>", "caption": "Table 10: 3D shape retrieval comparison with the state-of-the-art methods on the ModelNet40 dataset. R{}^{2}-MLP achieves the best retrieval performance among recent state-of-the-art methods.", "list_citation_info": ["You et al. [2018] Haoxuan You, Yifan Feng, Rongrong Ji, and Yue Gao. PVNet: A joint convolutional network of point cloud and multi-view for 3D shape recognition. In proceedings of the 2018 ACM Multimedia Conference on Multimedia Conference (MM), pages 1310\u20131318, Seoul, Korea, 2018.", "Chen et al. [2003] Ding-Yun Chen, Xiao-Pei Tian, Yu-Te Shen, and Ming Ouhyoung. On visual similarity based 3d model retrieval. Comput. Graph. Forum, 22(3):223\u2013232, 2003.", "Hamdi et al. [2021] Abdullah Hamdi, Silvio Giancola, and Bernard Ghanem. MVTN: multi-view transformation network for 3d shape recognition. In Proceedings of the 2021 IEEE/CVF International Conference on Computer Vision (ICCV), pages 1\u201311, Montreal, Canada, 2021.", "Su et al. [2015] Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik G. Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition. In Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), pages 945\u2013953, Santiago, Chile, 2015.", "Jiang et al. [2019] Jianwen Jiang, Di Bao, Ziqiang Chen, Xibin Zhao, and Yue Gao. MLVCNN: multi-loop-view convolutional neural network for 3d shape retrieval. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI), pages 8513\u20138520, Honolulu, HI, 2019.", "Chang et al. [2015] Angel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.03012, 2015."]}], "citation_info_to_title": {"Feng et al. [2018] Yifan Feng, Zizhao Zhang, Xibin Zhao, Rongrong Ji, and Yue Gao. GVCNN: group-view convolutional neural networks for 3d shape recognition. In Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 264\u2013272, Salt Lake City, UT, 2018.": "GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition", "Chen et al. [2021] Shuo Chen, Tan Yu, and Ping Li. MVT: multi-view vision transformer for 3D object recognition. In Proceedings of the 32nd British Machine Vision Conference (BMVC), page 349, Online, 2021.": "MVT: Multi-View Vision Transformer for 3D Object Recognition", "Chang et al. [2015] Angel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.03012, 2015.": "ShapeNet: An information-rich 3D model repository", "Yang and Wang [2019] Ze Yang and Liwei Wang. Learning relationships for multi-view 3d object recognition. In Proceedings of the 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pages 7504\u20137513, Seoul, Korea, 2019.": "Learning relationships for multi-view 3d object recognition", "Kanezaki et al. [2018] Asako Kanezaki, Yasuyuki Matsushita, and Yoshifumi Nishida. RotationNet: Joint object categorization and pose estimation using multiviews from unsupervised viewpoints. In Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5010\u20135019, Salt Lake City, UT, 2018.": "RotationNet: Joint object categorization and pose estimation using multiviews from unsupervised viewpoints", "Chen et al. [2003] Ding-Yun Chen, Xiao-Pei Tian, Yu-Te Shen, and Ming Ouhyoung. On visual similarity based 3d model retrieval. Comput. Graph. Forum, 22(3):223\u2013232, 2003.": "On visual similarity based 3d model retrieval", "Han et al. [2019a] Zhizhong Han, Honglei Lu, Zhenbao Liu, Chi-Man Vong, Yu-Shen Liu, Matthias Zwicker, Junwei Han, and C. L. Philip Chen. 3D2SeqViews: Aggregating sequential views for 3d global feature learning by CNN with hierarchical attention aggregation. IEEE Trans. Image Process., 28(8):3986\u20133999, 2019a.": "3D2SeqViews: Aggregating sequential views for 3d global feature learning by CNN with hierarchical attention aggregation", "Xu et al. [2021] Yong Xu, Chaoda Zheng, Ruotao Xu, Yuhui Quan, and Haibin Ling. Multi-view 3d shape recognition via correspondence-aware deep learning. IEEE Trans. Image Process., 30:5299\u20135312, 2021.": "Multi-view 3d shape recognition via correspondence-aware deep learning", "Wei et al. [2020] Xin Wei, Ruixuan Yu, and Jian Sun. View-GCN: View-based graph convolutional network for 3d shape analysis. In Proceedings of the 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1847\u20131856, Seattle, WA, 2020.": "View-GCN: View-based graph convolutional network for 3d shape analysis", "Su et al. [2015] Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik G. Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition. In Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), pages 945\u2013953, Santiago, Chile, 2015.": "Multi-view convolutional neural networks for 3d shape recognition", "You et al. [2018] Haoxuan You, Yifan Feng, Rongrong Ji, and Yue Gao. PVNet: A joint convolutional network of point cloud and multi-view for 3D shape recognition. In proceedings of the 2018 ACM Multimedia Conference on Multimedia Conference (MM), pages 1310\u20131318, Seoul, Korea, 2018.": "PVNet: A joint convolutional network of point cloud and multi-view for 3D shape recognition", "Jiang et al. [2019] Jianwen Jiang, Di Bao, Ziqiang Chen, Xibin Zhao, and Yue Gao. MLVCNN: multi-loop-view convolutional neural network for 3d shape retrieval. In Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI), pages 8513\u20138520, Honolulu, HI, 2019.": "MLVCNN: Multi-Loop-View Convolutional Neural Network for 3D Shape Retrieval", "Hamdi et al. [2021] Abdullah Hamdi, Silvio Giancola, and Bernard Ghanem. MVTN: multi-view transformation network for 3d shape recognition. In Proceedings of the 2021 IEEE/CVF International Conference on Computer Vision (ICCV), pages 1\u201311, Montreal, Canada, 2021.": "MVTN: Multi-View Transformation Network for 3D Shape Recognition", "Han et al. [2019b] Zhizhong Han, Mingyang Shang, Zhenbao Liu, Chi-Man Vong, Yu-Shen Liu, Matthias Zwicker, Junwei Han, and C. L. Philip Chen. SeqViews2SeqLabels: Learning 3D global features via aggregating sequential views by RNN with attention. IEEE Trans. Image Process., 28(2):658\u2013672, 2019b.": "SeqViews2SeqLabels: Learning 3D global features via aggregating sequential views by RNN with attention"}, "source_title_to_arxiv_id": {"MVTN: Multi-View Transformation Network for 3D Shape Recognition": "2011.13244"}}