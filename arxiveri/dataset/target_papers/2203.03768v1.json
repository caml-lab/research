{"title": "CrowdFormer: Weakly-supervised Crowd counting with Improved Generalizability", "abstract": "Convolutional neural networks (CNNs) have dominated the field of computer\nvision for nearly a decade due to their strong ability to learn local features.\nHowever, due to their limited receptive field, CNNs fail to model the global\ncontext. On the other hand, transformer, an attention-based architecture can\nmodel the global context easily. Despite this, there are limited studies that\ninvestigate the effectiveness of transformers in crowd counting. In addition,\nthe majority of the existing crowd counting methods are based on the regression\nof density maps which requires point-level annotation of each person present in\nthe scene. This annotation task is laborious and also error-prone. This has led\nto increased focus on weakly-supervised crowd counting methods which require\nonly the count-level annotations. In this paper, we propose a weakly-supervised\nmethod for crowd counting using a pyramid vision transformer. We have conducted\nextensive evaluations to validate the effectiveness of the proposed method. Our\nmethod is comparable to the state-of-the-art on the benchmark crowd datasets.\nMore importantly, it shows remarkable generalizability.", "authors": ["Siddharth Singh Savner", "Vivek Kanhangad"], "published_date": "2022_03_07", "pdf_url": "http://arxiv.org/pdf/2203.03768v1", "list_table_and_caption": [{"table": "<table><thead><tr><th rowspan=\"2\">Method</th><th colspan=\"2\">UCF_CC_50</th><th colspan=\"2\">QNRF</th><th colspan=\"2\">SHA</th><th colspan=\"2\">SHB</th></tr><tr><th>MAE</th><th>MSE</th><th>MAE</th><th>MSE</th><th>MAE</th><th>MSE</th><th>MAE</th><th>MSE</th></tr></thead><tbody><tr><th>Yang et al. [9]</th><td>-</td><td>-</td><td>-</td><td>-</td><td>104.6</td><td>145.2</td><td>12.3</td><td>21.2</td></tr><tr><th>MATT [6]</th><td>355.0</td><td>550.2</td><td>-</td><td>-</td><td>80.1</td><td>129.4</td><td>11.7</td><td>17.5</td></tr><tr><th>TransCrowd [11]</th><td>-</td><td>-</td><td>97.2</td><td>168.5</td><td>66.1</td><td>105.1</td><td>9.3</td><td>16.1</td></tr><tr><th>CCTrans [12]</th><td>245.0</td><td>343.6</td><td>92.1</td><td>158.9</td><td>64.4</td><td>95.4</td><td>7.0</td><td>11.5</td></tr><tr><th>ours</th><td>229.6</td><td>360.3</td><td>93.3</td><td>160.9</td><td>62.1</td><td>94.8</td><td>8.5</td><td>13.6</td></tr></tbody></table>", "caption": "Table 1: Comparison with state-of-the-art weakly-supervised methods on SHA [16], SHB [16], UCF_CC_50 [17], andQNRF [18] datasets. The best and second best results are shown in bold and underline, respectively.", "list_citation_info": ["[17] H. Idrees, I. Saleemi, C. Seibert, and M. Shah, \u201cMulti-source multi-scale counting in extremely dense crowd images,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013, pp. 2547\u20132554.", "[12] Y. Tian, X. Chu, and H. Wang, \u201cCCTrans: Simplifying and improving crowd counting with transformer,\u201d arXiv preprint arXiv:2109.14483, 2021.", "[6] Y. Lei, Y. Liu, P. Zhang, and L. Liu, \u201cTowards using count-level weak supervision for crowd counting,\u201d Pattern Recognition, vol. 109, p. 107616, 2020.", "[18] H. Idrees, M. Tayyab, K. Athrey, D. Zhang, S. Al-Maadeed, N. Rajpoot, and M. Shah, \u201cComposition loss for counting, density map estimation and localization in dense crowds,\u201d in European Conference on Computer Vision (ECCV), 2018, pp. 532\u2013546.", "[11] D. Liang, X. Chen, W. Xu, Y. Zhou, and X. Bai, \u201cTransCrowd: Weakly-supervised crowd counting with transformer,\u201d arXiv preprint arXiv:2104.09116, 2021.", "[16] Y. Zhang, D. Zhou, S. Chen, S. Gao, and Y. Ma, \u201cSingle-image crowd counting via multi-column convolutional neural network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 589\u2013597.", "[9] Y. Yang, G. Li, Z. Wu, L. Su, and N. Sebe, \u201cWeakly-supervised crowd counting learns from sorting rather than locations,\u201d in 2020 European Conference on Computer Vision (ECCV), 11 2020, pp. 1\u201317."]}, {"table": "<table><tbody><tr><th rowspan=\"2\">Method</th><td colspan=\"2\">SHB \\rightarrow SHA</td><td colspan=\"2\">SHA \\rightarrow SHB</td><td colspan=\"2\">QNRF \\rightarrow SHA</td><td colspan=\"2\">QNRF \\rightarrow SHB</td><td colspan=\"2\">SHA \\rightarrow QNRF</td><td colspan=\"2\">SHB \\rightarrow QNRF</td></tr><tr><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td><td>MAE</td><td>MSE</td></tr><tr><th>MCNN [16]#</th><td>221.4</td><td>357.8</td><td>85.2</td><td>142.3</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>D-ConvNet [19] #</th><td>140.4</td><td>226.1</td><td>49.1</td><td>99.2</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>RRSP [20] #</th><td>-</td><td>-</td><td>40.0</td><td>68.5</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>BL [21] #</th><td>-</td><td>-</td><td>-</td><td>-</td><td>69.8</td><td>123.8</td><td>15.3</td><td>26.5</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>TransCrowd [11]*</th><td>141.3</td><td>258.9</td><td>18.9</td><td>31.1</td><td>78.7</td><td>122.5</td><td>13.5</td><td>21.9</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>ours*</th><td>121.6</td><td>208.8</td><td>16.0</td><td>26.0</td><td>70.8</td><td>114.9</td><td>10.3</td><td>16.0</td><td>147.6</td><td>300.8</td><td>304.4</td><td>586.1</td></tr></tbody></table>", "caption": "Table 2: Performance comparison of different methods in cross-dataset settings. The best and second best results are shown in bold and underline, respectively. (# - fully-supervised, * - weakly-supervised).", "list_citation_info": ["[11] D. Liang, X. Chen, W. Xu, Y. Zhou, and X. Bai, \u201cTransCrowd: Weakly-supervised crowd counting with transformer,\u201d arXiv preprint arXiv:2104.09116, 2021.", "[21] Z. Ma, X. Wei, X. Hong, and Y. Gong, \u201cBayesian loss for crowd count estimation with point supervision,\u201d in 2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp. 6141\u20136150.", "[20] J. Wan, W. Luo, B. Wu, A. B. Chan, and W. Liu, \u201cResidual regression with semantic prior for crowd counting,\u201d in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 4031\u20134040.", "[19] Z. Shi, L. Zhang, Y. Liu, X. Cao, Y. Ye, M.-M. Cheng, and G. Zheng, \u201cCrowd counting with deep negative correlation learning,\u201d in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 5382\u20135390.", "[16] Y. Zhang, D. Zhou, S. Chen, S. Gao, and Y. Ma, \u201cSingle-image crowd counting via multi-column convolutional neural network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 589\u2013597."]}], "citation_info_to_title": {"[18] H. Idrees, M. Tayyab, K. Athrey, D. Zhang, S. Al-Maadeed, N. Rajpoot, and M. Shah, \u201cComposition loss for counting, density map estimation and localization in dense crowds,\u201d in European Conference on Computer Vision (ECCV), 2018, pp. 532\u2013546.": "Composition Loss for Counting, Density Map Estimation and Localization in Dense Crowds", "[16] Y. Zhang, D. Zhou, S. Chen, S. Gao, and Y. Ma, \u201cSingle-image crowd counting via multi-column convolutional neural network,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 589\u2013597.": "Single-image crowd counting via multi-column convolutional neural network", "[17] H. Idrees, I. Saleemi, C. Seibert, and M. Shah, \u201cMulti-source multi-scale counting in extremely dense crowd images,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013, pp. 2547\u20132554.": "Multi-source multi-scale counting in extremely dense crowd images", "[9] Y. Yang, G. Li, Z. Wu, L. Su, and N. Sebe, \u201cWeakly-supervised crowd counting learns from sorting rather than locations,\u201d in 2020 European Conference on Computer Vision (ECCV), 11 2020, pp. 1\u201317.": "Weakly-supervised crowd counting learns from sorting rather than locations", "[21] Z. Ma, X. Wei, X. Hong, and Y. Gong, \u201cBayesian loss for crowd count estimation with point supervision,\u201d in 2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp. 6141\u20136150.": "Bayesian loss for crowd count estimation with point supervision", "[6] Y. Lei, Y. Liu, P. Zhang, and L. Liu, \u201cTowards using count-level weak supervision for crowd counting,\u201d Pattern Recognition, vol. 109, p. 107616, 2020.": "Towards using count-level weak supervision for crowd counting", "[11] D. Liang, X. Chen, W. Xu, Y. Zhou, and X. Bai, \u201cTransCrowd: Weakly-supervised crowd counting with transformer,\u201d arXiv preprint arXiv:2104.09116, 2021.": "TransCrowd: Weakly-supervised crowd counting with transformer", "[20] J. Wan, W. Luo, B. Wu, A. B. Chan, and W. Liu, \u201cResidual regression with semantic prior for crowd counting,\u201d in 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 4031\u20134040.": "Residual regression with semantic prior for crowd counting", "[12] Y. Tian, X. Chu, and H. Wang, \u201cCCTrans: Simplifying and improving crowd counting with transformer,\u201d arXiv preprint arXiv:2109.14483, 2021.": "CCTrans: Simplifying and improving crowd counting with transformer", "[19] Z. Shi, L. Zhang, Y. Liu, X. Cao, Y. Ye, M.-M. Cheng, and G. Zheng, \u201cCrowd counting with deep negative correlation learning,\u201d in 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2018, pp. 5382\u20135390.": "Crowd counting with deep negative correlation learning"}, "source_title_to_arxiv_id": {"TransCrowd: Weakly-supervised crowd counting with transformer": "2104.09116"}}