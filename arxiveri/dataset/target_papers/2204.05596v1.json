{"title": "On the Equity of Nuclear Norm Maximization in Unsupervised Domain Adaptation", "abstract": "Nuclear norm maximization has shown the power to enhance the transferability\nof unsupervised domain adaptation model (UDA) in an empirical scheme. In this\npaper, we identify a new property termed equity, which indicates the balance\ndegree of predicted classes, to demystify the efficacy of nuclear norm\nmaximization for UDA theoretically. With this in mind, we offer a new\ndiscriminability-and-equity maximization paradigm built on squares loss, such\nthat predictions are equalized explicitly. To verify its feasibility and\nflexibility, two new losses termed Class Weighted Squares Maximization (CWSM)\nand Normalized Squares Maximization (NSM), are proposed to maximize both\npredictive discriminability and equity, from the class level and the sample\nlevel, respectively. Importantly, we theoretically relate these two novel\nlosses (i.e., CWSM and NSM) to the equity maximization under mild conditions,\nand empirically suggest the importance of the predictive equity in UDA.\nMoreover, it is very efficient to realize the equity constraints in both\nlosses. Experiments of cross-domain image classification on three popular\nbenchmark datasets show that both CWSM and NSM contribute to outperforming the\ncorresponding counterparts.", "authors": ["Wenju Zhang", "Xiang Zhang", "Qing Liao", "Long Lan", "Mengzhu Wang", "Wei Wang", "Baoyun Peng", "Zhengming Ding"], "published_date": "2022_04_12", "pdf_url": "http://arxiv.org/pdf/2204.05596v1", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Method</td><td>A\\toW</td><td>D\\toW</td><td>W\\toD</td><td>A\\toD</td><td>D\\toA</td><td>W\\toA</td><td>Avg</td></tr><tr><td>ResNet-50 he2016deep </td><td>68.4</td><td>96.7</td><td>99.3</td><td>68.9</td><td>62.5</td><td>60.7</td><td>76.1</td></tr><tr><td>DAN long2015learning </td><td>80.5</td><td>97.1</td><td>99.6</td><td>78.6</td><td>63.6</td><td>62.8</td><td>80.4</td></tr><tr><td>DANN ganin2016domain </td><td>82.0</td><td>96.9</td><td>99.1</td><td>79.7</td><td>68.2</td><td>67.4</td><td>82.2</td></tr><tr><td>JAN long2017deep </td><td>85.4</td><td>97.4</td><td>99.8</td><td>84.7</td><td>68.6</td><td>70.0</td><td>84.3</td></tr><tr><td>CDAN long2018conditional </td><td>94.1</td><td>98.6</td><td>100.0</td><td>92.9</td><td>71.0</td><td>69.3</td><td>87.7</td></tr><tr><td>SAFN xu2019larger </td><td>90.1</td><td>98.6</td><td>99.8</td><td>90.7</td><td>73.0</td><td>70.2</td><td>87.1</td></tr><tr><td>SymNets zhang2019domain </td><td>90.8</td><td>98.8</td><td>100.0</td><td>93.9</td><td>74.6</td><td>72.5</td><td>88.4</td></tr><tr><td>MaxSquare chen2019domain </td><td>92.4</td><td>99.1</td><td>100.0</td><td>90.0</td><td>68.1</td><td>64.2</td><td>85.6</td></tr><tr><td>BNM* cui2020towards </td><td>95.2</td><td>98.6</td><td>99.6</td><td>92.3</td><td>75.1</td><td>75.4</td><td>89.4</td></tr><tr><td>CWSM</td><td>94.5</td><td>99.0</td><td>99.7</td><td>92.6</td><td>75.6</td><td>75.9</td><td>89.6</td></tr><tr><td>NSM</td><td>95.4</td><td>98.8</td><td>99.5</td><td>93.8</td><td>75.6</td><td>76.3</td><td>89.9</td></tr></tbody></table>", "caption": "Table 4: Accuracy (%) of compared methods on the Office-31 dataset based on ResNet-50.", "list_citation_info": ["(23) M. Long, Y. Cao, J. Wang, M. Jordan, Learning transferable features with deep adaptation networks, in: International Conference on Machine Learning, 2015, pp. 97\u2013105.", "(33) Y. Zhang, H. Tang, K. Jia, M. Tan, Domain-symmetric networks for adversarial domain adaptation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 5031\u20135040.", "(20) M. Chen, H. Xue, D. Cai, Domain adaptation for semantic segmentation with maximum squares loss, in: Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 2090\u20132099.", "(42) K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 770\u2013778.", "(29) M. Long, H. Zhu, J. Wang, M. I. Jordan, Deep transfer learning with joint adaptation networks, in: International Conference on Machine Learning, 2017, pp. 2208\u20132217.", "(31) Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. March, V. Lempitsky, Domain-adversarial training of neural networks, Journal of Machine Learning Research 17 (59) (2016) 1\u201335.", "(32) M. Long, Z. Cao, J. Wang, M. I. Jordan, Conditional adversarial domain adaptation, in: Advances in Neural Information Processing Systems, 2018, pp. 1640\u20131650.", "(24) R. Xu, G. Li, J. Yang, L. Lin, Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation, in: Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 1426\u20131435.", "(21) S. Cui, S. Wang, J. Zhuo, L. Li, Q. Huang, Q. Tian, Towards discriminability and diversity: Batch nuclear-norm maximization under label insufficient situations, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 3941\u20133950."]}, {"table": "<table><tbody><tr><td>Method</td><td>Ar\\toCl</td><td>Ar\\toPr</td><td>Ar\\toRw</td><td>Cl\\toAr</td><td>Cl\\toPr</td><td>Cl\\toRw</td><td>Pr\\toAr</td><td>Pr\\toCl</td><td>Pr\\toRw</td><td>Rw\\toAr</td><td>Rw\\toCl</td><td>Rw\\toPr</td><td>Avg</td></tr><tr><td>ResNet-50 he2016deep </td><td>34.9</td><td>50.0</td><td>58.0</td><td>37.4</td><td>41.9</td><td>46.2</td><td>38.5</td><td>31.2</td><td>60.4</td><td>53.9</td><td>41.2</td><td>59.9</td><td>46.1</td></tr><tr><td>DAN long2015learning </td><td>43.6</td><td>57.0</td><td>67.9</td><td>45.8</td><td>56.5</td><td>60.4</td><td>44.0</td><td>43.6</td><td>67.7</td><td>63.1</td><td>51.5</td><td>74.3</td><td>56.3</td></tr><tr><td>DANN ganin2016domain </td><td>45.6</td><td>59.3</td><td>70.1</td><td>47.0</td><td>58.5</td><td>60.9</td><td>46.1</td><td>43.7</td><td>68.5</td><td>63.2</td><td>51.8</td><td>76.8</td><td>57.6</td></tr><tr><td>JAN long2017deep </td><td>45.9</td><td>61.2</td><td>68.9</td><td>50.4</td><td>59.7</td><td>61.0</td><td>45.8</td><td>43.4</td><td>70.3</td><td>63.9</td><td>52.4</td><td>76.8</td><td>58.3</td></tr><tr><td>CDAN long2018conditional </td><td>50.7</td><td>70.6</td><td>76.0</td><td>57.6</td><td>70.0</td><td>70.0</td><td>57.4</td><td>50.9</td><td>77.3</td><td>70.9</td><td>56.7</td><td>81.6</td><td>65.8</td></tr><tr><td>SAFN xu2019larger </td><td>52.0</td><td>71.7</td><td>76.3</td><td>64.2</td><td>69.9</td><td>71.9</td><td>63.7</td><td>51.4</td><td>77.1</td><td>70.9</td><td>57.1</td><td>81.5</td><td>67.3</td></tr><tr><td>SymNets zhang2019domain </td><td>47.7</td><td>72.9</td><td>78.5</td><td>64.2</td><td>71.3</td><td>74.2</td><td>64.2</td><td>48.8</td><td>79.5</td><td>74.5</td><td>52.6</td><td>82.7</td><td>67.6</td></tr><tr><td>MaxSquare* chen2019domain </td><td>50.3</td><td>70.9</td><td>76.5</td><td>60.5</td><td>68.3</td><td>69.8</td><td>59.0</td><td>47.0</td><td>76.5</td><td>70.4</td><td>53.0</td><td>80.9</td><td>65.3</td></tr><tr><td>BNM* cui2020towards </td><td>54.3</td><td>74.9</td><td>79.3</td><td>64.2</td><td>74.6</td><td>74.6</td><td>61.8</td><td>52.7</td><td>80.2</td><td>71.5</td><td>56.4</td><td>83.0</td><td>69.0</td></tr><tr><td>CWSM</td><td>55.8</td><td>75.9</td><td>79.8</td><td>65.6</td><td>74.6</td><td>75.6</td><td>63.3</td><td>53.8</td><td>80.7</td><td>72.9</td><td>57.1</td><td>83.4</td><td>69.9</td></tr><tr><td>NSM</td><td>56.8</td><td>76.5</td><td>80.3</td><td>66.6</td><td>75.6</td><td>75.9</td><td>63.6</td><td>53.9</td><td>81.0</td><td>73.3</td><td>57.9</td><td>83.8</td><td>70.4</td></tr></tbody></table>", "caption": "Table 5: Accuracy (%) of compared methods on the Office-Home dataset based on ResNet-50.", "list_citation_info": ["(23) M. Long, Y. Cao, J. Wang, M. Jordan, Learning transferable features with deep adaptation networks, in: International Conference on Machine Learning, 2015, pp. 97\u2013105.", "(33) Y. Zhang, H. Tang, K. Jia, M. Tan, Domain-symmetric networks for adversarial domain adaptation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 5031\u20135040.", "(20) M. Chen, H. Xue, D. Cai, Domain adaptation for semantic segmentation with maximum squares loss, in: Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 2090\u20132099.", "(42) K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 770\u2013778.", "(29) M. Long, H. Zhu, J. Wang, M. I. Jordan, Deep transfer learning with joint adaptation networks, in: International Conference on Machine Learning, 2017, pp. 2208\u20132217.", "(31) Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. March, V. Lempitsky, Domain-adversarial training of neural networks, Journal of Machine Learning Research 17 (59) (2016) 1\u201335.", "(32) M. Long, Z. Cao, J. Wang, M. I. Jordan, Conditional adversarial domain adaptation, in: Advances in Neural Information Processing Systems, 2018, pp. 1640\u20131650.", "(24) R. Xu, G. Li, J. Yang, L. Lin, Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation, in: Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 1426\u20131435.", "(21) S. Cui, S. Wang, J. Zhuo, L. Li, Q. Huang, Q. Tian, Towards discriminability and diversity: Batch nuclear-norm maximization under label insufficient situations, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 3941\u20133950."]}, {"table": "<table><tbody><tr><td>Method</td><td>plane</td><td>bcycl</td><td>bus</td><td>car</td><td>horse</td><td>knife</td><td>mcycl</td><td>person</td><td>plant</td><td>sktbrd</td><td>train</td><td>truck</td><td>Avg</td></tr><tr><td>ResNet-101 he2016deep </td><td>55.1</td><td>53.3</td><td>61.9</td><td>59.1</td><td>80.6</td><td>17.9</td><td>79.7</td><td>31.2</td><td>81.0</td><td>26.5</td><td>73.5</td><td>8.5</td><td>52.4</td></tr><tr><td>DANN ganin2016domain </td><td>81.9</td><td>77.7</td><td>82.8</td><td>44.3</td><td>81.2</td><td>29.5</td><td>65.1</td><td>28.6</td><td>51.9</td><td>54.6</td><td>82.8</td><td>7.8</td><td>57.4</td></tr><tr><td>DAN long2015learning </td><td>87.1</td><td>63.0</td><td>76.5</td><td>42.0</td><td>90.3</td><td>42.9</td><td>85.9</td><td>53.1</td><td>49.7</td><td>36.3</td><td>85.8</td><td>20.7</td><td>61.1</td></tr><tr><td>MaxSquare* chen2019domain </td><td>92.4</td><td>42.4</td><td>81.2</td><td>74.8</td><td>89.2</td><td>89.7</td><td>92.4</td><td>55.8</td><td>80.5</td><td>46.1</td><td>86.6</td><td>15.4</td><td>70.5</td></tr><tr><td>CDAN long2018conditional </td><td>85.2</td><td>66.9</td><td>83.0</td><td>50.8</td><td>84.2</td><td>74.9</td><td>88.1</td><td>74.5</td><td>83.4</td><td>76.0</td><td>81.9</td><td>38.0</td><td>73.9</td></tr><tr><td>SAFN xu2019larger </td><td>93.6</td><td>61.3</td><td>84.1</td><td>70.6</td><td>94.1</td><td>79.0</td><td>91.8</td><td>79.6</td><td>89.9</td><td>55.6</td><td>89.0</td><td>24.4</td><td>76.1</td></tr><tr><td>BNM* cui2020towards </td><td>94.0</td><td>82.7</td><td>77.2</td><td>65.2</td><td>93.1</td><td>76.2</td><td>85.9</td><td>77.4</td><td>88.5</td><td>68.2</td><td>89.3</td><td>47.9</td><td>78.8</td></tr><tr><td>CWSM</td><td>93.2</td><td>81.9</td><td>83.2</td><td>69.9</td><td>92.9</td><td>80.4</td><td>86.8</td><td>76.8</td><td>89.7</td><td>79.5</td><td>88.3</td><td>41.2</td><td>80.3</td></tr><tr><td>NSM</td><td>93.8</td><td>81.8</td><td>83.0</td><td>66.0</td><td>93.2</td><td>81.8</td><td>89.0</td><td>78.5</td><td>92.1</td><td>77.1</td><td>89.7</td><td>38.3</td><td>80.4</td></tr></tbody></table>", "caption": "Table 6: Accuracy (%) of compared methods on the VisDA-2017 dataset based on ResNet-101.", "list_citation_info": ["(23) M. Long, Y. Cao, J. Wang, M. Jordan, Learning transferable features with deep adaptation networks, in: International Conference on Machine Learning, 2015, pp. 97\u2013105.", "(20) M. Chen, H. Xue, D. Cai, Domain adaptation for semantic segmentation with maximum squares loss, in: Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 2090\u20132099.", "(42) K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 770\u2013778.", "(31) Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. March, V. Lempitsky, Domain-adversarial training of neural networks, Journal of Machine Learning Research 17 (59) (2016) 1\u201335.", "(32) M. Long, Z. Cao, J. Wang, M. I. Jordan, Conditional adversarial domain adaptation, in: Advances in Neural Information Processing Systems, 2018, pp. 1640\u20131650.", "(24) R. Xu, G. Li, J. Yang, L. Lin, Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation, in: Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 1426\u20131435.", "(21) S. Cui, S. Wang, J. Zhuo, L. Li, Q. Huang, Q. Tian, Towards discriminability and diversity: Batch nuclear-norm maximization under label insufficient situations, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 3941\u20133950."]}], "citation_info_to_title": {"(21) S. Cui, S. Wang, J. Zhuo, L. Li, Q. Huang, Q. Tian, Towards discriminability and diversity: Batch nuclear-norm maximization under label insufficient situations, in: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 3941\u20133950.": "Towards discriminability and diversity: Batch nuclear-norm maximization under label insufficient situations", "(32) M. Long, Z. Cao, J. Wang, M. I. Jordan, Conditional adversarial domain adaptation, in: Advances in Neural Information Processing Systems, 2018, pp. 1640\u20131650.": "Conditional Adversarial Domain Adaptation", "(31) Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. March, V. Lempitsky, Domain-adversarial training of neural networks, Journal of Machine Learning Research 17 (59) (2016) 1\u201335.": "Domain-adversarial training of neural networks", "(29) M. Long, H. Zhu, J. Wang, M. I. Jordan, Deep transfer learning with joint adaptation networks, in: International Conference on Machine Learning, 2017, pp. 2208\u20132217.": "Deep transfer learning with joint adaptation networks", "(33) Y. Zhang, H. Tang, K. Jia, M. Tan, Domain-symmetric networks for adversarial domain adaptation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 5031\u20135040.": "Domain-symmetric networks for adversarial domain adaptation", "(20) M. Chen, H. Xue, D. Cai, Domain adaptation for semantic segmentation with maximum squares loss, in: Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 2090\u20132099.": "Domain Adaptation for Semantic Segmentation with Maximum Squares Loss", "(23) M. Long, Y. Cao, J. Wang, M. Jordan, Learning transferable features with deep adaptation networks, in: International Conference on Machine Learning, 2015, pp. 97\u2013105.": "Learning transferable features with deep adaptation networks", "(42) K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 770\u2013778.": "Deep residual learning for image recognition", "(24) R. Xu, G. Li, J. Yang, L. Lin, Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation, in: Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 1426\u20131435.": "Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation"}, "source_title_to_arxiv_id": {"Domain Adaptation for Semantic Segmentation with Maximum Squares Loss": "1909.13589"}}