{"title": "3D Part Assembly Generation with Instance Encoded Transformer", "abstract": "It is desirable to enable robots capable of automatic assembly. Structural\nunderstanding of object parts plays a crucial role in this task yet remains\nrelatively unexplored. In this paper, we focus on the setting of furniture\nassembly from a complete set of part geometries, which is essentially a 6-DoF\npart pose estimation problem. We propose a multi-layer transformer-based\nframework that involves geometric and relational reasoning between parts to\nupdate the part poses iteratively. We carefully design a unique instance\nencoding to solve the ambiguity between geometrically-similar parts so that all\nparts can be distinguished. In addition to assembling from scratch, we extend\nour framework to a new task called in-process part assembly. Analogous to\nfurniture maintenance, it requires robots to continue with unfinished products\nand assemble the remaining parts into appropriate positions. Our method\nachieves far more than 10% improvements over the current state-of-the-art in\nmultiple metrics on the public PartNet dataset. Extensive experiments and\nquantitative comparisons demonstrate the effectiveness of the proposed\nframework.", "authors": ["Rufeng Zhang", "Tao Kong", "Weihao Wang", "Xuan Han", "Mingyu You"], "published_date": "2022_07_05", "pdf_url": "http://arxiv.org/pdf/2207.01779v1", "list_table_and_caption": [{"table": "<table><tr><td></td><td colspan=\"3\">Shape Chamfer Distance \\downarrow</td><td colspan=\"3\">Part Accuracy \\uparrow</td><td colspan=\"3\">Connectivity Accuracy \\uparrow</td></tr><tr><td></td><td>Chair</td><td>Table</td><td>Lamp</td><td>Chair</td><td>Table</td><td>Lamp</td><td>Chair</td><td>Table</td><td>Lamp</td></tr><tr><td>B-Global [1, 2]</td><td>0.0146</td><td>0.0112</td><td>0.0079</td><td>15.70</td><td>15.37</td><td>22.61</td><td>9.90</td><td>33.84</td><td>18.60</td></tr><tr><td>B-LSTM [27]</td><td>0.0131</td><td>0.0125</td><td>0.0077</td><td>21.77</td><td>28.64</td><td>20.78</td><td>6.80</td><td>22.56</td><td>14.05</td></tr><tr><td>B-Complement [28]</td><td>0.0241</td><td>0.0298</td><td>0.0150</td><td>8.78</td><td>2.32</td><td>12.67</td><td>9.19</td><td>15.57</td><td>26.56</td></tr><tr><td> DGL-Net [7]</td><td>0.0091</td><td>0.0050</td><td>0.0093</td><td>39.00</td><td>49.51</td><td>33.33</td><td>23.87</td><td>39.96</td><td>41.70</td></tr><tr><td> RGL-Net [8]</td><td>0.0087</td><td>0.0048</td><td>0.0072</td><td>49.06</td><td>54.16</td><td>37.56</td><td>32.26</td><td>42.15</td><td>57.34</td></tr><tr><td>Ours</td><td>0.0054</td><td>0.0035</td><td>0.0103</td><td>62.80</td><td>61.67</td><td>38.68</td><td>48.45</td><td>56.18</td><td>62.62</td></tr></table>", "caption": "TABLE I: Part assembly results on PartNet dataset.", "list_citation_info": ["[8] A. Narayan, R. Nagar, and S. Raman, \u201cRgl-net: A recurrent graph learning framework for progressive part assembly,\u201d in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2022, pp. 78\u201387.", "[7] J. Huang, G. Zhan, Q. Fan, K. Mo, L. Shao, B. Chen, L. Guibas, and H. Dong, \u201cGenerative 3d part assembly via dynamic graph learning,\u201d The IEEE Conference on Neural Information Processing Systems (NeurIPS), 2020.", "[27] R. Wu, Y. Zhuang, K. Xu, H. Zhang, and B. Chen, \u201cPq-net: A generative part seq2seq network for 3d shapes,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 829\u2013838.", "[28] M. Sung, H. Su, V. G. Kim, S. Chaudhuri, and L. Guibas, \u201cComplementme: Weakly-supervised component suggestions for 3d modeling,\u201d ACM Transactions on Graphics (TOG), vol. 36, no. 6, pp. 1\u201312, 2017.", "[1] J. Li, C. Niu, and K. Xu, \u201cLearning part generation and assembly for structure-aware shape synthesis,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 07, 2020, pp. 11\u2009362\u201311\u2009369."]}], "citation_info_to_title": {"[1] J. Li, C. Niu, and K. Xu, \u201cLearning part generation and assembly for structure-aware shape synthesis,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 07, 2020, pp. 11\u2009362\u201311\u2009369.": "Learning part generation and assembly for structure-aware shape synthesis", "[7] J. Huang, G. Zhan, Q. Fan, K. Mo, L. Shao, B. Chen, L. Guibas, and H. Dong, \u201cGenerative 3d part assembly via dynamic graph learning,\u201d The IEEE Conference on Neural Information Processing Systems (NeurIPS), 2020.": "Generative 3D Part Assembly via Dynamic Graph Learning", "[28] M. Sung, H. Su, V. G. Kim, S. Chaudhuri, and L. Guibas, \u201cComplementme: Weakly-supervised component suggestions for 3d modeling,\u201d ACM Transactions on Graphics (TOG), vol. 36, no. 6, pp. 1\u201312, 2017.": "Complementme: Weakly-supervised component suggestions for 3d modeling", "[27] R. Wu, Y. Zhuang, K. Xu, H. Zhang, and B. Chen, \u201cPq-net: A generative part seq2seq network for 3d shapes,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 829\u2013838.": "Pq-net: A generative part seq2seq network for 3d shapes", "[8] A. Narayan, R. Nagar, and S. Raman, \u201cRgl-net: A recurrent graph learning framework for progressive part assembly,\u201d in Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2022, pp. 78\u201387.": "Rgl-net: A recurrent graph learning framework for progressive part assembly"}, "source_title_to_arxiv_id": {"Rgl-net: A recurrent graph learning framework for progressive part assembly": "2107.12859"}}