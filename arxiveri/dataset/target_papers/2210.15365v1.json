{"title": "Li3DeTr: A LiDAR based 3D Detection Transformer", "abstract": "Inspired by recent advances in vision transformers for object detection, we\npropose Li3DeTr, an end-to-end LiDAR based 3D Detection Transformer for\nautonomous driving, that inputs LiDAR point clouds and regresses 3D bounding\nboxes. The LiDAR local and global features are encoded using sparse convolution\nand multi-scale deformable attention respectively. In the decoder head,\nfirstly, in the novel Li3DeTr cross-attention block, we link the LiDAR global\nfeatures to 3D predictions leveraging the sparse set of object queries learnt\nfrom the data. Secondly, the object query interactions are formulated using\nmulti-head self-attention. Finally, the decoder layer is repeated $L_{dec}$\nnumber of times to refine the object queries. Inspired by DETR, we employ\nset-to-set loss to train the Li3DeTr network. Without bells and whistles, the\nLi3DeTr network achieves 61.3% mAP and 67.6% NDS surpassing the\nstate-of-the-art methods with non-maximum suppression (NMS) on the nuScenes\ndataset and it also achieves competitive performance on the KITTI dataset. We\nalso employ knowledge distillation (KD) using a teacher and student model that\nslightly improves the performance of our network.", "authors": ["Gopi Krishna Erabati", "Helder Araujo"], "published_date": "2022_10_27", "pdf_url": "http://arxiv.org/pdf/2210.15365v1", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Method</td><td>NDS \\uparrow</td><td>mAP \\uparrow</td><td>mATE \\downarrow</td><td>mASE \\downarrow</td><td>mAOE \\downarrow</td><td>mAVE \\downarrow</td><td>mAAE \\downarrow</td><td>NMS</td></tr><tr><td>PointPillars [19]</td><td>55.0</td><td>40.1</td><td>39.2</td><td>26.9</td><td>47.6</td><td>27.0</td><td>10.2</td><td>\u2713</td></tr><tr><td>SSN [54]</td><td>61.7</td><td>51.0</td><td>33.9</td><td>24.5</td><td>42.9</td><td>26.6</td><td>8.7</td><td>\u2713</td></tr><tr><td>CyliNet RG [31]</td><td>66.1</td><td>57.6</td><td>28.3</td><td>25.3</td><td>29.1</td><td>26.8</td><td>18.0</td><td>\u2713</td></tr><tr><td>CVCNet-ens [4]</td><td>66.6</td><td>58.2</td><td>28.4</td><td>24.1</td><td>37.2</td><td>22.4</td><td>12.6</td><td>\u2713</td></tr><tr><td>HotSpotNet [5]</td><td>66.0</td><td>59.3</td><td>27.4</td><td>23.9</td><td>38.4</td><td>33.3</td><td>13.3</td><td>\u2713</td></tr><tr><td>CenterPoint [51]</td><td>65.5</td><td>58.0</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>VISTA-OHS [11]</td><td>69.8</td><td>63.0</td><td>25.6</td><td>23.3</td><td>32.1</td><td>21.6</td><td>12.2</td><td>\u2713</td></tr><tr><td>Object-DGCNN (pillar) [45]</td><td>62.8</td><td>53.2</td><td>34.6</td><td>26.5</td><td>31.6</td><td>26.0</td><td>19.1</td><td>\u2717</td></tr><tr><td>Object-DGCNN (voxel) [45]</td><td>66.0</td><td>58.7</td><td>33.3</td><td>26.3</td><td>28.8</td><td>25.1</td><td>19.0</td><td>\u2717</td></tr><tr><td>Ours (pillar)</td><td>63.0</td><td>53.8</td><td>35.1</td><td>26.4</td><td>32.1</td><td>26.5</td><td>19.0</td><td>\u2717</td></tr><tr><td>Ours (voxel)</td><td>67.6</td><td>61.3</td><td>30.5</td><td>25.4</td><td>35.2</td><td>26.7</td><td>12.5</td><td>\u2717</td></tr></tbody></table>", "caption": "Table 1: Comparison of recent works on nuScenes [1] test set.", "list_citation_info": ["[51] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11784\u201311793, 2021.", "[45] Yue Wang and Justin M Solomon. Object dgcnn: 3d object detection using dynamic graphs. Advances in Neural Information Processing Systems, 34, 2021.", "[54] Xinge Zhu, Yuexin Ma, Tai Wang, Yan Xu, Jianping Shi, and Dahua Lin. Ssn: Shape signature networks for multi-class object detection from point clouds. In European Conference on Computer Vision, pages 581\u2013597. Springer, 2020.", "[1] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuscenes: A multimodal dataset for autonomous driving. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020.", "[4] Qi Chen, Lin Sun, Ernest Cheung, and Alan L Yuille. Every view counts: Cross-view consistency in 3d object detection with hybrid-cylindrical-spherical voxelization. Advances in Neural Information Processing Systems, 33:21224\u201321235, 2020.", "[11] Shengheng Deng, Zhihao Liang, Lin Sun, and Kui Jia. Vista: Boosting 3d object detection via dual cross-view spatial attention. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8448\u20138457, 2022.", "[19] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019.", "[31] Meytal Rapoport-Lavie and Dan Raviv. It\u2019s all around you: Range-guided cylindrical network for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2992\u20133001, 2021.", "[5] Qi Chen, Lin Sun, Zhixin Wang, Kui Jia, and Alan Yuille. Object as hotspots: An anchor-free 3d object detection approach via firing of hotspots. In European conference on computer vision, pages 68\u201384. Springer, 2020."]}, {"table": "<table><tbody><tr><td></td><td colspan=\"3\">AP_{3D}</td><td colspan=\"3\">AP_{BEV}</td><td></td></tr><tr><td>Method</td><td>Easy</td><td>Mod.</td><td>Hard</td><td>Easy</td><td>Mod.</td><td>Hard</td><td>NMS</td></tr><tr><td colspan=\"8\">RGB &amp; LiDAR</td></tr><tr><td>MV3D [6]</td><td>71.2</td><td>62.6</td><td>56.5</td><td>86.5</td><td>78.1</td><td>76.6</td><td>\u2713</td></tr><tr><td>AVOD-FPN [17]</td><td>-</td><td>73.2</td><td>-</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>F-PointNet [28]</td><td>87.3</td><td>70.9</td><td>63.6</td><td>88.1</td><td>84.0</td><td>76.4</td><td>\u2713</td></tr><tr><td>3D-CVF [52]</td><td>89.6</td><td>79.8</td><td>78.4</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td colspan=\"8\">LiDAR</td></tr><tr><td>VoxelNet [53]</td><td>81.9</td><td>65.4</td><td>62.8</td><td>88.0</td><td>78.4</td><td>71.3</td><td>\u2713</td></tr><tr><td>PointPillars [19]</td><td>86.6</td><td>76.0</td><td>68.9</td><td>90.1</td><td>86.6</td><td>82.8</td><td>\u2713</td></tr><tr><td>TANet [23]</td><td>87.5</td><td>76.6</td><td>73.8</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>SECOND [47]</td><td>87.4</td><td>76.4</td><td>69.1</td><td>89.4</td><td>83.8</td><td>78.6</td><td>\u2713</td></tr><tr><td>3DSSD [49]</td><td>89.7</td><td>79.4</td><td>78.6</td><td>92.7</td><td>89.0</td><td>85.9</td><td>\u2713</td></tr><tr><td>VoTr-SSD [24]</td><td>87.8</td><td>78.2</td><td>76.9</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>Pointformer [27]</td><td>90.0</td><td>79.6</td><td>78.8</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>Ours (voxel)</td><td>87.6</td><td>76.8</td><td>73.9</td><td>89.6</td><td>86.8</td><td>83.1</td><td>\u2717</td></tr></tbody></table>", "caption": "Table 2: Comparison of recent works in terms of AP_{3D} and AP_{BEV} detection on KITTI [14] val set. We list results for car category for easy, moderate and hard samples with IoU=0.7.", "list_citation_info": ["[52] Jin Hyeok Yoo, Yecheol Kim, Jisong Kim, and Jun Won Choi. 3d-cvf: Generating joint camera and lidar features using cross-view spatial feature fusion for 3d object detection. In European Conference on Computer Vision, pages 720\u2013736. Springer, 2020.", "[6] Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 1907\u20131915, 2017.", "[23] Zhe Liu, Xin Zhao, Tengteng Huang, Ruolan Hu, Yu Zhou, and Xiang Bai. Tanet: Robust 3d object detection from point clouds with triple attention. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 11677\u201311684, 2020.", "[27] Xuran Pan, Zhuofan Xia, Shiji Song, Li Erran Li, and Gao Huang. 3d object detection with pointformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7463\u20137472, 2021.", "[47] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018.", "[14] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In Conference on Computer Vision and Pattern Recognition (CVPR), 2012.", "[53] Yin Zhou and Oncel Tuzel. Voxelnet: End-to-end learning for point cloud based 3d object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4490\u20134499, 2018.", "[28] Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas. Frustum pointnets for 3d object detection from rgb-d data. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 918\u2013927, 2018.", "[24] Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang, Hang Xu, and Chunjing Xu. Voxel transformer for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3164\u20133173, 2021.", "[19] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019.", "[49] Zetong Yang, Yanan Sun, Shu Liu, and Jiaya Jia. 3dssd: Point-based 3d single stage object detector. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11040\u201311048, 2020.", "[17] Jason Ku, Melissa Mozifian, Jungwook Lee, Ali Harakeh, and Steven L Waslander. Joint 3d proposal generation and object detection from view aggregation. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 1\u20138. IEEE, 2018."]}, {"table": "<table><thead><tr><th>Method</th><th>Car</th><th>Truck</th><th>Trailer</th><th>Bus</th><th>CV</th><th>Bicycle</th><th>Motor</th><th>Ped</th><th>TC</th><th>Barr</th><th>mAP</th></tr></thead><tbody><tr><th>Pointformer [27]</th><td>82.3</td><td>48.1</td><td>43.4</td><td>55.6</td><td>8.6</td><td>22.7</td><td>55.0</td><td>81.8</td><td>72.2</td><td>66.0</td><td>53.6</td></tr><tr><th>CenterPoint [51] \\ast</th><td>85.1</td><td>53.0</td><td>35.4</td><td>66.8</td><td>13.9</td><td>34.4</td><td>55.2</td><td>84.6</td><td>66.9</td><td>67.5</td><td>56.2</td></tr><tr><th>VISTA [11]</th><td>85.0</td><td>57.4</td><td>39.9</td><td>66.4</td><td>21.2</td><td>51.7</td><td>66.6</td><td>84.5</td><td>68.5</td><td>66.8</td><td>60.9</td></tr><tr><th>Obj-DGCNN [45]</th><td>84.0</td><td>54.0</td><td>40.4</td><td>66.8</td><td>20.2</td><td>44.7</td><td>66.2</td><td>81.6</td><td>64.7</td><td>62.6</td><td>58.5</td></tr><tr><th>Ours</th><td>85.8</td><td>56.5 \\uparrow 2.5</td><td>43.0 \\uparrow 2.6</td><td>70.9 \\uparrow 4.1</td><td>22.9 \\uparrow 2.7</td><td>51.6 \\uparrow 6.9</td><td>66.9</td><td>83.9</td><td>66.8</td><td>65.7</td><td>61.4</td></tr></tbody></table>", "caption": "Table 3: Performance of our network in terms of Average Precision (AP) by object category on the nuScenes val set. CV - Construction Vehicle, Motor - Motorcycle, Ped - Pedestrian, TC - Traffic Cone, Barr - Barrier. \\ast: MMDetection3D [8] implementation. The scores in green indicate the increase in performance with respect to scores in underline.", "list_citation_info": ["[51] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11784\u201311793, 2021.", "[45] Yue Wang and Justin M Solomon. Object dgcnn: 3d object detection using dynamic graphs. Advances in Neural Information Processing Systems, 34, 2021.", "[27] Xuran Pan, Zhuofan Xia, Shiji Song, Li Erran Li, and Gao Huang. 3d object detection with pointformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7463\u20137472, 2021.", "[11] Shengheng Deng, Zhihao Liang, Lin Sun, and Kui Jia. Vista: Boosting 3d object detection via dual cross-view spatial attention. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8448\u20138457, 2022.", "[8] MMDetection3D Contributors. MMDetection3D: OpenMMLab next-generation platform for general 3D object detection. https://github.com/open-mmlab/mmdetection3d, 2020."]}, {"table": "<table><thead><tr><th>Method</th><th><code>[0m,20m]</code></th><th><code>[20m,30m]</code></th><th><code>[30m,+</code>\\infty<code>]</code></th></tr></thead><tbody><tr><th>CenterPoint [51] \\ast</th><td>71.3</td><td>51.5</td><td>26.5</td></tr><tr><th>Obj-DGCNN [45]</th><td>73.2</td><td>55.5</td><td>30.3</td></tr><tr><th>Ours</th><td>75.6 \\uparrow 4.3</td><td>56.9</td><td>32.7 \\uparrow 6.2</td></tr></tbody></table>", "caption": "Table 4: Performance of our network in terms of mAP by object distance on the nuScenes val set. \\ast: MMDetection3D [8] implementation. The scores in green indicate the increase in performance with respect to scores in underline.", "list_citation_info": ["[51] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11784\u201311793, 2021.", "[8] MMDetection3D Contributors. MMDetection3D: OpenMMLab next-generation platform for general 3D object detection. https://github.com/open-mmlab/mmdetection3d, 2020.", "[45] Yue Wang and Justin M Solomon. Object dgcnn: 3d object detection using dynamic graphs. Advances in Neural Information Processing Systems, 34, 2021."]}, {"table": "<table><thead><tr><th>Method</th><th><code>[0m,4m]</code></th><th><code>[4m,+</code>\\infty<code>]</code></th></tr></thead><tbody><tr><th>CenterPoint [51] \\ast</th><td>34.9</td><td>23.5</td></tr><tr><th>Obj-DGCNN [45]</th><td>36.0</td><td>25.4</td></tr><tr><th>Ours</th><td>37.9 \\uparrow 3.0</td><td>27.8 \\uparrow 4.3</td></tr></tbody></table>", "caption": "Table 5: Performance of our network in terms of mAP by object size on the nuScenes val set. \\ast: MMDetection3D [8] implementation. The scores in green indicate the increase in performance with respect to scores in underline.", "list_citation_info": ["[51] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11784\u201311793, 2021.", "[8] MMDetection3D Contributors. MMDetection3D: OpenMMLab next-generation platform for general 3D object detection. https://github.com/open-mmlab/mmdetection3d, 2020.", "[45] Yue Wang and Justin M Solomon. Object dgcnn: 3d object detection using dynamic graphs. Advances in Neural Information Processing Systems, 34, 2021."]}, {"table": "<table><thead><tr><th>Self-attention</th><th>Cross-attention</th><th>mAP</th><th>NDS</th></tr></thead><tbody><tr><th rowspan=\"2\">DGCNN [46]</th><td>Deformable attn. [55]</td><th>58.6</th><td>66.0</td></tr><tr><td>Li3DeTr (ours)</td><th>59.0</th><td>66.3</td></tr><tr><th rowspan=\"2\">Multi-head self attn. [41]</th><td>Deformable attn. [55]</td><th>57.9</th><td>65.5</td></tr><tr><td>Li3DeTr (ours)</td><th>61.4</th><td>67.6</td></tr></tbody></table>", "caption": "Table 6: Ablation study with different attention operations in the decoder on the nuScenes val set", "list_citation_info": ["[55] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai. Deformable detr: Deformable transformers for end-to-end object detection. arXiv preprint arXiv:2010.04159, 2020.", "[46] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon. Dynamic graph cnn for learning on point clouds. Acm Transactions On Graphics (tog), 38(5):1\u201312, 2019.", "[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017."]}, {"table": "<table><thead><tr><th>Backbone</th><th>Method</th><th>mAP</th><th>NDS</th></tr></thead><tbody><tr><th rowspan=\"3\">PointPillars [19]</th><td>CenterPoint [51]</td><th>50.3</th><td>60.2</td></tr><tr><td>Object-DGCNN [45]</td><th>53.2</th><td>62.8</td></tr><tr><td>Ours</td><th>53.8</th><td>63.0</td></tr><tr><th rowspan=\"3\">VoxelNet [53]</th><td>CenterPoint [51]</td><th>56.4</th><td>64.8</td></tr><tr><td>Object-DGCNN [45]</td><th>58.6</th><td>66.0</td></tr><tr><td>Ours</td><th>61.4</th><td>67.6</td></tr></tbody></table>", "caption": "Table 8: Ablation study on different backbones on the nuScenes val set", "list_citation_info": ["[51] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11784\u201311793, 2021.", "[45] Yue Wang and Justin M Solomon. Object dgcnn: 3d object detection using dynamic graphs. Advances in Neural Information Processing Systems, 34, 2021.", "[53] Yin Zhou and Oncel Tuzel. Voxelnet: End-to-end learning for point cloud based 3d object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4490\u20134499, 2018.", "[19] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019."]}], "citation_info_to_title": {"[27] Xuran Pan, Zhuofan Xia, Shiji Song, Li Erran Li, and Gao Huang. 3d object detection with pointformer. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7463\u20137472, 2021.": "3D Object Detection with Pointformer", "[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.": "Attention is all you need", "[14] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In Conference on Computer Vision and Pattern Recognition (CVPR), 2012.": "Are we ready for autonomous driving? The KITTI Vision Benchmark Suite", "[8] MMDetection3D Contributors. MMDetection3D: OpenMMLab next-generation platform for general 3D object detection. https://github.com/open-mmlab/mmdetection3d, 2020.": "MMDetection3D: OpenMMLab next-generation platform for general 3D object detection", "[24] Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang, Hang Xu, and Chunjing Xu. Voxel transformer for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3164\u20133173, 2021.": "Voxel Transformer for 3D Object Detection", "[55] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai. Deformable detr: Deformable transformers for end-to-end object detection. arXiv preprint arXiv:2010.04159, 2020.": "Deformable DETR: Deformable Transformers for End-to-End Object Detection", "[6] Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 1907\u20131915, 2017.": "Multi-view 3d object detection network for autonomous driving", "[54] Xinge Zhu, Yuexin Ma, Tai Wang, Yan Xu, Jianping Shi, and Dahua Lin. Ssn: Shape signature networks for multi-class object detection from point clouds. In European Conference on Computer Vision, pages 581\u2013597. Springer, 2020.": "SSN: Shape Signature Networks for Multi-Class Object Detection from Point Clouds", "[52] Jin Hyeok Yoo, Yecheol Kim, Jisong Kim, and Jun Won Choi. 3d-cvf: Generating joint camera and lidar features using cross-view spatial feature fusion for 3d object detection. In European Conference on Computer Vision, pages 720\u2013736. Springer, 2020.": "3D-CVF: Generating Joint Camera and LiDAR Features Using Cross-View Spatial Feature Fusion for 3D Object Detection", "[51] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11784\u201311793, 2021.": "Center-based 3D Object Detection and Tracking", "[45] Yue Wang and Justin M Solomon. Object dgcnn: 3d object detection using dynamic graphs. Advances in Neural Information Processing Systems, 34, 2021.": "Object DGCNN: 3D Object Detection Using Dynamic Graphs", "[17] Jason Ku, Melissa Mozifian, Jungwook Lee, Ali Harakeh, and Steven L Waslander. Joint 3d proposal generation and object detection from view aggregation. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 1\u20138. IEEE, 2018.": "Joint 3d proposal generation and object detection from view aggregation", "[11] Shengheng Deng, Zhihao Liang, Lin Sun, and Kui Jia. Vista: Boosting 3d object detection via dual cross-view spatial attention. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8448\u20138457, 2022.": "Vista: Boosting 3d object detection via dual cross-view spatial attention", "[28] Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas. Frustum pointnets for 3d object detection from rgb-d data. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 918\u2013927, 2018.": "Frustum PointNets for 3D Object Detection from RGB-D Data", "[53] Yin Zhou and Oncel Tuzel. Voxelnet: End-to-end learning for point cloud based 3d object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4490\u20134499, 2018.": "Voxelnet: End-to-end learning for point cloud based 3d object detection", "[23] Zhe Liu, Xin Zhao, Tengteng Huang, Ruolan Hu, Yu Zhou, and Xiang Bai. Tanet: Robust 3d object detection from point clouds with triple attention. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 11677\u201311684, 2020.": "Tanet: Robust 3d object detection from point clouds with triple attention", "[1] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuscenes: A multimodal dataset for autonomous driving. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11621\u201311631, 2020.": "nuscenes: A multimodal dataset for autonomous driving", "[5] Qi Chen, Lin Sun, Zhixin Wang, Kui Jia, and Alan Yuille. Object as hotspots: An anchor-free 3d object detection approach via firing of hotspots. In European conference on computer vision, pages 68\u201384. Springer, 2020.": "Object as hotspots: An anchor-free 3d object detection approach via firing of hotspots", "[49] Zetong Yang, Yanan Sun, Shu Liu, and Jiaya Jia. 3dssd: Point-based 3d single stage object detector. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11040\u201311048, 2020.": "3DSSD: Point-based 3D Single Stage Object Detector", "[47] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018.": "Second: Sparsely embedded convolutional detection", "[31] Meytal Rapoport-Lavie and Dan Raviv. It\u2019s all around you: Range-guided cylindrical network for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2992\u20133001, 2021.": "Range-guided cylindrical network for 3d object detection", "[46] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon. Dynamic graph cnn for learning on point clouds. Acm Transactions On Graphics (tog), 38(5):1\u201312, 2019.": "Dynamic Graph CNN for Learning on Point Clouds", "[19] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019.": "Pointpillars: Fast Encoders for Object Detection from Point Clouds", "[4] Qi Chen, Lin Sun, Ernest Cheung, and Alan L Yuille. Every view counts: Cross-view consistency in 3d object detection with hybrid-cylindrical-spherical voxelization. Advances in Neural Information Processing Systems, 33:21224\u201321235, 2020.": "Every view counts: Cross-view consistency in 3d object detection with hybrid-cylindrical-spherical voxelization"}, "source_title_to_arxiv_id": {"Object DGCNN: 3D Object Detection Using Dynamic Graphs": "2110.06923", "Joint 3d proposal generation and object detection from view aggregation": "1712.02294"}}