{"title": "Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with Extremely Limited Labels", "abstract": "Recent studies on contrastive learning have achieved remarkable performance\nsolely by leveraging few labels in the context of medical image segmentation.\nExisting methods mainly focus on instance discrimination and invariant mapping.\nHowever, they face three common pitfalls: (1) tailness: medical image data\nusually follows an implicit long-tail class distribution. Blindly leveraging\nall pixels in training hence can lead to the data imbalance issues, and cause\ndeteriorated performance; (2) consistency: it remains unclear whether a\nsegmentation model has learned meaningful and yet consistent anatomical\nfeatures due to the intra-class variations between different anatomical\nfeatures; and (3) diversity: the intra-slice correlations within the entire\ndataset have received significantly less attention. This motivates us to seek a\nprincipled approach for strategically making use of the dataset itself to\ndiscover similar yet distinct samples from different anatomical views. In this\npaper, we introduce a novel semi-supervised 2D medical image segmentation\nframework termed Mine yOur owN Anatomy (MONA), and make three contributions.\nFirst, prior work argues that every pixel equally matters to the model\ntraining; we observe empirically that this alone is unlikely to define\nmeaningful anatomical features, mainly due to lacking the supervision signal.\nWe show two simple solutions towards learning invariances - through the use of\nstronger data augmentations and nearest neighbors. Second, we construct a set\nof objectives that encourage the model to be capable of decomposing medical\nimages into a collection of anatomical features in an unsupervised manner.\nLastly, we both empirically and theoretically, demonstrate the efficacy of our\nMONA on three benchmark datasets with different labeled settings, achieving new\nstate-of-the-art under different labeled semi-supervised settings", "authors": ["Chenyu You", "Weicheng Dai", "Fenglin Liu", "Yifei Min", "Haoran Su", "Xiaoran Zhang", "Xiaoxiao Li", "David A. Clifton", "Lawrence Staib", "James S. Duncan"], "published_date": "2022_09_27", "pdf_url": "http://arxiv.org/pdf/2209.13476v5", "list_table_and_caption": [{"table": "<p>ACDCLiTS1% Labeled5% Labeled10% Labeled1% Labeled5% Labeled10% LabeledMethodDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowUNet-F [70]89.90.62189.90.62189.90.62168.216.968.216.968.216.9UNet-L14.519.351.713.174.42.2057.034.660.430.461.628.3EM [84]21.121.459.85.6475.72.7356.638.461.233.362.938.5CCT [65]30.928.259.110.175.93.6052.452.360.648.763.831.2DAN [104]34.725.756.415.176.53.0157.227.162.325.863.230.7URPC [57]32.226.958.98.1473.22.6855.534.662.437.863.043.1DCT [68]36.024.258.510.878.12.6457.638.560.834.461.931.7ICT [83]35.821.359.04.5975.10.89858.332.260.139.162.532.4MT [77]36.819.658.311.280.12.3356.734.361.940.063.326.2UAMT [100]35.224.361.07.0377.63.1557.841.961.047.062.326.0CPS [19]37.130.061.02.9278.83.4157.739.662.136.064.023.6GCL [13]59.714.370.62.2487.00.75159.329.563.320.165.037.2SCS [42]59.412.773.65.3784.22.0157.839.661.528.864.633.9PLC [14]58.815.170.62.6787.31.3456.641.662.726.168.216.9\\bullet\u2009MONA (ours)82.62.0388.80.6290.70.86464.120.967.316.469.318.0</p>", "caption": "Table 1: Comparison of segmentation performance (DSC[%]/ASD[mm]) on ACDC and LiTS under three labeled ratio settings (1%, 5%, 10%). The best results are indicated in bold.", "list_citation_info": ["[65] Yassine Ouali, C\u00e9line Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistency training. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.", "[68] Siyuan Qiao, Wei Shen, Zhishuai Zhang, Bo Wang, and Alan Yuille. Deep co-training for semi-supervised image recognition. In European Conference on Computer Vision (ECCV), 2018.", "[70] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2015.", "[77] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in Neural Information Processing Systems (NeurIPS), 2017.", "[100] Lequan Yu, Shujun Wang, Xiaomeng Li, Chi-Wing Fu, and Pheng-Ann Heng. Uncertainty-aware self-ensembling model for semi-supervised 3d left atrium segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2019.", "[104] Yizhe Zhang, Lin Yang, Jianxu Chen, Maridel Fredericksen, David P Hughes, and Danny Z Chen. Deep adversarial networks for biomedical image segmentation utilizing unannotated images. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2017.", "[83] Vikas Verma, Kenji Kawaguchi, Alex Lamb, Juho Kannala, Yoshua Bengio, and David Lopez-Paz. Interpolation consistency training for semi-supervised learning. In International Joint Conference on Artificial Intelligence (IJCAI), 2019.", "[57] Xiangde Luo, Wenjun Liao, Jieneng Chen, Tao Song, Yinan Chen, Shichuan Zhang, Nianyong Chen, Guotai Wang, and Shaoting Zhang. Efficient semi-supervised gross target volume of nasopharyngeal carcinoma segmentation via uncertainty rectified pyramid consistency. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2021.", "[19] Xiaokang Chen, Yuhui Yuan, Gang Zeng, and Jingdong Wang. Semi-supervised semantic segmentation with cross pseudo supervision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.", "[84] Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord, and Patrick P\u00e9rez. Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.", "[13] Krishna Chaitanya, Ertunc Erdil, Neerav Karani, and Ender Konukoglu. Contrastive learning of global and local features for medical image segmentation with limited annotations. In Advances in Neural Information Processing Systems (NeurIPS), 2020.", "[42] Xinrong Hu, Dewen Zeng, Xiaowei Xu, and Yiyu Shi. Semi-supervised contrastive learning for label-efficient medical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2021.", "[14] Krishna Chaitanya, Ertunc Erdil, Neerav Karani, and Ender Konukoglu. Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation. arXiv preprint arXiv:2112.09645, 2021."]}, {"table": "<p>1% Labeled5% Labeled10% LabeledMethodDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowUNet-F [70]85.88.0185.88.0185.88.01UNet-L58.333.977.824.482.713.5EM [84]54.541.180.617.382.115.1CCT [65]62.827.579.021.979.416.3DAN [104]52.848.479.422.780.215.0URPC [57]65.729.773.720.581.912.3DCT [68]62.727.580.823.082.812.4ICT [83]59.932.876.515.482.212.0MT [77]58.835.676.515.579.419.8UAMT [100]61.137.676.320.983.714.2CPS [19]58.833.678.322.582.013.1GCL [13]71.620.383.57.4186.78.76SCS [42]71.419.381.111.582.69.68PLC [14]71.519.883.410.786.09.65\\bullet\u2009MONA (ours)83.99.0686.38.2287.66.83</p>", "caption": "Table 4: Comparison of segmentation performance (DSC[%]/ASD[mm]) on MMWHS under three labeled ratio settings (1%, 5%, 10%). On all three labeled settings, MONA significantly outperforms all the state-of-the-art methods by a significant margin. The best results are in bold.", "list_citation_info": ["[65] Yassine Ouali, C\u00e9line Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistency training. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.", "[68] Siyuan Qiao, Wei Shen, Zhishuai Zhang, Bo Wang, and Alan Yuille. Deep co-training for semi-supervised image recognition. In European Conference on Computer Vision (ECCV), 2018.", "[70] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2015.", "[77] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in Neural Information Processing Systems (NeurIPS), 2017.", "[100] Lequan Yu, Shujun Wang, Xiaomeng Li, Chi-Wing Fu, and Pheng-Ann Heng. Uncertainty-aware self-ensembling model for semi-supervised 3d left atrium segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2019.", "[104] Yizhe Zhang, Lin Yang, Jianxu Chen, Maridel Fredericksen, David P Hughes, and Danny Z Chen. Deep adversarial networks for biomedical image segmentation utilizing unannotated images. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2017.", "[83] Vikas Verma, Kenji Kawaguchi, Alex Lamb, Juho Kannala, Yoshua Bengio, and David Lopez-Paz. Interpolation consistency training for semi-supervised learning. In International Joint Conference on Artificial Intelligence (IJCAI), 2019.", "[57] Xiangde Luo, Wenjun Liao, Jieneng Chen, Tao Song, Yinan Chen, Shichuan Zhang, Nianyong Chen, Guotai Wang, and Shaoting Zhang. Efficient semi-supervised gross target volume of nasopharyngeal carcinoma segmentation via uncertainty rectified pyramid consistency. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2021.", "[19] Xiaokang Chen, Yuhui Yuan, Gang Zeng, and Jingdong Wang. Semi-supervised semantic segmentation with cross pseudo supervision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.", "[84] Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord, and Patrick P\u00e9rez. Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.", "[13] Krishna Chaitanya, Ertunc Erdil, Neerav Karani, and Ender Konukoglu. Contrastive learning of global and local features for medical image segmentation with limited annotations. In Advances in Neural Information Processing Systems (NeurIPS), 2020.", "[42] Xinrong Hu, Dewen Zeng, Xiaowei Xu, and Yiyu Shi. Semi-supervised contrastive learning for label-efficient medical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2021.", "[14] Krishna Chaitanya, Ertunc Erdil, Neerav Karani, and Ender Konukoglu. Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation. arXiv preprint arXiv:2112.09645, 2021."]}, {"table": "<p>1% Labeled5% Labeled10% LabeledFrameworkMethodDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowDSC \\uparrowASD \\downarrowonly pretainingMoCov2 [20]38.622.456.217.981.05.36kNN-MoCo [81]39.522.058.315.783.17.18SimCLR [18]34.824.351.719.980.34.16BYOL [35]35.97.2565.99.1585.62.51ISD [78]45.817.271.04.2985.32.97\\mathbf{\\circ}\u2009GLCon (ours)49.37.1174.23.8986.51.92w/ fine-tuningMoCov2 [20]77.74.7885.41.5286.71.74kNN-MoCo [81]78.04.2885.91.5186.91.61SimCLR [18]75.74.3383.22.0686.12.25BYOL [35]77.14.8485.32.0688.10.99ISD [78]80.13.0083.81.9588.61.20\\bullet\u2009MONA (ours)83.31.9889.10.78490.80.736</p>", "caption": "Table 5: Ablation study of different contrastive learning frameworks on ACDC under three labeled ratio settings (1%, 5%, 10%). We compare two settings: with or without fine-tuning on the segmentation performance (DSC[%]/ASD[mm]). We denote \u2018without fine-tuning\u201d to only pretaining. On all three labeled settings, our methods (i.e., GLCon and MONA) significantly outperform all the state-of-the-art methods by a significant margin. All the experiments are run with three different random seeds. The best results are in bold.", "list_citation_info": ["[18] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning (ICML), 2020.", "[35] Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. In Advances in Neural Information Processing Systems (NeurIPS), 2020.", "[78] Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Vipin Pillai, Paolo Favaro, and Hamed Pirsiavash. Isd: Self-supervised learning by iterative similarity distillation. In IEEE International Conference on Computer Vision (ICCV), 2021.", "[81] Wouter Van Gansbeke, Simon Vandenhende, Stamatios Georgoulis, and Luc V Gool. Revisiting contrastive methods for unsupervised learning of visual representations. In Advances in Neural Information Processing Systems (NeurIPS), 2021.", "[20] Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He. Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297, 2020."]}], "citation_info_to_title": {"[100] Lequan Yu, Shujun Wang, Xiaomeng Li, Chi-Wing Fu, and Pheng-Ann Heng. Uncertainty-aware self-ensembling model for semi-supervised 3d left atrium segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2019.": "Uncertainty-aware self-ensembling model for semi-supervised 3d left atrium segmentation", "[78] Ajinkya Tejankar, Soroush Abbasi Koohpayegani, Vipin Pillai, Paolo Favaro, and Hamed Pirsiavash. Isd: Self-supervised learning by iterative similarity distillation. In IEEE International Conference on Computer Vision (ICCV), 2021.": "ISD: Self-Supervised Learning by Iterative Similarity Distillation", "[70] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2015.": "U-net: Convolutional networks for biomedical image segmentation", "[83] Vikas Verma, Kenji Kawaguchi, Alex Lamb, Juho Kannala, Yoshua Bengio, and David Lopez-Paz. Interpolation consistency training for semi-supervised learning. In International Joint Conference on Artificial Intelligence (IJCAI), 2019.": "Interpolation Consistency Training for Semi-Supervised Learning", "[84] Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord, and Patrick P\u00e9rez. Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.": "Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation", "[14] Krishna Chaitanya, Ertunc Erdil, Neerav Karani, and Ender Konukoglu. Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation. arXiv preprint arXiv:2112.09645, 2021.": "Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation", "[104] Yizhe Zhang, Lin Yang, Jianxu Chen, Maridel Fredericksen, David P Hughes, and Danny Z Chen. Deep adversarial networks for biomedical image segmentation utilizing unannotated images. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2017.": "Deep Adversarial Networks for Biomedical Image Segmentation Utilizing Unannotated Images", "[13] Krishna Chaitanya, Ertunc Erdil, Neerav Karani, and Ender Konukoglu. Contrastive learning of global and local features for medical image segmentation with limited annotations. In Advances in Neural Information Processing Systems (NeurIPS), 2020.": "Contrastive learning of global and local features for medical image segmentation with limited annotations", "[68] Siyuan Qiao, Wei Shen, Zhishuai Zhang, Bo Wang, and Alan Yuille. Deep co-training for semi-supervised image recognition. In European Conference on Computer Vision (ECCV), 2018.": "Deep co-training for semi-supervised image recognition", "[42] Xinrong Hu, Dewen Zeng, Xiaowei Xu, and Yiyu Shi. Semi-supervised contrastive learning for label-efficient medical image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2021.": "Semi-supervised contrastive learning for label-efficient medical image segmentation", "[35] Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap your own latent-a new approach to self-supervised learning. In Advances in Neural Information Processing Systems (NeurIPS), 2020.": "Bootstrap your own latent - a new approach to self-supervised learning", "[65] Yassine Ouali, C\u00e9line Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistency training. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.": "Semi-supervised semantic segmentation with cross-consistency training", "[18] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning (ICML), 2020.": "A simple framework for contrastive learning of visual representations", "[57] Xiangde Luo, Wenjun Liao, Jieneng Chen, Tao Song, Yinan Chen, Shichuan Zhang, Nianyong Chen, Guotai Wang, and Shaoting Zhang. Efficient semi-supervised gross target volume of nasopharyngeal carcinoma segmentation via uncertainty rectified pyramid consistency. In International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2021.": "Efficient semi-supervised gross target volume of nasopharyngeal carcinoma segmentation via uncertainty rectified pyramid consistency", "[19] Xiaokang Chen, Yuhui Yuan, Gang Zeng, and Jingdong Wang. Semi-supervised semantic segmentation with cross pseudo supervision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021.": "Semi-supervised semantic segmentation with cross pseudo supervision", "[20] Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He. Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297, 2020.": "Improved Baselines with Momentum Contrastive Learning", "[81] Wouter Van Gansbeke, Simon Vandenhende, Stamatios Georgoulis, and Luc V Gool. Revisiting contrastive methods for unsupervised learning of visual representations. In Advances in Neural Information Processing Systems (NeurIPS), 2021.": "Revisiting contrastive methods for unsupervised learning of visual representations", "[77] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in Neural Information Processing Systems (NeurIPS), 2017.": "Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results"}, "source_title_to_arxiv_id": {"ISD: Self-Supervised Learning by Iterative Similarity Distillation": "2012.09259", "Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation": "2112.09645", "Semi-supervised semantic segmentation with cross pseudo supervision": "2106.01226"}}