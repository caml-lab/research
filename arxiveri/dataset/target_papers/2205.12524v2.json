{"title": "Accelerating Diffusion Models via Early Stop of the Diffusion Process", "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) have achieved impressive\nperformance on various generation tasks. By modeling the reverse process of\ngradually diffusing the data distribution into a Gaussian distribution,\ngenerating a sample in DDPMs can be regarded as iteratively denoising a\nrandomly sampled Gaussian noise. However, in practice DDPMs often need hundreds\neven thousands of denoising steps to obtain a high-quality sample from the\nGaussian noise, leading to extremely low inference efficiency. In this work, we\npropose a principled acceleration strategy, referred to as Early-Stopped DDPM\n(ES-DDPM), for DDPMs. The key idea is to stop the diffusion process early where\nonly the few initial diffusing steps are considered and the reverse denoising\nprocess starts from a non-Gaussian distribution. By further adopting a powerful\npre-trained generative model, such as GAN and VAE, in ES-DDPM, sampling from\nthe target non-Gaussian distribution can be efficiently achieved by diffusing\nsamples obtained from the pre-trained generative model. In this way, the number\nof required denoising steps is significantly reduced. In the meantime, the\nsample quality of ES-DDPM also improves substantially, outperforming both the\nvanilla DDPM and the adopted pre-trained generative model. On extensive\nexperiments across CIFAR-10, CelebA, ImageNet, LSUN-Bedroom and LSUN-Cat,\nES-DDPM obtains promising acceleration effect and performance improvement over\nrepresentative baseline methods. Moreover, ES-DDPM also demonstrates several\nattractive properties, including being orthogonal to existing acceleration\nmethods, as well as simultaneously enabling both global semantic and local\npixel-level control in image generation.", "authors": ["Zhaoyang Lyu", "Xudong XU", "Ceyuan Yang", "Dahua Lin", "Bo Dai"], "published_date": "2022_05_25", "pdf_url": "http://arxiv.org/pdf/2205.12524v2", "list_table_and_caption": [{"table": "<table><tr><td> CelebA-64</td><td>Method</td><td>FID</td></tr><tr><td rowspan=\"3\">Hybrid Models</td><td>StyleGAN2+100-step ES-DDPM (Ours)</td><td>3.01</td></tr><tr><td>StyleGAN2+200-step ES-DDPM (Ours)</td><td>2.55</td></tr><tr><td>1000-step DiffuseVAE (Pandey et al., 2022)</td><td>4.76</td></tr><tr><td rowspan=\"4\">Score-based Methods</td><td>1000-step DDPM* (Ho et al., 2020)</td><td>3.26</td></tr><tr><td>250-step PNDM (Liu et al., 2022)</td><td>2.71</td></tr><tr><td>NCSN (Song &amp; Ermon, 2019)</td><td>25.30</td></tr><tr><td>NCSNv2 (Song &amp; Ermon, 2020)</td><td>10.23</td></tr><tr><td rowspan=\"3\">GAN-based Methods</td><td>COCO-GAN (Lin et al., 2019)</td><td>4.00</td></tr><tr><td>StyleGAN2* (Karras et al., 2020)</td><td>4.55</td></tr><tr><td>QA-GAN (Parimala &amp; Channappayya, 2019)</td><td>6.42</td></tr><tr><td>VAE-based Methods</td><td>NCP-VAE (Aneja et al., 2020)</td><td>5.25</td></tr><tr><td> </td><td></td><td></td></tr><tr><td> CelebA-128</td><td>Method</td><td>FID</td></tr><tr><td rowspan=\"2\">Hybrid Models</td><td>StyleGAN2+100-step ES-DDPM (Ours)</td><td>1.76</td></tr><tr><td>StyleGAN2+200-step ES-DDPM (Ours)</td><td>1.79</td></tr><tr><td>Score-based Methods</td><td>1000-step DDPM* (Ho et al., 2020)</td><td>5.65</td></tr><tr><td rowspan=\"3\">GAN-based Methods</td><td>COCO-GAN (Lin et al., 2019)</td><td>5.74</td></tr><tr><td>StyleGAN2* (Karras et al., 2020)</td><td>2.13</td></tr><tr><td>PresGAN (Dieng et al., 2019)</td><td>29.12</td></tr><tr><td> </td><td></td><td></td></tr></table>", "caption": "Table 2: Performance comparison of CelebA unconditional image generation. \u201c*\u201d means the model is trained by ourselves.For our method and self trained models, we report FID between randomly generated 50000 images and the whole dataset.", "list_citation_info": ["Song & Ermon (2019) Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in Neural Information Processing Systems, 32, 2019.", "Aneja et al. (2020) Jyoti Aneja, Alex Schwing, Jan Kautz, and Arash Vahdat. Ncp-vae: Variational autoencoders with noise contrastive priors. 2020.", "Liu et al. (2022) Luping Liu, Yi Ren, Zhijie Lin, and Zhou Zhao. Pseudo numerical methods for diffusion models on manifolds. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=PlKWVd2yBkY.", "Dieng et al. (2019) Adji B Dieng, Francisco JR Ruiz, David M Blei, and Michalis K Titsias. Prescribed generative adversarial networks. arXiv preprint arXiv:1910.04302, 2019.", "Ho et al. (2020) Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33:6840\u20136851, 2020.", "Lin et al. (2019) Chieh Hubert Lin, Chia-Che Chang, Yu-Sheng Chen, Da-Cheng Juan, Wei Wei, and Hwann-Tzong Chen. Coco-gan: Generation by parts via conditional coordinating. In Proceedings of the IEEE/CVF international conference on computer vision, pp. 4512\u20134521, 2019.", "Pandey et al. (2022) Kushagra Pandey, Avideep Mukherjee, Piyush Rai, and Abhishek Kumar. Diffusevae: Efficient, controllable and high-fidelity generation from low-dimensional latents. arXiv preprint arXiv:2201.00308, 2022.", "Song & Ermon (2020) Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. Advances in neural information processing systems, 33:12438\u201312448, 2020.", "Parimala & Channappayya (2019) Kancharla Parimala and Sumohana Channappayya. Quality aware generative adversarial networks. Advances in neural information processing systems, 32, 2019.", "Karras et al. (2020) Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 8110\u20138119, 2020."]}, {"table": "<table><tr><td> ES-DDPM Length T^{\\prime}</td><td>0(BigGAN-deep)</td><td>100</td><td>200</td><td>300</td><td>400</td><td>500</td><td>600</td><td>700</td><td>800</td><td>900</td><td>1000(DDPM)</td></tr><tr><td>FID</td><td>4.06</td><td>3.75</td><td>3.47</td><td>3.30</td><td>3.16</td><td>2.92</td><td>2.71</td><td>2.50</td><td>2.31</td><td>2.07</td><td>2.13</td></tr><tr><td>sFID</td><td>3.96</td><td>3.91</td><td>3.96</td><td>3.93</td><td>3.90</td><td>3.83</td><td>3.84</td><td>3.84</td><td>3.84</td><td>3.90</td><td>4.28</td></tr><tr><td>IS</td><td>45.00</td><td>48.63</td><td>50.17</td><td>51.45</td><td>52.32</td><td>53.85</td><td>54.41</td><td>55.11</td><td>55.42</td><td>55.29</td><td>52.52</td></tr><tr><td>Precision</td><td>0.795</td><td>0.798</td><td>0.800</td><td>0.794</td><td>0.792</td><td>0.787</td><td>0.784</td><td>0.778</td><td>0.771</td><td>0.756</td><td>0.739</td></tr><tr><td>Recall</td><td>0.483</td><td>0.504</td><td>0.514</td><td>0.529</td><td>0.533</td><td>0.547</td><td>0.565</td><td>0.577</td><td>0.593</td><td>0.608</td><td>0.631</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 3: ImageNet-64 class-conditional image generation performance of ES-DDPM+BigGAN-deep.For the DDPM and ES-DDPM experiments, we follow the work (Dhariwal &amp; Nichol, 2021) to use Timestep-Respacing with jumping interval 4. The actual denoising steps is T^{\\prime}/4. We do not use classifier guidance.", "list_citation_info": ["Dhariwal & Nichol (2021) Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in Neural Information Processing Systems, 34, 2021."]}, {"table": "<table><tr><td> </td><td>Denoising Steps</td><td>200</td><td>100</td><td>50</td><td>20</td><td>10</td><td>5</td></tr><tr><td rowspan=\"6\">CelebA-64</td><td>ES-DDPM+StyleGAN2+DDIM(Ours)</td><td>2.55</td><td>3.01</td><td>3.97</td><td>4.90</td><td>6.44</td><td>9.15</td></tr><tr><td>DDIM (Song et al., 2020)</td><td>-</td><td>6.53</td><td>9.17</td><td>13.73</td><td>17.33</td><td>-</td></tr><tr><td>FastDPM (Kong &amp; Ping, 2021)</td><td>-</td><td>7.85</td><td>8.31</td><td>10.69</td><td>15.31</td><td>-</td></tr><tr><td>PNDM (Liu et al., 2022)</td><td>2.71</td><td>2.81</td><td>3.34</td><td>5.51</td><td>7.71</td><td>11.3</td></tr><tr><td>Diffusion Autoencoder (Preechakul et al., 2021)</td><td>-</td><td>5.30</td><td>7.05</td><td>10.18</td><td>12.92</td><td>-</td></tr><tr><td>TDPM-GAN (Zheng et al., 2022)</td><td>-</td><td>3.64</td><td>3.28</td><td>-</td><td>-</td><td>-</td></tr><tr><td>CelebA-128</td><td>ES-DDPM+StyleGAN2+DDIM(Ours)</td><td>1.79</td><td>1.76</td><td>1.86</td><td>2.27</td><td>3.26</td><td>6.15</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 6: FID comparison of different DDPM acceleration methods on CelebA. For our models, denoising steps less than 100 steps are achieved by accelerating ES-DDPM(T^{\\prime}=100) using DDIM.", "list_citation_info": ["Zheng et al. (2022) Huangjie Zheng, Pengcheng He, Weizhu Chen, and Mingyuan Zhou. Truncated diffusion probabilistic models. arXiv preprint arXiv:2202.09671, 2022.", "Kong & Ping (2021) Zhifeng Kong and Wei Ping. On fast sampling of diffusion probabilistic models. arXiv preprint arXiv:2106.00132, 2021.", "Liu et al. (2022) Luping Liu, Yi Ren, Zhijie Lin, and Zhou Zhao. Pseudo numerical methods for diffusion models on manifolds. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=PlKWVd2yBkY.", "Song et al. (2020) Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020.", "Preechakul et al. (2021) Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, and Supasorn Suwajanakorn. Diffusion autoencoders: Toward a meaningful and decodable representation. arXiv preprint arXiv:2111.15640, 2021."]}, {"table": "<table><tr><td> </td><td colspan=\"5\">FID</td><td colspan=\"5\">IS</td></tr><tr><td>Denoising Steps</td><td>25</td><td>20</td><td>15</td><td>10</td><td>5</td><td>25</td><td>20</td><td>15</td><td>10</td><td>5</td></tr><tr><td>ES-DDPM(T^{\\prime}=100)+BigGAN-deep+TR(Ours)</td><td>3.75</td><td>3.77</td><td>3.80</td><td>3.93</td><td>4.25</td><td>48.63</td><td>48.92</td><td>49.17</td><td>48.81</td><td>48.04</td></tr><tr><td>DDIM* (Song et al., 2020)</td><td>5.90</td><td>6.68</td><td>8.59</td><td>13.48</td><td>67.70</td><td>38.24</td><td>36.72</td><td>34.85</td><td>30.79</td><td>13.17</td></tr><tr><td>TR* (Nichol &amp; Dhariwal, 2021)</td><td>7.99</td><td>11.08</td><td>16.49</td><td>27.74</td><td>78.59</td><td>49.62</td><td>45.83</td><td>39.32</td><td>29.32</td><td>12.65</td></tr><tr><td>DDSS (Watson et al., 2021)</td><td>18.40</td><td>20.69</td><td>24.69</td><td>37.32</td><td>55.14</td><td>18.12</td><td>17.92</td><td>17.23</td><td>14.76</td><td>12.90</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 7: FID and IS comparison of different DDPM acceleration methods on the Imagenet-64 dataset. \u201c*\u201d means the images for evaluation are generated by ourselves for this method. ", "list_citation_info": ["Watson et al. (2021) Daniel Watson, William Chan, Jonathan Ho, and Mohammad Norouzi. Learning fast samplers for diffusion models by differentiating through sample quality. In International Conference on Learning Representations, 2021.", "Nichol & Dhariwal (2021) Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning, pp. 8162\u20138171. PMLR, 2021.", "Song et al. (2020) Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020."]}, {"table": "<table><tr><td> Denoising Steps</td><td>500</td><td>100</td><td>50</td><td>20</td><td>10</td><td>5</td></tr><tr><td>ES-DDPM(T^{\\prime}=100)+StyleGAN+TR(Ours)</td><td></td><td>1.85</td><td>1.83</td><td>2.03</td><td>2.67</td><td>3.84</td></tr><tr><td>DDIM (Song et al., 2020)</td><td></td><td>6.62</td><td>6.75</td><td>8.89</td><td>16.95</td><td></td></tr><tr><td>PNDM (Liu et al., 2022)</td><td></td><td>6.91</td><td>6.44</td><td>5.68</td><td>6.99</td><td>12.6</td></tr><tr><td>FastDPM (Kong &amp; Ping, 2021)</td><td></td><td>7.98</td><td>8.37</td><td>9.86</td><td>19.07</td><td></td></tr><tr><td>TDPM-GAN (Zheng et al., 2022)</td><td>3.95</td><td></td><td>4.10</td><td></td><td></td><td></td></tr><tr><td>TDPM-CT (Zheng et al., 2022)</td><td>4.01</td><td></td><td>4.95</td><td></td><td></td><td></td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 8: FID comparison of different DDPM acceleration methods on the LSUN-Bedroom dataset.", "list_citation_info": ["Liu et al. (2022) Luping Liu, Yi Ren, Zhijie Lin, and Zhou Zhao. Pseudo numerical methods for diffusion models on manifolds. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=PlKWVd2yBkY.", "Kong & Ping (2021) Zhifeng Kong and Wei Ping. On fast sampling of diffusion probabilistic models. arXiv preprint arXiv:2106.00132, 2021.", "Zheng et al. (2022) Huangjie Zheng, Pengcheng He, Weizhu Chen, and Mingyuan Zhou. Truncated diffusion probabilistic models. arXiv preprint arXiv:2202.09671, 2022.", "Song et al. (2020) Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020."]}, {"table": "<table><tr><td> Denoising Steps</td><td>100</td><td>50</td><td>20</td><td>10</td><td>5</td></tr><tr><td>ES-DDPM(T^{\\prime}=100)+StyleGAN2+TR(Ours)</td><td>5.47</td><td>5.88</td><td>7.27</td><td>9.72</td><td>13.48</td></tr><tr><td>DDIM* (Song et al., 2020)</td><td>7.43</td><td>8.80</td><td>12.40</td><td>20.11</td><td>48.39</td></tr><tr><td>TR* (Nichol &amp; Dhariwal, 2021)</td><td>9.88</td><td>14.60</td><td>28.86</td><td>56.62</td><td>114.00</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 9: FID comparison of different DDPM acceleration methods on the LSUN-Cat dataset. \u201c*\u201d means the images for evaluation are generated by ourselves for this method.", "list_citation_info": ["Nichol & Dhariwal (2021) Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning, pp. 8162\u20138171. PMLR, 2021.", "Song et al. (2020) Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020."]}], "citation_info_to_title": {"Ho et al. (2020) Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems, 33:6840\u20136851, 2020.": "Denoising diffusion probabilistic models", "Lin et al. (2019) Chieh Hubert Lin, Chia-Che Chang, Yu-Sheng Chen, Da-Cheng Juan, Wei Wei, and Hwann-Tzong Chen. Coco-gan: Generation by parts via conditional coordinating. In Proceedings of the IEEE/CVF international conference on computer vision, pp. 4512\u20134521, 2019.": "Coco-gan: Generation by parts via conditional coordinating", "Dieng et al. (2019) Adji B Dieng, Francisco JR Ruiz, David M Blei, and Michalis K Titsias. Prescribed generative adversarial networks. arXiv preprint arXiv:1910.04302, 2019.": "Prescribed Generative Adversarial Networks", "Karras et al. (2020) Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 8110\u20138119, 2020.": "Analyzing and improving the image quality of StyleGAN", "Preechakul et al. (2021) Konpat Preechakul, Nattanat Chatthee, Suttisak Wizadwongsa, and Supasorn Suwajanakorn. Diffusion autoencoders: Toward a meaningful and decodable representation. arXiv preprint arXiv:2111.15640, 2021.": "Diffusion Autoencoders: Toward a Meaningful and Decodable Representation", "Aneja et al. (2020) Jyoti Aneja, Alex Schwing, Jan Kautz, and Arash Vahdat. Ncp-vae: Variational autoencoders with noise contrastive priors. 2020.": "Ncp-vae: Variational autoencoders with noise contrastive priors", "Kong & Ping (2021) Zhifeng Kong and Wei Ping. On fast sampling of diffusion probabilistic models. arXiv preprint arXiv:2106.00132, 2021.": "On fast sampling of diffusion probabilistic models", "Watson et al. (2021) Daniel Watson, William Chan, Jonathan Ho, and Mohammad Norouzi. Learning fast samplers for diffusion models by differentiating through sample quality. In International Conference on Learning Representations, 2021.": "Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality", "Zheng et al. (2022) Huangjie Zheng, Pengcheng He, Weizhu Chen, and Mingyuan Zhou. Truncated diffusion probabilistic models. arXiv preprint arXiv:2202.09671, 2022.": "Truncated Diffusion Probabilistic Models", "Nichol & Dhariwal (2021) Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning, pp. 8162\u20138171. PMLR, 2021.": "Improved denoising diffusion probabilistic models", "Pandey et al. (2022) Kushagra Pandey, Avideep Mukherjee, Piyush Rai, and Abhishek Kumar. Diffusevae: Efficient, controllable and high-fidelity generation from low-dimensional latents. arXiv preprint arXiv:2201.00308, 2022.": "Diffusevae: Efficient, controllable and high-fidelity generation from low-dimensional latents", "Dhariwal & Nichol (2021) Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in Neural Information Processing Systems, 34, 2021.": "Diffusion models beat GANs on image synthesis", "Song et al. (2020) Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020.": "Denoising Diffusion Implicit Models", "Liu et al. (2022) Luping Liu, Yi Ren, Zhijie Lin, and Zhou Zhao. Pseudo numerical methods for diffusion models on manifolds. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=PlKWVd2yBkY.": "Pseudo numerical methods for diffusion models on manifolds", "Song & Ermon (2020) Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. Advances in neural information processing systems, 33:12438\u201312448, 2020.": "Improved Techniques for Training Score-Based Generative Models", "Song & Ermon (2019) Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in Neural Information Processing Systems, 32, 2019.": "Generative modeling by estimating gradients of the data distribution", "Parimala & Channappayya (2019) Kancharla Parimala and Sumohana Channappayya. Quality aware generative adversarial networks. Advances in neural information processing systems, 32, 2019.": "Quality Aware Generative Adversarial Networks"}, "source_title_to_arxiv_id": {"Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality": "2202.05830"}}