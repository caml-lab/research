{"title": "MVSTER: Epipolar Transformer for Efficient Multi-View Stereo", "abstract": "Learning-based Multi-View Stereo (MVS) methods warp source images into the\nreference camera frustum to form 3D volumes, which are fused as a cost volume\nto be regularized by subsequent networks. The fusing step plays a vital role in\nbridging 2D semantics and 3D spatial associations. However, previous methods\nutilize extra networks to learn 2D information as fusing cues, underusing 3D\nspatial correlations and bringing additional computation costs. Therefore, we\npresent MVSTER, which leverages the proposed epipolar Transformer to learn both\n2D semantics and 3D spatial associations efficiently. Specifically, the\nepipolar Transformer utilizes a detachable monocular depth estimator to enhance\n2D semantics and uses cross-attention to construct data-dependent 3D\nassociations along epipolar line. Additionally, MVSTER is built in a cascade\nstructure, where entropy-regularized optimal transport is leveraged to\npropagate finer depth estimations in each stage. Extensive experiments show\nMVSTER achieves state-of-the-art reconstruction performance with significantly\nhigher efficiency: Compared with MVSNet and CasMVSNet, our MVSTER achieves 34%\nand 14% relative improvements on the DTU benchmark, with 80% and 51% relative\nreductions in running time. MVSTER also ranks first on Tanks&Temples-Advanced\namong all published works. Code is released at https://github.com/JeffWang987.", "authors": ["Xiaofeng Wang", "Zheng Zhu", "Fangbo Qin", "Yun Ye", "Guan Huang", "Xu Chi", "Yijia He", "Xingang Wang"], "published_date": "2022_04_15", "pdf_url": "http://arxiv.org/pdf/2204.07346v1", "list_table_and_caption": [{"table": "<table><tbody><tr><th>Method</th><td>Acc.\\downarrow</td><td>Comp.\\downarrow</td><td>Overall\\downarrow</td><td>Runtime (s)\\downarrow</td></tr><tr><th>Gipuma [21]</th><td>0.283</td><td>0.873</td><td>0.578</td><td>-</td></tr><tr><th>COLMAP [45]</th><td>0.400</td><td>0.664</td><td>0.532</td><td>-</td></tr><tr><th>Tola [52]</th><td>0.342</td><td>1.190</td><td>0.766</td><td>-</td></tr><tr><th>MVSNet [66]</th><td>0.396</td><td>0.527</td><td>0.462</td><td>0.85</td></tr><tr><th>R-MVSNet [67]</th><td>0.383</td><td>0.452</td><td>0.417</td><td>0.89</td></tr><tr><th>Fast-MVSNet [70]</th><td>0.336</td><td>0.403</td><td>0.370</td><td>0.37</td></tr><tr><th>CVP-MVSNet* [69]</th><td>0.296</td><td>0.406</td><td>0.351</td><td>1.12</td></tr><tr><th>CasMVSNet [25]</th><td>0.325</td><td>0.385</td><td>0.355</td><td>0.35</td></tr><tr><th>UCS-Net* [10]</th><td>0.338</td><td>0.349</td><td>0.344</td><td>0.32</td></tr><tr><th>PatchmatchNet* [55]</th><td>0.427</td><td>0.277</td><td>0.352</td><td>0.18</td></tr><tr><th>AA-RMVSNet [58]</th><td>0.376</td><td>0.339</td><td>0.357</td><td>-</td></tr><tr><th>MVSTER</th><td>0.350</td><td>0.276</td><td>0.313</td><td>0.09</td></tr><tr><th>MVSTER*</th><td>0.340</td><td>0.266</td><td>0.303</td><td>0.17</td></tr><tr><th>TransMVSNet [16]</th><td>0.321</td><td>0.289</td><td>0.305</td><td>0.99</td></tr><tr><th>MVSTR [75]</th><td>0.356</td><td>0.295</td><td>0.326</td><td>0.81</td></tr><tr><th>UniMVSNet [39]</th><td>0.352</td><td>0.278</td><td>0.315</td><td>-</td></tr><tr><th>IterMVS* [54]</th><td>0.373</td><td>0.354</td><td>0.363</td><td>0.18</td></tr></tbody></table>", "caption": "Table 1: Quantitative results of different methods on the DTU evaluation set. Methods with * denote their input resolution is 1600\\times 1200. The last four methods with gray font come from technical reports.", "list_citation_info": ["[21] Galliani, S., Lasinger, K., Schindler, K.: Massively parallel multiview stereopsis by surface normal diffusion. In: IEEE International Conference on Computer Vision (2015)", "[10] Cheng, S., Xu, Z., Zhu, S., Li, Z., Li, L.E., Ramamoorthi, R., Su, H.: Deep stereo using adaptive thin volume representation with uncertainty awareness. In: IEEE Conference on Computer Vision and Pattern Recognition (2020)", "[75] Zhu, J., Peng, B., Li, W., Shen, H., Zhang, Z., Lei, J.: Multi-view stereo with transformer. arXiv preprint arXiv:2112.00336 (2021)", "[70] Yu, Z., Gao, S.: Fast-mvsnet: Sparse-to-dense multi-view stereo with learned propagation and gauss-newton refinement. In: IEEE Conference on Computer Vision and Pattern Recognition (2020)", "[54] Wang, F., Galliani, S., Vogel, C., Pollefeys, M.: Itermvs: Iterative probability estimation for efficient multi-view stereo. arXiv preprint arXiv:2112.05126 (2021)", "[45] Sch\u00f6nberger, J.L., Frahm, J.: Structure-from-motion revisited. In: IEEE Conference on Computer Vision and Pattern Recognition (2016)", "[52] Tola, E., Strecha, C., Fua, P.: Efficient large-scale multi-view stereo for ultra high-resolution image sets. Machine Vision and Applications (2012)", "[66] Yao, Y., Luo, Z., Li, S., Fang, T., Quan, L.: Mvsnet: Depth inference for unstructured multi-view stereo. In: European Conference on Computer Vision (2018)", "[67] Yao, Y., Luo, Z., Li, S., Shen, T., Fang, T., Quan, L.: Recurrent mvsnet for high-resolution multi-view stereo depth inference. In: IEEE Conference on Computer Vision and Pattern Recognition (2019)", "[55] Wang, F., Galliani, S., Vogel, C., Speciale, P., Pollefeys, M.: Patchmatchnet: Learned multi-view patchmatch stereo. In: IEEE Conference on Computer Vision and Pattern Recognition (2021)", "[16] Ding, Y., Yuan, W., Zhu, Q., Zhang, H., Liu, X., Wang, Y., Liu, X.: Transmvsnet: Global context-aware multi-view stereo network with transformers. arXiv preprint arXiv:2111.14600 (2021)", "[39] Peng, R., Wang, R., Wang, Z., Lai, Y., Wang, R.: Rethinking depth estimation for multi-view stereo: A unified representation and focal loss. arXiv preprint arXiv:2201.01501 (2022)", "[25] Gu, X., Fan, Z., Zhu, S., Dai, Z., Tan, F., Tan, P.: Cascade cost volume for high-resolution multi-view stereo and stereo matching. In: IEEE Conference on Computer Vision and Pattern Recognition (2020)", "[58] Wei, Z., Zhu, Q., Min, C., Chen, Y., Wang, G.: Aa-rmvsnet: Adaptive aggregation recurrent multi-view stereo network. In: IEEE International Conference on Computer Vision (2021)", "[69] Yi, H., Wei, Z., Ding, M., Zhang, R., Chen, Y., Wang, G., Tai, Y.: Pyramid multi-view stereo net with self-adaptive view aggregation. In: European Conference on Computer Vision (2020)"]}, {"table": "<table><tbody><tr><th>Method</th><td>Mean F-score</td><td>Aud.</td><td>Bal.</td><td>Cou.</td><td>Mus.</td><td>Pal.</td><td>Tem.</td></tr><tr><th>COLMAP [45]</th><td>27.24</td><td>16.02</td><td>25.23</td><td>34.70</td><td>41.51</td><td>18.05</td><td>27.94</td></tr><tr><th>ACMH [59]</th><td>34.02</td><td>23.41</td><td>32.91</td><td>\\mathbf{41.17}</td><td>48.13</td><td>23.87</td><td>34.60</td></tr><tr><th>R-MVSNet [67]</th><td>29.55</td><td>19.49</td><td>31.45</td><td>29.99</td><td>42.31</td><td>22.94</td><td>31.10</td></tr><tr><th>CasMVSNet [25]</th><td>31.12</td><td>19.81</td><td>38.46</td><td>29.10</td><td>43.87</td><td>27.36</td><td>28.11</td></tr><tr><th>PatchmatchNet [55]</th><td>32.31</td><td>23.69</td><td>37.73</td><td>30.04</td><td>41.80</td><td>28.31</td><td>32.29</td></tr><tr><th>EPP-MVSNet [36]</th><td>35.72</td><td>21.28</td><td>39.74</td><td>35.34</td><td>49.21</td><td>30.00</td><td>38.75</td></tr><tr><th>AA R-MVSNet [58]</th><td>33.53</td><td>20.96</td><td>40.15</td><td>32.05</td><td>46.01</td><td>29.28</td><td>32.71</td></tr><tr><th>MVSTER</th><td>\\mathbf{37.53}</td><td>\\mathbf{26.68}</td><td>\\mathbf{42.14}</td><td>35.65</td><td>\\mathbf{49.37}</td><td>\\mathbf{32.16}</td><td>\\mathbf{39.19}</td></tr><tr><th>TransMVSNet [16]</th><td>37.00</td><td>24.84</td><td>\\mathbf{44.69}</td><td>34.77</td><td>46.49</td><td>\\mathbf{34.69}</td><td>36.62</td></tr><tr><th>MVSTR [75]</th><td>32.85</td><td>22.83</td><td>39.04</td><td>33.87</td><td>45.46</td><td>27.95</td><td>27.97</td></tr><tr><th>UniMVSNet [39]</th><td>\\mathbf{38.96}</td><td>\\mathbf{28.33}</td><td>44.36</td><td>39.74</td><td>\\mathbf{52.89}</td><td>33.80</td><td>34.63</td></tr><tr><th>IterMVS [54]</th><td>34.17</td><td>25.90</td><td>38.41</td><td>31.16</td><td>44.83</td><td>29.59</td><td>35.15</td></tr></tbody></table>", "caption": "Table 2: Quantitative results on Tanks&amp;Temples-advanced. The evaluation metric is the mean F-score and the last four methods with gray font come from technical reports.", "list_citation_info": ["[59] Xu, Q., Tao, W.: Multi-scale geometric consistency guided multi-view stereo. In: IEEE Conference on Computer Vision and Pattern Recognition (2019)", "[36] Ma, X., Gong, Y., Wang, Q., Huang, J., Chen, L., Yu, F.: Epp-mvsnet: Epipolar-assembling based depth prediction for multi-view stereo. In: IEEE International Conference on Computer Vision (2021)", "[45] Sch\u00f6nberger, J.L., Frahm, J.: Structure-from-motion revisited. In: IEEE Conference on Computer Vision and Pattern Recognition (2016)", "[67] Yao, Y., Luo, Z., Li, S., Shen, T., Fang, T., Quan, L.: Recurrent mvsnet for high-resolution multi-view stereo depth inference. In: IEEE Conference on Computer Vision and Pattern Recognition (2019)", "[16] Ding, Y., Yuan, W., Zhu, Q., Zhang, H., Liu, X., Wang, Y., Liu, X.: Transmvsnet: Global context-aware multi-view stereo network with transformers. arXiv preprint arXiv:2111.14600 (2021)", "[39] Peng, R., Wang, R., Wang, Z., Lai, Y., Wang, R.: Rethinking depth estimation for multi-view stereo: A unified representation and focal loss. arXiv preprint arXiv:2201.01501 (2022)", "[55] Wang, F., Galliani, S., Vogel, C., Speciale, P., Pollefeys, M.: Patchmatchnet: Learned multi-view patchmatch stereo. In: IEEE Conference on Computer Vision and Pattern Recognition (2021)", "[75] Zhu, J., Peng, B., Li, W., Shen, H., Zhang, Z., Lei, J.: Multi-view stereo with transformer. arXiv preprint arXiv:2112.00336 (2021)", "[25] Gu, X., Fan, Z., Zhu, S., Dai, Z., Tan, F., Tan, P.: Cascade cost volume for high-resolution multi-view stereo and stereo matching. In: IEEE Conference on Computer Vision and Pattern Recognition (2020)", "[58] Wei, Z., Zhu, Q., Min, C., Chen, Y., Wang, G.: Aa-rmvsnet: Adaptive aggregation recurrent multi-view stereo network. In: IEEE International Conference on Computer Vision (2021)", "[54] Wang, F., Galliani, S., Vogel, C., Pollefeys, M.: Itermvs: Iterative probability estimation for efficient multi-view stereo. arXiv preprint arXiv:2112.05126 (2021)"]}, {"table": "<table><tbody><tr><th rowspan=\"2\">Methods</th><td colspan=\"3\">Training set </td><td colspan=\"3\">Test set </td></tr><tr><td>Acc.</td><td>Comp.</td><td>F_{1} -score</td><td>Acc.</td><td>Comp.</td><td>F_{1} -score</td></tr><tr><th>Gipuma [45]</th><td>84.44</td><td>34.91</td><td>36.38</td><td>86.47</td><td>24.91</td><td>45.18</td></tr><tr><th>PMVS [20]</th><td>90.23</td><td>32.08</td><td>46.06</td><td>90.08</td><td>31.84</td><td>44.16</td></tr><tr><th>COLMAP [45]</th><td>91.85</td><td>55.13</td><td>67.66</td><td>91.97</td><td>62.98</td><td>73.01</td></tr><tr><th>ACMH [59]</th><td>88.94</td><td>61.59</td><td>70.71</td><td>89.34</td><td>68.62</td><td>75.89</td></tr><tr><th>PatchmatchNet [55]</th><td>64.81</td><td>65.43</td><td>64.21</td><td>69.71</td><td>77.46</td><td>73.12</td></tr><tr><th>PatchMatch-RL [31]</th><td>76.05</td><td>62.22</td><td>67.78</td><td>74.48</td><td>72.89</td><td>72.38</td></tr><tr><th>MVSTER</th><td>76.92</td><td>68.08</td><td>72.06</td><td>77.09</td><td>82.47</td><td>79.01</td></tr><tr><th>PVSNet [61]</th><td>67.84</td><td>69.66</td><td>67.48</td><td>66.41</td><td>80.05</td><td>72.08</td></tr><tr><th>IterMVS [54]</th><td>79.79</td><td>66.08</td><td>71.69</td><td>84.73</td><td>76.49</td><td>80.06</td></tr></tbody></table>", "caption": "Table 3: Quantitative results on the ETH3D benchmark, which is split into a training set and a test set. The last two methods with gray font come from technical reports.", "list_citation_info": ["[59] Xu, Q., Tao, W.: Multi-scale geometric consistency guided multi-view stereo. In: IEEE Conference on Computer Vision and Pattern Recognition (2019)", "[61] Xu, Q., Tao, W.: Pvsnet: Pixelwise visibility-aware multi-view stereo network. arXiv preprint arXiv:2007.07714 (2020)", "[20] Furukawa, Y., Ponce, J.: Accurate, dense, and robust multiview stereopsis. IEEE Transactions on Pattern Analysis and Machine Intelligence (2010)", "[31] Lee, J.Y., DeGol, J., Zou, C., Hoiem, D.: Patchmatch-rl: Deep mvs with pixelwise depth, normal, and visibility. In: IEEE International Conference on Computer Vision (2021)", "[45] Sch\u00f6nberger, J.L., Frahm, J.: Structure-from-motion revisited. In: IEEE Conference on Computer Vision and Pattern Recognition (2016)", "[55] Wang, F., Galliani, S., Vogel, C., Speciale, P., Pollefeys, M.: Patchmatchnet: Learned multi-view patchmatch stereo. In: IEEE Conference on Computer Vision and Pattern Recognition (2021)", "[54] Wang, F., Galliani, S., Vogel, C., Pollefeys, M.: Itermvs: Iterative probability estimation for efficient multi-view stereo. arXiv preprint arXiv:2112.05126 (2021)"]}], "citation_info_to_title": {"[75] Zhu, J., Peng, B., Li, W., Shen, H., Zhang, Z., Lei, J.: Multi-view stereo with transformer. arXiv preprint arXiv:2112.00336 (2021)": "Multi-view stereo with transformer", "[10] Cheng, S., Xu, Z., Zhu, S., Li, Z., Li, L.E., Ramamoorthi, R., Su, H.: Deep stereo using adaptive thin volume representation with uncertainty awareness. In: IEEE Conference on Computer Vision and Pattern Recognition (2020)": "Deep stereo using adaptive thin volume representation with uncertainty awareness", "[45] Sch\u00f6nberger, J.L., Frahm, J.: Structure-from-motion revisited. In: IEEE Conference on Computer Vision and Pattern Recognition (2016)": "Structure-from-motion revisited", "[59] Xu, Q., Tao, W.: Multi-scale geometric consistency guided multi-view stereo. In: IEEE Conference on Computer Vision and Pattern Recognition (2019)": "Multi-scale geometric consistency guided multi-view stereo", "[52] Tola, E., Strecha, C., Fua, P.: Efficient large-scale multi-view stereo for ultra high-resolution image sets. Machine Vision and Applications (2012)": "Efficient large-scale multi-view stereo for ultra high-resolution image sets", "[16] Ding, Y., Yuan, W., Zhu, Q., Zhang, H., Liu, X., Wang, Y., Liu, X.: Transmvsnet: Global context-aware multi-view stereo network with transformers. arXiv preprint arXiv:2111.14600 (2021)": "Transmvsnet: Global context-aware multi-view stereo network with transformers", "[39] Peng, R., Wang, R., Wang, Z., Lai, Y., Wang, R.: Rethinking depth estimation for multi-view stereo: A unified representation and focal loss. arXiv preprint arXiv:2201.01501 (2022)": "Rethinking depth estimation for multi-view stereo: A unified representation and focal loss", "[67] Yao, Y., Luo, Z., Li, S., Shen, T., Fang, T., Quan, L.: Recurrent mvsnet for high-resolution multi-view stereo depth inference. In: IEEE Conference on Computer Vision and Pattern Recognition (2019)": "Recurrent MVSNet for High-Resolution Multi-View Stereo Depth Inference", "[66] Yao, Y., Luo, Z., Li, S., Fang, T., Quan, L.: Mvsnet: Depth inference for unstructured multi-view stereo. In: European Conference on Computer Vision (2018)": "Mvsnet: Depth Inference for Unstructured Multi-View Stereo", "[58] Wei, Z., Zhu, Q., Min, C., Chen, Y., Wang, G.: Aa-rmvsnet: Adaptive aggregation recurrent multi-view stereo network. In: IEEE International Conference on Computer Vision (2021)": "Aa-rmvsnet: Adaptive Aggregation Recurrent Multi-View Stereo Network", "[70] Yu, Z., Gao, S.: Fast-mvsnet: Sparse-to-dense multi-view stereo with learned propagation and gauss-newton refinement. In: IEEE Conference on Computer Vision and Pattern Recognition (2020)": "Fast-MVSNet: Sparse-to-Dense Multi-View Stereo with Learned Propagation and Gauss-Newton Refinement", "[31] Lee, J.Y., DeGol, J., Zou, C., Hoiem, D.: Patchmatch-rl: Deep mvs with pixelwise depth, normal, and visibility. In: IEEE International Conference on Computer Vision (2021)": "Patchmatch-rl: Deep MVS with Pixelwise Depth, Normal, and Visibility", "[20] Furukawa, Y., Ponce, J.: Accurate, dense, and robust multiview stereopsis. IEEE Transactions on Pattern Analysis and Machine Intelligence (2010)": "Accurate, dense, and robust multiview stereopsis", "[36] Ma, X., Gong, Y., Wang, Q., Huang, J., Chen, L., Yu, F.: Epp-mvsnet: Epipolar-assembling based depth prediction for multi-view stereo. In: IEEE International Conference on Computer Vision (2021)": "Epp-mvsnet: Epipolar-assembling based depth prediction for multi-view stereo", "[69] Yi, H., Wei, Z., Ding, M., Zhang, R., Chen, Y., Wang, G., Tai, Y.: Pyramid multi-view stereo net with self-adaptive view aggregation. In: European Conference on Computer Vision (2020)": "Pyramid Multi-View Stereo Net with Self-Adaptive View Aggregation", "[21] Galliani, S., Lasinger, K., Schindler, K.: Massively parallel multiview stereopsis by surface normal diffusion. In: IEEE International Conference on Computer Vision (2015)": "Massively parallel multiview stereopsis by surface normal diffusion", "[25] Gu, X., Fan, Z., Zhu, S., Dai, Z., Tan, F., Tan, P.: Cascade cost volume for high-resolution multi-view stereo and stereo matching. In: IEEE Conference on Computer Vision and Pattern Recognition (2020)": "Cascade cost volume for high-resolution multi-view stereo and stereo matching", "[55] Wang, F., Galliani, S., Vogel, C., Speciale, P., Pollefeys, M.: Patchmatchnet: Learned multi-view patchmatch stereo. In: IEEE Conference on Computer Vision and Pattern Recognition (2021)": "Patchmatchnet: Learned Multi-View Patchmatch Stereo", "[61] Xu, Q., Tao, W.: Pvsnet: Pixelwise visibility-aware multi-view stereo network. arXiv preprint arXiv:2007.07714 (2020)": "Pvsnet: Pixelwise visibility-aware multi-view stereo network", "[54] Wang, F., Galliani, S., Vogel, C., Pollefeys, M.: Itermvs: Iterative probability estimation for efficient multi-view stereo. arXiv preprint arXiv:2112.05126 (2021)": "Itermvs: Iterative Probability Estimation for Efficient Multi-View Stereo"}, "source_title_to_arxiv_id": {"Aa-rmvsnet: Adaptive Aggregation Recurrent Multi-View Stereo Network": "2108.03824"}}