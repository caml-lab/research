{"title": "DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited Annotations", "abstract": "Solving multi-label recognition (MLR) for images in the low-label regime is a\nchallenging task with many real-world applications. Recent work learns an\nalignment between textual and visual spaces to compensate for insufficient\nimage labels, but loses accuracy because of the limited amount of available MLR\nannotations. In this work, we utilize the strong alignment of textual and\nvisual features pretrained with millions of auxiliary image-text pairs and\npropose Dual Context Optimization (DualCoOp) as a unified framework for\npartial-label MLR and zero-shot MLR. DualCoOp encodes positive and negative\ncontexts with class names as part of the linguistic input (i.e. prompts). Since\nDualCoOp only introduces a very light learnable overhead upon the pretrained\nvision-language framework, it can quickly adapt to multi-label recognition\ntasks that have limited annotations and even unseen classes. Experiments on\nstandard multi-label recognition benchmarks across two challenging low-label\nsettings demonstrate the advantages of our approach over state-of-the-art\nmethods.", "authors": ["Ximeng Sun", "Ping Hu", "Kate Saenko"], "published_date": "2022_06_20", "pdf_url": "http://arxiv.org/pdf/2206.09541v1", "list_table_and_caption": [{"table": "<table><tr><td> Methods</td><td>#P</td><td>10\\%</td><td>20\\%</td><td>30\\%</td><td>40\\%</td><td>50\\%</td><td>60\\%</td><td>70\\%</td><td>80\\%</td><td>90\\%</td><td>Avg.</td></tr><tr><td colspan=\"2\">   MS-COCO [33]</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td> SSGRL [8]</td><td>64.7M</td><td>62.5</td><td>70.5</td><td>73.2</td><td>74.5</td><td>76.3</td><td>76.5</td><td>77.1</td><td>77.9</td><td>78.4</td><td>74.1</td></tr><tr><td>GCN-ML [9]</td><td>44.9M</td><td>63.8</td><td>70.9</td><td>72.8</td><td>74.0</td><td>76.7</td><td>77.1</td><td>77.3</td><td>78.3</td><td>78.6</td><td>74.4</td></tr><tr><td>KGGR [6]</td><td>\\geq 25M</td><td>66.6</td><td>71.4</td><td>73.8</td><td>76.7</td><td>77.5</td><td>77.9</td><td>78.4</td><td>78.7</td><td>79.1</td><td>75.6</td></tr><tr><td>Curriculum labeling [14]</td><td>\\geq 38M</td><td>26.7</td><td>31.8</td><td>51.5</td><td>65.4</td><td>70.0</td><td>71.9</td><td>74.0</td><td>77.4</td><td>78.0</td><td>60.7</td></tr><tr><td>Patial BCE [14]</td><td>\\geq 38M</td><td>61.6</td><td>70.5</td><td>74.1</td><td>76.3</td><td>77.2</td><td>77.7</td><td>78.2</td><td>78.4</td><td>78.5</td><td>74.7</td></tr><tr><td>SST [7]</td><td>33.5M</td><td>68.1</td><td>73.5</td><td>75.9</td><td>77.3</td><td>78.1</td><td>78.9</td><td>79.2</td><td>79.6</td><td>79.9</td><td>76.7</td></tr><tr><td>SST{}^{*}</td><td>33.5M</td><td>69.1</td><td>78.5</td><td>79.3</td><td>79.9</td><td>80.1</td><td>80.5</td><td>81.1</td><td>80.7</td><td>80.7</td><td>78.9</td></tr><tr><td>SARB [45]</td><td>29.6M</td><td>71.2</td><td>75.0</td><td>77.1</td><td>78.3</td><td>78.9</td><td>79.6</td><td>79.8</td><td>80.5</td><td>80.5</td><td>77.9</td></tr><tr><td>SARB{}^{*}</td><td>29.6M</td><td>75.5</td><td>78.5</td><td>79.0</td><td>79.5</td><td>80.4</td><td>80.2</td><td>80.8</td><td>80.6</td><td>80.8</td><td>79.4</td></tr><tr><td>DualCoOp (ours)</td><td>1.3M</td><td>78.7</td><td>80.9</td><td>81.7</td><td>82.0</td><td>82.5</td><td>82.7</td><td>82.8</td><td>83.0</td><td>83.1</td><td>81.9</td></tr><tr><td colspan=\"2\">   PASCAL VOC 2007  [15]</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td> SSGRL [8]</td><td>66.6M</td><td>77.7</td><td>87.6</td><td>89.9</td><td>90.7</td><td>91.4</td><td>91.8</td><td>91.9</td><td>92.2</td><td>92.2</td><td>89.5</td></tr><tr><td>GCN-ML [9]</td><td>44.9M</td><td>74.5</td><td>87.4</td><td>89.7</td><td>90.7</td><td>91.0</td><td>91.3</td><td>91.5</td><td>91.8</td><td>92.0</td><td>88.9</td></tr><tr><td>KGGR [6]</td><td>\\geq 25M</td><td>81.3</td><td>88.1</td><td>89.9</td><td>90.4</td><td>91.2</td><td>91.3</td><td>91.5</td><td>91.6</td><td>91.8</td><td>89.7</td></tr><tr><td>Curriculum labeling [14]</td><td>\\geq 38M</td><td>44.7</td><td>76.8</td><td>88.6</td><td>90.2</td><td>90.7</td><td>91.1</td><td>91.6</td><td>91.7</td><td>91.9</td><td>84.1</td></tr><tr><td>Patial BCE [14]</td><td>\\geq 38M</td><td>80.7</td><td>88.4</td><td>89.9</td><td>90.7</td><td>91.2</td><td>91.8</td><td>92.3</td><td>92.4</td><td>92.5</td><td>90.0</td></tr><tr><td>SST [7]</td><td>32.4M</td><td>81.5</td><td>89.0</td><td>90.3</td><td>91.0</td><td>91.6</td><td>92.0</td><td>92.5</td><td>92.6</td><td>92.7</td><td>90.4</td></tr><tr><td>SARB [45]</td><td>29.6M</td><td>83.5</td><td>88.6</td><td>90.7</td><td>91.4</td><td>91.9</td><td>92.2</td><td>92.6</td><td>92.8</td><td>92.9</td><td>90.7</td></tr><tr><td>DualCoOp (ours)</td><td>0.3M</td><td>90.3</td><td>92.2</td><td>92.8</td><td>93.3</td><td>93.6</td><td>93.9</td><td>94.0</td><td>94.1</td><td>94.2</td><td>93.2</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 1: Multi-label Recognition on MS-COCO and VOC2007 with partial labels. DualCoOp achieves the best performance over all SOTA methods. {}^{*} indicates previous models using weights pretrained by CLIP [46]", "list_citation_info": ["[33] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV, 2014.", "[45] Tao Pu, Tianshui Chen, Hefeng Wu, and Liang Lin. Semantic-aware representation blending for multi-label image recognition with partial labels. In AAAI, 2022.", "[46] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, 2021.", "[9] Zhao-Min Chen, Xiu-Shen Wei, Peng Wang, and Yanwen Guo. Multi-label image recognition with graph convolutional networks. In CVPR, 2019.", "[6] Tianshui Chen, Liang Lin, Xiaolu Hui, Riquan Chen, and Hefeng Wu. Knowledge-guided multi-label few-shot learning for general image recognition. IEEE Trans. on PAMI, 2020.", "[7] Tianshui Chen, Tao Pu, Hefeng Wu, Yuan Xie, and Liang Lin. Structured semantic transfer for multi-label recognition with partial labels. 2022.", "[15] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. IJCV, 88(2):303\u2013338, 2010.", "[8] Tianshui Chen, Muxin Xu, Xiaolu Hui, Hefeng Wu, and Liang Lin. Learning semantic-specific graph representation for multi-label image recognition. In ICCV, 2019.", "[14] Thibaut Durand, Nazanin Mehrasa, and Greg Mori. Learning a deep convnet for multi-label classification with partial labels. In CVPR, 2019."]}, {"table": "<table><tr><td rowspan=\"2\"> Methods</td><td></td><td colspan=\"3\">ZSL</td><td colspan=\"3\">GZSL</td></tr><tr><td rowspan=\"-2\">#P</td><td>P</td><td>R</td><td>F1</td><td>P</td><td>R</td><td>F1</td></tr><tr><td> CONSE [44]</td><td>-</td><td>11.4</td><td>28.3</td><td>16.2</td><td>23.8</td><td>28.8</td><td>26.1</td></tr><tr><td>Fast0Tag [68]</td><td>0.61M</td><td>24.7</td><td>61.4</td><td>25.3</td><td>38.5</td><td>46.5</td><td>42.1</td></tr><tr><td>Deep0Tag [48]</td><td>\\geq 23M</td><td>26.5</td><td>65.9</td><td>37.8</td><td>43.2</td><td>52.2</td><td>47.3</td></tr><tr><td>SDL (M=2) [3]</td><td>30.6M</td><td>26.3</td><td>65.3</td><td>37.5</td><td>59.0</td><td>60.8</td><td>59.9</td></tr><tr><td>DualCoOp (ours)</td><td>0.02M</td><td>35.3</td><td>87.6</td><td>50.3</td><td>58.4</td><td>68.1</td><td>62.9</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 2: Zero-Shot Multi-Label Recognition on MS-COCO[33]. DualCoOp achieves the best F1 score in both ZSL and GZSL settings.", "list_citation_info": ["[33] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV, 2014.", "[68] Yang Zhang, Boqing Gong, and Mubarak Shah. Fast zero-shot image tagging. In CVPR, 2016.", "[44] Mohammad Norouzi, Tomas Mikolov, Samy Bengio, Yoram Singer, Jonathon Shlens, Andrea Frome, Greg S Corrado, and Jeffrey Dean. Zero-shot learning by convex combination of semantic embeddings. arXiv preprint arXiv:1312.5650, 2013.", "[3] Avi Ben-Cohen, Nadav Zamir, Emanuel Ben-Baruch, Itamar Friedman, and Lihi Zelnik-Manor. Semantic diversity learning for zero-shot multi-label classification. In ICCV, 2021.", "[48] Shafin Rahman and Salman Khan. Deep multiple instance learning for zero-shot image tagging. In ACCV, 2018."]}, {"table": "<table><tr><td rowspan=\"2\"> Methods</td><td></td><td colspan=\"3\">Top-3</td><td colspan=\"3\">Top-5</td><td></td></tr><tr><td rowspan=\"-2\">#P</td><td>P</td><td>R</td><td>F1</td><td>P</td><td>R</td><td>F1</td><td rowspan=\"-2\">mAP</td></tr><tr><td colspan=\"2\">   Zero-Shot Learning (ZSL)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td> CONSE [44]</td><td>-</td><td>17.5</td><td>28.0</td><td>21.6</td><td>13.9</td><td>37.0</td><td>20.2</td><td>9.4</td></tr><tr><td>LabelEM [1]</td><td>-</td><td>15.6</td><td>25.0</td><td>19.2</td><td>13.4</td><td>35.7</td><td>19.5</td><td>7.1</td></tr><tr><td>Fast0Tag [68]</td><td>0.61M</td><td>22.6</td><td>36.2</td><td>27.8</td><td>18.2</td><td>48.4</td><td>26.4</td><td>15.1</td></tr><tr><td>One Attention per Label [25]</td><td>\\pagecolor{yellow!15}\\geq 12.8M</td><td>20.9</td><td>33.5</td><td>25.8</td><td>16.2</td><td>43.2</td><td>23.6</td><td>10.4</td></tr><tr><td>LESA (M=10) [21]</td><td>\\geq 0.45M</td><td>25.7</td><td>41.1</td><td>31.6</td><td>19.7</td><td>52.5</td><td>28.7</td><td>19.4</td></tr><tr><td>BiAM [43]</td><td>3.8M</td><td>\u2013</td><td>\u2013</td><td>33.1</td><td>\u2013</td><td>\u2013</td><td>30.7</td><td>26.3</td></tr><tr><td>SDL (M=7) [3]</td><td>33.6M</td><td>24.2</td><td>41.3</td><td>30.5</td><td>18.8</td><td>53.4</td><td>27.8</td><td>25.9</td></tr><tr><td>DualCoOp (ours)</td><td>0.02M</td><td>37.3</td><td>46.2</td><td>41.3</td><td>28.7</td><td>59.3</td><td>38.7</td><td>43.6</td></tr><tr><td colspan=\"2\">   Generalized Zero-Shot Learning (GZSL)</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td> CONSE [44]</td><td>-</td><td>11.5</td><td>5.1</td><td>7.0</td><td>9.6</td><td>7.1</td><td>8.1</td><td>2.1</td></tr><tr><td>LabelEM [1]</td><td>-</td><td>15.5</td><td>6.8</td><td>9.5</td><td>13.4</td><td>9.8</td><td>11.3</td><td>2.2</td></tr><tr><td>Fast0Tag [68]</td><td>0.61M</td><td>18.8</td><td>8.3</td><td>11.5</td><td>15.9</td><td>11.7</td><td>13.5</td><td>3.7</td></tr><tr><td>One Attention per Label [25]</td><td>\\geq 12.8M</td><td>17.9</td><td>7.9</td><td>10.9</td><td>15.6</td><td>11.5</td><td>13.2</td><td>3.7</td></tr><tr><td>LESA (M=10) [21]</td><td>\\pagecolor{yellow!15}\\geq 0.45M</td><td>23.6</td><td>10.4</td><td>14.4</td><td>19.8</td><td>14.6</td><td>16.8</td><td>5.6</td></tr><tr><td>BiAM [43]</td><td>3.8M</td><td>\u2013</td><td>\u2013</td><td>16.1</td><td>\u2013</td><td>\u2013</td><td>19.0</td><td>9.3</td></tr><tr><td>SDL (M=7) [3]</td><td>33.6M</td><td>27.7</td><td>13.9</td><td>18.5</td><td>23.0</td><td>19.3</td><td>21.0</td><td> 12.1</td></tr><tr><td>DualCoOp (ours)</td><td>0.02M</td><td>31.9</td><td>13.9</td><td>19.4</td><td>26.2</td><td>19.1</td><td> 22.1</td><td>12.0</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 3: Zero-Shot Multi-label Recognition on NUS-WIDE [10]. DualCoOp achieves the best F1 score over all SOTA methods at Top-3/Top-5 predictions in both ZSL and GZSL settings. ", "list_citation_info": ["[1] Zeynep Akata, Florent Perronnin, Zaid Harchaoui, and Cordelia Schmid. Label-embedding for image classification. IEEE Trans. on PAMI, 38(7):1425\u20131438, 2015.", "[10] Tat-Seng Chua, Jinhui Tang, Richang Hong, Haojie Li, Zhiping Luo, and Yantao Zheng. Nus-wide: a real-world web image database from national university of singapore. In ICIVR, 2009.", "[68] Yang Zhang, Boqing Gong, and Mubarak Shah. Fast zero-shot image tagging. In CVPR, 2016.", "[25] Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. Bilinear Attention Networks. In NIPS, 2018.", "[21] Dat Huynh and Ehsan Elhamifar. A shared multi-attention framework for multi-label zero-shot learning. In CVPR, 2020.", "[44] Mohammad Norouzi, Tomas Mikolov, Samy Bengio, Yoram Singer, Jonathon Shlens, Andrea Frome, Greg S Corrado, and Jeffrey Dean. Zero-shot learning by convex combination of semantic embeddings. arXiv preprint arXiv:1312.5650, 2013.", "[3] Avi Ben-Cohen, Nadav Zamir, Emanuel Ben-Baruch, Itamar Friedman, and Lihi Zelnik-Manor. Semantic diversity learning for zero-shot multi-label classification. In ICCV, 2021.", "[43] Sanath Narayan, Akshita Gupta, Salman Khan, Fahad Shahbaz Khan, Ling Shao, and Mubarak Shah. Discriminative region-based multi-label zero-shot learning. In ICCV, 2021."]}, {"table": "<table><tr><td> Method</td><td>Text Supervision</td><td>10\\%</td><td>30\\%</td><td>50\\%</td><td>70\\%</td><td>90\\%</td></tr><tr><td> Discrete Label</td><td>\u2717</td><td>70.6</td><td>75.1</td><td>76.5</td><td>77.3</td><td>78.0</td></tr><tr><td>SST</td><td>\u2713</td><td>69.1</td><td>79.3</td><td>80.1</td><td>81.1</td><td>80.7</td></tr><tr><td>SARB</td><td>\u2713</td><td>75.5</td><td>79.0</td><td>80.4</td><td>80.8</td><td>80.8</td></tr><tr><td>DualCoOp</td><td>\u2713</td><td>78.4</td><td>81.0</td><td>82.0</td><td>82.5</td><td>82.8</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 4: Comparison among methods on MS-COCO using partial labels with the same initialization. All methods use parameters pretrained by CLIP [46].", "list_citation_info": ["[46] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, 2021."]}], "citation_info_to_title": {"[15] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. IJCV, 88(2):303\u2013338, 2010.": "The Pascal Visual Object Classes (VOC) Challenge", "[44] Mohammad Norouzi, Tomas Mikolov, Samy Bengio, Yoram Singer, Jonathon Shlens, Andrea Frome, Greg S Corrado, and Jeffrey Dean. Zero-shot learning by convex combination of semantic embeddings. arXiv preprint arXiv:1312.5650, 2013.": "Zero-shot learning by convex combination of semantic embeddings", "[3] Avi Ben-Cohen, Nadav Zamir, Emanuel Ben-Baruch, Itamar Friedman, and Lihi Zelnik-Manor. Semantic diversity learning for zero-shot multi-label classification. In ICCV, 2021.": "Semantic Diversity Learning for Zero-Shot Multi-Label Classification", "[10] Tat-Seng Chua, Jinhui Tang, Richang Hong, Haojie Li, Zhiping Luo, and Yantao Zheng. Nus-wide: a real-world web image database from national university of singapore. In ICIVR, 2009.": "Nus-wide: A Real-World Web Image Database from National University of Singapore", "[21] Dat Huynh and Ehsan Elhamifar. A shared multi-attention framework for multi-label zero-shot learning. In CVPR, 2020.": "A shared multi-attention framework for multi-label zero-shot learning", "[14] Thibaut Durand, Nazanin Mehrasa, and Greg Mori. Learning a deep convnet for multi-label classification with partial labels. In CVPR, 2019.": "Learning a deep convnet for multi-label classification with partial labels", "[43] Sanath Narayan, Akshita Gupta, Salman Khan, Fahad Shahbaz Khan, Ling Shao, and Mubarak Shah. Discriminative region-based multi-label zero-shot learning. In ICCV, 2021.": "Discriminative Region-Based Multi-Label Zero-Shot Learning", "[33] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV, 2014.": "Microsoft COCO: Common Objects in Context", "[8] Tianshui Chen, Muxin Xu, Xiaolu Hui, Hefeng Wu, and Liang Lin. Learning semantic-specific graph representation for multi-label image recognition. In ICCV, 2019.": "Learning Semantic-Specific Graph Representation for Multi-Label Image Recognition", "[45] Tao Pu, Tianshui Chen, Hefeng Wu, and Liang Lin. Semantic-aware representation blending for multi-label image recognition with partial labels. In AAAI, 2022.": "Semantic-aware Representation Blending for Multi-label Image Recognition with Partial Labels", "[6] Tianshui Chen, Liang Lin, Xiaolu Hui, Riquan Chen, and Hefeng Wu. Knowledge-guided multi-label few-shot learning for general image recognition. IEEE Trans. on PAMI, 2020.": "Knowledge-guided multi-label few-shot learning for general image recognition", "[25] Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. Bilinear Attention Networks. In NIPS, 2018.": "Bilinear Attention Networks", "[48] Shafin Rahman and Salman Khan. Deep multiple instance learning for zero-shot image tagging. In ACCV, 2018.": "Deep Multiple Instance Learning for Zero-Shot Image Tagging", "[68] Yang Zhang, Boqing Gong, and Mubarak Shah. Fast zero-shot image tagging. In CVPR, 2016.": "Fast zero-shot image tagging", "[46] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, 2021.": "Learning transferable visual models from natural language supervision", "[9] Zhao-Min Chen, Xiu-Shen Wei, Peng Wang, and Yanwen Guo. Multi-label image recognition with graph convolutional networks. In CVPR, 2019.": "Multi-label image recognition with graph convolutional networks", "[1] Zeynep Akata, Florent Perronnin, Zaid Harchaoui, and Cordelia Schmid. Label-embedding for image classification. IEEE Trans. on PAMI, 38(7):1425\u20131438, 2015.": "Label-embedding for image classification", "[7] Tianshui Chen, Tao Pu, Hefeng Wu, Yuan Xie, and Liang Lin. Structured semantic transfer for multi-label recognition with partial labels. 2022.": "Structured Semantic Transfer for Multi-Label Recognition with Partial Labels"}, "source_title_to_arxiv_id": {"Semantic Diversity Learning for Zero-Shot Multi-Label Classification": "2105.05926", "Deep Multiple Instance Learning for Zero-Shot Image Tagging": "1803.06051"}}