{"title": "MOVE: Unsupervised Movable Object Segmentation and Detection", "abstract": "We introduce MOVE, a novel method to segment objects without any form of\nsupervision. MOVE exploits the fact that foreground objects can be shifted\nlocally relative to their initial position and result in realistic\n(undistorted) new images. This property allows us to train a segmentation model\non a dataset of images without annotation and to achieve state of the art\n(SotA) performance on several evaluation datasets for unsupervised salient\nobject detection and segmentation. In unsupervised single object discovery,\nMOVE gives an average CorLoc improvement of 7.2% over the SotA, and in\nunsupervised class-agnostic object detection it gives a relative AP improvement\nof 53% on average. Our approach is built on top of self-supervised features\n(e.g. from DINO or MAE), an inpainting network (based on the Masked\nAutoEncoder) and adversarial training.", "authors": ["Adam Bielski", "Paolo Favaro"], "published_date": "2022_10_14", "pdf_url": "http://arxiv.org/pdf/2210.07920v2", "list_table_and_caption": [{"table": "<table><tbody><tr><th rowspan=\"2\"><p>Model</p></th><td colspan=\"3\">DUT-OMRON Yang et al. [2013]</td><td colspan=\"3\">DUTS-TE Wang et al. [2017]</td><td colspan=\"3\">ECSSD Shi et al. [2015]</td></tr><tr><td>Acc</td><td>IoU</td><td>maxF_{\\beta}</td><td>Acc</td><td>IoU</td><td>maxF_{\\beta}</td><td>Acc</td><td>IoU</td><td>maxF_{\\beta}</td></tr><tr><th><p>HS Yan et al. [2013]</p></th><td>.843</td><td>.433</td><td>.561</td><td>.826</td><td>.369</td><td>.504</td><td>.847</td><td>.508</td><td>.673</td></tr><tr><th><p>wCtr Zhu et al. [2014]</p></th><td>.838</td><td>.416</td><td>.541</td><td>.835</td><td>.392</td><td>.522</td><td>.862</td><td>.517</td><td>.684</td></tr><tr><th><p>WSC Li et al. [2015]</p></th><td>.865</td><td>.387</td><td>.523</td><td>.862</td><td>.384</td><td>.528</td><td>.852</td><td>.498</td><td>.683</td></tr><tr><th><p>DeepUSPS Nguyen et al. [2019]</p></th><td>.779</td><td>.305</td><td>.414</td><td>.773</td><td>.305</td><td>.425</td><td>.795</td><td>.440</td><td>.584</td></tr><tr><th><p>SelfMask pseudo{}^{\\star} Shin et al. [2022]</p></th><td>.811</td><td>.403</td><td>-</td><td>.845</td><td>.466</td><td>-</td><td>.893</td><td>.646</td><td>-</td></tr><tr><th><p>BigBiGAN Voynov et al. [2021]</p></th><td>.856</td><td>.453</td><td>.549</td><td>.878</td><td>.498</td><td>.608</td><td>.899</td><td>.672</td><td>.782</td></tr><tr><th><p>E-BigBiGAN Voynov et al. [2021]</p></th><td>.860</td><td>.464</td><td>.563</td><td>.882</td><td>.511</td><td>.624</td><td>.906</td><td>.684</td><td>.797</td></tr><tr><th><p>Melas-Kyriazi et al. Melas-Kyriazi et al. [2021]</p></th><td>.883</td><td>.509</td><td>-</td><td>.893</td><td>.528</td><td>-</td><td>.915</td><td>.713</td><td>-</td></tr><tr><th><p>LOST Sim\u00e9oni et al. [2021]</p></th><td>.797</td><td>.410</td><td>.473</td><td>.871</td><td>.518</td><td>.611</td><td>.895</td><td>.654</td><td>.758</td></tr><tr><th><p>Deep Spectral Melas-Kyriazi et al. [2022]</p></th><td>-</td><td>.567</td><td>-</td><td>-</td><td>.514</td><td>-</td><td>-</td><td>.733</td><td>-</td></tr><tr><th><p>TokenCut Wang et al. [2022b]</p></th><td>.880</td><td>.533</td><td>.600</td><td>.903</td><td>.576</td><td>.672</td><td>.918</td><td>.712</td><td>.803</td></tr><tr><th><p>FreeSOLO Wang et al. [2022a]</p></th><td>.909</td><td>.560</td><td>.684</td><td>.924</td><td>.613</td><td>.750</td><td>.917</td><td>.703</td><td>.858</td></tr><tr><th>MOVE (Ours)</th><td>.923</td><td>.615</td><td>.712</td><td>.950</td><td>.713</td><td>.815</td><td>.954</td><td>.830</td><td>.916</td></tr><tr><th><p>LOST Sim\u00e9oni et al. [2021] + Bilateral</p></th><td>.818</td><td>.489</td><td>.578</td><td>.887</td><td>.572</td><td>.697</td><td>.916</td><td>.723</td><td>.837</td></tr><tr><th><p>TokenCut Wang et al. [2022b] + Bilateral</p></th><td>.897</td><td>.618</td><td>.697</td><td>.914</td><td>.624</td><td>.755</td><td>.934</td><td>.772</td><td>.874</td></tr><tr><th>MOVE (Ours) + Bilateral</th><td>.931</td><td>.636</td><td>.734</td><td>.951</td><td>.687</td><td>.821</td><td>.953</td><td>.801</td><td>.916</td></tr><tr><th><p>SelfMask on pseudo{}^{\\star}  Shin et al. [2022]</p></th><td>.923</td><td>.609</td><td>.733</td><td>.938</td><td>.648</td><td>.789</td><td>.943</td><td>.779</td><td>.894</td></tr><tr><th><p>SelfMask on pseudo{}^{\\star}  Shin et al. [2022] + Bilateral</p></th><td>.939</td><td>.677</td><td>.774</td><td>.949</td><td>.694</td><td>.819</td><td>.951</td><td>.803</td><td>.911</td></tr><tr><th>SelfMask on MOVE (Ours)</th><td>.933</td><td>.666</td><td>.756</td><td>.954</td><td>.728</td><td>.829</td><td>.956</td><td>.835</td><td>.921</td></tr><tr><th>SelfMask on MOVE (Ours) + Bilateral</th><td>.937</td><td>.665</td><td>.766</td><td>.952</td><td>.687</td><td>.827</td><td>.952</td><td>.800</td><td>.917</td></tr></tbody></table><p>{}^{\\star}We found that SelfMask\u2019s \\max F_{\\beta} metric was computed with an optimal threshold for each image instead of the entire dataset as in other methods; we re-evaluated their model for a fair comparison</p>", "caption": "Table 1:  Comparison to the unsupervised saliency detection methods on 3 benchmarks ", "list_citation_info": ["Nguyen et al. [2019] Tam Nguyen, M Dax, C Mummadi, N Ngo, Z Lou, and Thomas Brox. Deepusps: deep robust unsupervised saliency prediction via self-supervision. In Advances in Neural Information Processing Systems (NeurIPS), 2019.", "Melas-Kyriazi et al. [2021] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Finding an unsupervised image segmenter in each of your deep generative models. 2021.", "Zhu et al. [2014] W. Zhu, S. Liang, Y. Wei, and J. Sun. Saliency optimization from robust background detection. In 2014 IEEE Conference on Computer Vision and Pattern Recognition, pages 2814\u20132821, 2014.", "Wang et al. [2017] Lijun Wang, Huchuan Lu, Yifan Wang, Mengyang Feng, Dong Wang, Baocai Yin, and Xiang Ruan. Learning to detect salient objects with image-level supervision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 136\u2013145, 2017.", "Yang et al. [2013] Chuan Yang, Lihe Zhang, Huchuan Lu, Xiang Ruan, and Ming-Hsuan Yang. Saliency detection via graph-based manifold ranking. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 3166\u20133173. IEEE, 2013.", "Yan et al. [2013] Qiong Yan, Li Xu, Jianping Shi, and Jiaya Jia. Hierarchical saliency detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1155\u20131162, 2013.", "Li et al. [2015] Nianyi Li, Bilin Sun, and Jingyi Yu. A weighted sparse coding framework for saliency detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5216\u20135223, 2015.", "Wang et al. [2022a] Xinlong Wang, Zhiding Yu, Shalini De Mello, Jan Kautz, Anima Anandkumar, Chunhua Shen, and Jose M Alvarez. FreeSOLO: Learning to segment objects without annotations. arXiv preprint arXiv:2202.12181, 2022a.", "Sim\u00e9oni et al. [2021] Oriane Sim\u00e9oni, Gilles Puy, Huy V. Vo, Simon Roburin, Spyros Gidaris, Andrei Bursuc, Patrick P\u00e9rez, Renaud Marlet, and Jean Ponce. Localizing objects with self-supervised transformers and no labels. November 2021.", "Wang et al. [2022b] Yangtao Wang, Xi Shen, Shell Hu, Yuan Yuan, James Crowley, and Dominique Vaufreydaz. Self-supervised transformers for unsupervised object discovery using normalized cut. arXiv preprint arXiv:2202.11539, 2022b.", "Melas-Kyriazi et al. [2022] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Deep spectral methods: A surprisingly strong baseline for unsupervised semantic segmentation and localization. In CVPR, 2022.", "Shi et al. [2015] Jianping Shi, Qiong Yan, Li Xu, and Jiaya Jia. Hierarchical image saliency detection on extended cssd. IEEE transactions on pattern analysis and machine intelligence, 38(4):717\u2013729, 2015.", "Voynov et al. [2021] Andrey Voynov, Stanislav Morozov, and Artem Babenko. Object segmentation without labels with large-scale generative models. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 10596\u201310606. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/v139/voynov21a.html.", "Shin et al. [2022] Gyungin Shin, Samuel Albanie, and Weidi Wie. Unsupervised salient object detection with spectral cluster voting. 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), June 2022."]}, {"table": "<table><thead><tr><th>Method</th><th>IoU</th></tr></thead><tbody><tr><th>PerturbGAN Bielski and Favaro [2019]</th><td>0.360</td></tr><tr><th>ReDO Chen et al. [2019]</th><td>0.426</td></tr><tr><th>IEM Savarese et al. [2020]</th><td>0.551</td></tr><tr><th>Melas-Kyriazi Melas-Kyriazi et al. [2021]</th><td>0.664</td></tr><tr><th>Voynov Voynov et al. [2021]</th><td>0.683</td></tr><tr><th>Voynov-E Voynov et al. [2021]</th><td>0.710</td></tr><tr><th>Deep Spectral Melas-Kyriazi et al. [2022]</th><td>0.769</td></tr><tr><th>MOVE{}^{\\star}</th><td>0.814</td></tr><tr><th>MOVE</th><td>0.858</td></tr></tbody></table>", "caption": "Table 2: Comparison of unsupervised segmentation methods on the CUB-200-2011 test set. MOVE{}^{\\star} was trained on the CUB-200-2011 train set, while MOVE was trained on DUTS-TR", "list_citation_info": ["Melas-Kyriazi et al. [2021] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Finding an unsupervised image segmenter in each of your deep generative models. 2021.", "Bielski and Favaro [2019] Adam Bielski and Paolo Favaro. Emergence of object segmentation in perturbed generative models. In Advances in Neural Information Processing Systems, pages 7256\u20137266, 2019.", "Chen et al. [2019] Micka\u00ebl Chen, Thierry Arti\u00e8res, and Ludovic Denoyer. Unsupervised object segmentation by redrawing. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d\u2019Alch\u00e9 Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/32bbf7b2bc4ed14eb1e9c2580056a989-Paper.pdf.", "Melas-Kyriazi et al. [2022] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Deep spectral methods: A surprisingly strong baseline for unsupervised semantic segmentation and localization. In CVPR, 2022.", "Savarese et al. [2020] Pedro Savarese, Sunnie SY Kim, Michael Maire, Greg Shakhnarovich, and David McAllester. Information-theoretic segmentation by inpainting error maximization. arXiv preprint arXiv:2012.07287, 2020.", "Voynov et al. [2021] Andrey Voynov, Stanislav Morozov, and Artem Babenko. Object segmentation without labels with large-scale generative models. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 10596\u201310606. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/v139/voynov21a.html."]}, {"table": "<table><tbody><tr><th><p>Method</p></th><td>VOC07 Everingham et al. [a]</td><td>VOC12  Everingham et al. [b]</td><td>COCO20K Lin et al. [2014], Vo et al. [2020]</td></tr><tr><th><p>Selective Search Uijlings et al. [2013], Sim\u00e9oni et al. [2021]</p></th><td>18.8</td><td>20.9</td><td>16.0</td></tr><tr><th><p>EdgeBoxes Zitnick and Doll\u00e1r [2014], Sim\u00e9oni et al. [2021]</p></th><td>31.1</td><td>31.6</td><td>28.8</td></tr><tr><th><p>Kim et al. Kim and Torralba [2009], Sim\u00e9oni et al. [2021]</p></th><td>43.9</td><td>46.4</td><td>35.1</td></tr><tr><th><p>Zhange et al. Zhang et al. [2020], Sim\u00e9oni et al. [2021]</p></th><td>46.2</td><td>50.5</td><td>34.8</td></tr><tr><th><p>DDT+ Wei et al. [2019], Sim\u00e9oni et al. [2021]</p></th><td>50.2</td><td>53.1</td><td>38.2</td></tr><tr><th><p>rOSD Vo et al. [2020], Sim\u00e9oni et al. [2021]</p></th><td>54.5</td><td>55.3</td><td>48.5</td></tr><tr><th><p>LOD Vo et al. [2021], Sim\u00e9oni et al. [2021]</p></th><td>53.6</td><td>55.1</td><td>48.5</td></tr><tr><th><p>DINO-seg Caron et al. [2021], Sim\u00e9oni et al. [2021]</p></th><td>45.8</td><td>46.2</td><td>42.1</td></tr><tr><th><p>FreeSOLO Wang et al. [2022a]</p></th><td>56.1</td><td>56.7</td><td>52.8</td></tr><tr><th><p>LOST Sim\u00e9oni et al. [2021]</p></th><td>61.9</td><td>64.0</td><td>50.7</td></tr><tr><th><p>Deep Spectral Melas-Kyriazi et al. [2022]</p></th><td>62.7</td><td>66.4</td><td>52.2</td></tr><tr><th><p>TokenCut Wang et al. [2022b]</p></th><td>68.8</td><td>72.1</td><td>58.8</td></tr><tr><th>MOVE (Ours)</th><td>         76.0 (\\uparrow 7.2 )</td><td>         78.8 (\\uparrow 6.7 )</td><td>         66.6 (\\uparrow 7.8 )</td></tr><tr><th><p>LOD + CADSim\u00e9oni et al. [2021]</p></th><td>56.3</td><td>61.6</td><td>52.7</td></tr><tr><th><p>rOSD + CAD Sim\u00e9oni et al. [2021]</p></th><td>58.3</td><td>62.3</td><td>53.0</td></tr><tr><th><p>LOST + CAD Sim\u00e9oni et al. [2021]</p></th><td>65.7</td><td>70.4</td><td>57.5</td></tr><tr><th><p>TokenCut + CAD Wang et al. [2022b]</p></th><td>71.4</td><td>75.3</td><td>62.6</td></tr><tr><th>MOVE (Ours) + CAD</th><td>77.1</td><td>80.3</td><td>69.1</td></tr><tr><th>MOVE (Ours) Multi + CAD</th><td>         77.5 (\\uparrow 6.1)</td><td>         81.5 (\\uparrow 6.2)</td><td>         71.9 (\\uparrow 9.3)</td></tr></tbody></table>", "caption": "Table 3: Comparisons for unsupervised single object discovery. We compare MOVE to SotA object discovery methods on VOC07 Everingham et al. [a], VOC12  Everingham et al. [b] and COCO20K Lin et al. [2014], Vo et al. [2020] datasets. Models are evaluated with the CorLoc metric. +CAD indicates training a second stage class-agnostic detector with unsupervised \u201cpseudo-boxes\u201d labels. (\\uparrow\\mathbf{z}) indicates an improvement of z over prior sota", "list_citation_info": ["Lin et al. [2014] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Doll\u00e1r. Microsoft coco: Common objects in context, 2014. URL http://arxiv.org/abs/1405.0312.", "Everingham et al. [a] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results. http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html, a.", "Vo et al. [2021] Van Huy Vo, Elena Sizikova, Cordelia Schmid, Patrick P\u00e9rez, and Jean Ponce. Large-scale unsupervised object discovery. Advances in Neural Information Processing Systems, 34, 2021.", "Zitnick and Doll\u00e1r [2014] C. Lawrence Zitnick and Piotr Doll\u00e1r. Edge boxes: Locating object proposals from edges. In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors, Computer Vision \u2013 ECCV 2014, pages 391\u2013405, Cham, 2014. Springer International Publishing. ISBN 978-3-319-10602-1.", "Wei et al. [2019] Xiu-Shen Wei, Chen-Lin Zhang, Jianxin Wu, Chunhua Shen, and Zhi-Hua Zhou. Unsupervised object discovery and co-localization by deep descriptor transformation. Pattern Recognition, 88:113\u2013126, 2019.", "Vo et al. [2020] Huy V Vo, Patrick P\u00e9rez, and Jean Ponce. Toward unsupervised, multi-object discovery in large-scale image collections. In European Conference on Computer Vision, pages 779\u2013795. Springer, 2020.", "Caron et al. [2021] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging properties in self-supervised vision transformers. In Proceedings of the International Conference on Computer Vision (ICCV), 2021.", "Zhang et al. [2020] Runsheng Zhang, Yaping Huang, Mengyang Pu, Jian Zhang, Qingji Guan, Qi Zou, and Haibin Ling. Object discovery from a single unlabeled image by mining frequent itemsets with multi-scale features. IEEE Transactions on Image Processing, 29:8606\u20138621, 2020.", "Wang et al. [2022a] Xinlong Wang, Zhiding Yu, Shalini De Mello, Jan Kautz, Anima Anandkumar, Chunhua Shen, and Jose M Alvarez. FreeSOLO: Learning to segment objects without annotations. arXiv preprint arXiv:2202.12181, 2022a.", "Kim and Torralba [2009] Gunhee Kim and Antonio Torralba. Unsupervised detection of regions of interest using iterative link analysis. Advances in neural information processing systems, 22, 2009.", "Sim\u00e9oni et al. [2021] Oriane Sim\u00e9oni, Gilles Puy, Huy V. Vo, Simon Roburin, Spyros Gidaris, Andrei Bursuc, Patrick P\u00e9rez, Renaud Marlet, and Jean Ponce. Localizing objects with self-supervised transformers and no labels. November 2021.", "Melas-Kyriazi et al. [2022] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Deep spectral methods: A surprisingly strong baseline for unsupervised semantic segmentation and localization. In CVPR, 2022.", "Everingham et al. [b] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results. http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html, b.", "Wang et al. [2022b] Yangtao Wang, Xi Shen, Shell Hu, Yuan Yuan, James Crowley, and Dominique Vaufreydaz. Self-supervised transformers for unsupervised object discovery using normalized cut. arXiv preprint arXiv:2202.11539, 2022b.", "Uijlings et al. [2013] Jasper RR Uijlings, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154\u2013171, 2013."]}, {"table": "<table><thead><tr><th>Method</th><th>AP{}_{\\text{50}}</th><th>AP{}_{\\text{75}}</th><th>AP</th><th>AR{}_{\\text{1}}</th><th>AR{}_{\\text{10}}</th><th>AR{}_{\\text{100}}</th></tr></thead><tbody><tr><th>Sel. Search Uijlings et al. [2013]</th><td>0.5</td><td>0.1</td><td>0.2</td><td>0.2</td><td>1.5</td><td>10.9</td></tr><tr><th>DETReg Bar et al. [2021]</th><td>3.1</td><td>0.6</td><td>1.0</td><td>0.6</td><td>3.6</td><td>12.7</td></tr><tr><th>FreeSOLO Wang et al. [2022a]</th><td>12.2</td><td>4.2</td><td>5.5</td><td>4.6</td><td>11.4</td><td>15.3</td></tr><tr><th>MOVE (Ours)</th><td>19.0</td><td>6.5</td><td>8.2</td><td>5.7</td><td>13.6</td><td>15.9</td></tr></tbody></table>", "caption": "Table 4: Unsupervised class-agnostic object detection on MS COCO val2017. Compared results are taken directly from FreeSOLO Wang et al. [2022a]", "list_citation_info": ["Bar et al. [2021] Amir Bar, Xin Wang, Vadim Kantorov, Colorado J Reed, Roei Herzig, Gal Chechik, Anna Rohrbach, Trevor Darrell, and Amir Globerson. Detreg: Unsupervised pretraining with region priors for object detection, 2021.", "Uijlings et al. [2013] Jasper RR Uijlings, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154\u2013171, 2013.", "Wang et al. [2022a] Xinlong Wang, Zhiding Yu, Shalini De Mello, Jan Kautz, Anima Anandkumar, Chunhua Shen, and Jose M Alvarez. FreeSOLO: Learning to segment objects without annotations. arXiv preprint arXiv:2202.12181, 2022a."]}], "citation_info_to_title": {"Zhang et al. [2020] Runsheng Zhang, Yaping Huang, Mengyang Pu, Jian Zhang, Qingji Guan, Qi Zou, and Haibin Ling. Object discovery from a single unlabeled image by mining frequent itemsets with multi-scale features. IEEE Transactions on Image Processing, 29:8606\u20138621, 2020.": "Object Discovery from a Single Unlabeled Image by Mining Frequent Itemsets with Multi-Scale Features", "Chen et al. [2019] Micka\u00ebl Chen, Thierry Arti\u00e8res, and Ludovic Denoyer. Unsupervised object segmentation by redrawing. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d\u2019Alch\u00e9 Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/32bbf7b2bc4ed14eb1e9c2580056a989-Paper.pdf.": "Unsupervised Object Segmentation by Redrawing", "Kim and Torralba [2009] Gunhee Kim and Antonio Torralba. Unsupervised detection of regions of interest using iterative link analysis. Advances in neural information processing systems, 22, 2009.": "Unsupervised Detection of Regions of Interest Using Iterative Link Analysis", "Nguyen et al. [2019] Tam Nguyen, M Dax, C Mummadi, N Ngo, Z Lou, and Thomas Brox. Deepusps: deep robust unsupervised saliency prediction via self-supervision. In Advances in Neural Information Processing Systems (NeurIPS), 2019.": "Deep Robust Unsupervised Saliency Prediction via Self-Supervision", "Everingham et al. [a] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results. http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html, a.": "The PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results", "Li et al. [2015] Nianyi Li, Bilin Sun, and Jingyi Yu. A weighted sparse coding framework for saliency detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5216\u20135223, 2015.": "A weighted sparse coding framework for saliency detection", "Voynov et al. [2021] Andrey Voynov, Stanislav Morozov, and Artem Babenko. Object segmentation without labels with large-scale generative models. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 10596\u201310606. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/v139/voynov21a.html.": "Object Segmentation Without Labels with Large-Scale Generative Models", "Zhu et al. [2014] W. Zhu, S. Liang, Y. Wei, and J. Sun. Saliency optimization from robust background detection. In 2014 IEEE Conference on Computer Vision and Pattern Recognition, pages 2814\u20132821, 2014.": "Saliency optimization from robust background detection", "Bar et al. [2021] Amir Bar, Xin Wang, Vadim Kantorov, Colorado J Reed, Roei Herzig, Gal Chechik, Anna Rohrbach, Trevor Darrell, and Amir Globerson. Detreg: Unsupervised pretraining with region priors for object detection, 2021.": "Detreg: Unsupervised pretraining with region priors for object detection", "Wang et al. [2022b] Yangtao Wang, Xi Shen, Shell Hu, Yuan Yuan, James Crowley, and Dominique Vaufreydaz. Self-supervised transformers for unsupervised object discovery using normalized cut. arXiv preprint arXiv:2202.11539, 2022b.": "Self-supervised transformers for unsupervised object discovery using normalized cut", "Melas-Kyriazi et al. [2022] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Deep spectral methods: A surprisingly strong baseline for unsupervised semantic segmentation and localization. In CVPR, 2022.": "Deep spectral methods: A surprisingly strong baseline for unsupervised semantic segmentation and localization", "Melas-Kyriazi et al. [2021] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Finding an unsupervised image segmenter in each of your deep generative models. 2021.": "Finding an unsupervised image segmenter in each of your deep generative models", "Wang et al. [2022a] Xinlong Wang, Zhiding Yu, Shalini De Mello, Jan Kautz, Anima Anandkumar, Chunhua Shen, and Jose M Alvarez. FreeSOLO: Learning to segment objects without annotations. arXiv preprint arXiv:2202.12181, 2022a.": "FreeSOLO: Learning to segment objects without annotations", "Everingham et al. [b] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results. http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html, b.": "The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results", "Caron et al. [2021] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging properties in self-supervised vision transformers. In Proceedings of the International Conference on Computer Vision (ICCV), 2021.": "Emerging properties in self-supervised vision transformers", "Shin et al. [2022] Gyungin Shin, Samuel Albanie, and Weidi Wie. Unsupervised salient object detection with spectral cluster voting. 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), June 2022.": "Unsupervised salient object detection with spectral cluster voting", "Yang et al. [2013] Chuan Yang, Lihe Zhang, Huchuan Lu, Xiang Ruan, and Ming-Hsuan Yang. Saliency detection via graph-based manifold ranking. In Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pages 3166\u20133173. IEEE, 2013.": "Saliency detection via graph-based manifold ranking", "Wei et al. [2019] Xiu-Shen Wei, Chen-Lin Zhang, Jianxin Wu, Chunhua Shen, and Zhi-Hua Zhou. Unsupervised object discovery and co-localization by deep descriptor transformation. Pattern Recognition, 88:113\u2013126, 2019.": "Unsupervised Object Discovery and Co-Localization by Deep Descriptor Transformation", "Wang et al. [2017] Lijun Wang, Huchuan Lu, Yifan Wang, Mengyang Feng, Dong Wang, Baocai Yin, and Xiang Ruan. Learning to detect salient objects with image-level supervision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 136\u2013145, 2017.": "Learning to detect salient objects with image-level supervision", "Zitnick and Doll\u00e1r [2014] C. Lawrence Zitnick and Piotr Doll\u00e1r. Edge boxes: Locating object proposals from edges. In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, editors, Computer Vision \u2013 ECCV 2014, pages 391\u2013405, Cham, 2014. Springer International Publishing. ISBN 978-3-319-10602-1.": "Edge boxes: Locating object proposals from edges", "Uijlings et al. [2013] Jasper RR Uijlings, Koen EA Van De Sande, Theo Gevers, and Arnold WM Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154\u2013171, 2013.": "Selective Search for Object Recognition", "Bielski and Favaro [2019] Adam Bielski and Paolo Favaro. Emergence of object segmentation in perturbed generative models. In Advances in Neural Information Processing Systems, pages 7256\u20137266, 2019.": "Emergence of object segmentation in perturbed generative models", "Lin et al. [2014] Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Doll\u00e1r. Microsoft coco: Common objects in context, 2014. URL http://arxiv.org/abs/1405.0312.": "Microsoft coco: Common objects in context", "Vo et al. [2020] Huy V Vo, Patrick P\u00e9rez, and Jean Ponce. Toward unsupervised, multi-object discovery in large-scale image collections. In European Conference on Computer Vision, pages 779\u2013795. Springer, 2020.": "Toward unsupervised, multi-object discovery in large-scale image collections", "Sim\u00e9oni et al. [2021] Oriane Sim\u00e9oni, Gilles Puy, Huy V. Vo, Simon Roburin, Spyros Gidaris, Andrei Bursuc, Patrick P\u00e9rez, Renaud Marlet, and Jean Ponce. Localizing objects with self-supervised transformers and no labels. November 2021.": "Localizing objects with self-supervised transformers and no labels", "Shi et al. [2015] Jianping Shi, Qiong Yan, Li Xu, and Jiaya Jia. Hierarchical image saliency detection on extended cssd. IEEE transactions on pattern analysis and machine intelligence, 38(4):717\u2013729, 2015.": "Hierarchical Image Saliency Detection on Extended CSSD", "Vo et al. [2021] Van Huy Vo, Elena Sizikova, Cordelia Schmid, Patrick P\u00e9rez, and Jean Ponce. Large-scale unsupervised object discovery. Advances in Neural Information Processing Systems, 34, 2021.": "Large-scale unsupervised object discovery", "Yan et al. [2013] Qiong Yan, Li Xu, Jianping Shi, and Jiaya Jia. Hierarchical saliency detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1155\u20131162, 2013.": "Hierarchical Saliency Detection", "Savarese et al. [2020] Pedro Savarese, Sunnie SY Kim, Michael Maire, Greg Shakhnarovich, and David McAllester. Information-theoretic segmentation by inpainting error maximization. arXiv preprint arXiv:2012.07287, 2020.": "Information-theoretic segmentation by inpainting error maximization"}, "source_title_to_arxiv_id": {"Detreg: Unsupervised pretraining with region priors for object detection": "2106.04550", "Emerging properties in self-supervised vision transformers": "2104.14294", "Hierarchical Saliency Detection": "1408.5418"}}