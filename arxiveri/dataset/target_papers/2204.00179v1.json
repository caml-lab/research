{"title": "GraftNet: Towards Domain Generalized Stereo Matching with a Broad-Spectrum and Task-Oriented Feature", "abstract": "Although supervised deep stereo matching networks have made impressive\nachievements, the poor generalization ability caused by the domain gap prevents\nthem from being applied to real-life scenarios. In this paper, we propose to\nleverage the feature of a model trained on large-scale datasets to deal with\nthe domain shift since it has seen various styles of images. With the cosine\nsimilarity based cost volume as a bridge, the feature will be grafted to an\nordinary cost aggregation module. Despite the broad-spectrum representation,\nsuch a low-level feature contains much general information which is not aimed\nat stereo matching. To recover more task-specific information, the grafted\nfeature is further input into a shallow network to be transformed before\ncalculating the cost. Extensive experiments show that the model generalization\nability can be improved significantly with this broad-spectrum and\ntask-oriented feature. Specifically, based on two well-known architectures\nPSMNet and GANet, our methods are superior to other robust algorithms when\ntransferring from SceneFlow to KITTI 2015, KITTI 2012, and Middlebury. Code is\navailable at https://github.com/SpadeLiu/Graft-PSMNet.", "authors": ["Biyang Liu", "Huimin Yu", "Guodong Qi"], "published_date": "2022_04_01", "pdf_url": "http://arxiv.org/pdf/2204.00179v1", "list_table_and_caption": [{"table": "<table><tr><td rowspan=\"2\">    Model</td><td>KT-15</td><td>KT-12</td><td>MB</td><td>ET</td></tr><tr><td>&gt;3px</td><td>&gt;3px</td><td>&gt;2px</td><td>&gt;1px</td></tr><tr><td>GwcNet [10] </td><td>22.7%</td><td>20.2%</td><td>37.9%</td><td>54.2%</td></tr><tr><td>PSMNet [3] </td><td>16.3%</td><td>15.1%</td><td>34.2%</td><td>23.8%</td></tr><tr><td>GANet [44] </td><td>11.7%</td><td>10.1%</td><td>20.3%</td><td>14.1%</td></tr><tr><td>MS-PSMNet [2] </td><td>7.8%</td><td>14.0%</td><td>19.8%</td><td>16.8%</td></tr><tr><td>MS-GCNet [2] </td><td>6.2%</td><td>5.5%</td><td>18.5%</td><td>8.8%</td></tr><tr><td>DSMNet [45] </td><td>6.5%</td><td>6.2%</td><td>13.8%</td><td>6.2%</td></tr><tr><td>Graft-PSMNet </td><td>5.3%</td><td>5.0%</td><td>10.9%</td><td>10.7%</td></tr><tr><td>Graft-GANet </td><td>5.4%</td><td>4.6%</td><td>8.9%</td><td>6.2%</td></tr><tr><td>CFNet* [29] </td><td>6.0%</td><td>5.1%</td><td>15.4%</td><td>5.3%</td></tr><tr><td>RAFT-Stereo* [17] </td><td>5.7%</td><td>-</td><td>12.6%</td><td>3.3%</td></tr><tr><td>SGM+NDR [1] </td><td>5.5%</td><td>6.0%</td><td>12.4%</td><td>4.8%</td></tr><tr><td>Graft-PSMNet* </td><td>4.8%</td><td>4.3%</td><td>9.7%</td><td>7.7%</td></tr><tr><td>Graft-GANet* </td><td>4.9%</td><td>4.2%</td><td>9.8%</td><td>6.2%</td></tr></table>", "caption": "Table 5: Comparison of robust and domain generalized stereo matching methods, ours are listed at the bottom of the two subtables. * means the color jitter data augmentation strategy is leveraged during training. KT-15: KITTI 2015, KT-12: KITTI 2012, MB: Middlebury, ET: ETH3D. The best result is shown in bold and the second result is underlined.", "list_citation_info": ["[10] Xiaoyang Guo, Kai Yang, Wukui Yang, Xiaogang Wang, and Hongsheng Li. Group-wise correlation stereo network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3273\u20133282, 2019.", "[45] Feihu Zhang, Xiaojuan Qi, Ruigang Yang, Victor Prisacariu, Benjamin Wah, and Philip Torr. Domain-invariant stereo matching networks. In European Conference on Computer Vision, pages 420\u2013439. Springer, 2020.", "[2] Changjiang Cai, Matteo Poggi, Stefano Mattoccia, and Philippos Mordohai. Matching-space stereo networks for cross-domain generalization. In 2020 International Conference on 3D Vision (3DV), pages 364\u2013373. IEEE, 2020.", "[44] Feihu Zhang, Victor Prisacariu, Ruigang Yang, and Philip HS Torr. Ga-net: Guided aggregation net for end-to-end stereo matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 185\u2013194, 2019.", "[1] Filippo Aleotti, Fabio Tosi, Pierluigi Zama Ramirez, Matteo Poggi, Samuele Salti, Stefano Mattoccia, and Luigi Di Stefano. Neural disparity refinement for arbitrary resolution stereo. arXiv preprint arXiv:2110.15367, 2021.", "[29] Zhelun Shen, Yuchao Dai, and Zhibo Rao. Cfnet: Cascade and fused cost volume for robust stereo matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13906\u201313915, 2021.", "[3] Jia-Ren Chang and Yong-Sheng Chen. Pyramid stereo matching network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5410\u20135418, 2018.", "[17] Lahav Lipson, Zachary Teed, and Jia Deng. Raft-stereo: Multilevel recurrent field transforms for stereo matching. arXiv preprint arXiv:2109.07547, 2021."]}], "citation_info_to_title": {"[1] Filippo Aleotti, Fabio Tosi, Pierluigi Zama Ramirez, Matteo Poggi, Samuele Salti, Stefano Mattoccia, and Luigi Di Stefano. Neural disparity refinement for arbitrary resolution stereo. arXiv preprint arXiv:2110.15367, 2021.": "Neural disparity refinement for arbitrary resolution stereo", "[45] Feihu Zhang, Xiaojuan Qi, Ruigang Yang, Victor Prisacariu, Benjamin Wah, and Philip Torr. Domain-invariant stereo matching networks. In European Conference on Computer Vision, pages 420\u2013439. Springer, 2020.": "Domain-invariant stereo matching networks", "[29] Zhelun Shen, Yuchao Dai, and Zhibo Rao. Cfnet: Cascade and fused cost volume for robust stereo matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13906\u201313915, 2021.": "Cfnet: Cascade and fused cost volume for robust stereo matching", "[44] Feihu Zhang, Victor Prisacariu, Ruigang Yang, and Philip HS Torr. Ga-net: Guided aggregation net for end-to-end stereo matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 185\u2013194, 2019.": "Ga-net: Guided aggregation net for end-to-end stereo matching", "[2] Changjiang Cai, Matteo Poggi, Stefano Mattoccia, and Philippos Mordohai. Matching-space stereo networks for cross-domain generalization. In 2020 International Conference on 3D Vision (3DV), pages 364\u2013373. IEEE, 2020.": "Matching-space stereo networks for cross-domain generalization", "[10] Xiaoyang Guo, Kai Yang, Wukui Yang, Xiaogang Wang, and Hongsheng Li. Group-wise correlation stereo network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3273\u20133282, 2019.": "Group-wise correlation stereo network", "[3] Jia-Ren Chang and Yong-Sheng Chen. Pyramid stereo matching network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5410\u20135418, 2018.": "Pyramid stereo matching network", "[17] Lahav Lipson, Zachary Teed, and Jia Deng. Raft-stereo: Multilevel recurrent field transforms for stereo matching. arXiv preprint arXiv:2109.07547, 2021.": "Raft-stereo: Multilevel recurrent field transforms for stereo matching"}, "source_title_to_arxiv_id": {"Group-wise correlation stereo network": "1903.04025"}}