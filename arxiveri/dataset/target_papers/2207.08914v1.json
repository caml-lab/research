{"title": "Conditional DETR V2: Efficient Detection Transformer with Box Queries", "abstract": "In this paper, we are interested in Detection Transformer (DETR), an\nend-to-end object detection approach based on a transformer encoder-decoder\narchitecture without hand-crafted postprocessing, such as NMS. Inspired by\nConditional DETR, an improved DETR with fast training convergence, that\npresented box queries (originally called spatial queries) for internal decoder\nlayers, we reformulate the object query into the format of the box query that\nis a composition of the embeddings of the reference point and the\ntransformation of the box with respect to the reference point. This\nreformulation indicates the connection between the object query in DETR and the\nanchor box that is widely studied in Faster R-CNN. Furthermore, we learn the\nbox queries from the image content, further improving the detection quality of\nConditional DETR still with fast training convergence. In addition, we adopt\nthe idea of axial self-attention to save the memory cost and accelerate the\nencoder. The resulting detector, called Conditional DETR V2, achieves better\nresults than Conditional DETR, saves the memory cost and runs more efficiently.\nFor example, for the DC$5$-ResNet-$50$ backbone, our approach achieves $44.8$\nAP with $16.4$ FPS on the COCO $val$ set and compared to Conditional DETR, it\nruns $1.6\\times$ faster, saves $74$\\% of the overall memory cost, and improves\n$1.0$ AP score.", "authors": ["Xiaokang Chen", "Fangyun Wei", "Gang Zeng", "Jingdong Wang"], "published_date": "2022_07_18", "pdf_url": "http://arxiv.org/pdf/2207.08914v1", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Model</td><td>#epochs</td><td>GFLOPs</td><td>#params</td><td>AP</td><td>AP{}_{50}</td><td>AP{}_{75}</td><td>AP{}_{S}</td><td>AP{}_{M}</td><td>AP{}_{L}</td></tr><tr><td>DETR-R50 [4]</td><td>500</td><td>86</td><td>41M</td><td>42.0</td><td>62.4</td><td>44.2</td><td>20.5</td><td>45.8</td><td>61.1</td></tr><tr><td>DETR-R50 [4]</td><td>50</td><td>86</td><td>41M</td><td>34.9</td><td>55.5</td><td>36.0</td><td>14.4</td><td>37.2</td><td>54.5</td></tr><tr><td>PNP-DETR-R50 [41]</td><td>500</td><td>82</td><td>41M</td><td>41.8</td><td>62.1</td><td>44.4</td><td>21.2</td><td>45.3</td><td>60.8</td></tr><tr><td>Deformable DETR-R50 [48]</td><td>50</td><td>78</td><td>34M</td><td>39.4</td><td>59.6</td><td>42.3</td><td>20.6</td><td>42.9</td><td>55.5</td></tr><tr><td>UP-DETR-R50 [11]</td><td>150</td><td>86</td><td>41M</td><td>40.5</td><td>60.8</td><td>42.6</td><td>19.0</td><td>44.4</td><td>60.0</td></tr><tr><td>Anchor DETR-R50 [42]</td><td>50</td><td>94</td><td>37M</td><td>42.1</td><td>63.1</td><td>44.9</td><td>22.3</td><td>46.2</td><td>60.0</td></tr><tr><td>Conditional DETR-R50 [25]</td><td>50</td><td>90</td><td>44M</td><td>40.9</td><td>61.8</td><td>43.3</td><td>20.8</td><td>44.6</td><td>59.2</td></tr><tr><td>Conditional DETR V2-R50</td><td>50</td><td>89</td><td>46M</td><td>42.5</td><td>63.4</td><td>44.9</td><td>22.5</td><td>45.9</td><td>61.4</td></tr><tr><td>DETR-DC5-R50 [4]</td><td>500</td><td>187</td><td>41M</td><td>43.3</td><td>63.1</td><td>45.9</td><td>22.5</td><td>47.3</td><td>61.1</td></tr><tr><td>DETR-DC5-R50 [4]</td><td>50</td><td>187</td><td>41M</td><td>36.7</td><td>57.6</td><td>38.2</td><td>15.4</td><td>39.8</td><td>56.3</td></tr><tr><td>Faster RCNN-FPN-R50{}^{*} [31]</td><td>108</td><td>180</td><td>42M</td><td>42.0</td><td>62.1</td><td>45.5</td><td>26.6</td><td>45.5</td><td>53.4</td></tr><tr><td>TSP-RCNN-R50{}^{*} [34]</td><td>36</td><td>188</td><td>-</td><td>43.8</td><td>63.3</td><td>48.3</td><td>28.6</td><td>46.9</td><td>55.7</td></tr><tr><td>SMCA-R50{}^{*} [13]</td><td>50</td><td>152</td><td>40M</td><td>43.7</td><td>63.6</td><td>47.2</td><td>24.2</td><td>47.0</td><td>60.4</td></tr><tr><td>PNP-DETR-DC5-R50 [41]</td><td>500</td><td>144</td><td>41M</td><td>43.1</td><td>63.4</td><td>45.3</td><td>22.7</td><td>46.5</td><td>61.1</td></tr><tr><td>Deformable DETR-DC5-R50 [48]</td><td>50</td><td>128</td><td>34M</td><td>41.5</td><td>61.8</td><td>44.9</td><td>24.1</td><td>45.3</td><td>56.0</td></tr><tr><td>Two-Stage Deformable DETR-DC5-R50 [48]</td><td>50</td><td>128</td><td>34M</td><td>43.6</td><td>63.6</td><td>47.0</td><td>25.8</td><td>46.6</td><td>58.1</td></tr><tr><td>Anchor DETR-DC5-R50 [42]</td><td>50</td><td>173</td><td>37M</td><td>44.2</td><td>64.7</td><td>47.5</td><td>24.7</td><td>48.2</td><td>60.6</td></tr><tr><td>Conditional DETR-DC5-R50[25]</td><td>50</td><td>195</td><td>44M</td><td>43.8</td><td>64.4</td><td>46.7</td><td>24.0</td><td>47.6</td><td>60.7</td></tr><tr><td>Conditional DETR V2-DC5-R50</td><td>50</td><td>161</td><td>46M</td><td>44.8</td><td>65.3</td><td>48.2</td><td>25.5</td><td>48.6</td><td>62.0</td></tr><tr><td>Conditional DETR V2-DC5-R50{}^{+}</td><td>50</td><td>181</td><td>46M</td><td>45.2</td><td>66.0</td><td>48.4</td><td>26.5</td><td>49.0</td><td>62.1</td></tr><tr><td>DETR-R101 [4]</td><td>500</td><td>152</td><td>60M</td><td>43.5</td><td>63.8</td><td>46.4</td><td>21.9</td><td>48.0</td><td>61.8</td></tr><tr><td>DETR-R101 [4]</td><td>50</td><td>152</td><td>60M</td><td>36.9</td><td>57.8</td><td>38.6</td><td>15.5</td><td>40.6</td><td>55.6</td></tr><tr><td>Anchor DETR-R101 [42]</td><td>50</td><td>160</td><td>56M</td><td>43.5</td><td>64.3</td><td>46.6</td><td>23.2</td><td>47.7</td><td>61.4</td></tr><tr><td>Conditional DETR-R101 [25]</td><td>50</td><td>156</td><td>63M</td><td>42.8</td><td>63.7</td><td>46.0</td><td>21.7</td><td>46.6</td><td>60.9</td></tr><tr><td>Conditional DETR V2-R101</td><td>50</td><td>155</td><td>65M</td><td>43.9</td><td>65.3</td><td>46.7</td><td>25.2</td><td>48.0</td><td>62.6</td></tr><tr><td>DETR-DC5-R101 [4]</td><td>500</td><td>253</td><td>60M</td><td>{44.9}</td><td>{64.7}</td><td>47.7</td><td>23.7</td><td>{49.5}</td><td>{62.3}</td></tr><tr><td>DETR-DC5-R101 [4]</td><td>50</td><td>253</td><td>60M</td><td>38.6</td><td>59.7</td><td>40.7</td><td>17.2</td><td>42.2</td><td>57.4</td></tr><tr><td>Faster RCNN-FPN-R101{}^{*} [31]</td><td>108</td><td>246</td><td>60M</td><td>44.0</td><td>63.9</td><td>47.8</td><td>27.2</td><td>48.1</td><td>56.0</td></tr><tr><td>TSP-RCNN-R101{}^{*} [34]</td><td>36</td><td>254</td><td>-</td><td>44.8</td><td>63.8</td><td>49.2</td><td>29.0</td><td>47.9</td><td>57.1</td></tr><tr><td>SMCA-R101{}^{*} [13]</td><td>50</td><td>218</td><td>58M</td><td>44.4</td><td>65.2</td><td>48.0</td><td>24.3</td><td>48.5</td><td>61.0</td></tr><tr><td>Anchor DETR-DC5-R101 [42]</td><td>50</td><td>239</td><td>56M</td><td>45.1</td><td>65.7</td><td>48.8</td><td>25.8</td><td>49.4</td><td>61.6</td></tr><tr><td>Conditional DETR-DC5-R101[25]</td><td>50</td><td>262</td><td>63M</td><td>45.0</td><td>65.5</td><td>48.4</td><td>26.1</td><td>48.9</td><td>62.8</td></tr><tr><td>Conditional DETR V2-DC5-R101</td><td>50</td><td>228</td><td>65M</td><td>45.5</td><td>66.0</td><td>48.7</td><td>26.3</td><td>49.0</td><td>62.9</td></tr><tr><td>Conditional DETR V2-DC5-R101{}^{+}</td><td>50</td><td>247</td><td>65M</td><td>45.9</td><td>66.6</td><td>49.6</td><td>27.4</td><td>49.9</td><td>62.6</td></tr><tr><td>Conditional DETR-HR48 [25]</td><td>50</td><td>1090</td><td>87M</td><td>48.2</td><td>68.2</td><td>52.4</td><td>30.6</td><td>52.3</td><td>64.3</td></tr><tr><td>Conditional DETR V2-HR48</td><td>50</td><td>521</td><td>90M</td><td>49.8</td><td>70.2</td><td>54.2</td><td>32.1</td><td>53.3</td><td>65.9</td></tr></tbody></table>", "caption": "Table 1: Comparison of Conditional DETR V2 with other detection models on COCO 2017 val.{}^{*} means these methods use multi-scale feature.{}^{+} means we use 900 box queries.", "list_citation_info": ["[41] Wang, T., Yuan, L., Chen, Y., Feng, J., Yan, S.: Pnp-detr: Towards efficient visual analysis with transformers. In: ICCV. pp. 4661\u20134670 (2021)", "[42] Wang, Y., Zhang, X., Yang, T., Sun, J.: Anchor detr: Query design for transformer-based detector. arXiv preprint arXiv:2109.07107 (2021)", "[31] Ren, S., He, K., Girshick, R.B., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. TPAMI (2017)", "[25] Meng, D., Chen, X., Fan, Z., Zeng, G., Li, H., Yuan, Y., Sun, L., Wang, J.: Conditional detr for fast training convergence. In: ICCV. pp. 3651\u20133660 (2021)", "[4] Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., Zagoruyko, S.: End-to-end object detection with transformers. In: ECCV (2020)", "[11] Dai, Z., Cai, B., Lin, Y., Chen, J.: UP-DETR: unsupervised pre-training for object detection with transformers. CoRR abs/2011.09094 (2020), https://arxiv.org/abs/2011.09094", "[48] Zhu, X., Su, W., Lu, L., Li, B., Wang, X., Dai, J.: Deformable DETR: deformable transformers for end-to-end object detection. CoRR abs/2010.04159 (2020), https://arxiv.org/abs/2010.04159", "[34] Sun, Z., Cao, S., Yang, Y., Kitani, K.: Rethinking transformer-based set prediction for object detection. CoRR abs/2011.10881 (2020), https://arxiv.org/abs/2011.10881", "[13] Gao, P., Zheng, M., Wang, X., Dai, J., Li, H.: Fast convergence of DETR with spatially modulated co-attention. CoRR abs/2101.07448 (2021), https://arxiv.org/abs/2101.07448"]}], "citation_info_to_title": {"[42] Wang, Y., Zhang, X., Yang, T., Sun, J.: Anchor detr: Query design for transformer-based detector. arXiv preprint arXiv:2109.07107 (2021)": "Anchor detr: Query design for transformer-based detector", "[48] Zhu, X., Su, W., Lu, L., Li, B., Wang, X., Dai, J.: Deformable DETR: deformable transformers for end-to-end object detection. CoRR abs/2010.04159 (2020), https://arxiv.org/abs/2010.04159": "Deformable DETR: deformable transformers for end-to-end object detection", "[31] Ren, S., He, K., Girshick, R.B., Sun, J.: Faster R-CNN: towards real-time object detection with region proposal networks. TPAMI (2017)": "Faster R-CNN: towards real-time object detection with region proposal networks", "[4] Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., Zagoruyko, S.: End-to-end object detection with transformers. In: ECCV (2020)": "End-to-end object detection with transformers", "[25] Meng, D., Chen, X., Fan, Z., Zeng, G., Li, H., Yuan, Y., Sun, L., Wang, J.: Conditional detr for fast training convergence. In: ICCV. pp. 3651\u20133660 (2021)": "Conditional DETR for Fast Training Convergence", "[11] Dai, Z., Cai, B., Lin, Y., Chen, J.: UP-DETR: unsupervised pre-training for object detection with transformers. CoRR abs/2011.09094 (2020), https://arxiv.org/abs/2011.09094": "UP-DETR: unsupervised pre-training for object detection with transformers", "[34] Sun, Z., Cao, S., Yang, Y., Kitani, K.: Rethinking transformer-based set prediction for object detection. CoRR abs/2011.10881 (2020), https://arxiv.org/abs/2011.10881": "Rethinking transformer-based set prediction for object detection", "[13] Gao, P., Zheng, M., Wang, X., Dai, J., Li, H.: Fast convergence of DETR with spatially modulated co-attention. CoRR abs/2101.07448 (2021), https://arxiv.org/abs/2101.07448": "Fast convergence of DETR with spatially modulated co-attention", "[41] Wang, T., Yuan, L., Chen, Y., Feng, J., Yan, S.: Pnp-detr: Towards efficient visual analysis with transformers. In: ICCV. pp. 4661\u20134670 (2021)": "Pnp-detr: Towards efficient visual analysis with transformers"}, "source_title_to_arxiv_id": {"Conditional DETR for Fast Training Convergence": "2108.06152", "Rethinking transformer-based set prediction for object detection": "2011.10881", "Fast convergence of DETR with spatially modulated co-attention": "2101.07448"}}