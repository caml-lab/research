{"title": "PEANUT: Predicting and Navigating to Unseen Targets", "abstract": "Efficient ObjectGoal navigation (ObjectNav) in novel environments requires an\nunderstanding of the spatial and semantic regularities in environment layouts.\nIn this work, we present a straightforward method for learning these\nregularities by predicting the locations of unobserved objects from incomplete\nsemantic maps. Our method differs from previous prediction-based navigation\nmethods, such as frontier potential prediction or egocentric map completion, by\ndirectly predicting unseen targets while leveraging the global context from all\npreviously explored areas. Our prediction model is lightweight and can be\ntrained in a supervised manner using a relatively small amount of passively\ncollected data. Once trained, the model can be incorporated into a modular\npipeline for ObjectNav without the need for any reinforcement learning. We\nvalidate the effectiveness of our method on the HM3D and MP3D ObjectNav\ndatasets. We find that it achieves the state-of-the-art on both datasets,\ndespite not using any additional data for training.", "authors": ["Albert J. Zhai", "Shenlong Wang"], "published_date": "2022_12_05", "pdf_url": "http://arxiv.org/pdf/2212.02497v1", "list_table_and_caption": [{"table": "<table><tbody><tr><th>Method</th><td>SPL (\\uparrow)</td><td>Success (\\uparrow)</td><td>Ext. Data</td></tr><tr><th>DD-PPO [37]</th><td>0.12</td><td>0.26</td><td>no</td></tr><tr><th>Habitat-Web [35]</th><td>0.22</td><td>0.55</td><td>yes</td></tr><tr><th>OVRL [39]</th><td>0.27</td><td>0.60</td><td>no</td></tr><tr><th>ProcTHOR [14]</th><td>0.32</td><td>0.54</td><td>yes</td></tr><tr><th>PEANUT (Ours)</th><td>0.33</td><td>0.64</td><td>no</td></tr><tr><th></th><td></td><td></td><td></td></tr></tbody></table>", "caption": "Table 1: ObjectNav results on HM3D (test-standard). The \u201cExt. Data\u201d column indicates whether the method uses non-HM3D data when training its navigation policy.", "list_citation_info": ["[37] Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa, Devi Parikh, Manolis Savva, and Dhruv Batra. Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion frames. arXiv preprint arXiv:1911.00357, 2019.", "[39] Karmesh Yadav, Ram Ramrakhya, Arjun Majumdar, Vincent-Pierre Berges, Sachit Kuhar, Dhruv Batra, Alexei Baevski, and Oleksandr Maksymets. Offline visual representation learning for embodied navigation. arXiv preprint arXiv:2204.13226, 2022.", "[35] Ram Ramrakhya, Eric Undersander, Dhruv Batra, and Abhishek Das. Habitat-web: Learning embodied object-search strategies from human demonstrations at scale. In CVPR, 2022.", "[14] Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador, Kiana Ehsani, Winson Han, Eric Kolve, Ali Farhadi, Aniruddha Kembhavi, et al. Procthor: Large-scale embodied ai using procedural generation. arXiv preprint arXiv:2206.06994, 2022."]}, {"table": "<table><tbody><tr><th>Method</th><td>SPL (\\uparrow)</td><td>Success (\\uparrow)</td><td>Ext. Data</td></tr><tr><th>DD-PPO [37]</th><td>0.018</td><td>0.080</td><td>no</td></tr><tr><th>Habitat-Web [35]</th><td>0.102</td><td>0.354</td><td>yes</td></tr><tr><th>OVRL [39]</th><td>0.074</td><td>0.286</td><td>no</td></tr><tr><th>Red-Rabbit [42]</th><td>0.079</td><td>0.346</td><td>no</td></tr><tr><th>TreasureHunt [29]</th><td>0.110</td><td>0.284</td><td>yes</td></tr><tr><th>ANS [9]</th><td>0.092</td><td>0.273</td><td>no</td></tr><tr><th>PONI [33]</th><td>0.121</td><td>0.227</td><td>no</td></tr><tr><th>Stubborn [28]</th><td>0.149</td><td>0.407</td><td>no</td></tr><tr><th>PEANUT (Ours)</th><td>0.158</td><td>0.405</td><td>no</td></tr><tr><th></th><td></td><td></td><td></td></tr></tbody></table>", "caption": "Table 2: ObjectNav results on MP3D (val). The \u201cExt. Data\u201d column indicates whether the method uses non-MP3D data when training its navigation policy.", "list_citation_info": ["[9] Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, and Ruslan Salakhutdinov. Learning to explore using active neural slam. In ICLR, 2019.", "[35] Ram Ramrakhya, Eric Undersander, Dhruv Batra, and Abhishek Das. Habitat-web: Learning embodied object-search strategies from human demonstrations at scale. In CVPR, 2022.", "[37] Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa, Devi Parikh, Manolis Savva, and Dhruv Batra. Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion frames. arXiv preprint arXiv:1911.00357, 2019.", "[39] Karmesh Yadav, Ram Ramrakhya, Arjun Majumdar, Vincent-Pierre Berges, Sachit Kuhar, Dhruv Batra, Alexei Baevski, and Oleksandr Maksymets. Offline visual representation learning for embodied navigation. arXiv preprint arXiv:2204.13226, 2022.", "[42] Joel Ye, Dhruv Batra, Abhishek Das, and Erik Wijmans. Auxiliary tasks and exploration enable objectgoal navigation. In ICCV, 2021.", "[33] Santhosh Kumar Ramakrishnan, Devendra Singh Chaplot, Ziad Al-Halah, Jitendra Malik, and Kristen Grauman. Poni: Potential functions for objectgoal navigation with interaction-free learning. In CVPR, 2022.", "[28] Haokuan Luo, Albert Yue, Zhang-Wei Hong, and Pulkit Agrawal. Stubborn: A strong baseline for indoor object navigation. arXiv preprint arXiv:2203.07359, 2022.", "[29] Oleksandr Maksymets, Vincent Cartillier, Aaron Gokaslan, Erik Wijmans, Wojciech Galuba, Stefan Lee, and Dhruv Batra. Thda: Treasure hunt data augmentation for semantic navigation. In ICCV, 2021."]}, {"table": "<table><tbody><tr><td><svg><g><g><path></path></g><g><foreignobject><img/></foreignobject></g><g><path></path></g><g><foreignobject>Target: table</foreignobject></g></g></svg></td><td><svg><g><g><path></path></g><g><foreignobject><img/></foreignobject></g></g></svg></td><td><svg><g><g><path></path></g><g><foreignobject><img/></foreignobject></g></g></svg></td></tr><tr><td><svg><g><g><path></path></g><g><foreignobject><img/></foreignobject></g><g><path></path></g><g><foreignobject>Target: cushion</foreignobject></g></g></svg></td><td><svg><g><g><path></path></g><g><foreignobject><img/></foreignobject></g></g></svg></td><td><svg><g><g><path></path></g><g><foreignobject><img/></foreignobject></g></g></svg></td></tr></tbody></table>", "caption": "Figure 5: Qualitative comparison with potential functions (PONI) [33]. We visualize predictions made by PEANUT on MP3D (val) and compare them with potential functions estimated by PONI. We observe that PEANUT tends to make cleaner, sharper predictions than PONI, which often assigns high potentials to frontiers that clearly cannot lead to any target object.", "list_citation_info": ["[33] Santhosh Kumar Ramakrishnan, Devendra Singh Chaplot, Ziad Al-Halah, Jitendra Malik, and Kristen Grauman. Poni: Potential functions for objectgoal navigation with interaction-free learning. In CVPR, 2022."]}], "citation_info_to_title": {"[28] Haokuan Luo, Albert Yue, Zhang-Wei Hong, and Pulkit Agrawal. Stubborn: A strong baseline for indoor object navigation. arXiv preprint arXiv:2203.07359, 2022.": "Stubborn: A strong baseline for indoor object navigation", "[39] Karmesh Yadav, Ram Ramrakhya, Arjun Majumdar, Vincent-Pierre Berges, Sachit Kuhar, Dhruv Batra, Alexei Baevski, and Oleksandr Maksymets. Offline visual representation learning for embodied navigation. arXiv preprint arXiv:2204.13226, 2022.": "Offline visual representation learning for embodied navigation", "[42] Joel Ye, Dhruv Batra, Abhishek Das, and Erik Wijmans. Auxiliary tasks and exploration enable objectgoal navigation. In ICCV, 2021.": "Auxiliary tasks and exploration enable object-goal navigation", "[33] Santhosh Kumar Ramakrishnan, Devendra Singh Chaplot, Ziad Al-Halah, Jitendra Malik, and Kristen Grauman. Poni: Potential functions for objectgoal navigation with interaction-free learning. In CVPR, 2022.": "Poni: Potential functions for object-goal navigation with interaction-free learning", "[9] Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, and Ruslan Salakhutdinov. Learning to explore using active neural slam. In ICLR, 2019.": "Learning to explore using active neural slam", "[29] Oleksandr Maksymets, Vincent Cartillier, Aaron Gokaslan, Erik Wijmans, Wojciech Galuba, Stefan Lee, and Dhruv Batra. Thda: Treasure hunt data augmentation for semantic navigation. In ICCV, 2021.": "Thda: Treasure hunt data augmentation for semantic navigation", "[14] Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador, Kiana Ehsani, Winson Han, Eric Kolve, Ali Farhadi, Aniruddha Kembhavi, et al. Procthor: Large-scale embodied ai using procedural generation. arXiv preprint arXiv:2206.06994, 2022.": "Procthor: Large-scale embodied ai using procedural generation", "[37] Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa, Devi Parikh, Manolis Savva, and Dhruv Batra. Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion frames. arXiv preprint arXiv:1911.00357, 2019.": "Dd-ppo: Learning near-perfect pointgoal navigators from 25 billion frames", "[35] Ram Ramrakhya, Eric Undersander, Dhruv Batra, and Abhishek Das. Habitat-web: Learning embodied object-search strategies from human demonstrations at scale. In CVPR, 2022.": "Habitat-web: Learning embodied object-search strategies from human demonstrations at scale"}, "source_title_to_arxiv_id": {"Stubborn: A strong baseline for indoor object navigation": "2203.07359", "Offline visual representation learning for embodied navigation": "2204.13226", "Habitat-web: Learning embodied object-search strategies from human demonstrations at scale": "2204.03514"}}