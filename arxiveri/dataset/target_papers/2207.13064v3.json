{"title": "Video Manipulations Beyond Faces: A Dataset with Human-Machine Analysis", "abstract": "As tools for content editing mature, and artificial intelligence (AI) based\nalgorithms for synthesizing media grow, the presence of manipulated content\nacross online media is increasing. This phenomenon causes the spread of\nmisinformation, creating a greater need to distinguish between ``real'' and\n``manipulated'' content. To this end, we present VideoSham, a dataset\nconsisting of 826 videos (413 real and 413 manipulated). Many of the existing\ndeepfake datasets focus exclusively on two types of facial manipulations --\nswapping with a different subject's face or altering the existing face.\nVideoSham, on the other hand, contains more diverse, context-rich, and\nhuman-centric, high-resolution videos manipulated using a combination of 6\ndifferent spatial and temporal attacks. Our analysis shows that\nstate-of-the-art manipulation detection algorithms only work for a few specific\nattacks and do not scale well on VideoSham. We performed a user study on Amazon\nMechanical Turk with 1200 participants to understand if they can differentiate\nbetween the real and manipulated videos in VideoSham. Finally, we dig deeper\ninto the strengths and weaknesses of performances by humans and SOTA-algorithms\nto identify gaps that need to be filled with better AI algorithms. We present\nthe dataset at https://github.com/adobe-research/VideoSham-dataset.", "authors": ["Trisha Mittal", "Ritwik Sinha", "Viswanathan Swaminathan", "John Collomosse", "Dinesh Manocha"], "published_date": "2022_07_26", "pdf_url": "http://arxiv.org/pdf/2207.13064v3", "list_table_and_caption": [{"table": "<table><tbody><tr><th></th><th>S.No.</th><td>Attack</td><td>Method/Software</td><td>Description</td></tr><tr><th rowspan=\"8\">Spatial</th><th rowspan=\"2\">1</th><td rowspan=\"2\">Copy-Move and Splicing</td><td rowspan=\"2\">Adobe Photoshop{}^{\\textbf{TM}}, AfterEffects{}^{\\textbf{TM}}</td><td>Select and copy region within same video and paste</td></tr><tr><td>this somewhere else within the same video or different video</td></tr><tr><th>2</th><td>Retouching/Lighting</td><td>Adobe Lightroom {}^{\\textbf{TM}}</td><td>Brightness increase/decrease, Contrast Increase/Decrease, Median Filter</td></tr><tr><th rowspan=\"2\">3</th><td rowspan=\"2\">Face Swapping (FS)</td><td>FakeApp, FaceSwap [29]</td><td rowspan=\"2\">Transferring a face from source to target image/video</td></tr><tr><td>FaceShifter [32], FSGAN [44], DeepFaceLab [46]</td></tr><tr><th rowspan=\"2\">4</th><td rowspan=\"2\">Face Re-enactment (FR)</td><td>Neural Textures [59], First-Order-Motion [55]</td><td>Using facial movements and expression deformations of</td></tr><tr><td>Face2Face [60], IcFace [61], FSGAN [44],</td><td>a face to guide the motions and deformations of another face</td></tr><tr><th>5</th><td>Audio-driven FR (AFR)</td><td>Wav2Lip [47], APB2FACE [71], ATFHP [70]</td><td>Reenacting faces driven by a given audio signal to sync with lip movement</td></tr><tr><th>Temporal</th><th>6</th><td>Temporal</td><td>Adobe Lightroom {}^{\\textbf{TM}}</td><td>Frame Dropping, Frame Insertion, Shifting in time, Frame Swapping</td></tr><tr><th>Geometric</th><th>7</th><td>Geometric</td><td>Adobe Lightroom {}^{\\textbf{TM}}</td><td>Cropping, Resizing, Rotation, Shifting</td></tr></tbody></table>", "caption": "Table 1: Attacks: We summarize the various attacks that have explored in prior literature for manipulating images and videos.", "list_citation_info": ["[44] Yuval Nirkin, Yosi Keller, and Tal Hassner. Fsgan: Subject agnostic face swapping and reenactment. In Proceedings of the IEEE/CVF international conference on computer vision, pages 7184\u20137193, 2019.", "[59] Justus Thies, Michael Zollh\u00f6fer, and Matthias Nie\u00dfner. Deferred neural rendering: Image synthesis using neural textures. ACM Transactions on Graphics (TOG), 38(4):1\u201312, 2019.", "[60] Justus Thies, Michael Zollhofer, Marc Stamminger, Christian Theobalt, and Matthias Nie\u00dfner. Face2face: Real-time face capture and reenactment of rgb videos. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2387\u20132395, 2016.", "[47] KR Prajwal, Rudrabha Mukhopadhyay, Vinay P Namboodiri, and CV Jawahar. A lip sync expert is all you need for speech to lip generation in the wild. In Proceedings of the 28th ACM International Conference on Multimedia, pages 484\u2013492, 2020.", "[71] Jiangning Zhang, Liang Liu, Zhucun Xue, and Yong Liu. Apb2face: audio-guided face reenactment with auxiliary pose and blink signals. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4402\u20134406. IEEE, 2020.", "[55] Aliaksandr Siarohin, St\u00e9phane Lathuili\u00e8re, Sergey Tulyakov, Elisa Ricci, and Nicu Sebe. First order motion model for image animation. Advances in Neural Information Processing Systems, 32:7137\u20137147, 2019.", "[46] Ivan Perov, Daiheng Gao, Nikolay Chervoniy, Kunlin Liu, Sugasa Marangonda, Chris Um\u00e9, Mr Dpfks, Carl Shift Facenheim, Luis RP, Jian Jiang, et al. Deepfacelab: A simple, flexible and extensible face swapping framework. arXiv preprint arXiv:2005.05535, 2020.", "[32] Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, and Fang Wen. Faceshifter: Towards high fidelity and occlusion aware face swapping. arXiv preprint arXiv:1912.13457, 2019.", "[61] Soumya Tripathy, Juho Kannala, and Esa Rahtu. Icface: Interpretable and controllable face reenactment using gans. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3385\u20133394, 2020.", "[29] Iryna Korshunova, Wenzhe Shi, Joni Dambre, and Lucas Theis. Fast face-swap using convolutional neural networks. In Proceedings of the IEEE international conference on computer vision, pages 3677\u20133685, 2017.", "[70] Ran Yi, Zipeng Ye, Juyong Zhang, Hujun Bao, and Yong-Jin Liu. Audio-driven talking face video generation with learning-based personalized head pose. arXiv preprint arXiv:2002.10137, 2020."]}, {"table": "<table><tbody><tr><td>Faces</td><td>Datasets</td><td>Release Date</td><td colspan=\"2\"># Videos</td><td colspan=\"2\">Source</td><td>Attacks</td><td>Human</td><td>Context</td><td colspan=\"2\">Modality</td></tr><tr><td></td><td></td><td></td><td>Real</td><td>Fake</td><td>Original</td><td>Manipulated</td><td></td><td>Density</td><td></td><td>Visual</td><td>Audio</td></tr><tr><td rowspan=\"12\">Only</td><td>UADFV [68]</td><td>Nov-18</td><td>49</td><td>49</td><td>YouTube</td><td>Deep Learning</td><td>3</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2717</td></tr><tr><td>DF-TIMIT [28]</td><td>Dec-18</td><td>640</td><td>320</td><td>VidTIMIT [54]</td><td>Deep Learning</td><td>3,4</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2713</td></tr><tr><td>FaceForensics++ [51]</td><td>Jan-19</td><td>1000</td><td>4000</td><td>YouTube</td><td>Deep Learning</td><td>3,4</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2717</td></tr><tr><td>DFD [1]</td><td>Sep-19</td><td>0</td><td>3000</td><td>YouTube</td><td>Deep Learning</td><td>3</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2717</td></tr><tr><td>CelebDF [34]</td><td>Nov-19</td><td>5907</td><td>5639</td><td>YouTube</td><td>Deep Learning</td><td>3</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2717</td></tr><tr><td>DFDC [13]</td><td>Oct-21</td><td>23654</td><td>104,500</td><td>Actors</td><td>Unknown</td><td>3</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2717</td></tr><tr><td>DeeperForensics 1.0 [22]</td><td>Jan-21</td><td>50,000</td><td>10,000</td><td>Actors</td><td>Deep Learning</td><td>3</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2717</td></tr><tr><td>WildDeepFake [74]</td><td>Jan-21</td><td>3,805</td><td>3,509</td><td>Internet</td><td>Internet</td><td>3,4,5</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2717</td></tr><tr><td>KoDF [31]</td><td>Aug-21</td><td>62,166</td><td>175,776</td><td>Actors</td><td>Deep Learning</td><td>3,4,5</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2713</td></tr><tr><td>FakeAVCeleb [23]</td><td>Sep-21</td><td>490+</td><td>20,000+</td><td>VoxCeleb2 [11]</td><td>Deep Learning</td><td>3,4</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2713</td></tr><tr><td>ForgeryNet [21]</td><td>July-21</td><td>91,630</td><td>121,617</td><td>Multiple</td><td>Deep Learning</td><td>3,4</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2713</td></tr><tr><td>SR-DF [62]</td><td>Apr-21</td><td>1,000</td><td>4,000</td><td>YouTube</td><td>Deep Learning</td><td>3,4</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2713</td></tr><tr><td></td><td>Khelifi et al. [24]</td><td>Jan-19</td><td>200</td><td>200</td><td>Multiple</td><td>User Generated</td><td>6,7</td><td>1</td><td>\u2717</td><td>\u2713</td><td>\u2717</td></tr><tr><td rowspan=\"4\">Beyond</td><td>MTVFD [4]</td><td>2016</td><td>30</td><td>30</td><td>YouTube</td><td>User Generated</td><td>1,2</td><td>\\leq 1</td><td>\u2713</td><td>\u2717</td><td>\u2717</td></tr><tr><td>Liao et al [35]</td><td>2013</td><td>10</td><td>8</td><td>Multiple</td><td>User Generated</td><td>1</td><td>\\leq 1</td><td>\u2713</td><td>\u2713</td><td>\u2717</td></tr><tr><td>Su et al [58]</td><td>2015</td><td>7</td><td>7</td><td>SONY DSCP10</td><td>User Generated</td><td>1</td><td>\\leq 1</td><td>\u2713</td><td>\u2713</td><td>\u2717</td></tr><tr><td>Ours</td><td>Nov-21</td><td>413</td><td>413</td><td>Online Videos</td><td>User Generated</td><td></td><td>upto 40</td><td>\u2713</td><td>\u2713</td><td>\u2713</td></tr></tbody></table>", "caption": "Table 2: Characteristics of Video Manipulation Datasets: We compare VideoSham with state-of-the-art video manipulation datasets.", "list_citation_info": ["[24] Fouad Khelifi and Ahmed Bouridane. Perceptual video hashing for content identification and authentication. IEEE Transactions on Circuits and Systems for Video Technology, 29(1):50\u201367, 2017.", "[23] Hasam Khalid, Shahroz Tariq, and Simon S Woo. Fakeavceleb: A novel audio-video multimodal deepfake dataset. arXiv preprint arXiv:2108.05080, 2021.", "[68] Xin Yang, Yuezun Li, and Siwei Lyu. Exposing deep fakes using inconsistent head poses. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 8261\u20138265. IEEE, 2019.", "[4] Omar Ismael Al-Sanjary, Ahmed Abdullah Ahmed, and Ghazali Sulong. Development of a video tampering dataset for forensic investigation. Forensic science international, 266:565\u2013572, 2016.", "[62] Junke Wang, Zuxuan Wu, Jingjing Chen, and Yu-Gang Jiang. M2tr: Multi-modal multi-scale transformers for deepfake detection. arXiv preprint arXiv:2104.09770, 2021.", "[58] Lichao Su, Tianqiang Huang, and Jianmei Yang. A video forgery detection algorithm based on compressive sensing. Multimedia Tools and Applications, 74(17):6641\u20136656, 2015.", "[13] Brian Dolhansky, Russ Howes, Ben Pflaum, Nicole Baram, and Cristian Canton Ferrer. The deepfake detection challenge (dfdc) preview dataset. arXiv preprint arXiv:1910.08854, 2019.", "[54] Conrad Sanderson. The vidtimit database. Technical report, IDIAP, 2002.", "[22] Liming Jiang, Wayne Wu, Ren Li, Chen Qian, and Chen Change Loy. Deeperforensics-1.0: A large-scale dataset for real-world face forgery detection. arXiv preprint arXiv:2001.03024, 2020.", "[11] Joon Son Chung, Arsha Nagrani, and Andrew Zisserman. Voxceleb2: Deep speaker recognition. arXiv preprint arXiv:1806.05622, 2018.", "[35] Sheng-Yang Liao and Tian-Qiang Huang. Video copy-move forgery detection and localization based on tamura texture features. In 2013 6th international congress on image and signal processing (CISP), volume 2, pages 864\u2013868. IEEE, 2013.", "[34] Yuezun Li, Xin Yang, Pu Sun, Honggang Qi, and Siwei Lyu. Celeb-df: A new dataset for deepfake forensics. 2019.", "[74] Bojia Zi, Minghao Chang, Jingjing Chen, Xingjun Ma, and Yu-Gang Jiang. Wilddeepfake: A challenging real-world dataset for deepfake detection. In Proceedings of the 28th ACM International Conference on Multimedia, pages 2382\u20132390, 2020.", "[28] Pavel Korshunov and S\u00e9bastien Marcel. Deepfakes: a new threat to face recognition? assessment and detection. arXiv preprint arXiv:1812.08685, 2018.", "[51] Andreas Rossler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nie\u00dfner. Faceforensics++: Learning to detect manipulated facial images. In Proceedings of the IEEE International Conference on Computer Vision, pages 1\u201311, 2019.", "[31] Patrick Kwon, Jaeseong You, Gyuhyeon Nam, Sungwoo Park, and Gyeongsu Chae. Kodf: A large-scale korean deepfake detection dataset. arXiv preprint arXiv:2103.10094, 2021.", "[21] Yinan He, Bei Gan, Siyu Chen, Yichun Zhou, Guojun Yin, Luchuan Song, Lu Sheng, Jing Shao, and Ziwei Liu. Forgerynet: A versatile benchmark for comprehensive forgery analysis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4360\u20134369, 2021.", "[1] Contributing data to deepfake detection research, Sep 2019."]}, {"table": "<table><tbody><tr><td></td><td></td><td></td><td></td><td colspan=\"10\">Predicted </td></tr><tr><td rowspan=\"3\">GT</td><td></td><td></td><td rowspan=\"3\">#Vid.</td><td colspan=\"6\">Deepfake Detection Methods </td><td colspan=\"4\">Video Forensics Techniques</td></tr><tr><td></td><td></td><td colspan=\"2\">Li et al [33] </td><td colspan=\"2\">MesoNet [2]</td><td colspan=\"2\">Mittal et al. [41]</td><td colspan=\"2\">Long et al. [38]</td><td colspan=\"2\">Liu et al. [37]</td></tr><tr><td></td><td></td><td colspan=\"2\">Predicted</td><td colspan=\"2\">Predicted</td><td colspan=\"2\">Predicted</td><td colspan=\"2\">Predicted</td><td colspan=\"2\">Predicted </td></tr><tr><td></td><td></td><td></td><td></td><td>Real</td><td>Fake</td><td>Real</td><td>Fake</td><td>Real</td><td>Fake</td><td>Real</td><td>Fake</td><td>Real</td><td>Fake</td></tr><tr><td>Real</td><td></td><td></td><td>413</td><td>188</td><td>225</td><td>167</td><td>246</td><td>238</td><td>175</td><td>219</td><td>194</td><td>234</td><td>179</td></tr><tr><td rowspan=\"6\">Manipulated</td><td rowspan=\"6\">Attack</td><td>1</td><td>97</td><td>76</td><td>21</td><td>93</td><td>4</td><td>92</td><td>5</td><td>86</td><td>11</td><td>68</td><td>29</td></tr><tr><td>2</td><td>97</td><td>63</td><td>34</td><td>84</td><td>13</td><td>66</td><td>31</td><td>84</td><td>13</td><td>46</td><td>51</td></tr><tr><td>3</td><td>54</td><td>35</td><td>19</td><td>37</td><td>17</td><td>49</td><td>5</td><td>50</td><td>4</td><td>38</td><td>16</td></tr><tr><td>4</td><td>45</td><td>32</td><td>13</td><td>34</td><td>11</td><td>42</td><td>3</td><td>39</td><td>6</td><td>34</td><td>11</td></tr><tr><td>5</td><td>73</td><td>70</td><td>3</td><td>67</td><td>6</td><td>54</td><td>19</td><td>25</td><td>48</td><td>68</td><td>5</td></tr><tr><td>6</td><td>47</td><td>45</td><td>2</td><td>44</td><td>3</td><td>31</td><td>16</td><td>38</td><td>9</td><td>41</td><td>6</td></tr><tr><td></td><td></td><td></td><td>413 </td><td>321</td><td>92</td><td>359</td><td>54</td><td>334</td><td>79</td><td>322</td><td>91</td><td>295</td><td>118</td></tr></tbody></table>", "caption": "Table 4: Machine Performance:  We evaluate 3 state-of-the-art deepfake detection methods and 2 video forensics techniques on VideoSham. It is apparent that these algorithms do not perform well on VideoSham, speaking to its complexity and diversity.", "list_citation_info": ["[37] Yaqi Liu, Chao Xia, Xiaobin Zhu, and Shengwei Xu. Two-stage copy-move forgery detection with self deep matching and proposal superglue. IEEE Transactions on Image Processing, 31:541\u2013555, 2021.", "[41] Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket Bera, and Dinesh Manocha. Emotions don\u2019t lie: An audio-visual deepfake detection method using affective cues. In Proceedings of the 28th ACM international conference on multimedia, pages 2823\u20132832, 2020.", "[38] Chengjiang Long, Arslan Basharat, Anthony Hoogs, Priyanka Singh, Hany Farid, et al. A coarse-to-fine deep convolutional neural network framework for frame duplication detection and localization in forged videos. In CVPR Workshops, pages 1\u201310, 2019.", "[2] Darius Afchar, Vincent Nozick, Junichi Yamagishi, and Isao Echizen. Mesonet: a compact facial video forgery detection network. In 2018 IEEE International Workshop on Information Forensics and Security (WIFS), pages 1\u20137. IEEE, 2018.", "[33] Yuezun Li and Siwei Lyu. Exposing deepfake videos by detecting face warping artifacts. In IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2019."]}], "citation_info_to_title": {"[23] Hasam Khalid, Shahroz Tariq, and Simon S Woo. Fakeavceleb: A novel audio-video multimodal deepfake dataset. arXiv preprint arXiv:2108.05080, 2021.": "Fakeavceleb: A novel audio-video multimodal deepfake dataset", "[51] Andreas Rossler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nie\u00dfner. Faceforensics++: Learning to detect manipulated facial images. In Proceedings of the IEEE International Conference on Computer Vision, pages 1\u201311, 2019.": "Faceforensics++: Learning to detect manipulated facial images", "[60] Justus Thies, Michael Zollhofer, Marc Stamminger, Christian Theobalt, and Matthias Nie\u00dfner. Face2face: Real-time face capture and reenactment of rgb videos. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2387\u20132395, 2016.": "Face2face: Real-time face capture and reenactment of RGB videos", "[71] Jiangning Zhang, Liang Liu, Zhucun Xue, and Yong Liu. Apb2face: audio-guided face reenactment with auxiliary pose and blink signals. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4402\u20134406. IEEE, 2020.": "Apb2face: Audio-Guided Face Reenactment with Auxiliary Pose and Blink Signals", "[31] Patrick Kwon, Jaeseong You, Gyuhyeon Nam, Sungwoo Park, and Gyeongsu Chae. Kodf: A large-scale korean deepfake detection dataset. arXiv preprint arXiv:2103.10094, 2021.": "Kodf: A large-scale korean deepfake detection dataset", "[28] Pavel Korshunov and S\u00e9bastien Marcel. Deepfakes: a new threat to face recognition? assessment and detection. arXiv preprint arXiv:1812.08685, 2018.": "Deepfakes: A New Threat to Face Recognition? Assessment and Detection", "[58] Lichao Su, Tianqiang Huang, and Jianmei Yang. A video forgery detection algorithm based on compressive sensing. Multimedia Tools and Applications, 74(17):6641\u20136656, 2015.": "A video forgery detection algorithm based on compressive sensing", "[70] Ran Yi, Zipeng Ye, Juyong Zhang, Hujun Bao, and Yong-Jin Liu. Audio-driven talking face video generation with learning-based personalized head pose. arXiv preprint arXiv:2002.10137, 2020.": "Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose", "[55] Aliaksandr Siarohin, St\u00e9phane Lathuili\u00e8re, Sergey Tulyakov, Elisa Ricci, and Nicu Sebe. First order motion model for image animation. Advances in Neural Information Processing Systems, 32:7137\u20137147, 2019.": "First Order Motion Model for Image Animation", "[29] Iryna Korshunova, Wenzhe Shi, Joni Dambre, and Lucas Theis. Fast face-swap using convolutional neural networks. In Proceedings of the IEEE international conference on computer vision, pages 3677\u20133685, 2017.": "Fast face-swap using convolutional neural networks", "[4] Omar Ismael Al-Sanjary, Ahmed Abdullah Ahmed, and Ghazali Sulong. Development of a video tampering dataset for forensic investigation. Forensic science international, 266:565\u2013572, 2016.": "Development of a video tampering dataset for forensic investigation", "[33] Yuezun Li and Siwei Lyu. Exposing deepfake videos by detecting face warping artifacts. In IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2019.": "Exposing deepfake videos by detecting face warping artifacts", "[38] Chengjiang Long, Arslan Basharat, Anthony Hoogs, Priyanka Singh, Hany Farid, et al. A coarse-to-fine deep convolutional neural network framework for frame duplication detection and localization in forged videos. In CVPR Workshops, pages 1\u201310, 2019.": "A coarse-to-fine deep convolutional neural network framework for frame duplication detection and localization in forged videos", "[44] Yuval Nirkin, Yosi Keller, and Tal Hassner. Fsgan: Subject agnostic face swapping and reenactment. In Proceedings of the IEEE/CVF international conference on computer vision, pages 7184\u20137193, 2019.": "Fsgan: Subject agnostic face swapping and reenactment", "[22] Liming Jiang, Wayne Wu, Ren Li, Chen Qian, and Chen Change Loy. Deeperforensics-1.0: A large-scale dataset for real-world face forgery detection. arXiv preprint arXiv:2001.03024, 2020.": "Deeperforensics-10: A large-scale dataset for real-world face forgery detection", "[59] Justus Thies, Michael Zollh\u00f6fer, and Matthias Nie\u00dfner. Deferred neural rendering: Image synthesis using neural textures. ACM Transactions on Graphics (TOG), 38(4):1\u201312, 2019.": "Deferred Neural Rendering: Image Synthesis Using Neural Textures", "[62] Junke Wang, Zuxuan Wu, Jingjing Chen, and Yu-Gang Jiang. M2tr: Multi-modal multi-scale transformers for deepfake detection. arXiv preprint arXiv:2104.09770, 2021.": "M2tr: Multi-modal multi-scale transformers for deepfake detection", "[1] Contributing data to deepfake detection research, Sep 2019.": "Contributing data to deepfake detection research", "[11] Joon Son Chung, Arsha Nagrani, and Andrew Zisserman. Voxceleb2: Deep speaker recognition. arXiv preprint arXiv:1806.05622, 2018.": "Voxceleb2: Deep speaker recognition", "[24] Fouad Khelifi and Ahmed Bouridane. Perceptual video hashing for content identification and authentication. IEEE Transactions on Circuits and Systems for Video Technology, 29(1):50\u201367, 2017.": "Perceptual video hashing for content identification and authentication", "[46] Ivan Perov, Daiheng Gao, Nikolay Chervoniy, Kunlin Liu, Sugasa Marangonda, Chris Um\u00e9, Mr Dpfks, Carl Shift Facenheim, Luis RP, Jian Jiang, et al. Deepfacelab: A simple, flexible and extensible face swapping framework. arXiv preprint arXiv:2005.05535, 2020.": "Deepfacelab: A simple, flexible and extensible face swapping framework", "[61] Soumya Tripathy, Juho Kannala, and Esa Rahtu. Icface: Interpretable and controllable face reenactment using gans. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3385\u20133394, 2020.": "Icface: Interpretable and controllable face reenactment using gans", "[13] Brian Dolhansky, Russ Howes, Ben Pflaum, Nicole Baram, and Cristian Canton Ferrer. The deepfake detection challenge (dfdc) preview dataset. arXiv preprint arXiv:1910.08854, 2019.": "The Deepfake Detection Challenge (DFDC) Preview Dataset", "[32] Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, and Fang Wen. Faceshifter: Towards high fidelity and occlusion aware face swapping. arXiv preprint arXiv:1912.13457, 2019.": "Faceshifter: Towards high fidelity and occlusion aware face swapping", "[41] Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket Bera, and Dinesh Manocha. Emotions don\u2019t lie: An audio-visual deepfake detection method using affective cues. In Proceedings of the 28th ACM international conference on multimedia, pages 2823\u20132832, 2020.": "Emotions dont lie: An audio-visual deepfake detection method using affective cues", "[74] Bojia Zi, Minghao Chang, Jingjing Chen, Xingjun Ma, and Yu-Gang Jiang. Wilddeepfake: A challenging real-world dataset for deepfake detection. In Proceedings of the 28th ACM International Conference on Multimedia, pages 2382\u20132390, 2020.": "Wilddeepfake: A challenging real-world dataset for deepfake detection", "[35] Sheng-Yang Liao and Tian-Qiang Huang. Video copy-move forgery detection and localization based on tamura texture features. In 2013 6th international congress on image and signal processing (CISP), volume 2, pages 864\u2013868. IEEE, 2013.": "Video Copy-Move Forgery Detection and Localization Based on Tamura Texture Features", "[37] Yaqi Liu, Chao Xia, Xiaobin Zhu, and Shengwei Xu. Two-stage copy-move forgery detection with self deep matching and proposal superglue. IEEE Transactions on Image Processing, 31:541\u2013555, 2021.": "Two-stage copy-move forgery detection with self deep matching and proposal superglue", "[2] Darius Afchar, Vincent Nozick, Junichi Yamagishi, and Isao Echizen. Mesonet: a compact facial video forgery detection network. In 2018 IEEE International Workshop on Information Forensics and Security (WIFS), pages 1\u20137. IEEE, 2018.": "Mesonet: a compact facial video forgery detection network", "[34] Yuezun Li, Xin Yang, Pu Sun, Honggang Qi, and Siwei Lyu. Celeb-df: A new dataset for deepfake forensics. 2019.": "Celeb-df: A new dataset for deepfake forensics", "[54] Conrad Sanderson. The vidtimit database. Technical report, IDIAP, 2002.": "The vidtimit database", "[21] Yinan He, Bei Gan, Siyu Chen, Yichun Zhou, Guojun Yin, Luchuan Song, Lu Sheng, Jing Shao, and Ziwei Liu. Forgerynet: A versatile benchmark for comprehensive forgery analysis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4360\u20134369, 2021.": "ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis", "[47] KR Prajwal, Rudrabha Mukhopadhyay, Vinay P Namboodiri, and CV Jawahar. A lip sync expert is all you need for speech to lip generation in the wild. In Proceedings of the 28th ACM International Conference on Multimedia, pages 484\u2013492, 2020.": "A lip sync expert is all you need for speech to lip generation in the wild", "[68] Xin Yang, Yuezun Li, and Siwei Lyu. Exposing deep fakes using inconsistent head poses. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 8261\u20138265. IEEE, 2019.": "Exposing deep fakes using inconsistent head poses"}, "source_title_to_arxiv_id": {"First Order Motion Model for Image Animation": "2003.00196"}}