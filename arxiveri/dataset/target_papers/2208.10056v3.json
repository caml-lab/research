{"title": "Minkowski Tracker: A Sparse Spatio-Temporal R-CNN for Joint Object Detection and Tracking", "abstract": "Recent research in multi-task learning reveals the benefit of solving related\nproblems in a single neural network. 3D object detection and multi-object\ntracking (MOT) are two heavily intertwined problems predicting and associating\nan object instance location across time. However, most previous works in 3D MOT\ntreat the detector as a preceding separated pipeline, disjointly taking the\noutput of the detector as an input to the tracker. In this work, we present\nMinkowski Tracker, a sparse spatio-temporal R-CNN that jointly solves object\ndetection and tracking. Inspired by region-based CNN (R-CNN), we propose to\nsolve tracking as a second stage of the object detector R-CNN that predicts\nassignment probability to tracks. First, Minkowski Tracker takes 4D point\nclouds as input to generate a spatio-temporal Bird's-eye-view (BEV) feature map\nthrough a 4D sparse convolutional encoder network. Then, our proposed\nTrackAlign aggregates the track region-of-interest (ROI) features from the BEV\nfeatures. Finally, Minkowski Tracker updates the track and its confidence score\nbased on the detection-to-track match probability predicted from the ROI\nfeatures. We show in large-scale experiments that the overall performance gain\nof our method is due to four factors: 1. The temporal reasoning of the 4D\nencoder improves the detection performance 2. The multi-task learning of object\ndetection and MOT jointly enhances each other 3. The detection-to-track match\nscore learns implicit motion model to enhance track assignment 4. The\ndetection-to-track match score improves the quality of the track confidence\nscore. As a result, Minkowski Tracker achieved the state-of-the-art performance\non Nuscenes dataset tracking task without hand-designed motion models.", "authors": ["JunYoung Gwak", "Silvio Savarese", "Jeannette Bohg"], "published_date": "2022_08_22", "pdf_url": "http://arxiv.org/pdf/2208.10056v3", "list_table_and_caption": [{"table": "<table><thead><tr><th>Method</th><th>AMOTA\u2191</th><th>MOTA\u2191</th><th>RECALL\u2191</th><th>FP\u2193</th><th>FN\u2193</th><th>IDS\u2193</th><th>FRAG\u2193</th></tr></thead><tbody><tr><td>StanfordIPRL-TRI (Chiu et al. 2020)</td><td>0.550</td><td>0.459</td><td>0.600</td><td>17533</td><td>33216</td><td>950</td><td>776</td></tr><tr><td>CenterPoint (Yin, Zhou, and Krahenbuhl 2021){}^{*}</td><td>0.638</td><td>0.537</td><td>0.675</td><td>18612</td><td>22928</td><td>760</td><td>529</td></tr><tr><td>OGR3MOT (Zaech et al. 2022){}^{*}</td><td>0.656</td><td>0.554</td><td>0.692</td><td>17877</td><td>24013</td><td>288</td><td>371</td></tr><tr><td>Belief Propagation (Meyer et al. 2018){}^{*}</td><td>0.666</td><td>0.571</td><td>0.684</td><td>16884</td><td>22381</td><td>182</td><td>245</td></tr><tr><td>SimpleTrack (Pang, Li, and Wang 2021){}^{*}</td><td>0.668</td><td>0.566</td><td>0.703</td><td>17514</td><td>23451</td><td>575</td><td>591</td></tr><tr><td>ImmortalTracker (Wang et al. 2021){}^{*}</td><td>0.677</td><td>0.572</td><td>0.714</td><td>18012</td><td>21661</td><td>320</td><td>477</td></tr><tr><td>GNN-PMB (Liu et al. 2022){}^{*}</td><td>0.678</td><td>0.563</td><td>0.696</td><td>17071</td><td>21521</td><td>770</td><td>431</td></tr><tr><td>NEBP (Liang and Meyer 2022){}^{*}</td><td>0.683</td><td>0.584</td><td>0.705</td><td>16773</td><td>21971</td><td>227</td><td>299</td></tr><tr><td>TransFusion-L (Bai et al. 2022)</td><td>0.686</td><td>0.571</td><td>0.731</td><td>17851</td><td>23437</td><td>893</td><td>626</td></tr><tr><td>Minkowski Tracker (ours){}^{*}</td><td>0.698</td><td>0.578</td><td>0.757</td><td>19340</td><td>21220</td><td>325</td><td>217</td></tr></tbody></table>", "caption": "Table 1: Tracking result on Nuscenes test set. Our proposed method achieved state-of-the-art performance on AMOTA metric. Minkowski Tracker has the highest recall and lowest false negative, meaning that our 4D object detection trained jointly with online tracking recovers as many tracks as possible. Minkowski Tracker also has the lowest track fragmentation and low ID switches demonstrating that our network successfully learns implicit motion models to assign detections to tracks.", "list_citation_info": ["Wang et al. (2021) Wang, Q.; Chen, Y.; Pang, Z.; Wang, N.; and Zhang, Z. 2021. Immortal Tracker: Tracklet Never Dies. arXiv preprint arXiv:2111.13672.", "Liang and Meyer (2022) Liang, M.; and Meyer, F. 2022. Neural Enhanced Belief Propagation for Data Assocation in Multiobject Tracking. arXiv preprint arXiv:2203.09948.", "Pang, Li, and Wang (2021) Pang, Z.; Li, Z.; and Wang, N. 2021. Simpletrack: Understanding and rethinking 3d multi-object tracking. arXiv preprint arXiv:2111.09621.", "Yin, Zhou, and Krahenbuhl (2021) Yin, T.; Zhou, X.; and Krahenbuhl, P. 2021. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 11784\u201311793.", "Liu et al. (2022) Liu, J.; Bai, L.; Xia, Y.; Huang, T.; and Zhu, B. 2022. GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without Bells and Whistles. arXiv e-prints, arXiv\u20132206.", "Bai et al. (2022) Bai, X.; Hu, Z.; Zhu, X.; Huang, Q.; Chen, Y.; Fu, H.; and Tai, C.-L. 2022. Transfusion: Robust lidar-camera fusion for 3d object detection with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 1090\u20131099.", "Zaech et al. (2022) Zaech, J.-N.; Liniger, A.; Dai, D.; Danelljan, M.; and Van Gool, L. 2022. Learnable online graph representations for 3d multi-object tracking. IEEE Robotics and Automation Letters, 7(2): 5103\u20135110.", "Meyer et al. (2018) Meyer, F.; Kropfreiter, T.; Williams, J. L.; Lau, R.; Hlawatsch, F.; Braca, P.; and Win, M. Z. 2018. Message passing algorithms for scalable multitarget tracking. Proceedings of the IEEE, 106(2): 221\u2013259.", "Chiu et al. (2020) Chiu, H.-k.; Prioletti, A.; Li, J.; and Bohg, J. 2020. Probabilistic 3D Multi-Object Tracking for Autonomous Driving. arXiv preprint arXiv:2001.05673."]}, {"table": "<table><thead><tr><th>Method</th><th>mAP\u2191</th><th>NDS\u2191</th></tr><tr><th>CenterPoint</th><th>59.6</th><th>66.8</th></tr></thead><tbody><tr><td>CenterPoint + 4DEncoder</td><td>61.9</td><td>69.3</td></tr><tr><td>CenterPoint + 4DEncoder + track</td><td>62.4</td><td>69.5</td></tr></tbody></table>", "caption": "Table 2: Detection result comparison on Nuscenes detection validation split between CenterPoint (Yin, Zhou, and Krahenbuhl 2021) and Minkowski Tracker R-CNN. 4DEncoder refers to our network using a 4D sparse encoder. track refers to a detector jointly trained with a tracking loss.", "list_citation_info": ["Yin, Zhou, and Krahenbuhl (2021) Yin, T.; Zhou, X.; and Krahenbuhl, P. 2021. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 11784\u201311793."]}], "citation_info_to_title": {"Yin, Zhou, and Krahenbuhl (2021) Yin, T.; Zhou, X.; and Krahenbuhl, P. 2021. Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 11784\u201311793.": "Center-based 3D Object Detection and Tracking", "Bai et al. (2022) Bai, X.; Hu, Z.; Zhu, X.; Huang, Q.; Chen, Y.; Fu, H.; and Tai, C.-L. 2022. Transfusion: Robust lidar-camera fusion for 3d object detection with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 1090\u20131099.": "Transfusion: Robust lidar-camera fusion for 3d object detection with transformers", "Meyer et al. (2018) Meyer, F.; Kropfreiter, T.; Williams, J. L.; Lau, R.; Hlawatsch, F.; Braca, P.; and Win, M. Z. 2018. Message passing algorithms for scalable multitarget tracking. Proceedings of the IEEE, 106(2): 221\u2013259.": "Message Passing Algorithms for Scalable Multitarget Tracking", "Liu et al. (2022) Liu, J.; Bai, L.; Xia, Y.; Huang, T.; and Zhu, B. 2022. GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without Bells and Whistles. arXiv e-prints, arXiv\u20132206.": "GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without Bells and Whistles", "Wang et al. (2021) Wang, Q.; Chen, Y.; Pang, Z.; Wang, N.; and Zhang, Z. 2021. Immortal Tracker: Tracklet Never Dies. arXiv preprint arXiv:2111.13672.": "Immortal Tracker: Tracklet Never Dies", "Chiu et al. (2020) Chiu, H.-k.; Prioletti, A.; Li, J.; and Bohg, J. 2020. Probabilistic 3D Multi-Object Tracking for Autonomous Driving. arXiv preprint arXiv:2001.05673.": "Probabilistic 3D Multi-Object Tracking for Autonomous Driving", "Liang and Meyer (2022) Liang, M.; and Meyer, F. 2022. Neural Enhanced Belief Propagation for Data Assocation in Multiobject Tracking. arXiv preprint arXiv:2203.09948.": "Neural Enhanced Belief Propagation for Data Association in Multiobject Tracking", "Pang, Li, and Wang (2021) Pang, Z.; Li, Z.; and Wang, N. 2021. Simpletrack: Understanding and rethinking 3d multi-object tracking. arXiv preprint arXiv:2111.09621.": "Simpletrack: Understanding and Rethinking 3D Multi-Object Tracking", "Zaech et al. (2022) Zaech, J.-N.; Liniger, A.; Dai, D.; Danelljan, M.; and Van Gool, L. 2022. Learnable online graph representations for 3d multi-object tracking. IEEE Robotics and Automation Letters, 7(2): 5103\u20135110.": "Learnable Online Graph Representations for 3D Multi-Object Tracking"}, "source_title_to_arxiv_id": {"GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without Bells and Whistles": "2206.10255"}}