{"title": "Masked Contrastive Representation Learning", "abstract": "Masked image modelling (e.g., Masked AutoEncoder) and contrastive learning\n(e.g., Momentum Contrast) have shown impressive performance on unsupervised\nvisual representation learning. This work presents Masked Contrastive\nRepresentation Learning (MACRL) for self-supervised visual pre-training. In\nparticular, MACRL leverages the effectiveness of both masked image modelling\nand contrastive learning. We adopt an asymmetric setting for the siamese\nnetwork (i.e., encoder-decoder structure in both branches), where one branch\nwith higher mask ratio and stronger data augmentation, while the other adopts\nweaker data corruptions. We optimize a contrastive learning objective based on\nthe learned features from the encoder in both branches. Furthermore, we\nminimize the $L_1$ reconstruction loss according to the decoders' outputs. In\nour experiments, MACRL presents superior results on various vision benchmarks,\nincluding CIFAR-10, CIFAR-100, Tiny-ImageNet, and two other ImageNet subsets.\nOur framework provides unified insights on self-supervised visual pre-training\nand future research.", "authors": ["Yuchong Yao", "Nandakishor Desai", "Marimuthu Palaniswami"], "published_date": "2022_11_11", "pdf_url": "http://arxiv.org/pdf/2211.06012v1", "list_table_and_caption": [{"table": "<table><thead><tr><th><p>Method</p></th><th>CIFAR-10</th><th>CIFAR-100</th></tr></thead><tbody><tr><td><p>MAE [20]</p></td><td>96.18</td><td>81.68</td></tr><tr><td><p>MoCo [21]</p></td><td>95.61</td><td>74.59</td></tr><tr><td><p>MACRL{}^{\\ast}</p></td><td>96.43</td><td>81.38</td></tr><tr><td><p>MACRL</p></td><td>97.88</td><td>82.94</td></tr></tbody></table>", "caption": "Table 1: Fine-tuning Results on CIFAR. The fine-tuning on CIFAR-10 and CIFAR-100 with MAE, MoCo, and MACRL. The \\ast denotes the results for fine-tuning 100 epochs.", "list_citation_info": ["[20] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16000\u201316009, 2022.", "[21] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9729\u20139738, 2020."]}, {"table": "<table><thead><tr><th><p>Method</p></th><th>CIFAR-10</th><th>CIFAR-100</th></tr></thead><tbody><tr><td><p>MAE [20]</p></td><td>78.60</td><td>50.08</td></tr><tr><td><p>MoCo [21]</p></td><td>86.16</td><td>57.71</td></tr><tr><td><p>MACRL{}^{\\ast}</p></td><td>81.36</td><td>48.62</td></tr><tr><td><p>MACRL</p></td><td>91.02</td><td>66.27</td></tr></tbody></table>", "caption": "Table 2: Linear Probe Results on CIFAR. The linear probing on CIFAR-10 and CIFAR-100 with MAE, MoCo, and MACRL. The \\ast denotes the results for linear probed 100 epochs.", "list_citation_info": ["[20] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16000\u201316009, 2022.", "[21] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9729\u20139738, 2020."]}, {"table": "<table><thead><tr><th>Method</th><th>Tiny-ImageNet</th><th>Imagenette</th><th>Imagewoof</th></tr></thead><tbody><tr><td>MAE [20]</td><td>70.56</td><td>92.86</td><td>84.47</td></tr><tr><td>MoCo [21]</td><td>70.08</td><td>92.26</td><td>83.28</td></tr><tr><td>MACRL{}^{\\ast}</td><td>69.86</td><td>92.89</td><td>81.21</td></tr><tr><td>MACRL</td><td>72.06</td><td>93.37</td><td>87.14</td></tr></tbody></table>", "caption": "Table 3: Fine-tuning Results on ImageNet Subsets. The fine-tuning on ImageNet subsets with MAE, MoCo, and MACRL. The \\ast denotes the results for fine-tuning 200 epochs.", "list_citation_info": ["[20] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16000\u201316009, 2022.", "[21] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9729\u20139738, 2020."]}, {"table": "<table><thead><tr><th>Method</th><th>Tiny-ImageNet</th><th>Imagenette</th><th>Imagewoof</th></tr></thead><tbody><tr><td>MAE [20]</td><td>61.95</td><td>74.26</td><td>44.74</td></tr><tr><td>MoCo [21]</td><td>75.25</td><td>78.60</td><td>51.53</td></tr><tr><td>MACRL{}^{\\ast}</td><td>54.45</td><td>71.05</td><td>44.76</td></tr><tr><td>MACRL</td><td>75.44</td><td>80.56</td><td>54.98</td></tr></tbody></table>", "caption": "Table 4: Linear Probe Results on ImageNet Subsets. The fine-tuning on ImageNet subsets with MAE, MoCo, and MACRL. The \\ast denotes the results for linear probed 500 epochs.", "list_citation_info": ["[20] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16000\u201316009, 2022.", "[21] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9729\u20139738, 2020."]}], "citation_info_to_title": {"[20] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16000\u201316009, 2022.": "Masked Autoencoders are Scalable Vision Learners", "[21] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9729\u20139738, 2020.": "Momentum contrast for unsupervised visual representation learning"}, "source_title_to_arxiv_id": {"Masked Autoencoders are Scalable Vision Learners": "2111.06377"}}