{"title": "Argus++: Robust Real-time Activity Detection for Unconstrained Video Streams with Overlapping Cube Proposals", "abstract": "Activity detection is one of the attractive computer vision tasks to exploit\nthe video streams captured by widely installed cameras. Although achieving\nimpressive performance, conventional activity detection algorithms are usually\ndesigned under certain constraints, such as using trimmed and/or\nobject-centered video clips as inputs. Therefore, they failed to deal with the\nmulti-scale multi-instance cases in real-world unconstrained video streams,\nwhich are untrimmed and have large field-of-views. Real-time requirements for\nstreaming analysis also mark brute force expansion of them unfeasible.\n  To overcome these issues, we propose Argus++, a robust real-time activity\ndetection system for analyzing unconstrained video streams. The design of\nArgus++ introduces overlapping spatio-temporal cubes as an intermediate concept\nof activity proposals to ensure coverage and completeness of activity detection\nthrough over-sampling. The overall system is optimized for real-time processing\non standalone consumer-level hardware. Extensive experiments on different\nsurveillance and driving scenarios demonstrated its superior performance in a\nseries of activity detection benchmarks, including CVPR ActivityNet ActEV 2021,\nNIST ActEV SDL UF/KF, TRECVID ActEV 2020/2021, and ICCV ROAD 2021.", "authors": ["Lijun Yu", "Yijun Qian", "Wenhe Liu", "Alexander G. Hauptmann"], "published_date": "2022_01_14", "pdf_url": "http://arxiv.org/pdf/2201.05290v1", "list_table_and_caption": [{"table": "<table><thead><tr><th>System/Team</th><th>\\mathit{nAUDC}@0.2T_{\\mathit{fa}}\\downarrow</th><th>Mean P_{miss}@0.15T_{\\mathit{fa}}\\downarrow</th><th>Mean wP_{miss}@0.15R_{\\mathit{fa}}\\downarrow</th></tr></thead><tbody><tr><th>Argus++ (Ours)</th><td>0.39607</td><td>0.30622</td><td>0.81080</td></tr><tr><th>BUPT</th><td>0.40853</td><td>0.32489</td><td>0.79798</td></tr><tr><th>UCF</th><td>0.43059</td><td>0.34080</td><td>0.86431</td></tr><tr><th>M4D</th><td>0.84658</td><td>0.79410</td><td>0.88521</td></tr><tr><th>TokyoTech_AIST</th><td>0.85159</td><td>0.81970</td><td>0.94897</td></tr><tr><th>Team UEC</th><td>0.96405</td><td>0.95035</td><td>0.95670</td></tr></tbody></table>", "caption": "Table 4: NIST TRECVID 2021 ActEV Evaluation [1, 30]", "list_citation_info": ["[1] George Awad, Asad A. Butt, Keith Curtis, Jonathan Fiscus, Afzal Godil, Yooyoung Lee, Andrew Delgado, Jesse Zhang, Eliot Godard, Baptiste Chocot, Lukas Diduch, Jeffrey Liu, Yvette Graham, Gareth J. F. Jones, , and Georges Qu\u00e9not. Evaluating multiple video understanding and retrieval tasks at trecvid 2021. In Proceedings of TRECVID 2021. NIST, USA, 2021."]}, {"table": "<table><thead><tr><th>System/Team</th><th>\\mathit{nAUDC}@0.2T_{\\mathit{fa}}\\downarrow</th><th>Mean P_{miss}@0.15T_{\\mathit{fa}}\\downarrow</th><th>Mean wP_{miss}@0.15R_{\\mathit{fa}}\\downarrow</th></tr></thead><tbody><tr><th>Argus++ (Ours)</th><td>0.42307</td><td>0.33241</td><td>0.80965</td></tr><tr><th>UCF</th><td>0.54830</td><td>0.50285</td><td>0.83621</td></tr><tr><th>BUPT-MCPRL</th><td>0.55515</td><td>0.48779</td><td>0.84519</td></tr><tr><th>TokyoTech_AIST</th><td>0.79753</td><td>0.75502</td><td>0.87889</td></tr><tr><th>CERTH-ITI</th><td>0.86576</td><td>0.84454</td><td>0.88237</td></tr><tr><th>Team UEC</th><td>0.95168</td><td>0.95329</td><td>0.98300</td></tr><tr><th>Kindai_Kobe</th><td>0.96267</td><td>0.95204</td><td>0.93905</td></tr></tbody></table>", "caption": "Table 5: NIST TRECVID 2020 ActEV Evaluation [2, 29]", "list_citation_info": ["[2] George Awad, Asad A. Butt, Keith Curtis, Jonathan Fiscus, Afzal Godil, Yooyoung Lee, Andrew Delgado, Jesse Zhang, Eliot Godard, Baptiste Chocot, Lukas Diduch, Jeffrey Liu, Alan F. Smeaton, Yvette Graham, Gareth J. F. Jones, Wessel Kraaij, and Georges Quenot. TRECVID 2020: A comprehensive campaign for evaluating video retrieval tasks across multiple application domains. arXiv:2104.13473 [cs], Apr. 2021."]}, {"table": "<table><thead><tr><th>System/Team</th><th>Action@0.1 \\uparrow</th><th>Action@0.2 \\uparrow</th><th>Action@0.5 \\uparrow</th><th>Average \\uparrow</th></tr></thead><tbody><tr><th>Argus++ (Ours)</th><td>28.54</td><td>25.63</td><td>6.98</td><td>20.38</td></tr><tr><th>THE IFY</th><td>28.15</td><td>20.97</td><td>6.58</td><td>18.57</td></tr><tr><th>YAAAHO</th><td>26.81</td><td>20.40</td><td>7.02</td><td>18.07</td></tr><tr><th>hyj</th><td>26.52</td><td>20.32</td><td>7.05</td><td>17.97</td></tr><tr><th>3D RetinaNet [21]</th><td>25.70</td><td>19.40</td><td>6.47</td><td>17.19</td></tr><tr><th>LeeC</th><td>13.64</td><td>9.89</td><td>2.23</td><td>8.59</td></tr></tbody></table>", "caption": "Table 6: ICCV 2021 ROAD Challenge Action Detection<sup>7</sup><sup>7</sup>7https://eval.ai/web/challenges/challenge-page/1059/leaderboard/2748", "list_citation_info": ["[21] Gurkirt Singh, Stephen Akrigg, Manuele Di Maio, Valentina Fontana, Reza Javanmard Alitappeh, Suman Saha, Kossar Jeddisaravi, Farzad Yousefi, Jacob Culley, Tom Nicholson, Jordan Omokeowa, Salman Khan, Stanislao Grazioso, Andrew Bradley, Giuseppe Di Gironimo, and Fabio Cuzzolin. ROAD: The ROad event Awareness Dataset for Autonomous Driving. arXiv:2102.11585 [cs], Feb. 2021."]}], "citation_info_to_title": {"[2] George Awad, Asad A. Butt, Keith Curtis, Jonathan Fiscus, Afzal Godil, Yooyoung Lee, Andrew Delgado, Jesse Zhang, Eliot Godard, Baptiste Chocot, Lukas Diduch, Jeffrey Liu, Alan F. Smeaton, Yvette Graham, Gareth J. F. Jones, Wessel Kraaij, and Georges Quenot. TRECVID 2020: A comprehensive campaign for evaluating video retrieval tasks across multiple application domains. arXiv:2104.13473 [cs], Apr. 2021.": "TRECVID 2020: A comprehensive campaign for evaluating video retrieval tasks across multiple application domains", "[1] George Awad, Asad A. Butt, Keith Curtis, Jonathan Fiscus, Afzal Godil, Yooyoung Lee, Andrew Delgado, Jesse Zhang, Eliot Godard, Baptiste Chocot, Lukas Diduch, Jeffrey Liu, Yvette Graham, Gareth J. F. Jones, , and Georges Qu\u00e9not. Evaluating multiple video understanding and retrieval tasks at trecvid 2021. In Proceedings of TRECVID 2021. NIST, USA, 2021.": "Evaluating multiple video understanding and retrieval tasks at TRECVID 2021", "[21] Gurkirt Singh, Stephen Akrigg, Manuele Di Maio, Valentina Fontana, Reza Javanmard Alitappeh, Suman Saha, Kossar Jeddisaravi, Farzad Yousefi, Jacob Culley, Tom Nicholson, Jordan Omokeowa, Salman Khan, Stanislao Grazioso, Andrew Bradley, Giuseppe Di Gironimo, and Fabio Cuzzolin. ROAD: The ROad event Awareness Dataset for Autonomous Driving. arXiv:2102.11585 [cs], Feb. 2021.": "ROAD: The ROad event Awareness Dataset for Autonomous Driving"}, "source_title_to_arxiv_id": {"ROAD: The ROad event Awareness Dataset for Autonomous Driving": "2102.11585"}}