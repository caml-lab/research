{"title": "Rethinking IoU-based Optimization for Single-stage 3D Object Detection", "abstract": "Since Intersection-over-Union (IoU) based optimization maintains the\nconsistency of the final IoU prediction metric and losses, it has been widely\nused in both regression and classification branches of single-stage 2D object\ndetectors. Recently, several 3D object detection methods adopt IoU-based\noptimization and directly replace the 2D IoU with 3D IoU. However, such a\ndirect computation in 3D is very costly due to the complex implementation and\ninefficient backward operations. Moreover, 3D IoU-based optimization is\nsub-optimal as it is sensitive to rotation and thus can cause training\ninstability and detection performance deterioration. In this paper, we propose\na novel Rotation-Decoupled IoU (RDIoU) method that can mitigate the\nrotation-sensitivity issue, and produce more efficient optimization objectives\ncompared with 3D IoU during the training stage. Specifically, our RDIoU\nsimplifies the complex interactions of regression parameters by decoupling the\nrotation variable as an independent term, yet preserving the geometry of 3D\nIoU. By incorporating RDIoU into both the regression and classification\nbranches, the network is encouraged to learn more precise bounding boxes and\nconcurrently overcome the misalignment issue between classification and\nregression. Extensive experiments on the benchmark KITTI and Waymo Open Dataset\nvalidate that our RDIoU method can bring substantial improvement for the\nsingle-stage 3D object detection.", "authors": ["Hualian Sheng", "Sijia Cai", "Na Zhao", "Bing Deng", "Jianqiang Huang", "Xian-Sheng Hua", "Min-Jian Zhao", "Gim Hee Lee"], "published_date": "2022_07_19", "pdf_url": "http://arxiv.org/pdf/2207.09332v2", "list_table_and_caption": [{"table": "<table><tbody><tr><th rowspan=\"2\">Type</th><th rowspan=\"2\">Method</th><th rowspan=\"2\">M</th><th colspan=\"3\">Car-3D (IoU=0.7)</th><th colspan=\"3\">Ped.-3D (IoU=0.5)</th><th colspan=\"3\">Cyc.-3D (IoU=0.5)</th></tr><tr><td>Easy</td><td>Mod.*</td><td>Hard</td><td>Easy</td><td>Mod.</td><td>Hard</td><td>Easy</td><td>Mod.</td><td>Hard</td></tr><tr><th rowspan=\"8\">Two-stage</th><th>Part-A^{2} [24]</th><th>\u2713</th><th>89.56</th><th>79.41</th><th>78.84</th><th>65.69</th><th>60.05</th><th>55.45</th><th>85.50</th><th>69.90</th><th>65.49</th></tr><tr><th>STD [35]</th><th>\u2717</th><td>89.70</td><td>79.80</td><td>79.30</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>PV-RCNN [22]</th><th>\u2713</th><th>89.35</th><th>83.69</th><th>78.70</th><th>63.12</th><th>54.84</th><th>51.78</th><th>86.06</th><th>69.48</th><th>64.50</th></tr><tr><th>Voxel-RCNN [4]</th><th>\u2717</th><td>89.41</td><td>84.52</td><td>78.93</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>VoTr-TSD [16]</th><th>\u2717</th><th>89.04</th><th>84.04</th><th>78.68</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th></tr><tr><th>CT3D [21]</th><th>\u2713</th><td>89.11</td><td>85.04</td><td>78.76</td><td>64.23</td><td>59.84</td><td>55.76</td><td>85.04</td><td>71.71</td><td>68.05</td></tr><tr><th>CT3D [21]</th><th>\u2717</th><th>89.54</th><th>86.06</th><th>78.99</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th></tr><tr><th>BtcDet [30]</th><th>\u2717</th><td>-</td><td>86.57</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td></td></tr><tr><th rowspan=\"12\">Single-stage</th><th>VoxelNet [43]</th><th>\u2713</th><th>81.97</th><th>65.46</th><th>62.85</th><th>57.86</th><th>53.42</th><th>48.87</th><th>67.17</th><th>47.65</th><th>45.11</th></tr><tr><th>SECOND [31]</th><th>\u2713</th><td>88.61</td><td>78.62</td><td>77.22</td><td>56.55</td><td>52.98</td><td>47.73</td><td>80.59</td><td>67.16</td><td>63.11</td></tr><tr><th>PointPillar [10]</th><th>\u2713</th><th>86.46</th><th>77.28</th><th>74.65</th><th>57.75</th><th>52.29</th><th>47.91</th><th>80.06</th><th>62.69</th><th>59.71</th></tr><tr><th>3DSSD [34]</th><th>\u2713</th><td>89.71</td><td>79.45</td><td>78.67</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>SA-SSD [9]</th><th>\u2717</th><th>90.15</th><th>79.91</th><th>78.78</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th></tr><tr><th>CIA-SSD [37]</th><th>\u2717</th><td>90.04</td><td>78.91</td><td>78.80</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>SE-SSD [38]</th><th>\u2717</th><th>-</th><th>85.71</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th><th>-</th></tr><tr><th>VoTr-SSD [16]</th><th>\u2717</th><td>87.86</td><td>78.27</td><td>76.93</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>RDIoU (Ours)</th><th>\u2713</th><th>89.16</th><th>85.24</th><th>78.41</th><th>63.26</th><th>57.47</th><th>52.53</th><th>83.32</th><th>68.39</th><th>63.63</th></tr><tr><th>RDIoU (Ours)</th><th>\u2717</th><td>89.76</td><td>86.62</td><td>79.04</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr></tbody></table>", "caption": "Table 1: Performance comparisons with state-of-the-art methods on the KITTI val set with 11 recall positions. \\text{M}:\u2713means training on three classes. \\text{M}:\u2717means training only on car. Mod.* is the most important metric. The top-1 of two-stage and single-stage methods are bold, respectively.", "list_citation_info": ["[4] Deng, J., Shi, S., Li, P., Zhou, W., Zhang, Y., Li, H.: Voxel r-cnn: Towards high performance voxel-based 3d object detection. arXiv preprint arXiv:2012.15712 (2020)", "[21] Sheng, H., Cai, S., Liu, Y., Deng, B., Huang, J., Hua, X.S., Zhao, M.J.: Improving 3d object detection with channel-wise transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 2743\u20132752 (2021)", "[38] Zheng, W., Tang, W., Jiang, L., Fu, C.W.: Se-ssd: Self-ensembling single-stage object detector from point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 14494\u201314503 (2021)", "[35] Yang, Z., Sun, Y., Liu, S., Shen, X., Jia, J.: Std: Sparse-to-dense 3d object detector for point cloud. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 1951\u20131960 (2019)", "[10] Lang, A.H., Vora, S., Caesar, H., Zhou, L., Yang, J., Beijbom, O.: Pointpillars: Fast encoders for object detection from point clouds. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 12697\u201312705 (2019)", "[16] Mao, J., Xue, Y., Niu, M., Bai, H., Feng, J., Liang, X., Xu, H., Xu, C.: Voxel transformer for 3d object detection. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 3164\u20133173 (2021)", "[30] Xu, Q., Zhong, Y., Neumann, U.: Behind the curtain: Learning occluded shapes for 3d object detection. arXiv preprint arXiv:2112.02205 (2021)", "[22] Shi, S., Guo, C., Jiang, L., Wang, Z., Shi, J., Wang, X., Li, H.: Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 10529\u201310538 (2020)", "[43] Zhou, Y., Tuzel, O.: Voxelnet: End-to-end learning for point cloud based 3d object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4490\u20134499 (2018)", "[31] Yan, Y., Mao, Y., Li, B.: Second: Sparsely embedded convolutional detection. Sensors 18(10), 3337 (2018)", "[34] Yang, Z., Sun, Y., Liu, S., Jia, J.: 3dssd: Point-based 3d single stage object detector. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11040\u201311048 (2020)", "[37] Zheng, W., Tang, W., Chen, S., Jiang, L., Fu, C.W.: Cia-ssd: Confident iou-aware single-stage object detector from point cloud. arXiv preprint arXiv:2012.03015 (2020)", "[24] Shi, S., Wang, Z., Shi, J., Wang, X., Li, H.: From points to parts: 3d object detection from point cloud with part-aware and part-aggregation network. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) (2020)", "[9] He, C., Zeng, H., Huang, J., Hua, X.S., Zhang, L.: Structure aware single-stage 3d object detection from point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11873\u201311882 (2020)"]}, {"table": "<table><tbody><tr><th rowspan=\"2\">Method</th><th rowspan=\"2\">Reference</th><th rowspan=\"2\">Stage</th><td colspan=\"3\">3D AP (IoU=0.7)</td></tr><tr><td>Easy</td><td>Moderate*</td><td>Hard</td></tr><tr><th>Part-A^{2} [24]</th><th>TPAMI 2020</th><th>Two</th><td>87.81</td><td>78.49</td><td>73.51</td></tr><tr><th>STD [35]</th><th>ICCV 2019</th><th>Two</th><td>87.95</td><td>79.71</td><td>75.09</td></tr><tr><th>Point-GNN [25]</th><th>CVPR2020</th><th>Two</th><td>88.33</td><td>79.47</td><td>72.29</td></tr><tr><th>PV-RCNN [22]</th><th>CVPR 2020</th><th>Two</th><td>90.25</td><td>81.43</td><td>76.82</td></tr><tr><th>LiDAR-RCNN [13]</th><th>CVPR 2021</th><th>Two</th><td>85.97</td><td>74.21</td><td>69.18</td></tr><tr><th>VoTr-TSD [16]</th><th>ICCV 2021</th><th>Two</th><td>89.90</td><td>82.09</td><td>79.14</td></tr><tr><th>CT3D [21]</th><th>ICCV 2021</th><th>Two</th><td>87.83</td><td>81.77</td><td>77.16</td></tr><tr><th>BtcDet [30]</th><th>AAAI 2022</th><th>Two</th><td>90.64</td><td>82.86</td><td>78.09</td></tr><tr><th>VoxelNet [43]</th><th>CVPR 2018</th><th>Single</th><td>77.82</td><td>64.17</td><td>57.51</td></tr><tr><th>SECOND [31]</th><th>Sensors 2018</th><th>Single</th><td>83.34</td><td>72.55</td><td>65.82</td></tr><tr><th>PointPillar [10]</th><th>CVPR 2019</th><th>Single</th><td>82.58</td><td>74.31</td><td>68.99</td></tr><tr><th>3DSSD [34]</th><th>CVPR 2020</th><th>Single</th><td>88.36</td><td>79.57</td><td>74.55</td></tr><tr><th>SA-SSD [9]</th><th>CVPR 2020</th><th>Single</th><td>88.75</td><td>79.79</td><td>74.16</td></tr><tr><th>SE-SSD [38]</th><th>CVPR 2021</th><th>Single</th><td>91.49</td><td>82.54</td><td>77.15</td></tr><tr><th>RDIoU (Ours)</th><th>-</th><th>Single</th><td>90.65</td><td>82.30</td><td>77.26</td></tr></tbody></table>", "caption": "Table 2: Performance comparisons with state-of-the-art methods for car detection on the KITTI test benchmark with 40 recall positions. The top-1 of two-stage and single-stage methods are bold, respectively.", "list_citation_info": ["[13] Li, Z., Wang, F., Wang, N.: Lidar r-cnn: An efficient and universal 3d object detector. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 7546\u20137555 (2021)", "[21] Sheng, H., Cai, S., Liu, Y., Deng, B., Huang, J., Hua, X.S., Zhao, M.J.: Improving 3d object detection with channel-wise transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 2743\u20132752 (2021)", "[38] Zheng, W., Tang, W., Jiang, L., Fu, C.W.: Se-ssd: Self-ensembling single-stage object detector from point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 14494\u201314503 (2021)", "[35] Yang, Z., Sun, Y., Liu, S., Shen, X., Jia, J.: Std: Sparse-to-dense 3d object detector for point cloud. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 1951\u20131960 (2019)", "[10] Lang, A.H., Vora, S., Caesar, H., Zhou, L., Yang, J., Beijbom, O.: Pointpillars: Fast encoders for object detection from point clouds. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 12697\u201312705 (2019)", "[16] Mao, J., Xue, Y., Niu, M., Bai, H., Feng, J., Liang, X., Xu, H., Xu, C.: Voxel transformer for 3d object detection. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 3164\u20133173 (2021)", "[30] Xu, Q., Zhong, Y., Neumann, U.: Behind the curtain: Learning occluded shapes for 3d object detection. arXiv preprint arXiv:2112.02205 (2021)", "[25] Shi, W., Rajkumar, R.: Point-gnn: Graph neural network for 3d object detection in a point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 1711\u20131719 (2020)", "[22] Shi, S., Guo, C., Jiang, L., Wang, Z., Shi, J., Wang, X., Li, H.: Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 10529\u201310538 (2020)", "[43] Zhou, Y., Tuzel, O.: Voxelnet: End-to-end learning for point cloud based 3d object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4490\u20134499 (2018)", "[31] Yan, Y., Mao, Y., Li, B.: Second: Sparsely embedded convolutional detection. Sensors 18(10), 3337 (2018)", "[34] Yang, Z., Sun, Y., Liu, S., Jia, J.: 3dssd: Point-based 3d single stage object detector. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11040\u201311048 (2020)", "[24] Shi, S., Wang, Z., Shi, J., Wang, X., Li, H.: From points to parts: 3d object detection from point cloud with part-aware and part-aggregation network. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) (2020)", "[9] He, C., Zeng, H., Huang, J., Hua, X.S., Zhang, L.: Structure aware single-stage 3d object detection from point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11873\u201311882 (2020)"]}, {"table": "<table><tbody><tr><th rowspan=\"2\">Method</th><th rowspan=\"2\">Stage</th><td colspan=\"4\">3D AP/APH (IoU=0.7)</td><td colspan=\"4\">BEV AP/APH (IoU=0.7)</td></tr><tr><td>Overall</td><td>0-30m</td><td>30-50m</td><td>50m-Inf</td><td>Overall</td><td>0-30m</td><td>30-50m</td><td>50m-Inf</td></tr><tr><th colspan=\"10\">LEVEL_1</th></tr><tr><th>MVF [42]</th><th>Two</th><td>62.9/-</td><td>86.3/-</td><td>60.0/-</td><td>36.0/-</td><td>80.4/-</td><td>93.6/-</td><td>79.2/-</td><td>63.1/-</td></tr><tr><th>PV-RCNN [22]</th><th>Two</th><td>70.3/69.7</td><td>91.9/91.3</td><td>69.2/68.5</td><td>42.2/41.3</td><td>80.0/82.1</td><td>97.4/96.7</td><td>83.0/82.0</td><td>65.0/63.2</td></tr><tr><th>Voxel-RCNN [4]</th><th>Two</th><td>75.6/-</td><td>92.5/-</td><td>74.1/-</td><td>53.2/-</td><td>88.2/-</td><td>97.6/-</td><td>87.3/-</td><td>77.7/-</td></tr><tr><th>LiDAR-RCNN [13]</th><th>Two</th><td>76.0/75.5</td><td>92.1/91.6</td><td>74.6/74.1</td><td>54.5/53.4</td><td>90.1/89.3</td><td>97.0/96.5</td><td>89.5/88.6</td><td>78.9/77.4</td></tr><tr><th>CenterPoint [36]</th><th>Two</th><td>76.7/76.2</td><td>-/-</td><td>-/-</td><td>-/-</td><td></td><td>-/-</td><td>-/-</td><td>-/-</td></tr><tr><th>VoTr-TSD [16]</th><th>Two</th><td>75.0/74.3</td><td>92.3/91.7</td><td>73.4/72.6</td><td>51.1/50.0</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td></tr><tr><th>CT3D [21]</th><th>Two</th><td>76.3/-</td><td>92.5/-</td><td>75.1/-</td><td>55.4/-</td><td>90.5/-</td><td>97.6/-</td><td>88.1/-</td><td>78.9/-</td></tr><tr><th>BtcDet [30]</th><th>Two</th><td>78.6/78.1</td><td>96.1/-</td><td>77.6/-</td><td>54.5/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td></tr><tr><th>PointPillar* [10]</th><th>Single</th><td>72.1/71.5</td><td>88.3/87.8</td><td>69.9/69.3</td><td>48.0/47.3</td><td>87.9/87.1</td><td>96.6/96.0</td><td>87.1/86.2</td><td>78.1/76.5</td></tr><tr><th>Pillar-OD [29]</th><th>Single</th><td>69.8/-</td><td>88.5/-</td><td>66.5/-</td><td>42.9/-</td><td>87.1/-</td><td>95.8/-</td><td>84.7/-</td><td>72.1/-</td></tr><tr><th>VoTr-SSD [16]</th><th>Single</th><td>69.0/68.4</td><td>88.2/87.6</td><td>66.7/66.1</td><td>42.1/41.4</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td></tr><tr><th>RDIoU (Ours)</th><th>Single</th><td>78.4/78.0</td><td>93.0/92.6</td><td>75.4/74.9</td><td>56.2/55.6</td><td>91.6/91.0</td><td>98.1/97.7</td><td>90.8/90.2</td><td>82.4/81.1</td></tr><tr><th colspan=\"10\">LEVEL_2</th></tr><tr><th>PV-RCNN [22]</th><th>Two</th><td>65.4/64.8</td><td>91.6/91.0</td><td>65.1/64.5</td><td>36.5/35.7</td><td>77.5/76.6</td><td>94.6/94.0</td><td>80.4/79.4</td><td>55.4/53.8</td></tr><tr><th>Voxel-RCNN [4]</th><th>Two</th><td>66.6/-</td><td>91.7/-</td><td>67.9/-</td><td>40.8/-</td><td>81.1/-</td><td>97.0/-</td><td>81.4/-</td><td>63.3/-</td></tr><tr><th>LiDAR-RCNN [13]</th><th>Two</th><td>68.3/67.9</td><td>91.3/90.9</td><td>68.5/68.0</td><td>42.4/41.8</td><td>81.7/81.0</td><td>94.3/93.9</td><td>82.3/81.5</td><td>65.8/64.5</td></tr><tr><th>CenterPoint [36]</th><th>Two</th><td>68.8/68.3</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td></tr><tr><th>VoTr-TSD [16]</th><th>Two</th><td>65.9/65.3</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td></tr><tr><th>CT3D [21]</th><th>Two</th><td>69.0/-</td><td>91.8/-</td><td>68.9/-</td><td>42.6/-</td><td>81.7/-</td><td>97.1/-</td><td>82.2/-</td><td>64.3/-</td></tr><tr><th>BtcDet [30]</th><th>Two</th><td>70.1/69.6</td><td>96.0/-</td><td>70.1/-</td><td>43.9/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td></tr><tr><th>PointPillars* [10]</th><th>Single</th><td>63.6/63.1</td><td>87.4/86.9</td><td>62.9/62.3</td><td>37.2/36.7</td><td>81.3/80.4</td><td>94.0/93.5</td><td>81.7/80.8</td><td>65.5/64.1</td></tr><tr><th>VoTr-SSD [16]</th><th>Single</th><td>60.2/59.7</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td><td>-/-</td></tr><tr><th>RDIoU (Ours)</th><th>Single</th><td>69.5/69.1</td><td>92.3/91.9</td><td>69.3/68.9</td><td>43.7/43.1</td><td>83.1/82.5</td><td>97.5/97.1</td><td>85.2/84.6</td><td>68.3/67.2</td></tr></tbody></table>", "caption": "Table 3: Performance comparisons with state-of-the-art methods for the vehicle detection on the Waymo validation dataset. Here PointPillars* is implemented in mmdetection3D [3]. The top-1 of two-stage and single-stage methods are bold, respectively.", "list_citation_info": ["[29] Wang, Y., Fathi, A., Kundu, A., Ross, D.A., Pantofaru, C., Funkhouser, T., Solomon, J.: Pillar-based object detection for autonomous driving. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 18\u201334 (2020)", "[4] Deng, J., Shi, S., Li, P., Zhou, W., Zhang, Y., Li, H.: Voxel r-cnn: Towards high performance voxel-based 3d object detection. arXiv preprint arXiv:2012.15712 (2020)", "[13] Li, Z., Wang, F., Wang, N.: Lidar r-cnn: An efficient and universal 3d object detector. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 7546\u20137555 (2021)", "[42] Zhou, Y., Sun, P., Zhang, Y., Anguelov, D., Gao, J., Ouyang, T., Guo, J., Ngiam, J., Vasudevan, V.: End-to-end multi-view fusion for 3d object detection in lidar point clouds. In: Conference on Robot Learning (CoRL). pp. 923\u2013932 (2020)", "[21] Sheng, H., Cai, S., Liu, Y., Deng, B., Huang, J., Hua, X.S., Zhao, M.J.: Improving 3d object detection with channel-wise transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 2743\u20132752 (2021)", "[10] Lang, A.H., Vora, S., Caesar, H., Zhou, L., Yang, J., Beijbom, O.: Pointpillars: Fast encoders for object detection from point clouds. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 12697\u201312705 (2019)", "[16] Mao, J., Xue, Y., Niu, M., Bai, H., Feng, J., Liang, X., Xu, H., Xu, C.: Voxel transformer for 3d object detection. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 3164\u20133173 (2021)", "[30] Xu, Q., Zhong, Y., Neumann, U.: Behind the curtain: Learning occluded shapes for 3d object detection. arXiv preprint arXiv:2112.02205 (2021)", "[36] Yin, T., Zhou, X., Krahenbuhl, P.: Center-based 3d object detection and tracking. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11784\u201311793 (2021)", "[22] Shi, S., Guo, C., Jiang, L., Wang, Z., Shi, J., Wang, X., Li, H.: Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 10529\u201310538 (2020)", "[3] Contributors, M.: MMDetection3D: OpenMMLab next-generation platform for general 3D object detection. https://github.com/open-mmlab/mmdetection3d (2020)"]}, {"table": "<table><tbody><tr><th rowspan=\"2\">Method</th><td colspan=\"3\">\\text{3D}_{R11}</td><td>\\text{3D}_{R40}</td><td>FPS</td></tr><tr><td>Easy</td><td>Mod.</td><td>Hard</td><td>Mod.</td><td>(Hz)</td></tr><tr><th>PointPillar [10]</th><td>87.08</td><td>77.74</td><td>76.24</td><td>79.88</td><td>33.8</td></tr><tr><th>PointPillar (+RDIoU)</th><td>88.89</td><td>78.89</td><td>78.02</td><td>82.42</td><td>33.8</td></tr><tr><th>SECOND [31]</th><td>88.78</td><td>78.74</td><td>77.51</td><td>82.85</td><td>30.5</td></tr><tr><th>SECOND (+RDIoU)</th><td>89.24</td><td>86.10</td><td>78.60</td><td>85.80</td><td>30.5</td></tr><tr><th>CT-stacked</th><td>88.93</td><td>78.91</td><td>77.63</td><td>83.01</td><td>26.6</td></tr><tr><th>CT-stacked (+RDIoU)</th><td>89.76</td><td>86.62</td><td>79.04</td><td>86.20</td><td>26.6</td></tr></tbody></table>", "caption": "Table 4: Ablation study on different backbone networks. (+RDIoU) means replacing the classification and regression losses in baseline models with our proposed RDIoU.", "list_citation_info": ["[10] Lang, A.H., Vora, S., Caesar, H., Zhou, L., Yang, J., Beijbom, O.: Pointpillars: Fast encoders for object detection from point clouds. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 12697\u201312705 (2019)", "[31] Yan, Y., Mao, Y., Li, B.: Second: Sparsely embedded convolutional detection. Sensors 18(10), 3337 (2018)"]}, {"table": "<table><tbody><tr><td rowspan=\"2\">Method</td><td>3D IoU</td><td>RDIoU</td><td colspan=\"3\">\\text{3D}_{R11}</td><td>\\text{3D}_{R40}</td></tr><tr><td>guided</td><td>guided</td><td>Easy</td><td>Mod.</td><td>Hard</td><td>Mod.</td></tr><tr><td>Smooth-\\ell 1 loss [14]</td><td></td><td></td><td>89.19</td><td>78.86</td><td>77.53</td><td>83.14</td></tr><tr><td rowspan=\"2\">IoU loss [41]</td><td>\u2713</td><td></td><td>88.80</td><td>81.94</td><td>77.67</td><td>83.60</td></tr><tr><td></td><td>\u2713</td><td>89.40</td><td>85.60</td><td>78.76</td><td>85.73</td></tr><tr><td rowspan=\"2\">CIoU loss [40]</td><td>\u2713</td><td></td><td>88.82</td><td>83.20</td><td>77.48</td><td>84.01</td></tr><tr><td></td><td>\u2713</td><td>89.43</td><td>86.21</td><td>78.90</td><td>85.98</td></tr><tr><td rowspan=\"2\">DIoU loss [40]</td><td>\u2713</td><td></td><td>88.83</td><td>83.59</td><td>77.93</td><td>84.20</td></tr><tr><td></td><td>\u2713</td><td>89.76</td><td>86.62</td><td>79.04</td><td>86.20</td></tr></tbody></table>", "caption": "Table 5: Ablation study on RDIoU-guided regression loss. All models utilize RDIoU-guided quality focal loss for classification.", "list_citation_info": ["[40] Zheng, Z., Wang, P., Liu, W., Li, J., Ye, R., Ren, D.: Distance-iou loss: Faster and better learning for bounding box regression. In: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI). vol. 34, pp. 12993\u201313000 (2020)", "[14] Lin, T.Y., Goyal, P., Girshick, R., He, K., Doll\u00e1r, P.: Focal loss for dense object detection. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 2980\u20132988 (2017)", "[41] Zhou, D., Fang, J., Song, X., Guan, C., Yin, J., Dai, Y., Yang, R.: Iou loss for 2d/3d object detection. In: International Conference on 3D Vision (3DV). pp. 85\u201394. IEEE (2019)"]}, {"table": "<table><thead><tr><th rowspan=\"2\">Method</th><th colspan=\"3\">\\text{3D}_{R11}</th><th>\\text{3D}_{R40}</th></tr><tr><th>Easy</th><th>Mod.</th><th>Hard</th><th>Mod.</th></tr></thead><tbody><tr><th>PointPillar[10]</th><td>87.08</td><td>77.74</td><td>76.24</td><td>79.88</td></tr><tr><th>PointPillar (+3D IoU)</th><td>86.91</td><td>77.93</td><td>76.83</td><td>80.12</td></tr><tr><th>PointPillar (+ODIoU)</th><td>87.15</td><td>78.29</td><td>77.08</td><td>80.58</td></tr><tr><th>PointPillar (+RDIoU)</th><td>88.89</td><td>78.89</td><td>78.02</td><td>82.42</td></tr><tr><th>SECOND[31]</th><td>88.78</td><td>78.74</td><td>77.51</td><td>82.85</td></tr><tr><th>SECOND (+3D IoU)</th><td>88.04</td><td>80.97</td><td>77.06</td><td>83.02</td></tr><tr><th>SECOND (+ODIoU)</th><td>88.69</td><td>82.82</td><td>77.41</td><td>83.88</td></tr><tr><th>SECOND (+RDIoU)</th><td>89.24</td><td>86.10</td><td>78.60</td><td>85.80</td></tr><tr><th>CT-stacked</th><td>88.93</td><td>78.91</td><td>77.63</td><td>83.01</td></tr><tr><th>CT-stacked (+3D IoU)</th><td>88.23</td><td>81.09</td><td>77.16</td><td>83.29</td></tr><tr><th>CT-stacked (+ODIoU)</th><td>88.70</td><td>82.89</td><td>77.53</td><td>84.01</td></tr><tr><th>CT-stacked (+RDIoU)</th><td>89.76</td><td>86.62</td><td>79.04</td><td>86.20</td></tr></tbody></table>", "caption": "Table 8: Comparisons to 3D IoU and ODIoU.", "list_citation_info": ["[10] Lang, A.H., Vora, S., Caesar, H., Zhou, L., Yang, J., Beijbom, O.: Pointpillars: Fast encoders for object detection from point clouds. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 12697\u201312705 (2019)", "[31] Yan, Y., Mao, Y., Li, B.: Second: Sparsely embedded convolutional detection. Sensors 18(10), 3337 (2018)"]}, {"table": "<table><tbody><tr><th rowspan=\"2\">Type</th><th rowspan=\"2\">Method</th><td colspan=\"3\">\\text{3D}_{R11}</td><td>\\text{3D}_{R40}</td></tr><tr><td>Easy</td><td>Mod.</td><td>Hard</td><td>Mod.</td></tr><tr><th rowspan=\"6\">Single-stage</th><th>CIA-SSD[37]</th><td>89.48</td><td>78.54</td><td>77.35</td><td>81.93</td></tr><tr><th>CIA-SSD (+RDIoU)</th><td>89.07</td><td>85.44</td><td>78.55</td><td>85.23</td></tr><tr><th>SA-SSD[9]</th><td>89.26</td><td>79.28</td><td>78.35</td><td>82.65</td></tr><tr><th>SA-SSD (+RDIoU)</th><td>89.56</td><td>86.04</td><td>78.76</td><td>85.87</td></tr><tr><th>SE-SSD[38]</th><td>89.07</td><td>79.22</td><td>78.37</td><td>82.48</td></tr><tr><th>SE-SSD (+RDIoU)</th><td>89.24</td><td>85.98</td><td>78.60</td><td>85.24</td></tr><tr><th rowspan=\"6\">Two-stage</th><th>PV-RCNN[22]</th><td>89.31</td><td>84.49</td><td>78.78</td><td>84.93</td></tr><tr><th>PV-RCNN (+RDIoU)</th><td>89.47</td><td>86.21</td><td>79.01</td><td>85.96</td></tr><tr><th>Voxel-RCNN[4]</th><td>89.44</td><td>84.45</td><td>78.90</td><td>85.24</td></tr><tr><th>Voxel-RCNN (+RDIoU)</th><td>89.67</td><td>86.12</td><td>78.91</td><td>85.92</td></tr><tr><th>CT3D[21]</th><td>89.54</td><td>86.06</td><td>78.99</td><td>85.82</td></tr><tr><th>CT3D (+RDIoU)</th><td>89.31</td><td>86.27</td><td>78.90</td><td>85.94</td></tr></tbody></table>", "caption": "Table 9: Inserting our RDIoU into SOTA methods based on OpenPCDet[27].", "list_citation_info": ["[4] Deng, J., Shi, S., Li, P., Zhou, W., Zhang, Y., Li, H.: Voxel r-cnn: Towards high performance voxel-based 3d object detection. arXiv preprint arXiv:2012.15712 (2020)", "[38] Zheng, W., Tang, W., Jiang, L., Fu, C.W.: Se-ssd: Self-ensembling single-stage object detector from point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 14494\u201314503 (2021)", "[21] Sheng, H., Cai, S., Liu, Y., Deng, B., Huang, J., Hua, X.S., Zhao, M.J.: Improving 3d object detection with channel-wise transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 2743\u20132752 (2021)", "[27] Team, O.D.: Openpcdet: An open-source toolbox for 3d object detection from point clouds. https://github.com/open-mmlab/OpenPCDet (2020)", "[22] Shi, S., Guo, C., Jiang, L., Wang, Z., Shi, J., Wang, X., Li, H.: Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 10529\u201310538 (2020)", "[37] Zheng, W., Tang, W., Chen, S., Jiang, L., Fu, C.W.: Cia-ssd: Confident iou-aware single-stage object detector from point cloud. arXiv preprint arXiv:2012.03015 (2020)", "[9] He, C., Zeng, H., Huang, J., Hua, X.S., Zhang, L.: Structure aware single-stage 3d object detection from point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11873\u201311882 (2020)"]}], "citation_info_to_title": {"[35] Yang, Z., Sun, Y., Liu, S., Shen, X., Jia, J.: Std: Sparse-to-dense 3d object detector for point cloud. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 1951\u20131960 (2019)": "Std: Sparse-to-dense 3d object detector for point cloud", "[30] Xu, Q., Zhong, Y., Neumann, U.: Behind the curtain: Learning occluded shapes for 3d object detection. arXiv preprint arXiv:2112.02205 (2021)": "Behind the curtain: Learning occluded shapes for 3d object detection", "[21] Sheng, H., Cai, S., Liu, Y., Deng, B., Huang, J., Hua, X.S., Zhao, M.J.: Improving 3d object detection with channel-wise transformer. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 2743\u20132752 (2021)": "Improving 3D Object Detection with Channel-wise Transformer", "[40] Zheng, Z., Wang, P., Liu, W., Li, J., Ye, R., Ren, D.: Distance-iou loss: Faster and better learning for bounding box regression. In: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI). vol. 34, pp. 12993\u201313000 (2020)": "Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression", "[25] Shi, W., Rajkumar, R.: Point-gnn: Graph neural network for 3d object detection in a point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 1711\u20131719 (2020)": "Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud", "[9] He, C., Zeng, H., Huang, J., Hua, X.S., Zhang, L.: Structure aware single-stage 3d object detection from point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11873\u201311882 (2020)": "Structure aware single-stage 3d object detection from point cloud", "[10] Lang, A.H., Vora, S., Caesar, H., Zhou, L., Yang, J., Beijbom, O.: Pointpillars: Fast encoders for object detection from point clouds. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 12697\u201312705 (2019)": "Pointpillars: Fast Encoders for Object Detection from Point Clouds", "[31] Yan, Y., Mao, Y., Li, B.: Second: Sparsely embedded convolutional detection. Sensors 18(10), 3337 (2018)": "Second: Sparsely embedded convolutional detection", "[29] Wang, Y., Fathi, A., Kundu, A., Ross, D.A., Pantofaru, C., Funkhouser, T., Solomon, J.: Pillar-based object detection for autonomous driving. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 18\u201334 (2020)": "Pillar-based object detection for autonomous driving", "[34] Yang, Z., Sun, Y., Liu, S., Jia, J.: 3dssd: Point-based 3d single stage object detector. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11040\u201311048 (2020)": "3dssd: Point-based 3d single stage object detector", "[27] Team, O.D.: Openpcdet: An open-source toolbox for 3d object detection from point clouds. https://github.com/open-mmlab/OpenPCDet (2020)": "OpenPCDet: An Open-Source Toolbox for 3D Object Detection from Point Clouds", "[41] Zhou, D., Fang, J., Song, X., Guan, C., Yin, J., Dai, Y., Yang, R.: Iou loss for 2d/3d object detection. In: International Conference on 3D Vision (3DV). pp. 85\u201394. IEEE (2019)": "IOU Loss for 2D/3D Object Detection", "[24] Shi, S., Wang, Z., Shi, J., Wang, X., Li, H.: From points to parts: 3d object detection from point cloud with part-aware and part-aggregation network. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) (2020)": "From points to parts: 3D object detection from point cloud with part-aware and part-aggregation network", "[3] Contributors, M.: MMDetection3D: OpenMMLab next-generation platform for general 3D object detection. https://github.com/open-mmlab/mmdetection3d (2020)": "MMDetection3D: OpenMMLab next-generation platform for general 3D object detection", "[43] Zhou, Y., Tuzel, O.: Voxelnet: End-to-end learning for point cloud based 3d object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4490\u20134499 (2018)": "Voxelnet: End-to-end learning for point cloud based 3d object detection", "[14] Lin, T.Y., Goyal, P., Girshick, R., He, K., Doll\u00e1r, P.: Focal loss for dense object detection. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 2980\u20132988 (2017)": "Focal loss for dense object detection", "[22] Shi, S., Guo, C., Jiang, L., Wang, Z., Shi, J., Wang, X., Li, H.: Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 10529\u201310538 (2020)": "Pv-rcnn: Point-Voxel Feature Set Abstraction for 3D Object Detection", "[13] Li, Z., Wang, F., Wang, N.: Lidar r-cnn: An efficient and universal 3d object detector. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 7546\u20137555 (2021)": "Lidar r-cnn: An efficient and universal 3d object detector", "[36] Yin, T., Zhou, X., Krahenbuhl, P.: Center-based 3d object detection and tracking. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 11784\u201311793 (2021)": "Center-based 3D Object Detection and Tracking", "[42] Zhou, Y., Sun, P., Zhang, Y., Anguelov, D., Gao, J., Ouyang, T., Guo, J., Ngiam, J., Vasudevan, V.: End-to-end multi-view fusion for 3d object detection in lidar point clouds. In: Conference on Robot Learning (CoRL). pp. 923\u2013932 (2020)": "End-to-end multi-view fusion for 3D object detection in LiDAR point clouds", "[38] Zheng, W., Tang, W., Jiang, L., Fu, C.W.: Se-ssd: Self-ensembling single-stage object detector from point cloud. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). pp. 14494\u201314503 (2021)": "Se-ssd: Self-ensembling single-stage object detector from point cloud", "[16] Mao, J., Xue, Y., Niu, M., Bai, H., Feng, J., Liang, X., Xu, H., Xu, C.: Voxel transformer for 3d object detection. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). pp. 3164\u20133173 (2021)": "Voxel transformer for 3D object detection", "[37] Zheng, W., Tang, W., Chen, S., Jiang, L., Fu, C.W.: Cia-ssd: Confident iou-aware single-stage object detector from point cloud. arXiv preprint arXiv:2012.03015 (2020)": "Cia-ssd: Confident iou-aware single-stage object detector from point cloud", "[4] Deng, J., Shi, S., Li, P., Zhou, W., Zhang, Y., Li, H.: Voxel r-cnn: Towards high performance voxel-based 3d object detection. arXiv preprint arXiv:2012.15712 (2020)": "Voxel R-CNN: Towards High Performance Voxel-based 3D Object Detection"}, "source_title_to_arxiv_id": {"Improving 3D Object Detection with Channel-wise Transformer": "2108.10723", "Lidar r-cnn: An efficient and universal 3d object detector": "2103.15297"}}