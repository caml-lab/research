{"title": "Positive Pair Distillation Considered Harmful: Continual Meta Metric Learning for Lifelong Object Re-Identification", "abstract": "Lifelong object re-identification incrementally learns from a stream of\nre-identification tasks. The objective is to learn a representation that can be\napplied to all tasks and that generalizes to previously unseen\nre-identification tasks. The main challenge is that at inference time the\nrepresentation must generalize to previously unseen identities. To address this\nproblem, we apply continual meta metric learning to lifelong object\nre-identification. To prevent forgetting of previous tasks, we use knowledge\ndistillation and explore the roles of positive and negative pairs. Based on our\nobservation that the distillation and metric losses are antagonistic, we\npropose to remove positive pairs from distillation to robustify model updates.\nOur method, called Distillation without Positive Pairs (DwoPP), is evaluated on\nextensive intra-domain experiments on person and vehicle re-identification\ndatasets, as well as inter-domain experiments on the LReID benchmark. Our\nexperiments demonstrate that DwoPP significantly outperforms the\nstate-of-the-art. The code is here: https://github.com/wangkai930418/DwoPP_code", "authors": ["Kai Wang", "Chenshen Wu", "Andy Bagdanov", "Xialei Liu", "Shiqi Yang", "Shangling Jui", "Joost van de Weijer"], "published_date": "2022_10_04", "pdf_url": "http://arxiv.org/pdf/2210.01600v1", "list_table_and_caption": [{"table": "<table><tbody><tr><th>Metric:</th><td colspan=\"6\">mAP</td><td colspan=\"6\">Rank-1 Accuracy</td></tr><tr><th>Dataset:</th><td colspan=\"2\">Market</td><td colspan=\"2\">MSMT17</td><td colspan=\"2\">VeRi-776</td><td colspan=\"2\">Market</td><td colspan=\"2\">MSMT17</td><td colspan=\"2\">VeRi-776</td></tr><tr><th colspan=\"13\">Based on episodic optimization with DMML loss [Chen et al.(2019b)Chen, Zhang, Lu, andZhou]</th></tr><tr><th>Joint training:</th><td colspan=\"2\">82.2</td><td colspan=\"2\">44.7</td><td colspan=\"2\">73.6</td><td colspan=\"2\">92.6</td><td colspan=\"2\">68.9</td><td colspan=\"2\">92.1</td></tr><tr><th>Sessions:</th><td>last</td><td>avg</td><td>last</td><td>avg</td><td>last</td><td>avg</td><td>last</td><td>avg</td><td>last</td><td>avg</td><td>last</td><td>avg</td></tr><tr><th colspan=\"13\">without exemplars</th></tr><tr><th>DMML-FT (ICCV\u201919)</th><td>56.3</td><td>49.1</td><td>10.9</td><td>10.0</td><td>30.8</td><td>29.3</td><td>77.8</td><td>71.5</td><td>28.9</td><td>27.4</td><td>70.3</td><td>62.4</td></tr><tr><th>IDA (ECCV\u201920)</th><td>32.2</td><td>37.8</td><td>19.2</td><td>16.8</td><td>21.0</td><td>18.4</td><td>58.7</td><td>63.1</td><td>45.6</td><td>38.2</td><td>56.6</td><td>45.4</td></tr><tr><th>DwPP</th><td>57.8</td><td>48.4</td><td>16.3</td><td>13.3</td><td>30.9</td><td>28.9</td><td>78.1</td><td>70.7</td><td>39.0</td><td>33.9</td><td>71.7</td><td>63.3</td></tr><tr><th>Ours (DwoPP)</th><td>67.2</td><td>57.6</td><td>23.8</td><td>19.1</td><td>39.9</td><td>35.3</td><td>84.6</td><td>77.1</td><td>51.0</td><td>42.6</td><td>78.5</td><td>69.3</td></tr><tr><th colspan=\"13\">with 500 exemplars in total</th></tr><tr><th>ERD (CVPRW\u201922)</th><td>63.5</td><td>53.9</td><td>21.7</td><td>17.2</td><td>38.2</td><td>33.8</td><td>81.8</td><td>74.5</td><td>46.6</td><td>39.4</td><td>72.9</td><td>65.5</td></tr><tr><th colspan=\"13\">Based on global optimization with softmax-triplet loss from BoT [Luo et al.(2019)Luo, Gu, Liao, Lai, andJiang]</th></tr><tr><th>Joint training:</th><td colspan=\"2\">82.4</td><td colspan=\"2\">43.2</td><td colspan=\"2\">69.2</td><td colspan=\"2\">93.0</td><td colspan=\"2\">71.1</td><td colspan=\"2\">92.7</td></tr><tr><th>Sessions:</th><td>last</td><td>avg</td><td>last</td><td>avg</td><td>last</td><td>avg</td><td>last</td><td>avg</td><td>last</td><td>avg</td><td>last</td><td>avg</td></tr><tr><th colspan=\"13\">without exemplars</th></tr><tr><th>BoT-FT (CVPR\u201919)</th><td>30.7</td><td>33.5</td><td>6.6</td><td>8.4</td><td>25.8</td><td>24.9</td><td>55.4</td><td>58.8</td><td>20.6</td><td>25.4</td><td>65.3</td><td>62.1</td></tr><tr><th>LwF (ECCV\u201916)</th><td>40.5</td><td>40.2</td><td>10.7</td><td>11.8</td><td>31.2</td><td>28.1</td><td>65.9</td><td>65.4</td><td>30.3</td><td>32.3</td><td>71.3</td><td>65.8</td></tr><tr><th>PASS (CVPR\u201921)</th><td>40.0</td><td>40.1</td><td>9.9</td><td>11.6</td><td>30.7</td><td>27.3</td><td>65.8</td><td>64.2</td><td>29.7</td><td>31.9</td><td>70.9</td><td>64.4</td></tr><tr><th>AKA (CVPR\u201921)</th><td>52.5</td><td>45.6</td><td>15.1</td><td>13.3</td><td>30.9</td><td>27.1</td><td>76.2</td><td>69.9</td><td>37.3</td><td>34.6</td><td>72.9</td><td>64.4</td></tr><tr><th colspan=\"13\">with 500 exemplars in total</th></tr><tr><th>BoT-FT+ (CVPR\u201919)</th><td>61.5</td><td>52.4</td><td>21.5</td><td>17.5</td><td>36.7</td><td>32.3</td><td>81.0</td><td>74.4</td><td>47.7</td><td>41.3</td><td>76.2</td><td>69.6</td></tr><tr><th>iCaRL (CVPR\u201917)</th><td>58.0</td><td>52.2</td><td>21.6</td><td>18.3</td><td>38.0</td><td>33.3</td><td>78.7</td><td>74.5</td><td>47.5</td><td>42.2</td><td>78.1</td><td>70.9</td></tr><tr><th>LwF+ (ECCV\u201916)</th><td>60.7</td><td>54.0</td><td>20.8</td><td>17.5</td><td>38.3</td><td>33.3</td><td>80.3</td><td>75.4</td><td>46.6</td><td>40.8</td><td>77.9</td><td>70.1</td></tr></tbody></table>", "caption": "Table 1: Results in mAP and Rank-1 Accuracy (in %) after last task and average over all tasks. The top half reports results for meta metric learning, and the lower half for global optimization methods using the softmax-triplet loss (BoT [Luo et al.(2019)Luo, Gu, Liao, Lai, andJiang]). Results are further split into methods with and without exemplars. The best exemplar-free results are highlighted in bold.", "list_citation_info": ["[Luo et al.(2019)Luo, Gu, Liao, Lai, and Jiang] Hao Luo, Youzhi Gu, Xingyu Liao, Shenqi Lai, and Wei Jiang. Bag of tricks and a strong baseline for deep person re-identification. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2019.", "[Chen et al.(2019b)Chen, Zhang, Lu, and Zhou] Guangyi Chen, Tianren Zhang, Jiwen Lu, and Jie Zhou. Deep meta metric learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9547\u20139556, 2019b."]}, {"table": "<table><thead><tr><th></th><th colspan=\"6\">mAP</th><th colspan=\"6\">Rank-1 Accuracy</th></tr><tr><th></th><th>market</th><th>sysu</th><th>msmt17</th><th>cuhk03</th><th>seen avg.</th><th>unseen</th><th>market</th><th>sysu</th><th>msmt17</th><th>cuhk03</th><th>seen avg.</th><th>unseen</th></tr></thead><tbody><tr><td>BoT-FT</td><td>11.6</td><td>54.6</td><td>0.8</td><td>31.2</td><td>24.6</td><td>32.4</td><td>31.6</td><td>61.6</td><td>2.8</td><td>35.1</td><td>32.8</td><td>32.8</td></tr><tr><td>LwF</td><td>21.0</td><td>58.0</td><td>1.7</td><td>48.0</td><td>32.2</td><td>43.3</td><td>46.5</td><td>64.7</td><td>5.8</td><td>53.8</td><td>42.7</td><td>42.9</td></tr><tr><td>AKA</td><td>18.7</td><td>56.3</td><td>1.6</td><td>48.6</td><td>31.3</td><td>43.6</td><td>42.3</td><td>63.1</td><td>5.8</td><td>53.9</td><td>41.3</td><td>43.6</td></tr><tr><td>DMML-FT</td><td>22.5</td><td>56.8</td><td>2.3</td><td>67.0</td><td>37.2</td><td>42.8</td><td>47.3</td><td>62.6</td><td>8.4</td><td>73.8</td><td>48.0</td><td>42.6</td></tr><tr><td>DwPP</td><td>23.2</td><td>56.7</td><td>2.2</td><td>67.9</td><td>37.5</td><td>44.7</td><td>49.1</td><td>63.2</td><td>7.5</td><td>72.4</td><td>48.0</td><td>44.2</td></tr><tr><td>Ours (DwoPP)</td><td>34.4</td><td>67.3</td><td>4.1</td><td>53.5</td><td>39.8</td><td>48.5</td><td>58.6</td><td>73.0</td><td>12.3</td><td>59.6</td><td>50.9</td><td>47.8</td></tr></tbody></table>", "caption": "Table 2: Results after learning the last task.BoT [Luo et al.(2019)Luo, Gu, Liao, Lai, andJiang] (above) and DMML [Chen et al.(2019b)Chen, Zhang, Lu, andZhou] (below).", "list_citation_info": ["[Luo et al.(2019)Luo, Gu, Liao, Lai, and Jiang] Hao Luo, Youzhi Gu, Xingyu Liao, Shenqi Lai, and Wei Jiang. Bag of tricks and a strong baseline for deep person re-identification. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2019.", "[Chen et al.(2019b)Chen, Zhang, Lu, and Zhou] Guangyi Chen, Tianren Zhang, Jiwen Lu, and Jie Zhou. Deep meta metric learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9547\u20139556, 2019b."]}, {"table": "<table><thead><tr><th></th><th></th><th>DwoPP</th><th colspan=\"4\">DKD [Zhao et al.(2022)Zhao, Cui, Song, Qiu, and Liang]</th><th>DwPP</th></tr></thead><tbody><tr><td></td><td>\\alpha</td><td>0.0</td><td>0.1</td><td>0.3</td><td>0.5</td><td>1.0</td><td>1.0</td></tr><tr><td></td><td>\\beta</td><td>1.0</td><td>0.9</td><td>0.7</td><td>0.5</td><td>0.0</td><td>1-\\rho</td></tr><tr><td rowspan=\"2\">mAP</td><td>last</td><td>67.2</td><td>62.9</td><td>48.2</td><td>36.0</td><td>25.9</td><td>32.8</td></tr><tr><td>avg</td><td>57.6</td><td>53.7</td><td>46.8</td><td>39.1</td><td>32.1</td><td>37.8</td></tr></tbody></table>", "caption": "Table 3: Decoupling Eq. 6 into PPKD and NPKD with coefficients \\alpha and \\beta on Market-1501 with temperature T=1.0. \\rho is the positive probabilities as in DKD [Zhao et al.(2022)Zhao, Cui, Song, Qiu, and Liang].", "list_citation_info": ["[Zhao et al.(2022)Zhao, Cui, Song, Qiu, and Liang] Borui Zhao, Quan Cui, Renjie Song, Yiyu Qiu, and Jiajun Liang. Decoupled knowledge distillation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 11953\u201311962, 2022."]}], "citation_info_to_title": {"[Luo et al.(2019)Luo, Gu, Liao, Lai, and Jiang] Hao Luo, Youzhi Gu, Xingyu Liao, Shenqi Lai, and Wei Jiang. Bag of tricks and a strong baseline for deep person re-identification. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2019.": "Bag of tricks and a strong baseline for deep person re-identification", "[Chen et al.(2019b)Chen, Zhang, Lu, and Zhou] Guangyi Chen, Tianren Zhang, Jiwen Lu, and Jie Zhou. Deep meta metric learning. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9547\u20139556, 2019b.": "Deep meta metric learning", "[Zhao et al.(2022)Zhao, Cui, Song, Qiu, and Liang] Borui Zhao, Quan Cui, Renjie Song, Yiyu Qiu, and Jiajun Liang. Decoupled knowledge distillation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 11953\u201311962, 2022.": "Decoupled knowledge distillation"}, "source_title_to_arxiv_id": {"Decoupled knowledge distillation": "2203.08679"}}