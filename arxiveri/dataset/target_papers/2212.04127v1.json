{"title": "Progressive Multi-resolution Loss for Crowd Counting", "abstract": "Crowd counting is usually handled in a density map regression fashion, which\nis supervised via a L2 loss between the predicted density map and ground truth.\nTo effectively regulate models, various improved L2 loss functions have been\nproposed to find a better correspondence between predicted density and\nannotation positions. In this paper, we propose to predict the density map at\none resolution but measure the density map at multiple resolutions. By\nmaximizing the posterior probability in such a setting, we obtain a log-formed\nmulti-resolution L2-difference loss, where the traditional single-resolution L2\nloss is its particular case. We mathematically prove it is superior to a\nsingle-resolution L2 loss. Without bells and whistles, the proposed loss\nsubstantially improves several baselines and performs favorably compared to\nstate-of-the-art methods on four crowd counting datasets, ShanghaiTech A & B,\nUCF-QNRF, and JHU-Crowd++.", "authors": ["Ziheng Yan", "Yuankai Qi", "Guorong Li", "Xinyan Liu", "Weigang Zhang", "Qingming Huang", "Ming-Hsuan Yang"], "published_date": "2022_12_08", "pdf_url": "http://arxiv.org/pdf/2212.04127v1", "list_table_and_caption": [{"table": "<table><tbody><tr><td></td><td colspan=\"2\">JHU-Crowd++</td><td colspan=\"2\">UCF-QNRF</td><td colspan=\"2\">ShanghaiTech A</td><td colspan=\"2\">ShanghaiTech B</td></tr><tr><td></td><td>MAE \\downarrow</td><td>MSE \\downarrow</td><td>MAE \\downarrow</td><td>MSE \\downarrow</td><td>MAE \\downarrow</td><td>MSE \\downarrow</td><td>MAE \\downarrow</td><td>MSE \\downarrow</td></tr><tr><td>FIDT  [11]</td><td>66.6</td><td>253.6</td><td>89.0</td><td>153.5</td><td>57.0</td><td>103.4</td><td>6.9</td><td>11.8</td></tr><tr><td>Ours + FIDT</td><td>62.3(-4.3)</td><td>261.9(+8.3)</td><td>87.2(-1.8)</td><td>151.9(-1.6)</td><td>54.5(-2.5)</td><td>92.7(-10.7)</td><td>6.9(-0.0)</td><td>9.8(-2.0)</td></tr><tr><td>FDC-18  [14]</td><td>-</td><td>-</td><td>93.0</td><td>157.3</td><td>65.4</td><td>109.2</td><td>11.4</td><td>19.1</td></tr><tr><td>Ours + FDC-18</td><td>-</td><td>-</td><td>82.1(-10.9)</td><td>153.5(-3.8)</td><td>62.3(-3.1)</td><td>101.1(-8.1)</td><td>6.7(-4.7)</td><td>10.8(-8.3)</td></tr><tr><td>FDC-ConvNeXtS</td><td>61.3</td><td>275.2</td><td>83.2</td><td>156.7</td><td>59.2</td><td>97.3</td><td>7.0</td><td>11.1</td></tr><tr><td>Ours + FDC-ConvNeXtS</td><td>55.2(-6.1)</td><td>232.4(-42.8)</td><td>79.9(-3.3)</td><td>132.5(-24.2)</td><td>53.4(-5.8)</td><td>93.1(-4.2)</td><td>6.2(-0.8)</td><td>9.7(-1.4)</td></tr></tbody></table>", "caption": "Table 1: Combination with open source state-of-the-art methods. RED indicates the decrease in MAE and MSE compared with the original methods. ", "list_citation_info": ["[14] Xinyan Liu, Guorong Li, Zhenjun Han, Weigang Zhang, Yifan Yang, Qingming Huang, and Nicu Sebe. Exploiting sample correlation for crowd counting with multi-expert network. In ICCV, pages 3195\u20133204, 2021.", "[11] Dingkang Liang, Wei Xu, Yingying Zhu, and Yu Zhou. Focal Inverse Distance Transform Maps for Crowd Localization. arXiv preprint arXiv:2102.07925, 2021."]}, {"table": "<table><thead><tr><th>Datasets</th><th>Number of objects</th><th>#Train</th><th>#Test</th></tr></thead><tbody><tr><th>JHU-Crowd++ [25]</th><td>[0, 7,286]</td><td>2,722</td><td>1,600</td></tr><tr><th>UCF-QNRF [6]</th><td>[49, 12,865]</td><td>1,201</td><td>334</td></tr><tr><th>ShanghaiTech A [38]</th><td>[33, 3,139]</td><td>482</td><td>300</td></tr><tr><th>ShanghaiTech B [38]</th><td>[9, 578]</td><td>716</td><td>400</td></tr></tbody></table>", "caption": "Table 2: Crowd counting benchmarks. The second column represents the range of the number of objects per image. #Train and #Test represent the size of the training and test image sets. ", "list_citation_info": ["[6] Haroon Idrees, Muhmmad Tayyab, Kishan Athrey, Dong Zhang, Somaya Al-M\u00e1adeed, Nasir M. Rajpoot, and Mubarak Shah. Composition Loss for Counting, Density Map Estimation and Localization in Dense Crowds. In ECCV, volume 11206, pages 544\u2013559, 2018.", "[38] Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, and Yi Ma. Single-Image Crowd Counting via Multi-Column Convolutional Neural network. In CVPR, pages 589\u2013597, 2016.", "[25] Vishwanath A. Sindagi, Rajeev Yasarla, and Vishal M. Patel. JHU-CROWD++: Large-Scale Crowd Counting Dataset and A Benchmark Method. IEEE TPAMI, 44(5):2594\u20132609, 2022."]}, {"table": "<table><thead><tr><th></th><th></th><th colspan=\"2\">JHU-Crowd++</th><th colspan=\"2\">UCF-QNRF</th><th colspan=\"2\">ShanghaiTech A</th><th colspan=\"2\">ShanghaiTech B</th></tr><tr><th></th><th></th><th>MAE \\downarrow</th><th>MSE \\downarrow</th><th>MAE \\downarrow</th><th>MSE \\downarrow</th><th>MAE \\downarrow</th><th>MSE \\downarrow</th><th>MAE \\downarrow</th><th>MSE \\downarrow</th></tr></thead><tbody><tr><td>BL  [19]</td><td>ICCV\u201919</td><td>75.0</td><td>299.9</td><td>88.7</td><td>154.8</td><td>62.8</td><td>101.8</td><td>7.7</td><td>12.7</td></tr><tr><td>NoiseCC  [28]</td><td>NeurIPS\u201920</td><td>67.7</td><td>258.5</td><td>85.8</td><td>150.6</td><td>61.9</td><td>99.6</td><td>7.4</td><td>11.3</td></tr><tr><td>DM count  [33]</td><td>NeurIPS\u201920</td><td>68.4</td><td>283.3</td><td>85.6</td><td>148.3</td><td>59.7</td><td>95.7</td><td>7.4</td><td>11.8</td></tr><tr><td>GL  [29]</td><td>CVPR\u201921</td><td>59.9</td><td>259.5</td><td>84.3</td><td>147.5</td><td>61.3</td><td>95.4</td><td>7.3</td><td>11.7</td></tr><tr><td>Ours</td><td></td><td>57.5</td><td>227.0</td><td>80.1</td><td>131.2</td><td>61.1</td><td>104.8</td><td>6.6</td><td>10.8</td></tr></tbody></table>", "caption": "Table 3: Comparison with state-of-the-art loss functions.", "list_citation_info": ["[29] Jia Wan, Ziquan Liu, and Antoni B. Chan. A Generalized Loss Function for Crowd Counting and Localization. In CVPR, pages 1974\u20131983, 2021.", "[33] Boyu Wang, Huidong Liu, Dimitris Samaras, and Minh Hoai Nguyen. Distribution Matching for Crowd Counting. In NeurIPS, 2020.", "[19] Zhiheng Ma, Xing Wei, Xiaopeng Hong, and Yihong Gong. Bayesian Loss for Crowd Count Estimation With Point Supervision. In ICCV, pages 6141\u20136150, 2019.", "[28] Jia Wan and Antoni B. Chan. Modeling Noisy Annotations for Crowd Counting. In NeurIPS, 2020."]}, {"table": "<table><thead><tr><th></th><th></th><th></th><th colspan=\"2\">JHU-Crowd++</th><th colspan=\"2\">UCF-QNRF</th><th colspan=\"2\">ShanghaiTech A</th><th colspan=\"2\">ShanghaiTech B</th></tr><tr><th></th><th></th><th rowspan=\"-2\">Backbone</th><th>MAE \\downarrow</th><th>MSE \\downarrow</th><th>MAE \\downarrow</th><th>MSE \\downarrow</th><th>MAE \\downarrow</th><th>MSE \\downarrow</th><th>MAE \\downarrow</th><th>MSE \\downarrow</th></tr></thead><tbody><tr><td>MCNN  [38]</td><td>CVPR\u201916</td><td>-</td><td>188.9</td><td>483.4</td><td>277.0</td><td>426.0</td><td>110.2</td><td>173.2</td><td>26.4</td><td>41.3</td></tr><tr><td>SwitchCNN  [22]</td><td>CVPR\u201917</td><td>-</td><td>-</td><td>-</td><td>228.0</td><td>445.0</td><td>90.4</td><td>135.0</td><td>21.6</td><td>33.4</td></tr><tr><td>CSRNet  [10]</td><td>CVPR\u201918</td><td>VGG16</td><td>85.9</td><td>309.2</td><td>110.6</td><td>190.1</td><td>68.2</td><td>115.0</td><td>10.6</td><td>16.0</td></tr><tr><td>SANet  [1]</td><td>ECCV\u201918</td><td>-</td><td>91.1</td><td>320.4</td><td>-</td><td>-</td><td>67.0</td><td>104.5</td><td>8.4</td><td>13.6</td></tr><tr><td>CAN  [13]</td><td>CVPR\u201919</td><td>VGG16</td><td>100.1</td><td>314.0</td><td>107</td><td>183</td><td>62.3</td><td>100.0</td><td>7.8</td><td>12.2</td></tr><tr><td>SFCN  [35]</td><td>CVPR\u201919</td><td>ResNet101</td><td>77.5</td><td>297.6</td><td>102.0</td><td>171.4</td><td>64.8</td><td>107.5</td><td>7.6</td><td>13.0</td></tr><tr><td>MBTTBF  [24]</td><td>ICCV\u201919</td><td>VGG16</td><td>81.8</td><td>299.1</td><td>97.5</td><td>165.2</td><td>60.2</td><td>94.1</td><td>8.0</td><td>15.5</td></tr><tr><td>BL  [19]</td><td>ICCV\u201919</td><td>VGG19</td><td>75.0</td><td>299.9</td><td>88.7</td><td>154.8</td><td>62.8</td><td>101.8</td><td>7.7</td><td>12.7</td></tr><tr><td>KDMG  [32]</td><td>TPAMI\u201920</td><td>-</td><td>69.7</td><td>268.3</td><td>99.5</td><td>173.0</td><td>63.8</td><td>99.2</td><td>7.8</td><td>12.7</td></tr><tr><td>LSC-CNN  [21]</td><td>TPAMI\u201921</td><td>-</td><td>112.7</td><td>454.4</td><td>120.5</td><td>218.2</td><td>66.5</td><td>101.8</td><td>7.7</td><td>12.7</td></tr><tr><td>RPNet  [37]</td><td>CVPR\u201920</td><td>ResNet-101</td><td>-</td><td>-</td><td>-</td><td>-</td><td>61.2</td><td>96.9</td><td>8.1</td><td>11.6</td></tr><tr><td>AMRNet  [15]</td><td>ECCV\u201920</td><td>VGG16</td><td>-</td><td>-</td><td>86.6</td><td>152.2</td><td>61.6</td><td>98.4</td><td>7.0</td><td>11.0</td></tr><tr><td>NoiseCC  [28]</td><td>NeurIPS\u201920</td><td>VGG19</td><td>67.7</td><td>258.5</td><td>85.8</td><td>150.6</td><td>61.9</td><td>99.6</td><td>7.4</td><td>11.3</td></tr><tr><td>DM count  [33]</td><td>NeurIPS\u201920</td><td>VGG19</td><td>68.4</td><td>283.3</td><td>85.6</td><td>148.3</td><td>59.7</td><td>95.7</td><td>7.4</td><td>11.8</td></tr><tr><td>LA-Batch  [39]</td><td>TPAMI\u201921</td><td>VGG16</td><td>-</td><td>-</td><td>113.0</td><td>210.0</td><td>65.8</td><td>103.6</td><td>8.6</td><td>14.0</td></tr><tr><td>AutoScale  [36]</td><td>IJCV\u201921</td><td>VGG16</td><td>65.9</td><td>264.8</td><td>104.4</td><td>174.2</td><td>65.8</td><td>112.1</td><td>8.6</td><td>13.9</td></tr><tr><td>GL  [29]</td><td>CVPR\u201921</td><td>VGG19</td><td>59.9</td><td>259.5</td><td>84.3</td><td>147.5</td><td>61.3</td><td>95.4</td><td>7.3</td><td>11.7</td></tr><tr><td>P2PNet  [26]</td><td>ICCV\u201921</td><td>VGG16</td><td>-</td><td>-</td><td>85.3</td><td>154.5</td><td>52.7</td><td>85.1</td><td>6.2</td><td>9.9</td></tr><tr><td>SDA+BL  [18]</td><td>ICCV\u201921</td><td>VGG19</td><td>62.6</td><td>264.1</td><td>83.3</td><td>143.1</td><td>58.4</td><td>95.7</td><td>-</td><td>-</td></tr><tr><td>FIDT  [11]</td><td>arxiv</td><td>HRNet-W48</td><td>66.6</td><td>253.6</td><td>89.0</td><td>153.5</td><td>57.0</td><td>103.4</td><td>6.9</td><td>11.8</td></tr><tr><td>FDC-18  [14]</td><td>ICCV\u201921</td><td>ResNet-18</td><td>-</td><td>-</td><td>93.0</td><td>157.3</td><td>65.4</td><td>109.2</td><td>11.4</td><td>19.1</td></tr><tr><td>FDC-ConvNeXtS</td><td></td><td>ConvNeXtS</td><td>61.3</td><td>275.2</td><td>83.2</td><td>156.7</td><td>59.2</td><td>97.3</td><td>7.0</td><td>11.1</td></tr><tr><td>Ours + FIDT</td><td></td><td>HRNet-W48</td><td>62.3</td><td>261.9</td><td>87.2</td><td>151.9</td><td>54.5</td><td>92.7</td><td>6.9</td><td>9.8</td></tr><tr><td>Ours + FDC-18</td><td></td><td>ResNet-18</td><td>-</td><td>-</td><td>82.1</td><td>153.5</td><td>62.3</td><td>101.1</td><td>6.7</td><td>10.8</td></tr><tr><td>Ours + FDC-ConvNeXtS</td><td></td><td>ConvNeXtS</td><td>55.2</td><td>232.4</td><td>79.9</td><td>132.5</td><td>53.4</td><td>93.1</td><td>6.2</td><td>9.7</td></tr><tr><td>Ours + VGG16</td><td></td><td>VGG16</td><td>57.5</td><td>227.0</td><td>80.1</td><td>131.2</td><td>61.1</td><td>104.8</td><td>6.6</td><td>10.8</td></tr></tbody></table>", "caption": "Table 4: Comparison with state-of-the-art crowd Convnet methods.", "list_citation_info": ["[38] Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, and Yi Ma. Single-Image Crowd Counting via Multi-Column Convolutional Neural network. In CVPR, pages 589\u2013597, 2016.", "[14] Xinyan Liu, Guorong Li, Zhenjun Han, Weigang Zhang, Yifan Yang, Qingming Huang, and Nicu Sebe. Exploiting sample correlation for crowd counting with multi-expert network. In ICCV, pages 3195\u20133204, 2021.", "[36] Chenfeng Xu, Dingkang Liang, Yongchao Xu, Song Bai, Wei Zhan, Xiang Bai, and Masayoshi Tomizuka. Autoscale: Learning to Scale for Crowd Counting. IJCV, 130(2):405\u2013434, 2022.", "[26] Qingyu Song, Changan Wang, Zhengkai Jiang, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, and Yang Wu. Rethinking Counting and Localization in Crowds: A Purely Point-Based Framework. In ICCV, pages 3345\u20133354, 2021.", "[24] Vishwanath Sindagi and Vishal M. Patel. Multi-Level Bottom-Top and Top-Bottom Feature Fusion for Crowd Counting. In ICCV, pages 1002\u20131012, 2019.", "[13] Weizhe Liu, Mathieu Salzmann, and Pascal Fua. Context-Aware Crowd Counting. In CVPR, pages 5099\u20135108, 2019.", "[35] Qi Wang, Junyu Gao, Wei Lin, and Yuan Yuan. Learning From Synthetic Data for Crowd Counting in the Wild. In CVPR, pages 8198\u20138207, 2019.", "[11] Dingkang Liang, Wei Xu, Yingying Zhu, and Yu Zhou. Focal Inverse Distance Transform Maps for Crowd Localization. arXiv preprint arXiv:2102.07925, 2021.", "[15] Xiyang Liu, Jie Yang, Wenrui Ding, Tieqiang Wang, Zhijin Wang, and Junjun Xiong. Adaptive Mixture Regression Network with Local Counting Map for Crowd Counting. In ECCV, pages 241\u2013257, 2020.", "[1] Xinkun Cao, Zhipeng Wang, Yanyun Zhao, and Fei Su. Scale Aggregation Network for Accurate and Efficient Crowd Counting. In ECCV, pages 757\u2013773, 2018.", "[39] Joey Tianyi Zhou, Le Zhang, Jiawei Du, Xi Peng, Zhiwen Fang, Zhe Xiao, and Hongyuan Zhu. Locality-Aware Crowd Counting. IEEE TPAMI, 44(7):3602\u20133613, 2022.", "[19] Zhiheng Ma, Xing Wei, Xiaopeng Hong, and Yihong Gong. Bayesian Loss for Crowd Count Estimation With Point Supervision. In ICCV, pages 6141\u20136150, 2019.", "[32] Jia Wan, Qingzhong Wang, and Antoni B. Chan. Kernel-Based Density Map Generation for Dense Object Counting. IEEE TPAMI, 44(3):1357\u20131370, 2022.", "[21] Deepak Babu Sam, Skand Vishwanath Peri, Mukuntha Narayanan Sundararaman, Amogh Kamath, and R. Venkatesh Babu. Locate, Size, and Count: Accurately Resolving People in Dense Crowds via Detection. IEEE TPAMI, 43(8):2739\u20132751, 2021.", "[37] Yifan Yang, Guorong Li, Zhe Wu, Li Su, Qingming Huang, and Nicu Sebe. Reverse Perspective Network for Perspective-Aware Object Counting. In CVPR, pages 4373\u20134382, 2020.", "[29] Jia Wan, Ziquan Liu, and Antoni B. Chan. A Generalized Loss Function for Crowd Counting and Localization. In CVPR, pages 1974\u20131983, 2021.", "[18] Zhiheng Ma, Xiaopeng Hong, Xing Wei, Yunfeng Qiu, and Yihong Gong. Towards A Universal Model for Cross-Dataset Crowd Counting. In ICCV, pages 3185\u20133194, 2021.", "[10] Yuhong Li, Xiaofan Zhang, and Deming Chen. Csrnet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes. In CVPR, pages 1091\u20131100, 2018.", "[28] Jia Wan and Antoni B. Chan. Modeling Noisy Annotations for Crowd Counting. In NeurIPS, 2020.", "[22] Deepak Babu Sam, Shiv Surya, and R. Venkatesh Babu. Switching Convolutional Neural Network for Crowd Counting. In CVPR, pages 4031\u20134039, 2017.", "[33] Boyu Wang, Huidong Liu, Dimitris Samaras, and Minh Hoai Nguyen. Distribution Matching for Crowd Counting. In NeurIPS, 2020."]}], "citation_info_to_title": {"[36] Chenfeng Xu, Dingkang Liang, Yongchao Xu, Song Bai, Wei Zhan, Xiang Bai, and Masayoshi Tomizuka. Autoscale: Learning to Scale for Crowd Counting. IJCV, 130(2):405\u2013434, 2022.": "Autoscale: Learning to Scale for Crowd Counting", "[28] Jia Wan and Antoni B. Chan. Modeling Noisy Annotations for Crowd Counting. In NeurIPS, 2020.": "Modeling Noisy Annotations for Crowd Counting", "[6] Haroon Idrees, Muhmmad Tayyab, Kishan Athrey, Dong Zhang, Somaya Al-M\u00e1adeed, Nasir M. Rajpoot, and Mubarak Shah. Composition Loss for Counting, Density Map Estimation and Localization in Dense Crowds. In ECCV, volume 11206, pages 544\u2013559, 2018.": "Composition Loss for Counting, Density Map Estimation and Localization in Dense Crowds", "[10] Yuhong Li, Xiaofan Zhang, and Deming Chen. Csrnet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes. In CVPR, pages 1091\u20131100, 2018.": "CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes", "[24] Vishwanath Sindagi and Vishal M. Patel. Multi-Level Bottom-Top and Top-Bottom Feature Fusion for Crowd Counting. In ICCV, pages 1002\u20131012, 2019.": "Multi-Level Bottom-Top and Top-Bottom Feature Fusion for Crowd Counting", "[29] Jia Wan, Ziquan Liu, and Antoni B. Chan. A Generalized Loss Function for Crowd Counting and Localization. In CVPR, pages 1974\u20131983, 2021.": "A Generalized Loss Function for Crowd Counting and Localization", "[32] Jia Wan, Qingzhong Wang, and Antoni B. Chan. Kernel-Based Density Map Generation for Dense Object Counting. IEEE TPAMI, 44(3):1357\u20131370, 2022.": "Kernel-Based Density Map Generation for Dense Object Counting", "[13] Weizhe Liu, Mathieu Salzmann, and Pascal Fua. Context-Aware Crowd Counting. In CVPR, pages 5099\u20135108, 2019.": "Context-Aware Crowd Counting", "[19] Zhiheng Ma, Xing Wei, Xiaopeng Hong, and Yihong Gong. Bayesian Loss for Crowd Count Estimation With Point Supervision. In ICCV, pages 6141\u20136150, 2019.": "Bayesian Loss for Crowd Count Estimation With Point Supervision", "[11] Dingkang Liang, Wei Xu, Yingying Zhu, and Yu Zhou. Focal Inverse Distance Transform Maps for Crowd Localization. arXiv preprint arXiv:2102.07925, 2021.": "Focal Inverse Distance Transform Maps for Crowd Localization", "[15] Xiyang Liu, Jie Yang, Wenrui Ding, Tieqiang Wang, Zhijin Wang, and Junjun Xiong. Adaptive Mixture Regression Network with Local Counting Map for Crowd Counting. In ECCV, pages 241\u2013257, 2020.": "Adaptive Mixture Regression Network with Local Counting Map for Crowd Counting", "[39] Joey Tianyi Zhou, Le Zhang, Jiawei Du, Xi Peng, Zhiwen Fang, Zhe Xiao, and Hongyuan Zhu. Locality-Aware Crowd Counting. IEEE TPAMI, 44(7):3602\u20133613, 2022.": "Locality-Aware Crowd Counting", "[26] Qingyu Song, Changan Wang, Zhengkai Jiang, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, and Yang Wu. Rethinking Counting and Localization in Crowds: A Purely Point-Based Framework. In ICCV, pages 3345\u20133354, 2021.": "Rethinking Counting and Localization in Crowds: A Purely Point-Based Framework", "[14] Xinyan Liu, Guorong Li, Zhenjun Han, Weigang Zhang, Yifan Yang, Qingming Huang, and Nicu Sebe. Exploiting sample correlation for crowd counting with multi-expert network. In ICCV, pages 3195\u20133204, 2021.": "Exploiting sample correlation for crowd counting with multi-expert network", "[25] Vishwanath A. Sindagi, Rajeev Yasarla, and Vishal M. Patel. JHU-CROWD++: Large-Scale Crowd Counting Dataset and A Benchmark Method. IEEE TPAMI, 44(5):2594\u20132609, 2022.": "JHU-CROWD++: Large-Scale Crowd Counting Dataset and A Benchmark Method", "[1] Xinkun Cao, Zhipeng Wang, Yanyun Zhao, and Fei Su. Scale Aggregation Network for Accurate and Efficient Crowd Counting. In ECCV, pages 757\u2013773, 2018.": "Scale Aggregation Network for Accurate and Efficient Crowd Counting", "[18] Zhiheng Ma, Xiaopeng Hong, Xing Wei, Yunfeng Qiu, and Yihong Gong. Towards A Universal Model for Cross-Dataset Crowd Counting. In ICCV, pages 3185\u20133194, 2021.": "Towards A Universal Model for Cross-Dataset Crowd Counting", "[22] Deepak Babu Sam, Shiv Surya, and R. Venkatesh Babu. Switching Convolutional Neural Network for Crowd Counting. In CVPR, pages 4031\u20134039, 2017.": "Switching Convolutional Neural Network for Crowd Counting", "[35] Qi Wang, Junyu Gao, Wei Lin, and Yuan Yuan. Learning From Synthetic Data for Crowd Counting in the Wild. In CVPR, pages 8198\u20138207, 2019.": "Learning From Synthetic Data for Crowd Counting in the Wild", "[21] Deepak Babu Sam, Skand Vishwanath Peri, Mukuntha Narayanan Sundararaman, Amogh Kamath, and R. Venkatesh Babu. Locate, Size, and Count: Accurately Resolving People in Dense Crowds via Detection. IEEE TPAMI, 43(8):2739\u20132751, 2021.": "Locate, Size, and Count: Accurately Resolving People in Dense Crowds via Detection", "[38] Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, and Yi Ma. Single-Image Crowd Counting via Multi-Column Convolutional Neural network. In CVPR, pages 589\u2013597, 2016.": "Single-Image Crowd Counting via Multi-Column Convolutional Neural network", "[37] Yifan Yang, Guorong Li, Zhe Wu, Li Su, Qingming Huang, and Nicu Sebe. Reverse Perspective Network for Perspective-Aware Object Counting. In CVPR, pages 4373\u20134382, 2020.": "Reverse Perspective Network for Perspective-Aware Object Counting", "[33] Boyu Wang, Huidong Liu, Dimitris Samaras, and Minh Hoai Nguyen. Distribution Matching for Crowd Counting. In NeurIPS, 2020.": "Distribution Matching for Crowd Counting"}, "source_title_to_arxiv_id": {"Focal Inverse Distance Transform Maps for Crowd Localization": "2102.07925", "JHU-CROWD++: Large-Scale Crowd Counting Dataset and A Benchmark Method": "2004.03597"}}