{"title": "PARS: Pseudo-Label Aware Robust Sample Selection for Learning with Noisy Labels", "abstract": "Acquiring accurate labels on large-scale datasets is both time consuming and\nexpensive. To reduce the dependency of deep learning models on learning from\nclean labeled data, several recent research efforts are focused on learning\nwith noisy labels. These methods typically fall into three design categories to\nlearn a noise robust model: sample selection approaches, noise robust loss\nfunctions, or label correction methods. In this paper, we propose PARS:\nPseudo-Label Aware Robust Sample Selection, a hybrid approach that combines the\nbest from all three worlds in a joint-training framework to achieve robustness\nto noisy labels. Specifically, PARS exploits all training samples using both\nthe raw/noisy labels and estimated/refurbished pseudo-labels via self-training,\ndivides samples into an ambiguous and a noisy subset via loss analysis, and\ndesigns label-dependent noise-aware loss functions for both sets of filtered\nlabels. Results show that PARS significantly outperforms the state of the art\non extensive studies on the noisy CIFAR-10 and CIFAR-100 datasets, particularly\non challenging high-noise and low-resource settings. In particular, PARS\nachieved an absolute 12% improvement in test accuracy on the CIFAR-100 dataset\nwith 90% symmetric label noise, and an absolute 27% improvement in test\naccuracy when only 1/5 of the noisy labels are available during training as an\nadditional restriction. On a real-world noisy dataset, Clothing1M, PARS\nachieves competitive results to the state of the art.", "authors": ["Arushi Goel", "Yunlong Jiao", "Jordan Massiah"], "published_date": "2022_01_26", "pdf_url": "http://arxiv.org/pdf/2201.10836v1", "list_table_and_caption": [{"table": "<table><thead><tr><th>Datasets</th><th colspan=\"5\">CIFAR-10</th><th colspan=\"4\">CIFAR-100</th></tr></thead><tbody><tr><td>Noise Type</td><td colspan=\"4\">Sym.</td><td>Asym.</td><td colspan=\"4\">Sym.</td></tr><tr><td>Alg.\\backslashNoise Ratio</td><td>20%</td><td>50%</td><td>80%</td><td>90%</td><td>40%</td><td>20%</td><td>50%</td><td>80%</td><td>90%</td></tr><tr><td>Cross-Entropy Loss \\mathcal{L}_{CE}</td><td>86.8</td><td>79.4</td><td>62.9</td><td>42.7</td><td>85.0</td><td>62.0</td><td>46.7</td><td>19.9</td><td>10.1</td></tr><tr><td>Bootstrap (Reed et al., 2014)</td><td>86.8</td><td>79.8</td><td>63.3</td><td>42.9</td><td>-</td><td>62.1</td><td>46.6</td><td>19.9</td><td>10.2</td></tr><tr><td>F-correction (Patrini et al., 2017)</td><td>86.8</td><td>79.8</td><td>63.3</td><td>42.9</td><td>87.2</td><td>61.5</td><td>46.6</td><td>19.9</td><td>10.2</td></tr><tr><td>Mixup (Zhang et al., 2017)</td><td>95.6</td><td>87.1</td><td>71.6</td><td>52.2</td><td>-</td><td>67.8</td><td>57.3</td><td>30.8</td><td>14.6</td></tr><tr><td>Co-teaching+ (Yu et al., 2019)</td><td>89.5</td><td>85.7</td><td>67.4</td><td>47.9</td><td>-</td><td>65.6</td><td>51.8</td><td>27.9</td><td>13.7</td></tr><tr><td>P-correction (Yi &amp; Wu, 2019)</td><td>92.4</td><td>89.1</td><td>77.5</td><td>58.9</td><td>88.5</td><td>69.4</td><td>57.5</td><td>31.1</td><td>15.3</td></tr><tr><td>Meta-Learning (Li et al., 2019)</td><td>92.9</td><td>89.3</td><td>77.4</td><td>58.7</td><td>89.2</td><td>68.5</td><td>59.2</td><td>42.4</td><td>19.5</td></tr><tr><td>M-correction (Arazo et al., 2019)</td><td>94.0</td><td>92.0</td><td>86.8</td><td>69.1</td><td>87.4</td><td>73.9</td><td>66.1</td><td>48.2</td><td>24.3</td></tr><tr><td>DivideMix (Li et al., 2020)</td><td>96.1</td><td>94.6</td><td>93.2</td><td>76.0</td><td>93.4</td><td>77.3</td><td>74.6</td><td>60.2</td><td>31.5</td></tr><tr><td>ELR+ (Liu et al., 2020)</td><td>95.8</td><td>94.8</td><td>93.3</td><td>78.7</td><td>93.0</td><td>77.6</td><td>73.6</td><td>60.8</td><td>33.4</td></tr><tr><td>DM-AugDesc-WS-WAW (Nishi et al., 2021)</td><td>96.3</td><td>95.4</td><td>93.8</td><td>91.9</td><td>94.6</td><td>79.5</td><td>77.2</td><td>66.4</td><td>41.2</td></tr><tr><td>DM-AugDesc-WS-SAW (Nishi et al., 2021)</td><td>96.3</td><td>95.6</td><td>93.7</td><td>35.3</td><td>94.6</td><td>79.6</td><td>77.6</td><td>61.8</td><td>17.3</td></tr><tr><td>Robust Loss \\mathcal{L}_{RL} (warm-up training only)</td><td>84.0</td><td>76.4</td><td>74.1</td><td>54.5</td><td>79.0</td><td>63.9</td><td>59.8</td><td>42.1</td><td>18.9</td></tr><tr><td>PARS (ours)</td><td>96.3</td><td>95.8</td><td>94.9</td><td>93.6</td><td>95.4</td><td>77.7</td><td>75.3</td><td>69.2</td><td>53.1</td></tr></tbody></table>", "caption": "Table 1: Test Accuracy (%) for all the baselines and our proposed method, PARS, on CIFAR-10 and CIFAR-100 with symmetric noise (noise ratio ranging 20% to 90%) and asymmetric noise (noise ratio 40%) on CIFAR-10. The results above the \u201cDivideMix\u201d row are taken from Li et al. (2020).", "list_citation_info": ["Patrini et al. (2017) Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1944\u20131952, 2017.", "Li et al. (2019) Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S Kankanhalli. Learning to learn from noisy labeled data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5051\u20135059, 2019.", "Nishi et al. (2021) Kento Nishi, Yi Ding, Alex Rich, and Tobias Hollerer. Augmentation strategies for learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8022\u20138031, 2021.", "Yu et al. (2019) Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama. How does disagreement help generalization against label corruption? In International Conference on Machine Learning, pp. 7164\u20137173. PMLR, 2019.", "Reed et al. (2014) Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew Rabinovich. Training deep neural networks on noisy labels with bootstrapping. arXiv preprint arXiv:1412.6596, 2014.", "Arazo et al. (2019) Eric Arazo, Diego Ortego, Paul Albert, Noel O\u2019Connor, and Kevin McGuinness. Unsupervised label noise modeling and loss correction. In International Conference on Machine Learning, pp. 312\u2013321. PMLR, 2019.", "Li et al. (2020) Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020.", "Liu et al. (2020) Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early-learning regularization prevents memorization of noisy labels. Advances in Neural Information Processing Systems, 33, 2020.", "Zhang et al. (2017) Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017.", "Yi & Wu (2019) Kun Yi and Jianxin Wu. Probabilistic end-to-end noise correction for learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7017\u20137025, 2019."]}, {"table": "<table><thead><tr><th>Alg.\\backslashDataset</th><th>Clothing1M</th></tr></thead><tbody><tr><th>Cross-Entropy Loss \\mathcal{L}_{CE}</th><td>69.21</td></tr><tr><th>F-correction (Patrini et al., 2017)</th><td>69.84</td></tr><tr><th>M-correction (Arazo et al., 2019)</th><td>71.00</td></tr><tr><th>Joint-Optim (Tanaka et al., 2018)</th><td>72.16</td></tr><tr><th>Meta-Learning (Li et al., 2019)</th><td>73.47</td></tr><tr><th>P-correction (Yi &amp; Wu, 2019)</th><td>73.49</td></tr><tr><th>DivideMix (Li et al., 2020)</th><td>74.76</td></tr><tr><th>ELR+ (Liu et al., 2020)</th><td>74.81</td></tr><tr><th>DM-AugDesc-WS-WAW (Nishi et al., 2021)</th><td>74.72</td></tr><tr><th>DM-AugDesc-WS-SAW (Nishi et al., 2021)</th><td>75.11</td></tr><tr><th>Robust Loss \\mathcal{L}_{RL} (warm-up training only)</th><td>71.80</td></tr><tr><th>PARS (ours)</th><td>74.61</td></tr></tbody></table>", "caption": "Table 2: Test Accuracy (%) for all the baselines and our proposed method, PARS, on Clothing1M. The results above the \u201cDivideMix\u201d row are taken from Li et al. (2020).", "list_citation_info": ["Patrini et al. (2017) Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1944\u20131952, 2017.", "Li et al. (2019) Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S Kankanhalli. Learning to learn from noisy labeled data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5051\u20135059, 2019.", "Nishi et al. (2021) Kento Nishi, Yi Ding, Alex Rich, and Tobias Hollerer. Augmentation strategies for learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8022\u20138031, 2021.", "Arazo et al. (2019) Eric Arazo, Diego Ortego, Paul Albert, Noel O\u2019Connor, and Kevin McGuinness. Unsupervised label noise modeling and loss correction. In International Conference on Machine Learning, pp. 312\u2013321. PMLR, 2019.", "Li et al. (2020) Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020.", "Liu et al. (2020) Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early-learning regularization prevents memorization of noisy labels. Advances in Neural Information Processing Systems, 33, 2020.", "Tanaka et al. (2018) Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. Joint optimization framework for learning with noisy labels. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5552\u20135560, 2018.", "Yi & Wu (2019) Kun Yi and Jianxin Wu. Probabilistic end-to-end noise correction for learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7017\u20137025, 2019."]}, {"table": "<table><tbody><tr><th>Dataset</th><td colspan=\"2\">CIFAR-10</td><td colspan=\"2\">CIFAR-100</td></tr><tr><th># Labels</th><td colspan=\"2\">4000</td><td colspan=\"2\">10000</td></tr><tr><th>Noise Type</th><td colspan=\"2\">Sym.</td><td colspan=\"2\">Sym.</td></tr><tr><th>Alg.\\backslashNoise Ratio</th><td>50%</td><td>90%</td><td>50%</td><td>90%</td></tr><tr><th>FixMatch{}^{\\dagger} (Sohn et al., 2020)</th><td>82.7</td><td>54.9</td><td>55.6</td><td>22.0</td></tr><tr><th>DivideMix{}^{\\dagger} (Li et al., 2020)</th><td>66.0</td><td>37.1</td><td>25.2</td><td>8.0</td></tr><tr><th>AugDesc-WS{}^{\\dagger} (Nishi et al., 2021)</th><td>73.3</td><td>56.1</td><td>31.1</td><td>10.1</td></tr><tr><th>DivideMix+{}^{\\dagger} (Li et al., 2020)</th><td>74.3</td><td>40.7</td><td>10.6</td><td>7.2</td></tr><tr><th>AugDesc-WS+{}^{\\dagger} (Nishi et al., 2021)</th><td>73.2</td><td>57.5</td><td>30.1</td><td>7.6</td></tr><tr><th>PARS (ours)</th><td>95.3</td><td>70.3</td><td>76.3</td><td>48.9</td></tr></tbody></table>", "caption": "Table 3: Test Accuracy (%) for all the baselines and our proposed method, PARS, on CIFAR-10/100 datasets with 50% and 90% symmetric noise with a subset of training labels. + denotes that methods are adapted to include unlabeled data while training. \\dagger denotes re-training with the open-source code.", "list_citation_info": ["Nishi et al. (2021) Kento Nishi, Yi Ding, Alex Rich, and Tobias Hollerer. Augmentation strategies for learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8022\u20138031, 2021.", "Li et al. (2020) Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020.", "Sohn et al. (2020) Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Han Zhang, and Colin Raffel. Fixmatch: Simplifying semi-supervised learning with consistency and confidence. arXiv preprint arXiv:2001.07685, 2020."]}], "citation_info_to_title": {"Nishi et al. (2021) Kento Nishi, Yi Ding, Alex Rich, and Tobias Hollerer. Augmentation strategies for learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8022\u20138031, 2021.": "Augmentation strategies for learning with noisy labels", "Arazo et al. (2019) Eric Arazo, Diego Ortego, Paul Albert, Noel O\u2019Connor, and Kevin McGuinness. Unsupervised label noise modeling and loss correction. In International Conference on Machine Learning, pp. 312\u2013321. PMLR, 2019.": "Unsupervised label noise modeling and loss correction", "Patrini et al. (2017) Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1944\u20131952, 2017.": "Making deep neural networks robust to label noise: A loss correction approach", "Reed et al. (2014) Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew Rabinovich. Training deep neural networks on noisy labels with bootstrapping. arXiv preprint arXiv:1412.6596, 2014.": "Training Deep Neural Networks on Noisy Labels with Bootstrapping", "Li et al. (2020) Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020.": "Dividemix: Learning with Noisy Labels as Semi-Supervised Learning", "Tanaka et al. (2018) Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. Joint optimization framework for learning with noisy labels. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5552\u20135560, 2018.": "Joint optimization framework for learning with noisy labels", "Li et al. (2019) Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S Kankanhalli. Learning to learn from noisy labeled data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5051\u20135059, 2019.": "Learning to learn from noisy labeled data", "Liu et al. (2020) Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early-learning regularization prevents memorization of noisy labels. Advances in Neural Information Processing Systems, 33, 2020.": "Early-learning regularization prevents memorization of noisy labels", "Zhang et al. (2017) Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017.": "mixup: Beyond Empirical Risk Minimization", "Yi & Wu (2019) Kun Yi and Jianxin Wu. Probabilistic end-to-end noise correction for learning with noisy labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7017\u20137025, 2019.": "Probabilistic end-to-end noise correction for learning with noisy labels", "Yu et al. (2019) Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama. How does disagreement help generalization against label corruption? In International Conference on Machine Learning, pp. 7164\u20137173. PMLR, 2019.": "How does disagreement help generalization against label corruption?", "Sohn et al. (2020) Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Han Zhang, and Colin Raffel. Fixmatch: Simplifying semi-supervised learning with consistency and confidence. arXiv preprint arXiv:2001.07685, 2020.": "Fixmatch: Simplifying semi-supervised learning with consistency and confidence"}, "source_title_to_arxiv_id": {"Augmentation strategies for learning with noisy labels": "2103.02130"}}