{"title": "Stochastic Backpropagation: A Memory Efficient Strategy for Training Video Models", "abstract": "We propose a memory efficient method, named Stochastic Backpropagation (SBP),\nfor training deep neural networks on videos. It is based on the finding that\ngradients from incomplete execution for backpropagation can still effectively\ntrain the models with minimal accuracy loss, which attributes to the high\nredundancy of video. SBP keeps all forward paths but randomly and independently\nremoves the backward paths for each network layer in each training step. It\nreduces the GPU memory cost by eliminating the need to cache activation values\ncorresponding to the dropped backward paths, whose amount can be controlled by\nan adjustable keep-ratio. Experiments show that SBP can be applied to a wide\nrange of models for video tasks, leading to up to 80.0% GPU memory saving and\n10% training speedup with less than 1% accuracy drop on action recognition and\ntemporal action detection.", "authors": ["Feng Cheng", "Mingze Xu", "Yuanjun Xiong", "Hao Chen", "Xinyu Li", "Wei Li", "Wei Xia"], "published_date": "2022_03_31", "pdf_url": "http://arxiv.org/pdf/2203.16755v1", "list_table_and_caption": [{"table": "<table><tr><td>Method</td><td>Training</td><td>mAP (%)</td><td> GPU Mem(#GPUs \\times GB) </td></tr><tr><td rowspan=\"4\">TRN [52]</td><td>Feat. Extract.</td><td>55.3</td><td>1\\times 12</td></tr><tr><td>E2E</td><td>56.8</td><td>8\\times 14.6</td></tr><tr><td>SBP (0.25)</td><td>56.7</td><td>8\\times 5.6</td></tr><tr><td>SBP (0.125)</td><td>56.9</td><td>8\\times 4.3</td></tr><tr><td rowspan=\"4\">LSTR [54]</td><td>Feat. Extract.</td><td>56.8</td><td>1\\times 5</td></tr><tr><td>E2E</td><td>59.2</td><td>8\\times 32</td></tr><tr><td>SBP (0.25)</td><td>59.1</td><td>8\\times 12.2</td></tr><tr><td>SBP (0.125)</td><td>59.5</td><td>8\\times 7</td></tr></table>", "caption": "Table 4: Comparison of SBP, using a fixed feature extractor (Feat. Extract.), and end-to-end (E2E) training on TRN and LSTR.", "list_citation_info": ["[54] Mingze Xu, Yuanjun Xiong, Hao Chen, Xinyu Li, Wei Xia, Zhuowen Tu, and Stefano Soatto. Long short-term transformer for online action detection. NeurIPS, 2021.", "[52] Mingze Xu, Mingfei Gao, Yi-Ting Chen, Larry S Davis, and David J Crandall. Temporal recurrent networks for online action detection. In ICCV, 2019."]}], "citation_info_to_title": {"[52] Mingze Xu, Mingfei Gao, Yi-Ting Chen, Larry S Davis, and David J Crandall. Temporal recurrent networks for online action detection. In ICCV, 2019.": "Temporal Recurrent Networks for Online Action Detection", "[54] Mingze Xu, Yuanjun Xiong, Hao Chen, Xinyu Li, Wei Xia, Zhuowen Tu, and Stefano Soatto. Long short-term transformer for online action detection. NeurIPS, 2021.": "Long short-term transformer for online action detection"}, "source_title_to_arxiv_id": {"Long short-term transformer for online action detection": "2107.03377"}}