{"title": "Colonoscopy 3D Video Dataset with Paired Depth from 2D-3D Registration", "abstract": "Screening colonoscopy is an important clinical application for several 3D\ncomputer vision techniques, including depth estimation, surface reconstruction,\nand missing region detection. However, the development, evaluation, and\ncomparison of these techniques in real colonoscopy videos remain largely\nqualitative due to the difficulty of acquiring ground truth data. In this work,\nwe present a Colonoscopy 3D Video Dataset (C3VD) acquired with a high\ndefinition clinical colonoscope and high-fidelity colon models for benchmarking\ncomputer vision methods in colonoscopy. We introduce a novel multimodal 2D-3D\nregistration technique to register optical video sequences with ground truth\nrendered views of a known 3D model. The different modalities are registered by\ntransforming optical images to depth maps with a Generative Adversarial Network\nand aligning edge features with an evolutionary optimizer. This registration\nmethod achieves an average translation error of 0.321 millimeters and an\naverage rotation error of 0.159 degrees in simulation experiments where\nerror-free ground truth is available. The method also leverages video\ninformation, improving registration accuracy by 55.6% for translation and 60.4%\nfor rotation compared to single frame registration. 22 short video sequences\nwere registered to generate 10,015 total frames with paired ground truth depth,\nsurface normals, optical flow, occlusion, six degree-of-freedom pose, coverage\nmaps, and 3D models. The dataset also includes screening videos acquired by a\ngastroenterologist with paired ground truth pose and 3D surface models. The\ndataset and registration source code are available at durr.jhu.edu/C3VD.", "authors": ["Taylor L. Bobrow", "Mayank Golhar", "Rohan Vijayan", "Venkata S. Akshintala", "Juan R. Garcia", "Nicholas J. Durr"], "published_date": "2022_06_17", "pdf_url": "http://arxiv.org/pdf/2206.08903v2", "list_table_and_caption": [{"table": "<table><tbody><tr><th colspan=\"3\">Camera</th><th></th><th></th><th></th><th colspan=\"6\">Ground Truth</th><td></td></tr><tr><td>Type</td><td>FoV</td><td>Res.</td><td>Tissue Type</td><td>3D GT</td><td>Registration</td><td>Frames</td><td>Pose</td><td>Depth</td><td>Normals</td><td>Flow</td><td>3D Model</td><td>Dataset</td></tr><tr><td>Stereo da Vinci</td><td>Narrow</td><td>SD</td><td>Ex-vivo Porcine</td><td>CT</td><td>Manual</td><td>16</td><td>\u2713</td><td></td><td></td><td></td><td>\u2713</td><td>[10]</td></tr><tr><td>Stereo CMOS</td><td>Narrow</td><td>SD</td><td>Phantom</td><td>CT</td><td>Calib Plate</td><td>120</td><td></td><td>\u2713</td><td></td><td></td><td>\u2713</td><td>[11]</td></tr><tr><td>Stereo da Vinci</td><td>Narrow</td><td>SD</td><td>Phantom</td><td>CT</td><td>Fiducials</td><td>5,816</td><td></td><td></td><td></td><td></td><td>\u2713</td><td>[12, 13]</td></tr><tr><td>Stereo da Vinci</td><td>Narrow</td><td>SD</td><td>In-vivo Animal</td><td>N/A</td><td>N/A</td><td>20,000</td><td></td><td></td><td></td><td></td><td></td><td>[14]</td></tr><tr><td>Stereo da Vinci</td><td>Narrow</td><td>SD</td><td>In-vivo Animal</td><td>N/A</td><td>N/A</td><td>92,672</td><td></td><td>\u2713</td><td></td><td></td><td>\u2713</td><td>[15]</td></tr><tr><td>Stereo da Vinci</td><td>Narrow</td><td>SD</td><td>Ex-vivo Porcine</td><td>SI</td><td>N/A</td><td>40</td><td></td><td>\u2713</td><td></td><td></td><td></td><td>[16]<sup>*</sup></td></tr><tr><td>Stereo da Vinci</td><td>Narrow</td><td>SD</td><td>Ex-vivo Porcine</td><td>CT</td><td>Fiducials</td><td>131</td><td></td><td></td><td></td><td></td><td>\u2713</td><td>[17]</td></tr><tr><td>Stereo Rendered</td><td>Narrow</td><td>SD</td><td>Virtual</td><td>CT</td><td>N/A</td><td>6,320</td><td>\u2713</td><td></td><td></td><td></td><td></td><td>[18]</td></tr><tr><td>Monocular USB</td><td>Narrow</td><td>SD</td><td>Phantom</td><td>N/A</td><td>N/A</td><td>23,935</td><td>\u2713</td><td></td><td></td><td></td><td></td><td>[19]</td></tr><tr><td>Monocular Rendered</td><td>Narrow</td><td>SD</td><td>Virtual</td><td>CT</td><td>N/A</td><td>16,016</td><td></td><td>\u2713</td><td></td><td></td><td></td><td>[20]</td></tr><tr><td>Monocular Rendered</td><td>Narrow</td><td>SD</td><td>Virtual</td><td>CT</td><td>N/A</td><td>18,000</td><td>\u2713</td><td>\u2713</td><td></td><td></td><td></td><td>[21]<sup>*</sup></td></tr><tr><td>Monocular Pill Cam</td><td>Wide</td><td>SD/HD</td><td>Ex-vivo Porcine</td><td>OS</td><td>N/A</td><td>42,700</td><td>\u2713</td><td></td><td></td><td></td><td>\u2713</td><td>[22]</td></tr><tr><td>Monocular Rendered</td><td>Narrow</td><td>SD</td><td>Virtual</td><td>CT</td><td>N/A</td><td>21,887</td><td>\u2713</td><td>\u2713</td><td></td><td></td><td></td><td>[22]</td></tr><tr><td>Monocular Colonoscope</td><td>Wide</td><td>HD</td><td>Phantom</td><td>Sculpted</td><td>Optimized</td><td>10,015</td><td>\u2713</td><td>\u2713</td><td>\u2713</td><td>\u2713</td><td>\u2713</td><td>Proposed</td></tr></tbody></table><ul><li><p>Ground Truth (GT), Computed Tomography (CT), Structured Illumination (SI), Optical Scan (OS)</p></li><li>*<p>Only available to challenge participants</p></li></ul>", "caption": "Table 1: Comparison of Endoscopy Reconstruction Datasets", "list_citation_info": ["[16] M. Allan, J. Mcleod, C. Wang, J. C. Rosenthal, Z. Hu, N. Gard, P. Eisert, K. X. Fu, T. Zeffiro, W. Xia et al., \u201cStereo correspondence and reconstruction of endoscopic data challenge,\u201d arXiv preprint arXiv:2101.01133, 2021.", "[15] D. Recasens, J. Lamarca, J. M. F\u00e1cil, J. Montiel, and J. Civera, \u201cEndo-depth-and-motion: Reconstruction and tracking in endoscopic videos using depth networks and photometric constraints,\u201d IEEE Robotics and Automation Letters, vol. 6, no. 4, pp. 7225\u20137232, 2021.", "[17] L. Maier-Hein, A. Groch, A. Bartoli, S. Bodenstedt, G. Boissonnat, P.-L. Chang, N. Clancy, D. S. Elson, S. Haase, E. Heim et al., \u201cComparative validation of single-shot optical techniques for laparoscopic 3-d surface reconstruction,\u201d IEEE transactions on medical imaging, vol. 33, no. 10, pp. 1913\u20131930, 2014.", "[22] K. B. Ozyoruk, G. I. Gokceler, G. Coskun, K. Incetan, Y. Almalioglu, F. Mahmood, E. Curto, L. Perdigoto, M. Oliveira, H. Sahin et al., \u201cEndoslam dataset and an unsupervised monocular visual odometry and depth estimation approach for endoscopic videos: Endo-sfmlearner,\u201d arXiv preprint arXiv:2006.16670, 2020.", "[12] D. Stoyanov, M. V. Scarzanella, P. Pratt, and G.-Z. Yang, \u201cReal-time stereo reconstruction in robotically assisted minimally invasive surgery,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2010, pp. 275\u2013282.", "[14] M. Ye, E. Johns, A. Handa, L. Zhang, P. Pratt, and G.-Z. Yang, \u201cSelf-supervised siamese learning on stereo image pairs for depth estimation in robotic surgery,\u201d arXiv preprint arXiv:1705.08260, 2017.", "[11] V. Penza, A. S. Ciullo, S. Moccia, L. S. Mattos, and E. De Momi, \u201cEndoabs dataset: Endoscopic abdominal stereo image dataset for benchmarking 3d stereo reconstruction algorithms,\u201d The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 14, no. 5, p. e1926, 2018.", "[21] A. Rau, B. Bhattarai, L. Agapito, and D. Stoyanov, \u201cBimodal camera pose prediction for endoscopy,\u201d arXiv preprint arXiv:2204.04968, 2022.", "[19] M. J. Fulton, J. M. Prendergast, E. R. DiTommaso, and M. E. Rentschler, \u201cComparing visual odometry systems in actively deforming simulated colon environments,\u201d in 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020, pp. 4988\u20134995.", "[10] P. Edwards, D. Psychogyios, S. Speidel, L. Maier-Hein, D. Stoyanov et al., \u201cServ-ct: A disparity dataset from ct for validation of endoscopic 3d reconstruction,\u201d arXiv preprint arXiv:2012.11779, 2020.", "[20] A. Rau, P. E. Edwards, O. F. Ahmad, P. Riordan, M. Janatka, L. B. Lovat, and D. Stoyanov, \u201cImplicit domain adaptation with conditional generative adversarial networks for depth prediction in endoscopy,\u201d International journal of computer assisted radiology and surgery, vol. 14, no. 7, pp. 1167\u20131176, 2019.", "[18] S. Zhang, L. Zhao, S. Huang, M. Ye, and Q. Hao, \u201cA template-based 3d reconstruction of colon structures and textures from stereo colonoscopic images,\u201d IEEE Transactions on Medical Robotics and Bionics, vol. 3, no. 1, pp. 85\u201395, 2021."]}], "citation_info_to_title": {"[11] V. Penza, A. S. Ciullo, S. Moccia, L. S. Mattos, and E. De Momi, \u201cEndoabs dataset: Endoscopic abdominal stereo image dataset for benchmarking 3d stereo reconstruction algorithms,\u201d The International Journal of Medical Robotics and Computer Assisted Surgery, vol. 14, no. 5, p. e1926, 2018.": "Endoabs dataset: Endoscopic abdominal stereo image dataset for benchmarking 3d stereo reconstruction algorithms", "[21] A. Rau, B. Bhattarai, L. Agapito, and D. Stoyanov, \u201cBimodal camera pose prediction for endoscopy,\u201d arXiv preprint arXiv:2204.04968, 2022.": "Bimodal camera pose prediction for endoscopy", "[19] M. J. Fulton, J. M. Prendergast, E. R. DiTommaso, and M. E. Rentschler, \u201cComparing visual odometry systems in actively deforming simulated colon environments,\u201d in 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2020, pp. 4988\u20134995.": "Comparing visual odometry systems in actively deforming simulated colon environments", "[14] M. Ye, E. Johns, A. Handa, L. Zhang, P. Pratt, and G.-Z. Yang, \u201cSelf-supervised siamese learning on stereo image pairs for depth estimation in robotic surgery,\u201d arXiv preprint arXiv:1705.08260, 2017.": "Self-supervised siamese learning on stereo image pairs for depth estimation in robotic surgery", "[22] K. B. Ozyoruk, G. I. Gokceler, G. Coskun, K. Incetan, Y. Almalioglu, F. Mahmood, E. Curto, L. Perdigoto, M. Oliveira, H. Sahin et al., \u201cEndoslam dataset and an unsupervised monocular visual odometry and depth estimation approach for endoscopic videos: Endo-sfmlearner,\u201d arXiv preprint arXiv:2006.16670, 2020.": "Endo-sfmlearner: An Unsupervised Monocular Visual Odometry and Depth Estimation Approach for Endoscopic Videos", "[20] A. Rau, P. E. Edwards, O. F. Ahmad, P. Riordan, M. Janatka, L. B. Lovat, and D. Stoyanov, \u201cImplicit domain adaptation with conditional generative adversarial networks for depth prediction in endoscopy,\u201d International journal of computer assisted radiology and surgery, vol. 14, no. 7, pp. 1167\u20131176, 2019.": "Implicit domain adaptation with conditional generative adversarial networks for depth prediction in endoscopy", "[12] D. Stoyanov, M. V. Scarzanella, P. Pratt, and G.-Z. Yang, \u201cReal-time stereo reconstruction in robotically assisted minimally invasive surgery,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2010, pp. 275\u2013282.": "Real-time stereo reconstruction in robotically assisted minimally invasive surgery", "[10] P. Edwards, D. Psychogyios, S. Speidel, L. Maier-Hein, D. Stoyanov et al., \u201cServ-ct: A disparity dataset from ct for validation of endoscopic 3d reconstruction,\u201d arXiv preprint arXiv:2012.11779, 2020.": "Serv-ct: A Disparity Dataset from CT for Validation of Endoscopic 3D Reconstruction", "[15] D. Recasens, J. Lamarca, J. M. F\u00e1cil, J. Montiel, and J. Civera, \u201cEndo-depth-and-motion: Reconstruction and tracking in endoscopic videos using depth networks and photometric constraints,\u201d IEEE Robotics and Automation Letters, vol. 6, no. 4, pp. 7225\u20137232, 2021.": "Endo-depth-and-motion: Reconstruction and tracking in endoscopic videos using depth networks and photometric constraints", "[18] S. Zhang, L. Zhao, S. Huang, M. Ye, and Q. Hao, \u201cA template-based 3d reconstruction of colon structures and textures from stereo colonoscopic images,\u201d IEEE Transactions on Medical Robotics and Bionics, vol. 3, no. 1, pp. 85\u201395, 2021.": "A template-based 3d reconstruction of colon structures and textures from stereo colonoscopic images", "[16] M. Allan, J. Mcleod, C. Wang, J. C. Rosenthal, Z. Hu, N. Gard, P. Eisert, K. X. Fu, T. Zeffiro, W. Xia et al., \u201cStereo correspondence and reconstruction of endoscopic data challenge,\u201d arXiv preprint arXiv:2101.01133, 2021.": "Stereo Correspondence and Reconstruction of Endoscopic Data Challenge", "[17] L. Maier-Hein, A. Groch, A. Bartoli, S. Bodenstedt, G. Boissonnat, P.-L. Chang, N. Clancy, D. S. Elson, S. Haase, E. Heim et al., \u201cComparative validation of single-shot optical techniques for laparoscopic 3-d surface reconstruction,\u201d IEEE transactions on medical imaging, vol. 33, no. 10, pp. 1913\u20131930, 2014.": "Comparative validation of single-shot optical techniques for laparoscopic 3-d surface reconstruction"}, "source_title_to_arxiv_id": {"Bimodal camera pose prediction for endoscopy": "2204.04968"}}