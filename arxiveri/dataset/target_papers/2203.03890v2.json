{"title": "ClearPose: Large-scale Transparent Object Dataset and Benchmark", "abstract": "Transparent objects are ubiquitous in household settings and pose distinct\nchallenges for visual sensing and perception systems. The optical properties of\ntransparent objects leave conventional 3D sensors alone unreliable for object\ndepth and pose estimation. These challenges are highlighted by the shortage of\nlarge-scale RGB-Depth datasets focusing on transparent objects in real-world\nsettings. In this work, we contribute a large-scale real-world RGB-Depth\ntransparent object dataset named ClearPose to serve as a benchmark dataset for\nsegmentation, scene-level depth completion and object-centric pose estimation\ntasks. The ClearPose dataset contains over 350K labeled real-world RGB-Depth\nframes and 5M instance annotations covering 63 household objects. The dataset\nincludes object categories commonly used in daily life under various lighting\nand occluding conditions as well as challenging test scenarios such as cases of\nocclusion by opaque or translucent objects, non-planar orientations, presence\nof liquids, etc. We benchmark several state-of-the-art depth completion and\nobject pose estimation deep neural networks on ClearPose. The dataset and\nbenchmarking source code is available at https://github.com/opipari/ClearPose.", "authors": ["Xiaotong Chen", "Huijie Zhang", "Zeren Yu", "Anthony Opipari", "Odest Chadwicke Jenkins"], "published_date": "2022_03_08", "pdf_url": "http://arxiv.org/pdf/2203.03890v2", "list_table_and_caption": [{"table": "<table><thead><tr><th>dataset</th><th>modality</th><th>#obj</th><th>#frame</th><th>#pose annotation</th></tr></thead><tbody><tr><th>TOD [13]</th><th>RGB-D</th><td>15</td><td>48K(real)</td><td>\\sim0.1M</td></tr><tr><th>ClearGrasp [15]</th><th>RGB-D</th><td>10</td><td>50K(syn)+286(real)</td><td>\\sim0.2M</td></tr><tr><th>TODD [22]</th><th>RGB-D</th><td>6</td><td>15K(real)</td><td>\\sim0.1M</td></tr><tr><th>Omniverse [26]</th><th>RGB-D</th><td>9</td><td>60K(syn)</td><td>\\sim0.2M</td></tr><tr><th>TransCG [7]</th><th>RGB-D</th><td>51</td><td>58K(real)</td><td>\\sim0.2M</td></tr><tr><th>Trans10K{{}^{*}} [20]</th><th>RGB</th><td>10K</td><td>15K(real)</td><td>seg only</td></tr><tr><th>ProLIT [25]</th><th>Light-Field</th><td>5</td><td>75K(syn)+300(real)</td><td>\\sim0.1M</td></tr><tr><th>StereObj1M{{}^{*}} [12]</th><th>Stereo</th><td>7</td><td>\\sim150K(real)</td><td>\\sim0.6M</td></tr><tr><th>ClearPose (ours)</th><th>RGB-D</th><td>63</td><td>350K(real)</td><td>\\sim5M</td></tr></tbody></table>", "caption": "Table 1: Comparison between existing transparent object datasets and ClearPose. {{}^{*}}Trans10K is a transparent segmentation dataset and has no object-centric pose labels. {{}^{*}}StereObj1M is not publicly available at the time of submission so the #frame and #pose annotation are estimated based on the published ratio of transparent objects in the entire object set [12]", "list_citation_info": ["[15] Sajjan, S., Moore, M., Pan, M., Nagaraja, G., Lee, J., Zeng, A., Song, S.: Clear grasp: 3d shape estimation of transparent objects for manipulation. In: 2020 IEEE International Conference on Robotics and Automation (ICRA). pp. 3634\u20133642. IEEE (2020)", "[7] Fang, H., Fang, H.S., Xu, S., Lu, C.: Transcg: A large-scale real-world dataset for transparent object depth completion and grasping. arXiv preprint arXiv:2202.08471 (2022)", "[20] Xie, E., Wang, W., Wang, W., Ding, M., Shen, C., Luo, P.: Segmenting transparent objects in the wild. In: European conference on computer vision. pp. 696\u2013711. Springer (2020)", "[12] Liu, X., Iwase, S., Kitani, K.M.: Stereobj-1m: Large-scale stereo image dataset for 6d object pose estimation. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 10870\u201310879 (2021)", "[25] Zhou, Z., Chen, X., Jenkins, O.C.: Lit: Light-field inference of transparency for refractive object localization. IEEE Robotics and Automation Letters 5(3), 4548\u20134555 (2020)", "[26] Zhu, L., Mousavian, A., Xiang, Y., Mazhar, H., van Eenbergen, J., Debnath, S., Fox, D.: Rgb-d local implicit function for depth completion of transparent objects. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4649\u20134658 (2021)", "[13] Liu, X., Jonschkowski, R., Angelova, A., Konolige, K.: Keypose: Multi-view 3d labeling and keypoint estimation for transparent objects. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 11602\u201311610 (2020)", "[22] Xu, H., Wang, Y.R., Eppel, S., Aspuru-Guzik, A., Shkurti, F., Garg, A.: Seeing glass: Joint point cloud and depth completion for transparent objects. arXiv preprint arXiv:2110.00087 (2021)"]}], "citation_info_to_title": {"[25] Zhou, Z., Chen, X., Jenkins, O.C.: Lit: Light-field inference of transparency for refractive object localization. IEEE Robotics and Automation Letters 5(3), 4548\u20134555 (2020)": "Lit: Light-field inference of transparency for refractive object localization", "[12] Liu, X., Iwase, S., Kitani, K.M.: Stereobj-1m: Large-scale stereo image dataset for 6d object pose estimation. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 10870\u201310879 (2021)": "Stereobj-1m: Large-scale stereo image dataset for 6d object pose estimation", "[13] Liu, X., Jonschkowski, R., Angelova, A., Konolige, K.: Keypose: Multi-view 3d labeling and keypoint estimation for transparent objects. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. pp. 11602\u201311610 (2020)": "Keypose: Multi-view 3d labeling and keypoint estimation for transparent objects", "[26] Zhu, L., Mousavian, A., Xiang, Y., Mazhar, H., van Eenbergen, J., Debnath, S., Fox, D.: Rgb-d local implicit function for depth completion of transparent objects. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4649\u20134658 (2021)": "RGB-D Local Implicit Function for Depth Completion of Transparent Objects", "[15] Sajjan, S., Moore, M., Pan, M., Nagaraja, G., Lee, J., Zeng, A., Song, S.: Clear grasp: 3d shape estimation of transparent objects for manipulation. In: 2020 IEEE International Conference on Robotics and Automation (ICRA). pp. 3634\u20133642. IEEE (2020)": "Clear grasp: 3D shape estimation of transparent objects for manipulation", "[22] Xu, H., Wang, Y.R., Eppel, S., Aspuru-Guzik, A., Shkurti, F., Garg, A.: Seeing glass: Joint point cloud and depth completion for transparent objects. arXiv preprint arXiv:2110.00087 (2021)": "Seeing glass: Joint point cloud and depth completion for transparent objects", "[20] Xie, E., Wang, W., Wang, W., Ding, M., Shen, C., Luo, P.: Segmenting transparent objects in the wild. In: European conference on computer vision. pp. 696\u2013711. Springer (2020)": "Segmenting transparent objects in the wild", "[7] Fang, H., Fang, H.S., Xu, S., Lu, C.: Transcg: A large-scale real-world dataset for transparent object depth completion and grasping. arXiv preprint arXiv:2202.08471 (2022)": "Transcg: A large-scale real-world dataset for transparent object depth completion and grasping"}, "source_title_to_arxiv_id": {"RGB-D Local Implicit Function for Depth Completion of Transparent Objects": "2104.00622"}}