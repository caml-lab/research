{"title": "SoMoFormer: Multi-Person Pose Forecasting with Transformers", "abstract": "Human pose forecasting is a challenging problem involving complex human body\nmotion and posture dynamics. In cases that there are multiple people in the\nenvironment, one's motion may also be influenced by the motion and dynamic\nmovements of others. Although there are several previous works targeting the\nproblem of multi-person dynamic pose forecasting, they often model the entire\npose sequence as time series (ignoring the underlying relationship between\njoints) or only output the future pose sequence of one person at a time. In\nthis paper, we present a new method, called Social Motion Transformer\n(SoMoFormer), for multi-person 3D pose forecasting. Our transformer\narchitecture uniquely models human motion input as a joint sequence rather than\na time sequence, allowing us to perform attention over joints while predicting\nan entire future motion sequence for each joint in parallel. We show that with\nthis problem reformulation, SoMoFormer naturally extends to multi-person scenes\nby using the joints of all people in a scene as input queries. Using learned\nembeddings to denote the type of joint, person identity, and global position,\nour model learns the relationships between joints and between people, attending\nmore strongly to joints from the same or nearby people. SoMoFormer outperforms\nstate-of-the-art methods for long-term motion prediction on the SoMoF benchmark\nas well as the CMU-Mocap and MuPoTS-3D datasets. Code will be made available\nafter publication.", "authors": ["Edward Vendrow", "Satyajit Kumar", "Ehsan Adeli", "Hamid Rezatofighi"], "published_date": "2022_08_30", "pdf_url": "http://arxiv.org/pdf/2208.14023v1", "list_table_and_caption": [{"table": "<table><tbody><tr><th></th><th colspan=\"5\">3DPW Prediction in Time</th><td></td></tr><tr><th>Method</th><th>100ms</th><th>240ms</th><th>500ms</th><th>640ms</th><th>900ms</th><th>Overall</th></tr><tr><th>Mo-Att [19] + ST-GAT [11]</th><td>62.4</td><td>94.6</td><td>153.2</td><td>188.0</td><td>249.9</td><td>149.6</td></tr><tr><th>SC-MPF [1]</th><td>45.4</td><td>73.7</td><td>129.2</td><td>159.5</td><td>208.3</td><td>123.2</td></tr><tr><th>Zero Velocity</th><td>29.4</td><td>53.6</td><td>94.5</td><td>112.7</td><td>143.1</td><td>86.7</td></tr><tr><th>TRiPOD [2]</th><td>31.0</td><td>50.8</td><td>84.7</td><td>104.1</td><td>150.4</td><td>84.2</td></tr><tr><th>DViTA [25]</th><td>19.5</td><td>36.9</td><td>68.3</td><td>85.5</td><td>118.2</td><td>65.7</td></tr><tr><th>FutureMotion [30]</th><td>9.5</td><td>22.9</td><td>50.9</td><td>66.2</td><td>97.4</td><td>49.4</td></tr><tr><th>SoMoFormer</th><td>9.1</td><td>21.3</td><td>47.5</td><td>61.6</td><td>91.9</td><td>46.3</td></tr></tbody></table>", "caption": "Table 1: Experimental results in VIM on the SoMoF 3DPW test set.", "list_citation_info": ["[30] Wang, J., Xu, H., Narasimhan, M., Wang, X.: Multi-person 3d motion prediction with multi-range transformers. Advances in Neural Information Processing Systems 34 (2021)", "[2] Adeli, V., Ehsanpour, M., Reid, I., Niebles, J.C., Savarese, S., Adeli, E., Rezatofighi, H.: Tripod: Human trajectory and pose dynamics forecasting in the wild. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 13390\u201313400 (2021)", "[11] Huang, Y., Bi, H., Li, Z., Mao, T., Wang, Z.: Stgat: Modeling spatial-temporal interactions for human trajectory prediction. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 6272\u20136281 (2019)", "[25] Parsaeifard, B., Saadatnejad, S., Liu, Y., Mordan, T., Alahi, A.: Learning decoupled representations for human pose forecasting. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 2294\u20132303 (2021)", "[19] Mao, W., Liu, M., Salzmann, M.: History repeats itself: Human motion prediction via motion attention. In: ECCV (2020)", "[1] Adeli, V., Adeli, E., Reid, I.D., Niebles, J.C., Rezatofighi, H.: Socially and contextually aware human motion and pose forecasting. IEEE Robotics and Automation Letters 5, 6033\u20136040 (2020)"]}, {"table": "<table><thead><tr><th></th><th colspan=\"3\">CMU-Mocap Test Set</th><th colspan=\"3\">MuPoTS-3D Test Set</th></tr><tr><th>Method</th><th>1 sec</th><th>2 sec</th><th>3 sec</th><th>  1 sec</th><th>2 sec</th><th>3 sec</th></tr></thead><tbody><tr><th>HRI [19]</th><td>0.503</td><td>0.932</td><td>1.422</td><td>  0.261</td><td>0.469</td><td>0.714</td></tr><tr><th>LTD [20]</th><td>0.480</td><td>0.869</td><td>1.181</td><td>  0.191</td><td>0.337</td><td>0.466</td></tr><tr><th>Multi-Range [30]</th><td>0.456</td><td>0.840</td><td>1.11</td><td>  0.206</td><td>0.393</td><td>0.574</td></tr><tr><th>SoMoFormer</th><td>0.42</td><td>0.80</td><td>1.06</td><td>  0.173</td><td>0.305</td><td>0.423</td></tr></tbody></table>", "caption": "Table 2: Experimental results in MPJPE on CMU-Mocap and MuPoTS-3D.", "list_citation_info": ["[30] Wang, J., Xu, H., Narasimhan, M., Wang, X.: Multi-person 3d motion prediction with multi-range transformers. Advances in Neural Information Processing Systems 34 (2021)", "[19] Mao, W., Liu, M., Salzmann, M.: History repeats itself: Human motion prediction via motion attention. In: ECCV (2020)", "[20] Mao, W., Liu, M., Salzmann, M., Li, H.: Learning trajectory dependencies for human motion prediction. 2019 IEEE/CVF International Conference on Computer Vision (ICCV) pp. 9488\u20139496 (2019)"]}], "citation_info_to_title": {"[20] Mao, W., Liu, M., Salzmann, M., Li, H.: Learning trajectory dependencies for human motion prediction. 2019 IEEE/CVF International Conference on Computer Vision (ICCV) pp. 9488\u20139496 (2019)": "Learning trajectory dependencies for human motion prediction", "[30] Wang, J., Xu, H., Narasimhan, M., Wang, X.: Multi-person 3d motion prediction with multi-range transformers. Advances in Neural Information Processing Systems 34 (2021)": "Multi-person 3D Motion Prediction with Multi-Range Transformers", "[19] Mao, W., Liu, M., Salzmann, M.: History repeats itself: Human motion prediction via motion attention. In: ECCV (2020)": "History repeats itself: Human motion prediction via motion attention", "[1] Adeli, V., Adeli, E., Reid, I.D., Niebles, J.C., Rezatofighi, H.: Socially and contextually aware human motion and pose forecasting. IEEE Robotics and Automation Letters 5, 6033\u20136040 (2020)": "Socially and contextually aware human motion and pose forecasting", "[2] Adeli, V., Ehsanpour, M., Reid, I., Niebles, J.C., Savarese, S., Adeli, E., Rezatofighi, H.: Tripod: Human trajectory and pose dynamics forecasting in the wild. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 13390\u201313400 (2021)": "Tripod: Human trajectory and pose dynamics forecasting in the wild", "[11] Huang, Y., Bi, H., Li, Z., Mao, T., Wang, Z.: Stgat: Modeling spatial-temporal interactions for human trajectory prediction. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 6272\u20136281 (2019)": "Stgat: Modeling spatial-temporal interactions for human trajectory prediction", "[25] Parsaeifard, B., Saadatnejad, S., Liu, Y., Mordan, T., Alahi, A.: Learning decoupled representations for human pose forecasting. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 2294\u20132303 (2021)": "Learning Decoupled Representations for Human Pose Forecasting"}, "source_title_to_arxiv_id": {"Tripod: Human trajectory and pose dynamics forecasting in the wild": "2104.04029"}}