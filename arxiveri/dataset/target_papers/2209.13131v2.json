{"title": "Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances", "abstract": "With the advent of Deep Learning (DL), Super-Resolution (SR) has also become\na thriving research area. However, despite promising results, the field still\nfaces challenges that require further research e.g., allowing flexible\nupsampling, more effective loss functions, and better evaluation metrics. We\nreview the domain of SR in light of recent advances, and examine\nstate-of-the-art models such as diffusion (DDPM) and transformer-based SR\nmodels. We present a critical discussion on contemporary strategies used in SR,\nand identify promising yet unexplored research directions. We complement\nprevious surveys by incorporating the latest developments in the field such as\nuncertainty-driven losses, wavelet networks, neural architecture search, novel\nnormalization methods, and the latests evaluation techniques. We also include\nseveral visualizations for the models and methods throughout each chapter in\norder to facilitate a global understanding of the trends in the field. This\nreview is ultimately aimed at helping researchers to push the boundaries of DL\napplied to SR.", "authors": ["Brian Moser", "Federico Raue", "Stanislav Frolov", "J\u00f6rn Hees", "Sebastian Palacio", "Andreas Dengel"], "published_date": "2022_09_27", "pdf_url": "http://arxiv.org/pdf/2209.13131v2", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Purpose</td><td>Dataset</td><td>Amount of</td><td>Year of</td></tr><tr><td></td><td>name</td><td>images</td><td>release</td></tr><tr><td rowspan=\"3\">Classic SR Training</td><td>BSDS200 [2]</td><td>500</td><td>2001</td></tr><tr><td>T91 [33]</td><td>91</td><td>2010</td></tr><tr><td>General-100 [36]</td><td>100</td><td>2016</td></tr><tr><td rowspan=\"5\">Classic SR Testing</td><td>BSDS100 [2]</td><td>100</td><td>2001</td></tr><tr><td>Set14 [1]</td><td>14</td><td>2010</td></tr><tr><td>Set5 [34]</td><td>5</td><td>2012</td></tr><tr><td>Urban100 [32]</td><td>100</td><td>2015</td></tr><tr><td>Manga109 [35]</td><td>109</td><td>2017</td></tr><tr><td rowspan=\"3\">1K images</td><td>CelebA-HQ [156]</td><td>30,000</td><td>2017</td></tr><tr><td>Flickr-Faces-HQ [157]</td><td>70,000</td><td>2019</td></tr><tr><td>Flickr1024 [158]</td><td>1024</td><td>2019</td></tr><tr><td rowspan=\"2\">2K images</td><td>DIV2K [159]</td><td>900</td><td>2017</td></tr><tr><td>Flickr2K [51]</td><td>2650</td><td>2017</td></tr><tr><td>4K images</td><td>UHDSR4K [160]</td><td>8,099</td><td>2021</td></tr><tr><td rowspan=\"2\">8K images</td><td>DIV8K [161]</td><td>1,504</td><td>2019</td></tr><tr><td>UHDSR8K [160]</td><td>2,966</td><td>2021</td></tr><tr><td rowspan=\"8\">other SR datasets</td><td>BSDS500 [162]</td><td>500</td><td>2010</td></tr><tr><td>KITTI [163]</td><td>3889</td><td>2012</td></tr><tr><td>CASIA Webfaces [164]</td><td>494,414</td><td>2014</td></tr><tr><td>CelebA [165]</td><td>202,599</td><td>2015</td></tr><tr><td>VGGFace2 [166]</td><td>3,310,000</td><td>2018</td></tr><tr><td>PIRM [39]</td><td>200</td><td>2018</td></tr><tr><td>OST300 [167]</td><td>300</td><td>2018</td></tr><tr><td>HIDE [168]</td><td>8,422</td><td>2019</td></tr><tr><td></td><td>SCI1k [169]</td><td>1,000</td><td>2021</td></tr><tr><td rowspan=\"5\">Video SR datasets</td><td>VID4 [170]</td><td>4</td><td>2013</td></tr><tr><td>MCL-V [171]</td><td>12</td><td>2015</td></tr><tr><td>GOPRO [172]</td><td>33</td><td>2017</td></tr><tr><td>Vimeo-90k [173]</td><td>90,000</td><td>2019</td></tr><tr><td>RealVSR [174]</td><td>500</td><td>2021</td></tr></tbody></table>", "caption": "TABLE I: Benchmark datasets for Super-Resolution (SISR and MISR).", "list_citation_info": ["[170] C. Liu and D. Sun, \u201cOn bayesian adaptive video super resolution,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 36, no. 2, pp. 346\u2013360, 2013.", "[161] S. Gu, A. Lugmayr, M. Danelljan, M. Fritsche, J. Lamour, and R. Timofte, \u201cDiv8k: Diverse 8k resolution image dataset,\u201d in 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW). IEEE, 2019, pp. 3512\u20133516.", "[162] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik, \u201cContour detection and hierarchical image segmentation,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 33, no. 5, pp. 898\u2013916, 2010.", "[172] S. Nah, T. H. Kim, and K. M. Lee, \u201cDeep multi-scale convolutional neural network for dynamic scene deblurring,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.", "[171] J. Y. Lin, R. Song, C.-H. Wu, T. Liu, H. Wang, and C.-C. J. Kuo, \u201cMcl-v: A streaming video quality assessment database,\u201d Journal of Visual Communication and Image Representation, vol. 30, pp. 1\u20139, 2015.", "[158] Y. Wang, L. Wang, J. Yang, W. An, and Y. Guo, \u201cFlickr1024: A large-scale dataset for stereo image super-resolution,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, 2019, pp. 0\u20130.", "[33] J. Yang, J. Wright, T. S. Huang, and Y. Ma, \u201cImage super-resolution via sparse representation,\u201d IEEE transactions on image processing, vol. 19, no. 11, pp. 2861\u20132873, 2010.", "[32] J.-B. Huang, A. Singh, and N. Ahuja, \u201cSingle image super-resolution from transformed self-exemplars,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 5197\u20135206.", "[166] Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, \u201cVggface2: A dataset for recognising faces across pose and age,\u201d in 2018 13th IEEE international conference on automatic face & gesture recognition (FG 2018). IEEE, 2018, pp. 67\u201374.", "[168] Z. Shen, W. Wang, X. Lu, J. Shen, H. Ling, T. Xu, and L. Shao, \u201cHuman-aware motion deblurring,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), October 2019.", "[169] J. Yang, S. Shen, H. Yue, and K. Li, \u201cImplicit transformer network for screen content image continuous super-resolution,\u201d Advances in Neural Information Processing Systems, vol. 34, 2021.", "[1] R. Zeyde, M. Elad, and M. Protter, \u201cOn single image scale-up using sparse-representations,\u201d in International conference on curves and surfaces. Springer, 2010, pp. 711\u2013730.", "[156] T. Karras, T. Aila, S. Laine, and J. Lehtinen, \u201cProgressive growing of gans for improved quality, stability, and variation,\u201d arXiv preprint arXiv:1710.10196, 2017.", "[2] D. Martin, C. Fowlkes, D. Tal, and J. Malik, \u201cA database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics,\u201d in Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, vol. 2. IEEE, 2001, pp. 416\u2013423.", "[51] B. Lim, S. Son, H. Kim, S. Nah, and K. M. Lee, \u201cEnhanced deep residual networks for single image super-resolution,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, July 2017.", "[36] C. Dong, C. C. Loy, and X. Tang, \u201cAccelerating the super-resolution convolutional neural network,\u201d in European conference on computer vision. Springer, 2016, pp. 391\u2013407.", "[34] M. Bevilacqua, A. Roumy, C. Guillemot, and M. L. Alberi-Morel, \u201cLow-complexity single-image super-resolution based on nonnegative neighbor embedding,\u201d 2012.", "[173] T. Xue, B. Chen, J. Wu, D. Wei, and W. T. Freeman, \u201cVideo enhancement with task-oriented flow,\u201d International Journal of Computer Vision (IJCV), vol. 127, no. 8, pp. 1106\u20131125, 2019.", "[35] Y. Matsui, K. Ito, Y. Aramaki, A. Fujimoto, T. Ogawa, T. Yamasaki, and K. Aizawa, \u201cSketch-based manga retrieval using manga109 dataset,\u201d Multimedia Tools and Applications, vol. 76, no. 20, pp. 21\u2009811\u201321\u2009838, 2017.", "[165] Z. Liu, P. Luo, X. Wang, and X. Tang, \u201cDeep learning face attributes in the wild,\u201d in Proceedings of the IEEE international conference on computer vision, 2015, pp. 3730\u20133738.", "[160] K. Zhang, D. Li, W. Luo, W. Ren, B. Stenger, W. Liu, H. Li, and M.-H. Yang, \u201cBenchmarking ultra-high-definition image super-resolution,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 14\u2009769\u201314\u2009778.", "[174] X. Yang, W. Xiang, H. Zeng, and L. Zhang, \u201cReal-world video super-resolution: A benchmark dataset and a decomposition based learning scheme,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 4781\u20134790.", "[39] Y. Blau, R. Mechrez, R. Timofte, T. Michaeli, and L. Zelnik-Manor, \u201cThe 2018 pirm challenge on perceptual image super-resolution,\u201d in Proceedings of the European Conference on Computer Vision (ECCV) Workshops, 2018, pp. 0\u20130.", "[157] T. Karras, S. Laine, and T. Aila, \u201cA style-based generator architecture for generative adversarial networks,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 4401\u20134410.", "[167] X. Wang, K. Yu, C. Dong, and C. C. Loy, \u201cRecovering realistic texture in image super-resolution by deep spatial feature transform,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 606\u2013615.", "[163] A. Geiger, P. Lenz, and R. Urtasun, \u201cAre we ready for autonomous driving? the kitti vision benchmark suite,\u201d in 2012 IEEE conference on computer vision and pattern recognition. IEEE, 2012, pp. 3354\u20133361.", "[164] D. Yi, Z. Lei, S. Liao, and S. Z. Li, \u201cLearning face representation from scratch,\u201d arXiv preprint arXiv:1411.7923, 2014.", "[159] E. Agustsson and R. Timofte, \u201cNtire 2017 challenge on single image super-resolution: Dataset and study,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, 2017, pp. 126\u2013135."]}, {"table": "<table><tbody><tr><th rowspan=\"2\">Model</th><td colspan=\"3\">Set5</td><td colspan=\"3\">Set14</td><td colspan=\"3\">BSDS100</td></tr><tr><td>x2</td><td>x3</td><td>x4</td><td>x2</td><td>x3</td><td>x4</td><td>x2</td><td>x3</td><td>x4</td></tr><tr><th></th><td>PSNR/SSIM</td><td>PSNR/SSIM</td><td>PSNR/SSIM</td><td>PSNR/SSIM</td><td>PSNR/SSIM</td><td>PSNR/SSIM</td><td>PSNR/SSIM</td><td>PSNR/SSIM</td><td>PSNR/SSIM</td></tr><tr><th>Bicubic</th><td>33.66/0.9542</td><td>30.39/0.8682</td><td>28.42/0.8104</td><td>30.24/0.8688</td><td>27.55/0.7742</td><td>26.00/0.7027</td><td>29.56/0.8431</td><td>27.21/0.7385</td><td>25.96/0.6675</td></tr><tr><th>DIP [138]</th><td>n.a.</td><td>n.a.</td><td>28.90/n.a.</td><td>n.a.</td><td>n.a.</td><td>27.00/n.a.</td><td>n.a.</td><td>n.a.</td><td>n.a.</td></tr><tr><th>NAS-DIP [151]</th><td>35.90/n.a.</td><td>n.a.</td><td>31.09/n.a.</td><td>31.89/n.a.</td><td>n.a.</td><td>28.37/n.a.</td><td>n.a.</td><td>n.a.</td><td>n.a.</td></tr><tr><th>SelfExSR [32]</th><td>36.49/0.9537</td><td>32.58/0.9093</td><td>30.31/0.8619</td><td>32.22/0.9034</td><td>29.16/0.8196</td><td>27.40/0.7518</td><td>31.18/0.8855</td><td>28.29/0.7840</td><td>26.84/0.7106</td></tr><tr><th>SRCNN [42]</th><td>36.66/0.9542</td><td>32.75/0.9090</td><td>30.48/0.8628</td><td>32.42/0.9063</td><td>29.28/0.8209</td><td>27.49/0.7503</td><td>31.36/0.8879</td><td>28.41/0.7863</td><td>26.90/0.7101</td></tr><tr><th>FSRCNN [36]</th><td>37.00/0.9558</td><td>33.16/0.9140</td><td>30.71/0.8657</td><td>32.63/0.9088</td><td>29.43/0.8242</td><td>27.59/0.7535</td><td>31.51/0.8910</td><td>n.a.</td><td>26.97/0.7140</td></tr><tr><th>ESPCN [71]</th><td>n.a.</td><td>33.13/n.a.</td><td>30.90/n.a.</td><td>n.a.</td><td>29.49/n.a.</td><td>27.73/n.a.</td><td>n.a.</td><td>n.a.</td><td>n.a.</td></tr><tr><th>MZSR [142]</th><td>37.25/0.9567</td><td>n.a.</td><td>n.a.</td><td>n.a.</td><td>n.a.</td><td>n.a.</td><td>31.64/0.8928</td><td>n.a.</td><td>n.a.</td></tr><tr><th>ZSSR [92]</th><td>37.37/0.9570</td><td>33.42/0.9188</td><td>31.13/0.8796</td><td>33.00/0.9108</td><td>29.80/0.8304</td><td>28.01/0.7651</td><td>31.65/0.8920</td><td>28.67/0.7945</td><td>27.12/0.7211</td></tr><tr><th>LapSRN [46]</th><td>37.52/0.9591</td><td>33.81/0.9220</td><td>31.54/0.8852</td><td>32.99/0.9124</td><td>29.79/0.8325</td><td>28.09/0.7700</td><td>31.80/0.8952</td><td>28.82/0.7980</td><td>27.32/0.7275</td></tr><tr><th>VDSR [101]</th><td>37.53/0.9587</td><td>33.66/0.9213</td><td>31.35/0.8838</td><td>33.03/0.9124</td><td>29.77/0.8314</td><td>28.01/0.7674</td><td>31.90/0.8960</td><td>28.82/0.7976</td><td>27.29/0.7251</td></tr><tr><th>DWSR [128]</th><td>37.43/0.9568</td><td>33.82/0.9215</td><td>31.39/0.8833</td><td>33.07/0.9106</td><td>29.83/0.8308</td><td>28.04/0.7669</td><td>31.80/0.8940</td><td>n.a.</td><td>27.25/0.7240</td></tr><tr><th>DRCN [109]</th><td>37.63/0.9588</td><td>33.82/0.9226</td><td>31.53/0.8854</td><td>33.04/0.9118</td><td>29.76/0.8311</td><td>28.02/0.7670</td><td>31.85/0.8942</td><td>28.80/0.7963</td><td>28.23/0.7233</td></tr><tr><th>MoreMNAS [10]</th><td>37.57/0.9584</td><td>n.a.</td><td>n.a.</td><td>33.25/0.9142</td><td>n.a.</td><td>n.a.</td><td>31.94/0.8966</td><td>n.a.</td><td>n.a.</td></tr><tr><th>RED [105]</th><td>37.66/0.9599</td><td>33.82/0.9230</td><td>31.51/0.8869</td><td>32.94/0.9144</td><td>29.61/0.8341</td><td>27.86/0.7718</td><td>31.99/0.8974</td><td>28.93/0.7994</td><td>27.40/0.7290</td></tr><tr><th>DSRN [112]</th><td>37.66/0.9590</td><td>33.88/0.9220</td><td>31.40/0.8830</td><td>33.15/0.9130</td><td>30.26/0.8370</td><td>28.07/0.7700</td><td>32.10/0.8970</td><td>28.81/0.7970</td><td>27.25/0.7240</td></tr><tr><th>DRRN [70]</th><td>37.74/0.9591</td><td>34.03/0.9244</td><td>31.68/0.8888</td><td>33.23/0.9136</td><td>29.96/0.8349</td><td>28.21/0.7720</td><td>32.05/0.8973</td><td>28.95/0.8004</td><td>27.38/0.7284</td></tr><tr><th>CARN-M [118]</th><td>37.53/0.9583</td><td>33.99/0.9236</td><td>31.92/0.8903</td><td>33.26/0.9141</td><td>30.08/0.8367</td><td>28.42/0.7762</td><td>31.92/0.8960</td><td>28.91/0.8000</td><td>27.44/0.7304</td></tr><tr><th>MemNet [97]</th><td>37.78/0.9597</td><td>34.09/0.9248</td><td>31.74/0.8893</td><td>33.28/0.9142</td><td>30.00/0.8350</td><td>28.26/0.7723</td><td>32.08/0.8978</td><td>28.96/0.8001</td><td>27.40/0.7281</td></tr><tr><th>IDN [46]</th><td>37.83/0.9600</td><td>34.11/0.9253</td><td>31.82/0.8903</td><td>33.30/0.9148</td><td>29.99/0.8354</td><td>28.25/0.7730</td><td>32.08/0.8985</td><td>28.95/0.8013</td><td>27.41/0.7297</td></tr><tr><th>FALSR [147]</th><td>37.82/0.9595</td><td>n.a.</td><td>n.a.</td><td>33.55/0.9168</td><td>n.a.</td><td>n.a.</td><td>32.12/0.8987</td><td>n.a.</td><td>n.a.</td></tr><tr><th>MWCNN [131]</th><td>37.91/0.9600</td><td>34.17/0.9271</td><td>32.12/0.8941</td><td>33.70/0.9182</td><td>30.16/0.8414</td><td>28.41/0.7816</td><td>32.23/0.8999</td><td>29.12/0.8060</td><td>27.62/0.7355</td></tr><tr><th>NLRN [115]</th><td>38.00/0.9603</td><td>34.27/0.9266</td><td>31.92/0.8916</td><td>33.46/0.9159</td><td>30.16/0.8374</td><td>28.36/0.7745</td><td>32.19/0.8992</td><td>29.06/0.8026</td><td>27.48/0.7306</td></tr><tr><th>CARN [118]</th><td>37.76/0.9590</td><td>34.29/0.9255</td><td>32.13/0.8937</td><td>33.52/0.9166</td><td>30.29/0.8407</td><td>28.60/0.7806</td><td>32.09/0.8978</td><td>29.06/0.8034</td><td>27.58/0.7349</td></tr><tr><th>IMDN [122]</th><td>38.00/0.9605</td><td>34.36/0.9270</td><td>32.21/0.8948</td><td>33.63/0.9177</td><td>30.32/0.8417</td><td>28.58/0.7811</td><td>32.19/0.8996</td><td>29.09/0.8046</td><td>27.56/0.7353</td></tr><tr><th>RFDN [120]</th><td>38.05/0.9606</td><td>34.41/0.9273</td><td>32.24/0.8952</td><td>33.68/0.9184</td><td>30.34/0.8420</td><td>28.61/0.7819</td><td>32.16/0.8994</td><td>29.09/0.8050</td><td>27.57/0.7360</td></tr><tr><th>RFDN-L [120]</th><td>38.08/0.9606</td><td>34.47/0.9280</td><td>32.28/0.8957</td><td>33.67/0.9190</td><td>30.35/0.8421</td><td>28.61/0.7818</td><td>32.18/0.8996</td><td>29.11/0.8053</td><td>27.58/0.7363</td></tr><tr><th>DeCoNAS [148]</th><td>37.96/0.9594</td><td>n.a.</td><td>n.a.</td><td>33.63/0.9175</td><td>n.a.</td><td>n.a.</td><td>32.15/0.8986</td><td>n.a.</td><td>n.a.</td></tr><tr><th>HNAS [150]</th><td>38.11/0.9640</td><td>n.a.</td><td>n.a.</td><td>33.60/0.9200</td><td>n.a.</td><td>n.a.</td><td>32.17/0.9020</td><td>n.a.</td><td>n.a.</td></tr><tr><th>ESRN [144]</th><td>38.04/0.9607</td><td>34.46/0.9281</td><td>32.26/0.8957</td><td>33.71/0.9185</td><td>30.43/0.8439</td><td>28.63/0.7818</td><td>32.23/0.9005</td><td>29.15/0.8072</td><td>27.62/0.7378</td></tr><tr><th>SRFBN [69]</th><td>38.11/0.9609</td><td>34.70/0.9292</td><td>32.47/0.8983</td><td>33.82/0.9196</td><td>30.51/0.8461</td><td>28.81/0.7868</td><td>32.29/0.9010</td><td>29.24/0.8084</td><td>27.72/0.7409</td></tr><tr><th>SRFBN+ [69]</th><td>38.18/0.9611</td><td>34.77/0.9297</td><td>32.56/0.8992</td><td>33.90/0.9203</td><td>30.61/0.8473</td><td>28.87/0.7881</td><td>32.34/0.9015</td><td>29.29/0.8093</td><td>27.77/0.7419</td></tr><tr><th>MDSR [41]</th><td>38.17/0.9605</td><td>34.77/0.9288</td><td>32.60/0.8982</td><td>33.92/0.9203</td><td>30.53/0.8465</td><td>28.82/0.7876</td><td>32.34/0.9014</td><td>29.30/0.8101</td><td>27.78/0.7425</td></tr><tr><th>EDSR [41]</th><td>38.20/0.9606</td><td>34.76/0.9290</td><td>32.62/0.8984</td><td>34.02/0.9204</td><td>30.66/0.8481</td><td>28.94/0.7901</td><td>32.37/0.9018</td><td>29.32/0.8104</td><td>27.79/0.7437</td></tr><tr><th>WRAN [133]</th><td>38.32/0.9630</td><td>34.79/0.9310</td><td>32.36/0.8990</td><td>34.21/0.9220</td><td>30.71/0.8520</td><td>28.60/0.7860</td><td>32.57/0.9070</td><td>29.36/0.8190</td><td>27.71/0.7420</td></tr><tr><th>DRLN [6]</th><td>38.27/0.9616</td><td>34.78/0.9303</td><td>32.63/0.9002</td><td>34.28/0.9231</td><td>30.73/0.8488</td><td>28.94/0.7900</td><td>32.44/0.9028</td><td>29.36/0.8117</td><td>27.83/0.7444</td></tr><tr><th>HAN [87]</th><td>38.33/0.9617</td><td>34.85/0.9305</td><td>32.75/0.9016</td><td>34.24/0.9224</td><td>30.77/0.8495</td><td>28.99/0.7907</td><td>32.45/0.9030</td><td>29.39/0.8120</td><td>27.85/0.7454</td></tr><tr><th>DRLN+ [6]</th><td>38.34/0.9619</td><td>34.86/0.9307</td><td>32.74/0.9013</td><td>34.43/0.9247</td><td>30.80/0.8498</td><td>29.02/0.7914</td><td>32.47/0.9032</td><td>29.40/0.8125</td><td>27.87/0.7453</td></tr><tr><th>SwinIR [175]</th><td>38.46/0.9624</td><td>35.04/0.9322</td><td>32.93/0.9043</td><td>33.07/0.9106</td><td>31.00/0.8542</td><td>29.15/0.7958</td><td>31.80/0.8940</td><td>29.49/0.8150</td><td>27.95/0.7494</td></tr><tr><th>WIDN [129]</th><td>39.60/0.9830</td><td>34.48/0.9430</td><td>32.85/0.9290</td><td>34.44/0.9800</td><td>30.95/0.9310</td><td>29.75/0.9090</td><td>33.52/0.9790</td><td>29.99/0.9280</td><td>28.10/0.9100</td></tr><tr><th>CAR (EDSR) [7]</th><td>38.94/0.9658</td><td>n.a.</td><td>33.88/0.9174</td><td>35.61/0.9404</td><td>n.a.</td><td>30.31/0.8382</td><td>33.83/0.9262</td><td>n.a.</td><td>29.15/0.8001</td></tr></tbody></table>", "caption": "TABLE III: Comparison (PSNR/SSIM) of SR approaches discussed in this work: Simple, residual, recurrent, attention-based, lightweight and wavelet networks, as well as NAS derived networks and unsupervised trained models. The ordering reflects roughly the performance ranking. However, some comparisons are not fair due to different settings, e.g., NAS vs unsupervised results. Also, some publications do not report results on the commonly used datasets. Therefore, they are not listed (e.g. WESPE [135], DSN [140], CinCGan [56]).", "list_citation_info": ["[140] X. Cheng, Z. Fu, and J. Yang, \u201cZero-shot image super-resolution with depth guided internal degradation learning,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 265\u2013280.", "[71] W. Shi, J. Caballero, F. Husz\u00e1r, J. Totz, A. P. Aitken, R. Bishop, D. Rueckert, and Z. Wang, \u201cReal-time single image and video super-resolution using an efficient sub-pixel convolutional neural network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 1874\u20131883.", "[92] A. Shocher, N. Cohen, and M. Irani, \u201c\u201czero-shot\u201d super-resolution using deep internal learning,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 3118\u20133126.", "[147] X. Chu, B. Zhang, H. Ma, R. Xu, and Q. Li, \u201cFast, accurate and lightweight super-resolution with neural architecture search,\u201d in 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021, pp. 59\u201364.", "[109] J. Kim, J. K. Lee, and K. M. Lee, \u201cDeeply-recursive convolutional network for image super-resolution,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 1637\u20131645.", "[138] D. Ulyanov, A. Vedaldi, and V. Lempitsky, \u201cDeep image prior,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 9446\u20139454.", "[46] Z. Hui, X. Wang, and X. Gao, \u201cFast and accurate single image super-resolution via information distillation network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 723\u2013731.", "[32] J.-B. Huang, A. Singh, and N. Ahuja, \u201cSingle image super-resolution from transformed self-exemplars,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 5197\u20135206.", "[6] S. Anwar and N. Barnes, \u201cDensely residual laplacian super-resolution,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020.", "[87] B. Niu, W. Wen, W. Ren, X. Zhang, L. Yang, S. Wang, K. Zhang, X. Cao, and H. Shen, \u201cSingle image super-resolution via a holistic attention network,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 191\u2013207.", "[148] J. Y. Ahn and N. I. Cho, \u201cNeural architecture search for image super-resolution using densely constructed search space: Deconas,\u201d in 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021, pp. 4829\u20134836.", "[7] W. Sun and Z. Chen, \u201cLearned image downscaling for upscaling using content adaptive resampler,\u201d IEEE Transactions on Image Processing, vol. 29, pp. 4027\u20134040, 2020.", "[10] X. Chu, B. Zhang, and R. Xu, \u201cMulti-objective reinforced evolution in mobile neural architecture search,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 99\u2013113.", "[36] C. Dong, C. C. Loy, and X. Tang, \u201cAccelerating the super-resolution convolutional neural network,\u201d in European conference on computer vision. Springer, 2016, pp. 391\u2013407.", "[97] Y. Tai, J. Yang, X. Liu, and C. Xu, \u201cMemnet: A persistent memory network for image restoration,\u201d in Proceedings of the IEEE international conference on computer vision, 2017, pp. 4539\u20134547.", "[133] S. Xue, W. Qiu, F. Liu, and X. Jin, \u201cWavelet-based residual attention network for image super-resolution,\u201d Neurocomputing, vol. 382, pp. 116\u2013126, 2020.", "[56] Y. Yuan, S. Liu, J. Zhang, Y. Zhang, C. Dong, and L. Lin, \u201cUnsupervised image super-resolution using cycle-in-cycle generative adversarial networks,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2018, pp. 701\u2013710.", "[115] D. Liu, B. Wen, Y. Fan, C. C. Loy, and T. S. Huang, \u201cNon-local recurrent network for image restoration,\u201d arXiv preprint arXiv:1806.02919, 2018.", "[105] X. Mao, C. Shen, and Y.-B. Yang, \u201cImage restoration using very deep convolutional encoder-decoder networks with symmetric skip connections,\u201d Advances in neural information processing systems, vol. 29, pp. 2802\u20132810, 2016.", "[101] J. Kim, J. K. Lee, and K. M. Lee, \u201cAccurate image super-resolution using very deep convolutional networks,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 1646\u20131654.", "[118] N. Ahn, B. Kang, and K.-A. Sohn, \u201cFast, accurate, and lightweight super-resolution with cascading residual network,\u201d in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 252\u2013268.", "[151] Y.-C. Chen, C. Gao, E. Robb, and J.-B. Huang, \u201cNas-dip: Learning deep image prior with neural architecture search,\u201d in Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XVIII 16. Springer, 2020, pp. 442\u2013459.", "[131] P. Liu, H. Zhang, K. Zhang, L. Lin, and W. Zuo, \u201cMulti-level wavelet-cnn for image restoration,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, 2018, pp. 773\u2013782.", "[122] Z. Hui, X. Gao, Y. Yang, and X. Wang, \u201cLightweight image super-resolution with information multi-distillation network,\u201d in Proceedings of the 27th ACM International Conference on Multimedia, 2019, pp. 2024\u20132032.", "[175] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo, \u201cSwin transformer: Hierarchical vision transformer using shifted windows,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 10\u2009012\u201310\u2009022.", "[120] J. Liu, J. Tang, and G. Wu, \u201cResidual feature distillation network for lightweight image super-resolution,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 41\u201355.", "[41] B. Lim, S. Son, H. Kim, S. Nah, and K. Mu Lee, \u201cEnhanced deep residual networks for single image super-resolution,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, 2017, pp. 136\u2013144.", "[69] Z. Li, J. Yang, Z. Liu, X. Yang, G. Jeon, and W. Wu, \u201cFeedback network for image super-resolution,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 3867\u20133876.", "[129] F. Sahito, P. Zhiwen, J. Ahmed, and R. A. Memon, \u201cWavelet-integrated deep networks for single image super-resolution,\u201d Electronics, vol. 8, no. 5, p. 553, 2019.", "[128] T. Guo, H. Seyed Mousavi, T. Huu Vu, and V. Monga, \u201cDeep wavelet prediction for image super-resolution,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2017, pp. 104\u2013113.", "[70] Y. Tai, J. Yang, and X. Liu, \u201cImage super-resolution via deep recursive residual network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 3147\u20133155.", "[142] J. W. Soh, S. Cho, and N. I. Cho, \u201cMeta-transfer learning for zero-shot super-resolution,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 3516\u20133525.", "[144] D. Song, C. Xu, X. Jia, Y. Chen, C. Xu, and Y. Wang, \u201cEfficient residual dense block search for image super-resolution,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 07, 2020, pp. 12\u2009007\u201312\u2009014.", "[150] Y. Guo, Y. Luo, Z. He, J. Huang, and J. Chen, \u201cHierarchical neural architecture search for single image super-resolution,\u201d IEEE Signal Processing Letters, vol. 27, pp. 1255\u20131259, 2020.", "[135] A. Ignatov, N. Kobyshev, R. Timofte, K. Vanhoey, and L. Van Gool, \u201cWespe: weakly supervised photo enhancer for digital cameras,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2018, pp. 691\u2013700.", "[112] W. Han, S. Chang, D. Liu, M. Yu, M. Witbrock, and T. S. Huang, \u201cImage super-resolution via dual-state recurrent networks,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 1654\u20131663.", "[42] C. Dong, C. C. Loy, K. He, and X. Tang, \u201cImage super-resolution using deep convolutional networks,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 38, no. 2, pp. 295\u2013307, 2015."]}], "citation_info_to_title": {"[39] Y. Blau, R. Mechrez, R. Timofte, T. Michaeli, and L. Zelnik-Manor, \u201cThe 2018 pirm challenge on perceptual image super-resolution,\u201d in Proceedings of the European Conference on Computer Vision (ECCV) Workshops, 2018, pp. 0\u20130.": "The 2018 PIRM Challenge on Perceptual Image Super-Resolution", "[115] D. Liu, B. Wen, Y. Fan, C. C. Loy, and T. S. Huang, \u201cNon-local recurrent network for image restoration,\u201d arXiv preprint arXiv:1806.02919, 2018.": "Non-local recurrent network for image restoration", "[131] P. Liu, H. Zhang, K. Zhang, L. Lin, and W. Zuo, \u201cMulti-level wavelet-cnn for image restoration,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, 2018, pp. 773\u2013782.": "Multi-level wavelet-cnn for image restoration", "[87] B. Niu, W. Wen, W. Ren, X. Zhang, L. Yang, S. Wang, K. Zhang, X. Cao, and H. Shen, \u201cSingle image super-resolution via a holistic attention network,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 191\u2013207.": "Single Image Super-Resolution via a Holistic Attention Network", "[161] S. Gu, A. Lugmayr, M. Danelljan, M. Fritsche, J. Lamour, and R. Timofte, \u201cDiv8k: Diverse 8k resolution image dataset,\u201d in 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW). IEEE, 2019, pp. 3512\u20133516.": "Div8k: Diverse 8k resolution image dataset", "[144] D. Song, C. Xu, X. Jia, Y. Chen, C. Xu, and Y. Wang, \u201cEfficient residual dense block search for image super-resolution,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, no. 07, 2020, pp. 12\u2009007\u201312\u2009014.": "Efficient residual dense block search for image super-resolution", "[51] B. Lim, S. Son, H. Kim, S. Nah, and K. M. Lee, \u201cEnhanced deep residual networks for single image super-resolution,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, July 2017.": "Enhanced deep residual networks for single image super-resolution", "[101] J. Kim, J. K. Lee, and K. M. Lee, \u201cAccurate image super-resolution using very deep convolutional networks,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 1646\u20131654.": "Accurate image super-resolution using very deep convolutional networks", "[105] X. Mao, C. Shen, and Y.-B. Yang, \u201cImage restoration using very deep convolutional encoder-decoder networks with symmetric skip connections,\u201d Advances in neural information processing systems, vol. 29, pp. 2802\u20132810, 2016.": "Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections", "[1] R. Zeyde, M. Elad, and M. Protter, \u201cOn single image scale-up using sparse-representations,\u201d in International conference on curves and surfaces. Springer, 2010, pp. 711\u2013730.": "On single image scale-up using sparse-representations", "[172] S. Nah, T. H. Kim, and K. M. Lee, \u201cDeep multi-scale convolutional neural network for dynamic scene deblurring,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.": "Deep multi-scale convolutional neural network for dynamic scene deblurring", "[71] W. Shi, J. Caballero, F. Husz\u00e1r, J. Totz, A. P. Aitken, R. Bishop, D. Rueckert, and Z. Wang, \u201cReal-time single image and video super-resolution using an efficient sub-pixel convolutional neural network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 1874\u20131883.": "Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network", "[92] A. Shocher, N. Cohen, and M. Irani, \u201c\u201czero-shot\u201d super-resolution using deep internal learning,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 3118\u20133126.": "Zero-Shot Super-Resolution Using Deep Internal Learning", "[135] A. Ignatov, N. Kobyshev, R. Timofte, K. Vanhoey, and L. Van Gool, \u201cWespe: weakly supervised photo enhancer for digital cameras,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2018, pp. 691\u2013700.": "Wespe: weakly supervised photo enhancer for digital cameras", "[147] X. Chu, B. Zhang, H. Ma, R. Xu, and Q. Li, \u201cFast, accurate and lightweight super-resolution with neural architecture search,\u201d in 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021, pp. 59\u201364.": "Fast, accurate and lightweight super-resolution with neural architecture search", "[10] X. Chu, B. Zhang, and R. Xu, \u201cMulti-objective reinforced evolution in mobile neural architecture search,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 99\u2013113.": "Multi-objective reinforced evolution in mobile neural architecture search", "[173] T. Xue, B. Chen, J. Wu, D. Wei, and W. T. Freeman, \u201cVideo enhancement with task-oriented flow,\u201d International Journal of Computer Vision (IJCV), vol. 127, no. 8, pp. 1106\u20131125, 2019.": "Video enhancement with task-oriented flow", "[156] T. Karras, T. Aila, S. Laine, and J. Lehtinen, \u201cProgressive growing of gans for improved quality, stability, and variation,\u201d arXiv preprint arXiv:1710.10196, 2017.": "Progressive growing of gans for improved quality, stability, and variation", "[122] Z. Hui, X. Gao, Y. Yang, and X. Wang, \u201cLightweight image super-resolution with information multi-distillation network,\u201d in Proceedings of the 27th ACM International Conference on Multimedia, 2019, pp. 2024\u20132032.": "Lightweight image super-resolution with information multi-distillation network", "[7] W. Sun and Z. Chen, \u201cLearned image downscaling for upscaling using content adaptive resampler,\u201d IEEE Transactions on Image Processing, vol. 29, pp. 4027\u20134040, 2020.": "Learned image downscaling for upscaling using content adaptive resampler", "[158] Y. Wang, L. Wang, J. Yang, W. An, and Y. Guo, \u201cFlickr1024: A large-scale dataset for stereo image super-resolution,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, 2019, pp. 0\u20130.": "Flickr1024: A large-scale dataset for stereo image super-resolution", "[163] A. Geiger, P. Lenz, and R. Urtasun, \u201cAre we ready for autonomous driving? the kitti vision benchmark suite,\u201d in 2012 IEEE conference on computer vision and pattern recognition. IEEE, 2012, pp. 3354\u20133361.": "Are we ready for autonomous driving? The KITTI Vision Benchmark Suite", "[69] Z. Li, J. Yang, Z. Liu, X. Yang, G. Jeon, and W. Wu, \u201cFeedback network for image super-resolution,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 3867\u20133876.": "Feedback network for image super-resolution", "[151] Y.-C. Chen, C. Gao, E. Robb, and J.-B. Huang, \u201cNas-dip: Learning deep image prior with neural architecture search,\u201d in Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XVIII 16. Springer, 2020, pp. 442\u2013459.": "Nas-dip: Learning deep image prior with neural architecture search", "[165] Z. Liu, P. Luo, X. Wang, and X. Tang, \u201cDeep learning face attributes in the wild,\u201d in Proceedings of the IEEE international conference on computer vision, 2015, pp. 3730\u20133738.": "Deep learning face attributes in the wild", "[129] F. Sahito, P. Zhiwen, J. Ahmed, and R. A. Memon, \u201cWavelet-integrated deep networks for single image super-resolution,\u201d Electronics, vol. 8, no. 5, p. 553, 2019.": "Wavelet-integrated deep networks for single image super-resolution", "[70] Y. Tai, J. Yang, and X. Liu, \u201cImage super-resolution via deep recursive residual network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 3147\u20133155.": "Image super-resolution via deep recursive residual network", "[175] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo, \u201cSwin transformer: Hierarchical vision transformer using shifted windows,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 10\u2009012\u201310\u2009022.": "Swin transformer: Hierarchical vision transformer using shifted windows", "[148] J. Y. Ahn and N. I. Cho, \u201cNeural architecture search for image super-resolution using densely constructed search space: Deconas,\u201d in 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021, pp. 4829\u20134836.": "Neural architecture search for image super-resolution using densely constructed search space: Deconas", "[32] J.-B. Huang, A. Singh, and N. Ahuja, \u201cSingle image super-resolution from transformed self-exemplars,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 5197\u20135206.": "Single image super-resolution from transformed self-exemplars", "[167] X. Wang, K. Yu, C. Dong, and C. C. Loy, \u201cRecovering realistic texture in image super-resolution by deep spatial feature transform,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 606\u2013615.": "Recovering realistic texture in image super-resolution by deep spatial feature transform", "[34] M. Bevilacqua, A. Roumy, C. Guillemot, and M. L. Alberi-Morel, \u201cLow-complexity single-image super-resolution based on nonnegative neighbor embedding,\u201d 2012.": "Low-complexity single-image super-resolution based on nonnegative neighbor embedding", "[168] Z. Shen, W. Wang, X. Lu, J. Shen, H. Ling, T. Xu, and L. Shao, \u201cHuman-aware motion deblurring,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), October 2019.": "Human-aware motion deblurring", "[118] N. Ahn, B. Kang, and K.-A. Sohn, \u201cFast, accurate, and lightweight super-resolution with cascading residual network,\u201d in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 252\u2013268.": "Fast, accurate, and lightweight super-resolution with cascading residual network", "[138] D. Ulyanov, A. Vedaldi, and V. Lempitsky, \u201cDeep image prior,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 9446\u20139454.": "Deep image prior", "[33] J. Yang, J. Wright, T. S. Huang, and Y. Ma, \u201cImage super-resolution via sparse representation,\u201d IEEE transactions on image processing, vol. 19, no. 11, pp. 2861\u20132873, 2010.": "Image Super-Resolution via Sparse Representation", "[174] X. Yang, W. Xiang, H. Zeng, and L. Zhang, \u201cReal-world video super-resolution: A benchmark dataset and a decomposition based learning scheme,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 4781\u20134790.": "Real-world video super-resolution: A benchmark dataset and a decomposition based learning scheme", "[46] Z. Hui, X. Wang, and X. Gao, \u201cFast and accurate single image super-resolution via information distillation network,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 723\u2013731.": "Fast and accurate single image super-resolution via information distillation network", "[97] Y. Tai, J. Yang, X. Liu, and C. Xu, \u201cMemnet: A persistent memory network for image restoration,\u201d in Proceedings of the IEEE international conference on computer vision, 2017, pp. 4539\u20134547.": "Memnet: A Persistent Memory Network for Image Restoration", "[150] Y. Guo, Y. Luo, Z. He, J. Huang, and J. Chen, \u201cHierarchical neural architecture search for single image super-resolution,\u201d IEEE Signal Processing Letters, vol. 27, pp. 1255\u20131259, 2020.": "Hierarchical neural architecture search for single image super-resolution", "[159] E. Agustsson and R. Timofte, \u201cNtire 2017 challenge on single image super-resolution: Dataset and study,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, 2017, pp. 126\u2013135.": "Ntire 2017 Challenge on Single Image Super-Resolution: Dataset and Study", "[120] J. Liu, J. Tang, and G. Wu, \u201cResidual feature distillation network for lightweight image super-resolution,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 41\u201355.": "Residual feature distillation network for lightweight image super-resolution", "[2] D. Martin, C. Fowlkes, D. Tal, and J. Malik, \u201cA database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics,\u201d in Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, vol. 2. IEEE, 2001, pp. 416\u2013423.": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics", "[42] C. Dong, C. C. Loy, K. He, and X. Tang, \u201cImage super-resolution using deep convolutional networks,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 38, no. 2, pp. 295\u2013307, 2015.": "Image Super-Resolution Using Deep Convolutional Networks", "[133] S. Xue, W. Qiu, F. Liu, and X. Jin, \u201cWavelet-based residual attention network for image super-resolution,\u201d Neurocomputing, vol. 382, pp. 116\u2013126, 2020.": "Wavelet-based residual attention network for image super-resolution", "[171] J. Y. Lin, R. Song, C.-H. Wu, T. Liu, H. Wang, and C.-C. J. Kuo, \u201cMcl-v: A streaming video quality assessment database,\u201d Journal of Visual Communication and Image Representation, vol. 30, pp. 1\u20139, 2015.": "Mcl-v: A streaming video quality assessment database", "[164] D. Yi, Z. Lei, S. Liao, and S. Z. Li, \u201cLearning face representation from scratch,\u201d arXiv preprint arXiv:1411.7923, 2014.": "Learning face representation from scratch", "[157] T. Karras, S. Laine, and T. Aila, \u201cA style-based generator architecture for generative adversarial networks,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 4401\u20134410.": "A style-based generator architecture for generative adversarial networks", "[109] J. Kim, J. K. Lee, and K. M. Lee, \u201cDeeply-recursive convolutional network for image super-resolution,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 1637\u20131645.": "Deeply-recursive convolutional network for image super-resolution", "[6] S. Anwar and N. Barnes, \u201cDensely residual laplacian super-resolution,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020.": "Densely residual Laplacian super-resolution", "[112] W. Han, S. Chang, D. Liu, M. Yu, M. Witbrock, and T. S. Huang, \u201cImage super-resolution via dual-state recurrent networks,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 1654\u20131663.": "Image super-resolution via dual-state recurrent networks", "[170] C. Liu and D. Sun, \u201cOn bayesian adaptive video super resolution,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 36, no. 2, pp. 346\u2013360, 2013.": "On Bayesian Adaptive Video Super Resolution", "[162] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik, \u201cContour detection and hierarchical image segmentation,\u201d IEEE transactions on pattern analysis and machine intelligence, vol. 33, no. 5, pp. 898\u2013916, 2010.": "Contour detection and hierarchical image segmentation", "[35] Y. Matsui, K. Ito, Y. Aramaki, A. Fujimoto, T. Ogawa, T. Yamasaki, and K. Aizawa, \u201cSketch-based manga retrieval using manga109 dataset,\u201d Multimedia Tools and Applications, vol. 76, no. 20, pp. 21\u2009811\u201321\u2009838, 2017.": "Sketch-based manga retrieval using manga109 dataset", "[160] K. Zhang, D. Li, W. Luo, W. Ren, B. Stenger, W. Liu, H. Li, and M.-H. Yang, \u201cBenchmarking ultra-high-definition image super-resolution,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 14\u2009769\u201314\u2009778.": "Benchmarking ultra-high-definition image super-resolution", "[142] J. W. Soh, S. Cho, and N. I. Cho, \u201cMeta-transfer learning for zero-shot super-resolution,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 3516\u20133525.": "Meta-transfer learning for zero-shot super-resolution", "[128] T. Guo, H. Seyed Mousavi, T. Huu Vu, and V. Monga, \u201cDeep wavelet prediction for image super-resolution,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2017, pp. 104\u2013113.": "Deep wavelet prediction for image super-resolution", "[36] C. Dong, C. C. Loy, and X. Tang, \u201cAccelerating the super-resolution convolutional neural network,\u201d in European conference on computer vision. Springer, 2016, pp. 391\u2013407.": "Accelerating the super-resolution convolutional neural network", "[169] J. Yang, S. Shen, H. Yue, and K. Li, \u201cImplicit transformer network for screen content image continuous super-resolution,\u201d Advances in Neural Information Processing Systems, vol. 34, 2021.": "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution", "[140] X. Cheng, Z. Fu, and J. Yang, \u201cZero-shot image super-resolution with depth guided internal degradation learning,\u201d in European Conference on Computer Vision. Springer, 2020, pp. 265\u2013280.": "Zero-shot image super-resolution with depth guided internal degradation learning", "[41] B. Lim, S. Son, H. Kim, S. Nah, and K. Mu Lee, \u201cEnhanced deep residual networks for single image super-resolution,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition workshops, 2017, pp. 136\u2013144.": "Enhanced deep residual networks for single image super-resolution", "[56] Y. Yuan, S. Liu, J. Zhang, Y. Zhang, C. Dong, and L. Lin, \u201cUnsupervised image super-resolution using cycle-in-cycle generative adversarial networks,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2018, pp. 701\u2013710.": "Unsupervised image super-resolution using cycle-in-cycle generative adversarial networks", "[166] Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, \u201cVggface2: A dataset for recognising faces across pose and age,\u201d in 2018 13th IEEE international conference on automatic face & gesture recognition (FG 2018). IEEE, 2018, pp. 67\u201374.": "Vggface2: A dataset for recognising faces across pose and age"}, "source_title_to_arxiv_id": {"Swin transformer: Hierarchical vision transformer using shifted windows": "2103.14030", "Neural architecture search for image super-resolution using densely constructed search space: Deconas": "2104.09048", "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution": "2112.06174", "Vggface2: A dataset for recognising faces across pose and age": "1710.08092"}}