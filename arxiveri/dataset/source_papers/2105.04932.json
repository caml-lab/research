{"title": "One shot face swapping on megapixels", "abstract": "Face swapping has both positive applications such as entertainment, human-computer interaction, etc., and negative applications such as DeepFake threats to politics, economics, etc. Nevertheless, it is necessary to understand the scheme of advanced methods for high-quality face swapping and generate enough and representative face swapping images to train DeepFake detection algorithms. This paper proposes the first Megapixel level method for one shot Face Swapping (or MegaFS for short). Firstly, MegaFS organizes face representation hierarchically by the proposed Hierarchical Representation Face Encoder (HieRFE) in an extended latent space to maintain more facial details, rather than compressed representation in previous face swapping methods. Secondly, a carefully designed Face Transfer Module (FTM) is proposed to transfer the identity from a source image to the target by a non-linear trajectory without explicit feature disentanglement. Finally, the swapped faces can be synthesized by StyleGAN2 with the benefits of its training stability and powerful generative capability. Each part of MegaFS can be trained separately so the requirement of our model for GPU memory can be satisfied for megapixel face swapping. In summary, complete face representation, stable training, and limited memory usage are the three novel contributions to the success of our method. Extensive experiments demonstrate the superiority of MegaFS and the first megapixel level face swapping database is released for research on DeepFake detection and face image editing in the public domain. The dataset is at this link.", "authors": ["Yuhao Zhu", " Qi Li", " Jian Wang", " Chengzhong Xu", " Zhenan Sun"], "pdf_url": "https://arxiv.org/abs/2105.04932", "list_table_and_caption": [{"table": "<table><thead><tr><th>Method</th><th>ID retrieval \\uparrow</th><th>pose \\downarrow</th><th>expression \\downarrow</th></tr></thead><tbody><tr><th>DeepFakes [11]</th><td>88.39</td><td>4.64</td><td>3.33</td></tr><tr><th>FaceSwap [15]</th><td>72.69</td><td>2.58</td><td>2.89</td></tr><tr><th>Face2Face [53]</th><td>-</td><td>2.68</td><td>2.09</td></tr><tr><th>Neural Textures [52]</th><td>-</td><td>2.21</td><td>1.64</td></tr><tr><th>FaceShifter [28]</th><td>90.68</td><td>2.55</td><td>2.82</td></tr><tr><th>Ours</th><td>90.83</td><td>2.64</td><td>2.96</td></tr></tbody></table>", "caption": "Table 1: Quantitative comparison results on FaceForensics++. The best two results are shown in red and blue respectively. \\uparrow means higher is better, and \\downarrow means lower is better.", "list_citation_info": ["[11] DeepFakes. https://github.com/ondyari/FaceForensics/tree/master/dataset/DeepFakes. Accessed: 2020-10-08.", "[52] Justus Thies, Michael Zollh\u00f6fer, and Matthias Nie\u00dfner. Deferred neural rendering: Image synthesis using neural textures. ACM Transactions on Graphics, 38(4):1\u201312, 2019.", "[53] Justus Thies, Michael Zollhofer, Marc Stamminger, Christian Theobalt, and Matthias Nie\u00dfner. Face2face: Real-time face capture and reenactment of rgb videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2387\u20132395, 2016.", "[15] FaceSwap. https://github.com/ondyari/FaceForensics/tree/master/dataset/FaceSwapKowalski. Accessed: 2020-10-08.", "[28] Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, and Fang Wen. Advancing high fidelity identity swapping for forgery detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, June 2020."]}]}