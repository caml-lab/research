{"title": "Constrained Few-shot Class-incremental Learning", "abstract": "Continually learning new classes from fresh data without forgetting previous knowledge of old classes is a very challenging research problem. Moreover, it is imperative that such learning must respect certain memory and computational constraints such as (i) training samples are limited to only a few per class, (ii) the computational cost of learning a novel class remains constant, and (iii) the memory footprint of the model grows at most linearly with the number of classes observed. To meet the above constraints, we propose C-FSCIL, which is architecturally composed of a frozen meta-learned feature extractor, a trainable fixed-size fully connected layer, and a rewritable dynamically growing memory that stores as many vectors as the number of encountered classes. C-FSCIL provides three update modes that offer a trade-off between accuracy and compute-memory cost of learning novel classes. C-FSCIL exploits hyperdimensional embedding that allows to continually express many more classes than the fixed dimensions in the vector space, with minimal interference. The quality of class vector representations is further improved by aligning them quasi-orthogonally to each other by means of novel loss functions. Experiments on the CIFAR100, miniImageNet, and Omniglot datasets show that C-FSCIL outperforms the baselines with remarkable accuracy and compression. It also scales up to the largest problem size ever tried in this few-shot setting by learning 423 novel classes on top of 1200 base classes with less than 1.6% accuracy drop. Our code is available at https://github.com/IBM/constrained-FSCIL.", "authors": ["Michael Hersche", " Geethan Karunaratne", " Giovanni Cherubini", " Luca Benini", " Abu Sebastian", " Abbas Rahimi"], "pdf_url": "https://arxiv.org/abs/2203.16588", "list_table_and_caption": [{"table": "<table><tbody><tr><th>Session (s)</th><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><th>No. of classes |\\tilde{\\mathcal{C}}^{(s)}|</th><td>60</td><td>65</td><td>70</td><td>75</td><td>80</td><td>85</td><td>90</td><td>95</td><td>100</td></tr><tr><th>AL-MML [48]</th><td>61.31</td><td>50.09</td><td>45.17</td><td>41.16</td><td>37.48</td><td>35.52</td><td>32.19</td><td>29.46</td><td>24.42</td></tr><tr><th>IDLVQ-C [5]</th><td>64.77</td><td>59.87</td><td>55.93</td><td>52.62</td><td>49.88</td><td>47.55</td><td>44.83</td><td>43.14</td><td>41.84</td></tr><tr><th>Semantic KD{}^{*} [6]</th><td>&lt;62</td><td>&lt;59</td><td>&lt;54</td><td>&lt;50</td><td>&lt;49</td><td>&lt;45</td><td>&lt;42</td><td>&lt;40</td><td>&lt;39</td></tr><tr><th>VAE{}^{*} [7]</th><td>&lt;62</td><td>&lt;60</td><td>&lt;54</td><td>&lt;52</td><td>&lt;50</td><td>&lt;49</td><td>&lt;46</td><td>&lt;44</td><td>&lt;43</td></tr><tr><th>F2M [44]</th><td>67.28</td><td>63.80</td><td>60.38</td><td>57.06</td><td>54.08</td><td>51.39</td><td>48.82</td><td>46.58</td><td>44.65</td></tr><tr><th>CEC [56]</th><td>72.00</td><td>66.83</td><td>62.97</td><td>59.43</td><td>56.70</td><td>53.73</td><td>51.19</td><td>49.24</td><td>47.63</td></tr><tr><th>C-FSCIL Mode\u20091 d=512 (ours)</th><td>76.37</td><td>70.94</td><td>66.36</td><td>62.64</td><td>59.31</td><td>56.02</td><td>53.14</td><td>51.04</td><td>48.87</td></tr><tr><th>C-FSCIL Mode\u20092 d=512 (ours)</th><td>76.45</td><td>71.23</td><td>66.71</td><td>63.01</td><td>60.09</td><td>56.73</td><td>53.94</td><td>52.01</td><td>50.08</td></tr><tr><th>C-FSCIL Mode\u20093 d=512 (ours)</th><td>76.40</td><td>71.14</td><td>66.46</td><td>63.29</td><td>60.42</td><td>57.46</td><td>54.78</td><td>53.11</td><td>51.41</td></tr></tbody></table>", "caption": "Table 1: Classification accuracy (%) on miniImageNet in the 5-way 5-shot FSCIL setting. [*]: Upper bound based on the visual illustration in the corresponding work. ", "list_citation_info": ["[44] Guangyuan Shi, Jiaxin Chen, Wenlong Zhang, Li-Ming Zhan, and Xiao-Ming Wu. Overcoming catastrophic forgetting in incremental few-shot learning by finding flat minima. In Advances in Neural Information Processing Systems (NeurIPS), 2021.", "[48] Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei, and Yihong Gong. Few-shot class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.", "[56] Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, and Yinghui Xu. Few-shot incremental learning with continually evolved classifiers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021.", "[5] Kuilin Chen and Chi-Guhn Lee. Incremental few-shot learning via vector quantization in deep embedded space. In International Conference on Learning Representations (ICLR), 2021.", "[6] Ali Cheraghian, Shafin Rahman, Pengfei Fang, Soumava Kumar Roy, Lars Petersson, and Mehrtash Harandi. Semantic-aware knowledge distillation for few-shot class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021.", "[7] Ali Cheraghian, Shafin Rahman, Sameera Ramasinghe, Pengfei Fang, Christian Simon, Lars Petersson, and Mehrtash Harandi. Synthesized feature based few-shot class-incremental learning on a mixture of subspaces. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021."]}, {"table": "<table><tbody><tr><th>Session (s)</th><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><th>No. of classes |\\tilde{\\mathcal{C}}^{(s)}|</th><td>60</td><td>65</td><td>70</td><td>75</td><td>80</td><td>85</td><td>90</td><td>95</td><td>100</td></tr><tr><th>AL-MML [48]</th><td>64.10</td><td>55.88</td><td>47.07</td><td>45.16</td><td>40.11</td><td>36.38</td><td>33.96</td><td>31.55</td><td>29.37</td></tr><tr><th>Semantic KD{}^{*} [6]</th><td>&lt;64</td><td>&lt;57</td><td>&lt;51</td><td>&lt;46</td><td>&lt;43</td><td>&lt;41</td><td>&lt;39</td><td>&lt;37</td><td>&lt;35</td></tr><tr><th>VAE{}^{*} [7]</th><td>&lt;62</td><td>&lt;58</td><td>&lt;57</td><td>&lt;52</td><td>&lt;51</td><td>&lt;49</td><td>&lt;46</td><td>&lt;45</td><td>&lt;42</td></tr><tr><th>F2M [44]</th><td>64.71</td><td>62.05</td><td>59.01</td><td>55.58</td><td>52.55</td><td>49.96</td><td>48.08</td><td>46.67</td><td>44.67</td></tr><tr><th>CEC [56]</th><td>73.07</td><td>68.88</td><td>65.26</td><td>61.19</td><td>58.09</td><td>55.57</td><td>53.22</td><td>51.34</td><td>49.14</td></tr><tr><th>C-FSCIL Mode\u20091 d=512 (ours)</th><td>77.47</td><td>72.20</td><td>67.53</td><td>63.23</td><td>59.58</td><td>56.67</td><td>53.94</td><td>51.55</td><td>49.36</td></tr><tr><th>C-FSCIL Mode\u20092 d=512 (ours)</th><td>77.50</td><td>72.45</td><td>67.94</td><td>63.80</td><td>60.24</td><td>57.34</td><td>54.61</td><td>52.41</td><td>50.23</td></tr><tr><th>C-FSCIL Mode\u20093 d=512 (ours)</th><td>77.47</td><td>72.40</td><td>67.47</td><td>63.25</td><td>59.84</td><td>56.95</td><td>54.42</td><td>52.47</td><td>50.47</td></tr></tbody></table>", "caption": "Table 2: Classification accuracy (%) on CIFAR100 in the 5-way 5-shot FSCIL setting. [*]: Upper bound based on the visual illustration in the corresponding work. ", "list_citation_info": ["[44] Guangyuan Shi, Jiaxin Chen, Wenlong Zhang, Li-Ming Zhan, and Xiao-Ming Wu. Overcoming catastrophic forgetting in incremental few-shot learning by finding flat minima. In Advances in Neural Information Processing Systems (NeurIPS), 2021.", "[48] Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei, and Yihong Gong. Few-shot class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.", "[56] Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, and Yinghui Xu. Few-shot incremental learning with continually evolved classifiers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021.", "[6] Ali Cheraghian, Shafin Rahman, Pengfei Fang, Soumava Kumar Roy, Lars Petersson, and Mehrtash Harandi. Semantic-aware knowledge distillation for few-shot class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021.", "[7] Ali Cheraghian, Shafin Rahman, Sameera Ramasinghe, Pengfei Fang, Christian Simon, Lars Petersson, and Mehrtash Harandi. Synthesized feature based few-shot class-incremental learning on a mixture of subspaces. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021."]}, {"table": "<table><tbody><tr><td>Session (s)</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td><td>10</td></tr><tr><td>No. of classes |\\tilde{\\mathcal{C}}^{(s)}|</td><td>1200</td><td>1247</td><td>1294</td><td>1341</td><td>1388</td><td>1435</td><td>1482</td><td>1529</td><td>1576</td><td>1623</td></tr><tr><td>ProtoNet{}^{*}[45]</td><td>70.61</td><td>70.20</td><td>70.01</td><td>69.68</td><td>69.48</td><td>68.99</td><td>68.74</td><td>68.07</td><td>67.60</td><td>67.41</td></tr><tr><td>CEC{}^{*}[56]</td><td>78.91</td><td>79.07</td><td>78.74</td><td>78.60</td><td>77.94</td><td>77.55</td><td>77.18</td><td>76.77</td><td>76.39</td><td>76.11</td></tr><tr><td>C-FSCIL Mode\u20091 d=512 (ours)</td><td>84.16</td><td>83.82</td><td>83.69</td><td>83.32</td><td>83.22</td><td>82.78</td><td>82.70</td><td>82.32</td><td>81.77</td><td>81.56</td></tr><tr><td>C-FSCIL Mode\u20092 d=512 (ours)</td><td>86.87</td><td>86.77</td><td>86.57</td><td>86.44</td><td>86.40</td><td>86.20</td><td>86.25</td><td>85.96</td><td>85.63</td><td>85.49</td></tr><tr><td>C-FSCIL Mode\u20093 d=512 (ours)</td><td>87.21</td><td>87.03</td><td>86.89</td><td>86.60</td><td>86.43</td><td>86.32</td><td>86.13</td><td>85.98</td><td>85.59</td><td>85.70</td></tr></tbody></table>", "caption": "Table 3: Classification accuracy (%) on Omniglot in the 47-way 5-shot FSCIL setting.[*]: Reproduced baselines.", "list_citation_info": ["[45] Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical Networks for Few-Shot Learning. In Advances in Neural Information Processing Systems (NeurIPS), 2017.", "[56] Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, and Yinghui Xu. Few-shot incremental learning with continually evolved classifiers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021."]}, {"table": "<table><thead><tr><th colspan=\"2\">Session (s)</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th></tr><tr><th colspan=\"2\">No. of classes |\\tilde{\\mathcal{C}}^{(s)}|</th><th>1200</th><th>1247</th><th>1294</th><th>1341</th><th>1388</th><th>1435</th><th>1482</th><th>1529</th><th>1576</th><th>1623</th></tr></thead><tbody><tr><th>Mode/ Work</th><th>d</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><td></td></tr><tr><th rowspan=\"5\">Mode 1</th><th>512</th><td>84.16</td><td>83.82</td><td>83.69</td><td>83.32</td><td>83.22</td><td>82.78</td><td>82.70</td><td>82.32</td><td>81.77</td><td>81.56</td></tr><tr><th>256</th><td>82.26</td><td>81.99</td><td>81.95</td><td>81.73</td><td>81.74</td><td>81.42</td><td>81.42</td><td>81.18</td><td>80.70</td><td>80.39</td></tr><tr><th>128</th><td>80.78</td><td>80.97</td><td>80.50</td><td>80.24</td><td>79.80</td><td>79.45</td><td>79.01</td><td>78.41</td><td>78.11</td><td>78.19</td></tr><tr><th>64</th><td>72.89</td><td>72.87</td><td>72.49</td><td>72.18</td><td>71.52</td><td>70.85</td><td>70.73</td><td>69.87</td><td>69.59</td><td>69.30</td></tr><tr><th>32</th><td>57.07</td><td>56.70</td><td>56.14</td><td>55.72</td><td>54.97</td><td>54.36</td><td>53.85</td><td>53.19</td><td>52.45</td><td>52.52</td></tr><tr><th rowspan=\"5\">Mode 2</th><th>512</th><td>86.87</td><td>86.77</td><td>86.57</td><td>86.44</td><td>86.40</td><td>86.20</td><td>86.25</td><td>85.96</td><td>85.63</td><td>85.49</td></tr><tr><th>256</th><td>84.32</td><td>84.35</td><td>84.23</td><td>83.94</td><td>84.02</td><td>83.93</td><td>83.86</td><td>83.78</td><td>83.44</td><td>83.19</td></tr><tr><th>128</th><td>82.85</td><td>83.29</td><td>82.70</td><td>82.65</td><td>82.14</td><td>82.03</td><td>81.91</td><td>81.31</td><td>80.68</td><td>81.15</td></tr><tr><th>64</th><td>76.07</td><td>76.73</td><td>76.46</td><td>75.98</td><td>75.86</td><td>75.17</td><td>75.20</td><td>74.31</td><td>74.43</td><td>74.28</td></tr><tr><th>32</th><td>64.31</td><td>63.71</td><td>63.94</td><td>63.72</td><td>63.04</td><td>62.66</td><td>62.04</td><td>61.58</td><td>61.35</td><td>61.15</td></tr><tr><th rowspan=\"5\">Mode 3</th><th>512</th><td>87.21</td><td>87.03</td><td>86.89</td><td>86.60</td><td>86.43</td><td>86.32</td><td>86.13</td><td>85.98</td><td>85.59</td><td>85.70</td></tr><tr><th>256</th><td>84.59</td><td>84.57</td><td>84.39</td><td>84.11</td><td>84.25</td><td>83.89</td><td>83.95</td><td>83.94</td><td>83.62</td><td>83.35</td></tr><tr><th>128</th><td>83.51</td><td>83.29</td><td>83.14</td><td>82.87</td><td>82.54</td><td>81.90</td><td>82.03</td><td>81.50</td><td>81.29</td><td>81.31</td></tr><tr><th>64</th><td>76.67</td><td>76.30</td><td>76.46</td><td>76.22</td><td>75.66</td><td>75.51</td><td>75.53</td><td>74.19</td><td>74.23</td><td>74.25</td></tr><tr><th>32</th><td>64.99</td><td>64.66</td><td>64.61</td><td>63.72</td><td>63.34</td><td>63.14</td><td>62.66</td><td>62.23</td><td>61.69</td><td>62.17</td></tr><tr><th rowspan=\"4\">ProtoNet [45]</th><th>256</th><td>70.61</td><td>70.20</td><td>70.01</td><td>69.68</td><td>69.48</td><td>68.99</td><td>68.74</td><td>68.07</td><td>67.60</td><td>-</td></tr><tr><th>128</th><td>63.75</td><td>63.34</td><td>63.15</td><td>62.44</td><td>62.38</td><td>62.00</td><td>61.61</td><td>61.29</td><td>60.68</td><td>60.13</td></tr><tr><th>64</th><td>49.69</td><td>49.10</td><td>48.63</td><td>48.13</td><td>47.67</td><td>46.97</td><td>46.73</td><td>46.11</td><td>45.47</td><td>45.08</td></tr><tr><th>32</th><td>36.53</td><td>36.11</td><td>35.74</td><td>35.45</td><td>34.87</td><td>34.37</td><td>34.08</td><td>33.42</td><td>32.99</td><td>32.71</td></tr><tr><th rowspan=\"5\">CEC [56]</th><th>512</th><td>76.44</td><td>76.62</td><td>76.21</td><td>76.10</td><td>75.37</td><td>74.92</td><td>74.60</td><td>74.04</td><td>73.43</td><td>73.19</td></tr><tr><th>256</th><td>76.94</td><td>76.94</td><td>76.56</td><td>76.35</td><td>75.62</td><td>75.20</td><td>74.84</td><td>74.45</td><td>73.94</td><td>73.59</td></tr><tr><th>128</th><td>77.10</td><td>77.15</td><td>76.94</td><td>76.89</td><td>76.26</td><td>75.79</td><td>75.46</td><td>75.05</td><td>74.58</td><td>74.28</td></tr><tr><th>64</th><td>78.91</td><td>79.07</td><td>78.74</td><td>78.60</td><td>77.94</td><td>77.55</td><td>77.18</td><td>76.77</td><td>76.39</td><td>76.11</td></tr><tr><th>32</th><td>74.51</td><td>74.59</td><td>74.32</td><td>73.97</td><td>73.31</td><td>72.76</td><td>72.28</td><td>71.84</td><td>71.55</td><td>71.41</td></tr></tbody></table>", "caption": "Table A3: Dimension ablation on Omniglot. Classification accuracy (%) on Omniglot in the 47-way 5-shot FSCIL setting. ", "list_citation_info": ["[45] Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical Networks for Few-Shot Learning. In Advances in Neural Information Processing Systems (NeurIPS), 2017.", "[56] Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, and Yinghui Xu. Few-shot incremental learning with continually evolved classifiers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021."]}, {"table": "<table><tbody><tr><th colspan=\"2\">Session (s)</th><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><th colspan=\"2\">No. of classes |\\tilde{\\mathcal{C}}^{(s)}|</th><td>60</td><td>65</td><td>70</td><td>75</td><td>80</td><td>85</td><td>90</td><td>95</td><td>100</td></tr><tr><th>Mode/ Work</th><th>Feature extractor</th><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><th>AL-MML [48]</th><th>ResNet-18</th><td>61.31</td><td>50.09</td><td>45.17</td><td>41.16</td><td>37.48</td><td>35.52</td><td>32.19</td><td>29.46</td><td>24.42</td></tr><tr><th>IDLVQ-C [5]</th><th>ResNet-18</th><td>64.77</td><td>59.87</td><td>55.93</td><td>52.62</td><td>49.88</td><td>47.55</td><td>44.83</td><td>43.14</td><td>41.84</td></tr><tr><th>Semantic KD [6]</th><th>ResNet-18</th><td>&lt;62</td><td>&lt;59</td><td>&lt;54</td><td>&lt;50</td><td>&lt;49</td><td>&lt;45</td><td>&lt;42</td><td>&lt;40</td><td>&lt;39</td></tr><tr><th>VAE [7]</th><th>ResNet-18</th><td>&lt;62</td><td>&lt;60</td><td>&lt;54</td><td>&lt;52</td><td>&lt;50</td><td>&lt;49</td><td>&lt;46</td><td>&lt;44</td><td>&lt;43</td></tr><tr><th>F2M [44]</th><th>ResNet-18</th><td>67.28</td><td>63.80</td><td>60.38</td><td>57.06</td><td>54.08</td><td>51.39</td><td>48.82</td><td>46.58</td><td>44.65</td></tr><tr><th>CEC [56]</th><th>ResNet-18</th><td>72.00</td><td>66.83</td><td>62.97</td><td>59.43</td><td>56.70</td><td>53.73</td><td>51.19</td><td>49.24</td><td>47.63</td></tr><tr><th>C-FSCIL Mode\u20091</th><th>ResNet-12</th><td>76.37</td><td>70.94</td><td>66.36</td><td>62.64</td><td>59.31</td><td>56.02</td><td>53.14</td><td>51.04</td><td>48.87</td></tr><tr><th>C-FSCIL Mode\u20092</th><th>ResNet-12</th><td>76.45</td><td>71.23</td><td>66.71</td><td>63.01</td><td>60.09</td><td>56.73</td><td>53.94</td><td>52.01</td><td>50.08</td></tr><tr><th>C-FSCIL Mode\u20093</th><th>ResNet-12</th><td>76.40</td><td>71.14</td><td>66.46</td><td>63.29</td><td>60.42</td><td>57.46</td><td>54.78</td><td>53.11</td><td>51.41</td></tr><tr><th>C-FSCIL Mode 1</th><th>ResNet-12 (small)</th><td>76.08</td><td>70.63</td><td>66.11</td><td>62.23</td><td>58.91</td><td>56.12</td><td>53.11</td><td>51.02</td><td>48.93</td></tr><tr><th>C-FSCIL Mode 2</th><th>ResNet-12 (small)</th><td>75.90</td><td>70.52</td><td>66.01</td><td>62.11</td><td>58.86</td><td>56.19</td><td>53.23</td><td>51.31</td><td>49.53</td></tr><tr><th>C-FSCIL Mode 3</th><th>ResNet-12 (small)</th><td>76.12</td><td>70.20</td><td>65.29</td><td>62.25</td><td>59.35</td><td>56.76</td><td>54.18</td><td>52.15</td><td>50.47</td></tr></tbody></table>", "caption": "Table A7: Feature extractor ablation on miniImageNet. Classification accuracy (%) in the 5-way 5-shot FSCIL setting.", "list_citation_info": ["[44] Guangyuan Shi, Jiaxin Chen, Wenlong Zhang, Li-Ming Zhan, and Xiao-Ming Wu. Overcoming catastrophic forgetting in incremental few-shot learning by finding flat minima. In Advances in Neural Information Processing Systems (NeurIPS), 2021.", "[48] Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei, and Yihong Gong. Few-shot class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.", "[56] Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, and Yinghui Xu. Few-shot incremental learning with continually evolved classifiers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021.", "[5] Kuilin Chen and Chi-Guhn Lee. Incremental few-shot learning via vector quantization in deep embedded space. In International Conference on Learning Representations (ICLR), 2021.", "[6] Ali Cheraghian, Shafin Rahman, Pengfei Fang, Soumava Kumar Roy, Lars Petersson, and Mehrtash Harandi. Semantic-aware knowledge distillation for few-shot class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021.", "[7] Ali Cheraghian, Shafin Rahman, Sameera Ramasinghe, Pengfei Fang, Christian Simon, Lars Petersson, and Mehrtash Harandi. Synthesized feature based few-shot class-incremental learning on a mixture of subspaces. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021."]}, {"table": "<table><tbody><tr><th colspan=\"2\">Session (s)</th><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td><td>8</td><td>9</td></tr><tr><th colspan=\"2\">No. of classes |\\tilde{\\mathcal{C}}^{(s)}|</th><td>60</td><td>65</td><td>70</td><td>75</td><td>80</td><td>85</td><td>90</td><td>95</td><td>100</td></tr><tr><th>Mode/ Work</th><th>Feature extractor</th><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><th>AL-MML [48]</th><th>ResNet-18</th><td>64.10</td><td>55.88</td><td>47.07</td><td>45.16</td><td>40.11</td><td>36.38</td><td>33.96</td><td>31.55</td><td>29.37</td></tr><tr><th>Semantic KD{}^{*} [6]</th><th>ResNet-18</th><td>&lt;64</td><td>&lt;57</td><td>&lt;51</td><td>&lt;46</td><td>&lt;43</td><td>&lt;41</td><td>&lt;39</td><td>&lt;37</td><td>&lt;35</td></tr><tr><th>VAE{}^{*} [7]</th><th>ResNet-18</th><td>&lt;62</td><td>&lt;58</td><td>&lt;57</td><td>&lt;52</td><td>&lt;51</td><td>&lt;49</td><td>&lt;46</td><td>&lt;45</td><td>&lt;42</td></tr><tr><th>F2M [44]</th><th>ResNet-18</th><td>64.71</td><td>62.05</td><td>59.01</td><td>55.58</td><td>52.55</td><td>49.96</td><td>48.08</td><td>46.67</td><td>44.67</td></tr><tr><th>CEC [56]</th><th>ResNet-20</th><td>73.07</td><td>68.88</td><td>65.26</td><td>61.19</td><td>58.09</td><td>55.57</td><td>53.22</td><td>51.34</td><td>49.14</td></tr><tr><th>C-FSCIL Mode\u20091</th><th>ResNet-12</th><td>77.47</td><td>72.20</td><td>67.53</td><td>63.23</td><td>59.58</td><td>56.67</td><td>53.94</td><td>51.55</td><td>49.36</td></tr><tr><th>C-FSCIL Mode\u20092</th><th>ResNet-12</th><td>77.50</td><td>72.45</td><td>67.94</td><td>63.80</td><td>60.24</td><td>57.34</td><td>54.61</td><td>52.41</td><td>50.23</td></tr><tr><th>C-FSCIL Mode\u20093</th><th>ResNet-12</th><td>77.47</td><td>72.40</td><td>67.47</td><td>63.25</td><td>59.84</td><td>56.95</td><td>54.42</td><td>52.47</td><td>50.47</td></tr><tr><th>C-FSCIL Mode\u20091</th><th>ResNet-12 (small)</th><td>76.58</td><td>71.51</td><td>66.79</td><td>62.49</td><td>58.8</td><td>55.72</td><td>52.91</td><td>50.56</td><td>48.39</td></tr><tr><th>C-FSCIL Mode\u20092</th><th>ResNet-12 (small)</th><td>76.57</td><td>71.86</td><td>67.34</td><td>63.05</td><td>59.46</td><td>56.42</td><td>53.80</td><td>51.37</td><td>49.26</td></tr><tr><th>C-FSCIL Mode\u20093</th><th>ResNet-12 (small)</th><td>76.58</td><td>71.74</td><td>66.71</td><td>62.20</td><td>58.94</td><td>56.21</td><td>53.63</td><td>51.41</td><td>49.50</td></tr></tbody></table>", "caption": "Table A8: Feature extractor ablation on CIFAR100. Classification accuracy (%) in the 5-way 5-shot FSCIL setting.", "list_citation_info": ["[44] Guangyuan Shi, Jiaxin Chen, Wenlong Zhang, Li-Ming Zhan, and Xiao-Ming Wu. Overcoming catastrophic forgetting in incremental few-shot learning by finding flat minima. In Advances in Neural Information Processing Systems (NeurIPS), 2021.", "[48] Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei, and Yihong Gong. Few-shot class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.", "[56] Chi Zhang, Nan Song, Guosheng Lin, Yun Zheng, Pan Pan, and Yinghui Xu. Few-shot incremental learning with continually evolved classifiers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021.", "[6] Ali Cheraghian, Shafin Rahman, Pengfei Fang, Soumava Kumar Roy, Lars Petersson, and Mehrtash Harandi. Semantic-aware knowledge distillation for few-shot class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2021.", "[7] Ali Cheraghian, Shafin Rahman, Sameera Ramasinghe, Pengfei Fang, Christian Simon, Lars Petersson, and Mehrtash Harandi. Synthesized feature based few-shot class-incremental learning on a mixture of subspaces. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021."]}]}