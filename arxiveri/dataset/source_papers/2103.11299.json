{"title": "A modular and unified framework for detecting and localizing video anomalies", "abstract": "Anomaly detection in videos has been attracting an increasing amount of attention. Despite the competitive performance of recent methods on benchmark datasets, they typically lack desirable features such as modularity, cross-domain adaptivity, interpretability, and real-time anomalous event detection. Furthermore, current state-of-the-art approaches are evaluated using the standard instance-based detection metric by considering video frames as independent instances, which is not ideal for video anomaly detection. Motivated by these research gaps, we propose a modular and unified approach to the online video anomaly detection and localization problem, called MOVAD, which consists of a novel transfer learning based plug-and-play architecture, a sequential anomaly detector, a mathematical framework for selecting the detection threshold, and a suitable performance metric for real-time anomalous event detection in videos. Extensive performance evaluations on benchmark datasets show that the proposed framework significantly outperforms the current state-of-the-art approaches.", "authors": ["Keval Doshi", " Yasin Yilmaz"], "pdf_url": "https://arxiv.org/abs/2103.11299", "list_table_and_caption": [{"table": "<table><thead><tr><th colspan=\"2\">Online Detection</th></tr></thead><tbody><tr><td>Methodology</td><td>APD</td></tr><tr><td>Liu et al. [22]</td><td>0.504</td></tr><tr><td>Morais et al. [31]</td><td>0.324</td></tr><tr><td>Luo et al. [27]</td><td>0.447</td></tr><tr><td>Ours</td><td>0.705</td></tr></tbody></table>", "caption": "Table 1: Online detection comparison in terms of the proposed APD metric on the ShanghaiTech dataset. Higher APD value represents a better online anomaly detection performance.", "list_citation_info": ["[27] Weixin Luo, Wen Liu, Dongze Lian, Jinhui Tang, Lixin Duan, Xi Peng, and Shenghua Gao. Video anomaly detection with sparse coding inspired deep neural networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2019.", "[31] Romero Morais, Vuong Le, Truyen Tran, Budhaditya Saha, Moussa Mansour, and Svetha Venkatesh. Learning regularity in skeleton trajectories for anomaly detection in videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 11996\u201312004, 2019.", "[22] Wen Liu, Weixin Luo, Dongze Lian, and Shenghua Gao. Future frame prediction for anomaly detection\u2013a new baseline. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6536\u20136545, 2018."]}, {"table": "<table><thead><tr><th colspan=\"4\">Offline Localization</th></tr><tr><th>Methodology</th><th>CUHK Avenue</th><th>UCSD Ped 2</th><th>ShanghaiTech</th></tr></thead><tbody><tr><td>MPPCA [15]</td><td>-</td><td>69.3</td><td>-</td></tr><tr><td>Del et al. [6]</td><td>78.3</td><td>-</td><td>-</td></tr><tr><td>Conv-AE [11]</td><td>80.0</td><td>85.0</td><td>60.9</td></tr><tr><td>ConvLSTM-AE[25]</td><td>77.0</td><td>88.1</td><td>-</td></tr><tr><td>Growing Neural Gas [44]</td><td>-</td><td>93.5</td><td>-</td></tr><tr><td>Stacked RNN[26]</td><td>81.7</td><td>92.2</td><td>68.0</td></tr><tr><td>Deep Generic [12]</td><td>-</td><td>92.2</td><td>-</td></tr><tr><td>GANs [35]</td><td>-</td><td>88.4</td><td>-</td></tr><tr><td>Future Frame [22]</td><td>85.1</td><td>95.4</td><td>72.8</td></tr><tr><td>Skeletal Trajectory [31]</td><td>-</td><td>-</td><td>73.4</td></tr><tr><td>Multi-timescale Prediction [39]</td><td>82.85</td><td>-</td><td>76.03</td></tr><tr><td>Memory-guided Normality [33]</td><td>88.5</td><td>97.0</td><td>70.5</td></tr><tr><td>Ours</td><td>88.7</td><td>97.2</td><td>73.62</td></tr></tbody></table>", "caption": "Table 2: Offline anomaly localization comparison in terms of frame-level AUC on three datasets.", "list_citation_info": ["[25] Weixin Luo, Wen Liu, and Shenghua Gao. Remembering history with convolutional lstm for anomaly detection. In 2017 IEEE International Conference on Multimedia and Expo (ICME), pages 439\u2013444. IEEE, 2017.", "[11] Mahmudul Hasan, Jonghyun Choi, Jan Neumann, Amit K Roy-Chowdhury, and Larry S Davis. Learning temporal regularity in video sequences. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 733\u2013742, 2016.", "[44] Qianru Sun, Hong Liu, and Tatsuya Harada. Online growing neural gas for anomaly detection in changing surveillance scenes. Pattern Recognition, 64:187\u2013201, 2017.", "[15] Jaechul Kim and Kristen Grauman. Observe locally, infer globally: a space-time mrf for detecting abnormal activities with incremental updates. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 2921\u20132928. IEEE, 2009.", "[39] Royston Rodrigues, Neha Bhargava, Rajbabu Velmurugan, and Subhasis Chaudhuri. Multi-timescale trajectory prediction for abnormal human activity detection. In The IEEE Winter Conference on Applications of Computer Vision, pages 2626\u20132634, 2020.", "[31] Romero Morais, Vuong Le, Truyen Tran, Budhaditya Saha, Moussa Mansour, and Svetha Venkatesh. Learning regularity in skeleton trajectories for anomaly detection in videos. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 11996\u201312004, 2019.", "[26] Weixin Luo, Wen Liu, and Shenghua Gao. A revisit of sparse coding based anomaly detection in stacked rnn framework. In Proceedings of the IEEE International Conference on Computer Vision, pages 341\u2013349, 2017.", "[6] Allison Del Giorno, J Andrew Bagnell, and Martial Hebert. A discriminative framework for anomaly detection in large videos. In European Conference on Computer Vision, pages 334\u2013349. Springer, 2016.", "[22] Wen Liu, Weixin Luo, Dongze Lian, and Shenghua Gao. Future frame prediction for anomaly detection\u2013a new baseline. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6536\u20136545, 2018.", "[33] Hyunjong Park, Jongyoun Noh, and Bumsub Ham. Learning memory-guided normality for anomaly detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14372\u201314381, 2020.", "[35] Mahdyar Ravanbakhsh, Moin Nabi, Hossein Mousavi, Enver Sangineto, and Nicu Sebe. Plug-and-play cnn for crowd motion analysis: An application in abnormal event detection. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 1689\u20131698. IEEE, 2018.", "[12] Ryota Hinami, Tao Mei, and Shin\u2019ichi Satoh. Joint detection and recounting of abnormal events by learning deep generic knowledge. In Proceedings of the IEEE International Conference on Computer Vision, pages 3619\u20133627, 2017."]}, {"table": "<table><thead><tr><th>Target</th><th>Methods</th><th>1-shot (K=1)</th><th>5-shot (K=5)</th><th>10-shot (K=10)</th></tr></thead><tbody><tr><td>UCSD Ped 2</td><td>Pre-trained (ShanghaiTech)</td><td>81.95</td><td>81.95</td><td>81.95</td></tr><tr><td></td><td>Pre-trained (UCF Crime)</td><td>62.53</td><td>62.53</td><td>62.53</td></tr><tr><td></td><td>r-GAN (ShanghaiTech)</td><td>91.19</td><td>91.8</td><td>92.8</td></tr><tr><td></td><td>r-GAN (UCF Crime)</td><td>83.08</td><td>86.41</td><td>90.21</td></tr><tr><td></td><td>Ours</td><td>93.19</td><td>95.91</td><td>96.01</td></tr><tr><td>CUHK Avenue</td><td>Pre-trained (ShanghaiTech)</td><td>71.43</td><td>71.43</td><td>71.43</td></tr><tr><td></td><td>Pre-trained (UCF Crime)</td><td>71.43</td><td>71.43</td><td>71.43</td></tr><tr><td></td><td>r-GAN (ShanghaiTech)</td><td>76.58</td><td>77.1</td><td>78.79</td></tr><tr><td></td><td>r-GAN (UCF Crime)</td><td>72.62</td><td>74.68</td><td>79.02</td></tr><tr><td></td><td>Ours</td><td>80.18</td><td>80.21</td><td>80.68</td></tr><tr><td>UR Fall</td><td>Pre-trained (ShanghaiTech)</td><td>64.08</td><td>64.08</td><td>64.08</td></tr><tr><td></td><td>Pre-trained (UCF Crime)</td><td>50.87</td><td>50.87</td><td>50.87</td></tr><tr><td></td><td>r-GAN (ShanghaiTech)</td><td>75.51</td><td>78.7</td><td>83.24</td></tr><tr><td></td><td>r-GAN (UCF Crime)</td><td>74.59</td><td>79.08</td><td>81.85</td></tr><tr><td></td><td>Ours</td><td>86.11</td><td>88.7</td><td>91.28</td></tr></tbody></table>", "caption": "Table 3: Few-shot scene adaptation comparison of the proposed and the state-of-the-art [24] algorithms in terms of frame-level AUC. The proposed algorithm is able to quickly adapt to new scenarios.", "list_citation_info": ["[24] Yiwei Lu, Frank Yu, Mahesh Kumar Krishna Reddy, and Yang Wang. Few-shot scene-adaptive anomaly detection. arXiv preprint arXiv:2007.07843, 2020."]}]}