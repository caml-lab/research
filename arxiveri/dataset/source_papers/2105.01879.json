{"title": "Mos: Towards scaling out-of-distribution detection for large semantic space", "abstract": "Detecting out-of-distribution (OOD) inputs is a central challenge for safely deploying machine learning models in the real world. Existing solutions are mainly driven by small datasets, with low resolution and very few class labels (e.g., CIFAR). As a result, OOD detection for large-scale image classification tasks remains largely unexplored. In this paper, we bridge this critical gap by proposing a group-based OOD detection framework, along with a novel OOD scoring function termed MOS. Our key idea is to decompose the large semantic space into smaller groups with similar concepts, which allows simplifying the decision boundaries between in- vs. out-of-distribution data for effective OOD detection. Our method scales substantially better for high-dimensional class space than previous approaches. We evaluate models trained on ImageNet against four carefully curated OOD datasets, spanning diverse semantics. MOS establishes state-of-the-art performance, reducing the average FPR95 by 14.33% while achieving 6x speedup in inference compared to the previous best method.", "authors": ["Rui Huang", " Yixuan Li"], "pdf_url": "https://arxiv.org/abs/2105.01879", "list_table_and_caption": [{"table": "<table><thead><tr><th rowspan=\"3\">Method</th><th rowspan=\"3\">TestTime(min)</th><th colspan=\"2\">iNaturalist</th><th colspan=\"2\">SUN</th><th colspan=\"2\">Places</th><th colspan=\"2\">Textures</th><th colspan=\"2\">Average</th></tr><tr><th>AUROC</th><th>FPR95</th><th>AUROC</th><th>FPR95</th><th>AUROC</th><th>FPR95</th><th>AUROC</th><th>FPR95</th><th>AUROC</th><th>FPR95</th></tr><tr><th>\\uparrow</th><th>\\downarrow</th><th>\\uparrow</th><th>\\downarrow</th><th>\\uparrow</th><th>\\downarrow</th><th>\\uparrow</th><th>\\downarrow</th><th>\\uparrow</th><th>\\downarrow</th></tr></thead><tbody><tr><th>MSP [16]</th><th>3.1</th><td>87.59</td><td>63.69</td><td>78.34</td><td>79.98</td><td>76.76</td><td>81.44</td><td>74.45</td><td>82.73</td><td>79.29</td><td>76.96</td></tr><tr><th>ODIN [29]</th><th>23.6</th><td>89.36</td><td>62.69</td><td>83.92</td><td>71.67</td><td>80.67</td><td>76.27</td><td>76.30</td><td>81.31</td><td>82.56</td><td>72.99</td></tr><tr><th>Mahalanobis [27]</th><th>145.4</th><td>46.33</td><td>96.34</td><td>65.20</td><td>88.43</td><td>64.46</td><td>89.75</td><td>72.10</td><td>52.23</td><td>62.02</td><td>81.69</td></tr><tr><th>Energy [32]</th><th>3.1</th><td>88.48</td><td>64.91</td><td>85.32</td><td>65.33</td><td>81.37</td><td>73.02</td><td>75.79</td><td>80.87</td><td>82.74</td><td>71.03</td></tr><tr><th>KL Matching [15]</th><th>20.6</th><td>93.00</td><td>27.36</td><td>78.72</td><td>67.52</td><td>76.49</td><td>72.61</td><td>87.07</td><td>49.70</td><td>83.82</td><td>54.30</td></tr><tr><th>MOS (ours)</th><th>3.2</th><td>98.15</td><td>9.28</td><td>92.01</td><td>40.63</td><td>89.06</td><td>49.54</td><td>81.23</td><td>60.43</td><td>90.11</td><td>39.97</td></tr></tbody></table>", "caption": "Table 1: OOD detection performance comparison between MOS and baselines. All methods are fine-tuned from the same pre-trained BiT-S-R101x1 backbone with ImageNet-1k as in-distribution dataset. The description of 4 OOD test datasets is provided in Section 4.1. \\uparrow indicates larger values are better, while \\downarrow indicates smaller values are better. All values are percentages. Bold numbers are superior results. Test time for all methods are evaluated with the same in- and out-of-distribution datasets (60k images in total). ", "list_citation_info": ["[32] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. Advances in Neural Information Processing Systems, 2020.", "[15] Dan Hendrycks, Steven Basart, Mantas Mazeika, Mohammadreza Mostajabi, Jacob Steinhardt, and Dawn Song. A benchmark for anomaly segmentation. arXiv preprint arXiv:1911.11132, 2019.", "[16] Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. In 5th International Conference on Learning Representations, ICLR 2017, 2017.", "[27] Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. In Advances in Neural Information Processing Systems, pages 7167\u20137177, 2018.", "[29] Shiyu Liang, Yixuan Li, and Rayadurgam Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. In 6th International Conference on Learning Representations, ICLR 2018, 2018."]}]}