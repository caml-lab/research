{"title": "Unlocking high-accuracy differentially private image classification through scale", "abstract": "Differential Privacy (DP) provides a formal privacy guarantee preventing adversaries with access to a machine learning model from extracting information about individual training points. Differentially Private Stochastic Gradient Descent (DP-SGD), the most popular DP training method for deep learning, realizes this protection by injecting noise during training. However previous works have found that DP-SGD often leads to a significant degradation in performance on standard image classification benchmarks. Furthermore, some authors have postulated that DP-SGD inherently performs poorly on large models, since the norm of the noise required to preserve privacy is proportional to the model dimension. In contrast, we demonstrate that DP-SGD on over-parameterized models can perform significantly better than previously thought. Combining careful hyper-parameter tuning with simple techniques to ensure signal propagation and improve the convergence rate, we obtain a new SOTA without extra data on CIFAR-10 of 81.4% under (8, 10^{-5})-DP using a 40-layer Wide-ResNet, improving over the previous SOTA of 71.7%. When fine-tuning a pre-trained NFNet-F3, we achieve a remarkable 83.8% top-1 accuracy on ImageNet under (0.5, 8*10^{-7})-DP. Additionally, we also achieve 86.7% top-1 accuracy under (8, 8 \\cdot 10^{-7})-DP, which is just 4.3% below the current non-private SOTA for this task. We believe our results are a significant step towards closing the accuracy gap between private and non-private image classification.", "authors": ["Soham De", " Leonard Berrada", " Jamie Hayes", " Samuel L. Smith", " Borja Balle"], "pdf_url": "https://arxiv.org/abs/2204.13650", "list_table_and_caption": [{"table": "<table><tbody><tr><th></th><th rowspan=\"2\">\\varepsilon</th><td colspan=\"2\">Test Accuracy (%)</td></tr><tr><th></th><td>Median</td><td>Std. Dev.</td></tr><tr><th rowspan=\"3\">Tram\u00e8r and Boneh (2021)</th><th>1</th><td>60.3</td><td>\u2013</td></tr><tr><th>2</th><td>67.2</td><td>\u2013</td></tr><tr><th>3</th><td>69.3</td><td>\u2013</td></tr><tr><th rowspan=\"3\">D\u00f6rmann et al. (2021)</th><th>1.93</th><td>58.6</td><td>\u2013</td></tr><tr><th>4.21</th><td>66.2</td><td>\u2013</td></tr><tr><th>7.42</th><td>70.1</td><td>\u2013</td></tr><tr><th>Klause et al. (2022)</th><th>7.5</th><td>71.7</td><td>\u2013</td></tr><tr><th rowspan=\"6\">Ours (WRN-16-4)</th><th>1</th><td>56.8</td><td>(0.6)</td></tr><tr><th>2</th><td>64.9</td><td>(0.5)</td></tr><tr><th>3</th><td>69.2</td><td>(0.3)</td></tr><tr><th>4</th><td>71.9</td><td>(0.3)</td></tr><tr><th>6</th><td>77.0</td><td>(0.8)</td></tr><tr><th>8</th><td>79.5</td><td>(0.7)</td></tr><tr><th rowspan=\"6\">Ours (WRN-40-4)</th><th>1</th><td>56.4</td><td>(0.6)</td></tr><tr><th>2</th><td>65.9</td><td>(0.5)</td></tr><tr><th>3</th><td>70.7</td><td>(0.2)</td></tr><tr><th>4</th><td>73.5</td><td>(0.6)</td></tr><tr><th>6</th><td>78.8</td><td>(0.4)</td></tr><tr><th>8</th><td>81.4</td><td>(0.2)</td></tr></tbody></table>", "caption": "Table 3:  CIFAR-10 test accuracy of our Wide-ResNet models trained with DP-SGD without additional data.For our results, we report the median computed over five independent runs as well as the standard deviation.", "list_citation_info": ["Klause et al. (2022) H. Klause, A. Ziller, D. Rueckert, K. Hammernik, and G. Kaissis. Differentially private training of residual networks with scale normalisation. arXiv, 2022.", "Tram\u00e8r and Boneh (2021) F. Tram\u00e8r and D. Boneh. Differentially private learning needs better features (or much more data). International Conference on Learning Representations, 2021.", "D\u00f6rmann et al. (2021) F. D\u00f6rmann, O. Frisk, L. N. Andersen, and C. F. Pedersen. Not all noise is accounted equally: How differentially private learning benefits from large sampling rates. International Workshop on Machine Learning for Signal Processing, 2021."]}, {"table": "<table><thead><tr><th rowspan=\"2\">Method</th><th rowspan=\"2\">Model</th><th rowspan=\"2\">(\\varepsilon,\\delta)</th><th colspan=\"2\">Accuracy (%)</th></tr><tr><th>Top-1</th><th>Top-5</th></tr></thead><tbody><tr><th>Kurakin et al. (2022)</th><th>ResNet-18</th><td>(13.2,10^{-6})</td><td>6.9</td><td>\u2013</td></tr><tr><th>Ours</th><th>NF-ResNet-50</th><td>(8.0,8\\cdot 10^{-7})</td><td>32.4</td><td>55.8</td></tr></tbody></table>", "caption": "Table 4: Top-1 and top-5 accuracy when training on ImageNet using DP-SGD without additional data.", "list_citation_info": ["Kurakin et al. (2022) A. Kurakin, S. Chien, S. Song, R. Geambasu, A. Terzis, and A. Thakurta. Toward training at imagenet scale with differential privacy. arXiv, 2022."]}, {"table": "<table><tbody><tr><th rowspan=\"3\">Fine-tuning Method</th><th rowspan=\"3\">\\varepsilon</th><td colspan=\"4\">Test Accuracy (%)</td></tr><tr><td colspan=\"2\">CIFAR-10</td><td colspan=\"2\">CIFAR-100</td></tr><tr><td>Median</td><td>Std. Dev.</td><td>Median</td><td>Std. Dev.</td></tr><tr><th rowspan=\"2\">Yu et al. (2021b)</th><th>1</th><td>94.3</td><td>\u2013</td><td>\u2013</td><td>\u2013</td></tr><tr><th>2</th><td>94.8</td><td>\u2013</td><td>\u2013</td><td>\u2013</td></tr><tr><th>Tram\u00e8r and Boneh (2021)</th><th>2</th><td>92.7</td><td>\u2013</td><td>\u2013</td><td>\u2013</td></tr><tr><th rowspan=\"4\">Classifier layer</th><th>1</th><td>93.1</td><td>(0.03)</td><td>70.3</td><td>(0.09)</td></tr><tr><th>2</th><td>93.6</td><td>(0.05)</td><td>73.9</td><td>(0.32)</td></tr><tr><th>4</th><td>94.0</td><td>(0.08)</td><td>76.1</td><td>(0.31)</td></tr><tr><th>8</th><td>94.2</td><td>(0.07)</td><td>77.6</td><td>(0.10)</td></tr><tr><th rowspan=\"4\">All layers</th><th>1</th><td>94.8</td><td>(0.08)</td><td>67.4</td><td>(0.17)</td></tr><tr><th>2</th><td>95.4</td><td>(0.15)</td><td>74.7</td><td>(0.15)</td></tr><tr><th>4</th><td>96.1</td><td>(0.06)</td><td>79.2</td><td>(0.24)</td></tr><tr><th>8</th><td>96.6</td><td>(0.08)</td><td>81.8</td><td>(0.07)</td></tr></tbody></table>", "caption": "Table 5: CIFAR-10 and CIFAR-100 test accuracies when fine-tuning with DP-SGD a 28-10 Wide-ResNet pre-trained on ImageNet (down-sampled to 32\\times 32).We report the median accuracy across 5 runs.", "list_citation_info": ["Yu et al. (2021b) D. Yu, H. Zhang, W. Chen, and T. Liu. Do not let privacy overbill utility: Gradient embedding perturbation for private learning. International Conference on Learning Representations, 2021b.", "Tram\u00e8r and Boneh (2021) F. Tram\u00e8r and D. Boneh. Differentially private learning needs better features (or much more data). International Conference on Learning Representations, 2021."]}, {"table": "<table><tbody><tr><th rowspan=\"2\">\\varepsilon</th><th rowspan=\"2\">Method</th><td colspan=\"2\">Test Accuracy (%)</td></tr><tr><td>Median</td><td>Std. Dev.</td></tr><tr><th rowspan=\"2\">0.5</th><th>Luo et al. (2021)</th><td>73.3</td><td>\u2013</td></tr><tr><th>Ours</th><td>76.7</td><td>(0.3)</td></tr><tr><th rowspan=\"2\">1.0</th><th>Luo et al. (2021)</th><td>76.6</td><td>\u2013</td></tr><tr><th>Ours</th><td>80.4</td><td>(0.7)</td></tr><tr><th rowspan=\"2\">1.5</th><th>Luo et al. (2021)</th><td>81.6</td><td>\u2013</td></tr><tr><th>Ours</th><td>83.8</td><td>(0.3)</td></tr><tr><th>2</th><th>Ours</th><td>84.9</td><td>(0.2)</td></tr><tr><th>4</th><th>Ours</th><td>87.0</td><td>(0.2)</td></tr><tr><th>6</th><th>Ours</th><td>88.4</td><td>(0.2)</td></tr><tr><th>8</th><th>Ours</th><td>89.0</td><td>(0.2)</td></tr></tbody></table>", "caption": "Table 11: Test accuracy on CIFAR-10 when privately fine-tuning from the WRN-40-4 pre-trained on CIFAR-100. We report the median test accuracy and the standard deviation across 5 independent runs.", "list_citation_info": ["Luo et al. (2021) Z. Luo, D. J. Wu, E. Adeli, and L. Fei-Fei. Scalable differential privacy with sparse network finetuning. Conference on Computer Vision and Pattern Recognition, 2021."]}]}