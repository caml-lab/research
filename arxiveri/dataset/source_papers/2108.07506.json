{"title": "Pr-rrn: Pairwise-regularized residual-recursive networks for non-rigid structure-from-motion", "abstract": "We propose PR-RRN, a novel neural-network based method for Non-rigid Structure-from-Motion (NRSfM). PR-RRN consists of Residual-Recursive Networks (RRN) and two extra regularization losses. RRN is designed to effectively recover 3D shape and camera from 2D keypoints with novel residual-recursive structure. As NRSfM is a highly under-constrained problem, we propose two new pairwise regularization to further regularize the reconstruction. The Rigidity-based Pairwise Contrastive Loss regularizes the shape representation by encouraging higher similarity between the representations of high-rigidity pairs of frames than low-rigidity pairs. We propose minimum singular-value ratio to measure the pairwise rigidity. The Pairwise Consistency Loss enforces the reconstruction to be consistent when the estimated shapes and cameras are exchanged between pairs. Our approach achieves state-of-the-art performance on CMU MOCAP and PASCAL3D+ dataset.", "authors": ["Haitian Zeng", " Yuchao Dai", " Xin Yu", " Xiaohan Wang", " Yi Yang"], "pdf_url": "https://arxiv.org/abs/2108.07506", "list_table_and_caption": [{"table": "<table><thead><tr><th>Methods</th><th>Subj. 07</th><th>Subj. 20</th><th>Subj. 23</th><th>Subj. 33</th><th>Subj. 34</th><th>Subj. 38</th><th>Subj. 39</th><th>Subj. 43</th><th>Subj. 93</th></tr></thead><tbody><tr><th>CSF [15]</th><td>1.231</td><td>1.164</td><td>1.238</td><td>1.156</td><td>1.165</td><td>1.188</td><td>1.172</td><td>1.267</td><td>1.117</td></tr><tr><th>URN [7]</th><td>1.504</td><td>1.770</td><td>1.329</td><td>1.205</td><td>1.305</td><td>1.303</td><td>1.550</td><td>1.434</td><td>1.601</td></tr><tr><th>CNS [6]</th><td>0.310</td><td>0.217</td><td>0.184</td><td>0.177</td><td>0.249</td><td>0.223</td><td>0.312</td><td>0.266</td><td>0.245</td></tr><tr><th>C3DPO [30]</th><td>0.226</td><td>0.235</td><td>0.342</td><td>0.357</td><td>0.354</td><td>0.391</td><td>0.189</td><td>0.351</td><td>0.246</td></tr><tr><th>DNRSFM [20]</th><td>0.045</td><td>0.137</td><td>0.053</td><td>0.137</td><td>0.062</td><td>0.053</td><td>0.041</td><td>0.125</td><td>0.214</td></tr><tr><th>PR-RRN (Ours)</th><td>0.024</td><td>0.034</td><td>0.039</td><td>0.043</td><td>0.039</td><td>0.034</td><td>0.025</td><td>0.028</td><td>0.152</td></tr><tr><th>PR-RRN (Unseen)</th><td>0.061</td><td>0.167</td><td>0.249</td><td>0.254</td><td>0.265</td><td>0.108</td><td>0.028</td><td>0.080</td><td>0.242</td></tr></tbody></table>", "caption": "Table 1: The reconstruction error \\mathrm{e_{3D}} on CMU MOCAP.", "list_citation_info": ["[7] Geonho Cha, Minsik Lee, and Songhwai Oh. Unsupervised 3d reconstruction networks. In ICCV, pages 3848\u20133857, 2019.", "[15] Paulo F. U. Gotardo and Aleix M. Martinez. Computing smooth time trajectories for camera and deformable shape in structure from motion with occlusion. IEEE TPAMI, 33(10):2051\u20132065, 2011.", "[6] Geonho Cha, Minsik Lee, and Songhwai Oh. Reconstruct as far as you can: Consensus of non-rigid reconstruction from feasible regions. IEEE TPAMI, pages 1\u20131, 2019.", "[30] David Novotny, Nikhila Ravi, Ben Graham, Natalia Neverova, and Andrea Vedaldi. C3dpo: Canonical 3d pose networks for non-rigid structure from motion. In ICCV, 2019.", "[20] Chen Kong and Simon Lucey. Deep non-rigid structure from motion with missing data. IEEE TPAMI, pages 1\u20131, 2020."]}, {"table": "<table><tbody><tr><td></td><td>CSF</td><td>KSTA</td><td>BMM</td><td>CNS</td><td>NLO</td><td>RIKS</td><td>SPS</td><td>SFC</td><td>MUS</td><td>URN</td><td>C3D</td><td>DNR</td><td>Ours</td></tr><tr><td>Aeroplane</td><td>0.363</td><td>0.175</td><td>1.459</td><td>0.416</td><td>0.876</td><td>0.132</td><td>0.930</td><td>0.504</td><td>0.261</td><td>0.121</td><td>0.272</td><td>0.024</td><td>0.031</td></tr><tr><td>Bicycle</td><td>0.424</td><td>0.245</td><td>1.376</td><td>0.356</td><td>0.269</td><td>0.136</td><td>1.322</td><td>0.372</td><td>0.178</td><td>0.328</td><td>0.585</td><td>0.003</td><td>0.005</td></tr><tr><td>Bus</td><td>0.217</td><td>0.199</td><td>1.023</td><td>0.250</td><td>0.140</td><td>0.160</td><td>0.604</td><td>0.251</td><td>0.113</td><td>0.097</td><td>0.271</td><td>0.004</td><td>0.008</td></tr><tr><td>Car</td><td>0.195</td><td>0.186</td><td>1.278</td><td>0.258</td><td>0.104</td><td>0.097</td><td>0.872</td><td>0.282</td><td>0.078</td><td>0.104</td><td>0.276</td><td>0.009</td><td>0.005</td></tr><tr><td>Chair</td><td>0.398</td><td>0.399</td><td>1.297</td><td>0.170</td><td>0.146</td><td>0.192</td><td>1.046</td><td>0.226</td><td>0.210</td><td>0.115</td><td>0.658</td><td>0.007</td><td>0.025</td></tr><tr><td>Diningtable</td><td>0.406</td><td>0.267</td><td>1.000</td><td>0.170</td><td>0.109</td><td>0.207</td><td>1.050</td><td>0.221</td><td>0.264</td><td>0.115</td><td>0.441</td><td>0.060</td><td>0.015</td></tr><tr><td>Motorbike</td><td>0.278</td><td>0.255</td><td>0.857</td><td>0.457</td><td>0.432</td><td>0.118</td><td>0.986</td><td>0.361</td><td>0.222</td><td>0.287</td><td>0.492</td><td>0.002</td><td>0.006</td></tr><tr><td>Sofa</td><td>0.409</td><td>0.307</td><td>1.126</td><td>0.250</td><td>0.149</td><td>0.228</td><td>1.328</td><td>0.302</td><td>0.167</td><td>0.181</td><td>0.343</td><td>0.004</td><td>0.007</td></tr><tr><td>Average</td><td>0.336</td><td>0.223</td><td>1.178</td><td>0.291</td><td>0.278</td><td>0.159</td><td>1.017</td><td>0.315</td><td>0.186</td><td>0.168</td><td>0.417</td><td>0.014</td><td>0.013</td></tr></tbody></table>", "caption": "Table 2: The reconstruction error \\mathrm{e_{3D}} on PASCAL3D+. The performances of compared methods are quoted from [2, 8, 20].", "list_citation_info": ["[2] Antonio Agudo, Melcior Pijoan, and Francesc Moreno-Noguer. Image collection pop-up: 3d reconstruction and clustering of rigid and non-rigid categories. In CVPR, pages 2607\u20132615, 2018."]}, {"table": "<table><thead><tr><th>Model</th><th>20</th><th>23</th><th>33</th><th>43</th><th>93</th></tr><tr><th>DNRSFM [20]</th><th>0.137</th><th>0.053</th><th>0.137</th><th>0.125</th><th>0.214</th></tr></thead><tbody><tr><th>Vanilla</th><td>0.147</td><td>0.352</td><td>0.060</td><td>0.072</td><td>0.213</td></tr><tr><th>RRN</th><td>0.041</td><td>0.050</td><td>0.051</td><td>0.047</td><td>0.305</td></tr></tbody></table>", "caption": "Table 3: Analysis on RRN structure.", "list_citation_info": ["[20] Chen Kong and Simon Lucey. Deep non-rigid structure from motion with missing data. IEEE TPAMI, pages 1\u20131, 2020."]}]}