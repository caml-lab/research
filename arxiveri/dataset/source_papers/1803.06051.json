{"title": "Deep Multiple Instance Learning for Zero-Shot Image Tagging", "abstract": "In-line with the success of deep learning on traditional recognition problem, several end-to-end deep models for zero-shot recognition have been proposed in the literature. These models are successful to predict a single unseen label given an input image, but does not scale to cases where multiple unseen objects are present. In this paper, we model this problem within the framework of Multiple Instance Learning (MIL). To the best of our knowledge, we propose the first end-to-end trainable deep MIL framework for the multi-label zero-shot tagging problem. Due to its novel design, the proposed framework has several interesting features: (1) Unlike previous deep MIL models, it does not use any off-line procedure (e.g., Selective Search or EdgeBoxes) for bag generation. (2) During test time, it can process any number of unseen labels given their semantic embedding vectors. (3) Using only seen labels per image as weak annotation, it can produce a bounding box for each predicted labels. We experiment with the NUS-WIDE dataset and achieve superior performance across conventional, zero-shot and generalized zero-shot tagging tasks.", "authors": ["Shafin Rahman", " Salman Khan"], "pdf_url": "https://arxiv.org/abs/1803.06051", "list_table_and_caption": [{"table": "<table><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">MiAP</td><td colspan=\"3\">K=3</td><td colspan=\"3\">K=5</td></tr><tr><td>P</td><td>R</td><td>F1</td><td>P</td><td>R</td><td>F1</td></tr><tr><td>Fast0Tag [10]</td><td>35.73</td><td>20.24</td><td>34.48</td><td>25.51</td><td>16.16</td><td>45.87</td><td>23.90</td></tr><tr><td>Baseline</td><td>40.45</td><td>22.95</td><td>39.09</td><td>28.92</td><td>17.99</td><td>51.09</td><td>26.61</td></tr><tr><td>Ours (Bag: 32)</td><td>53.97</td><td>30.17</td><td>51.41</td><td>38.03</td><td>22.66</td><td>64.35</td><td>33.52</td></tr><tr><td>Ours (Bag: 64)</td><td>53.94</td><td>30.23</td><td>51.61</td><td>38.18</td><td>22.73</td><td>64.54</td><td>33.62</td></tr></table>", "caption": "Table 1: Results for conventional tagging. K denotes the number of assigned tags.", "list_citation_info": ["[10] Zhang, Z., Saligrama, V.: Zero-shot learning via joint latent similarity embedding. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (June 2016)"]}, {"table": "<table><tr><td rowspan=\"3\">Method</td><td colspan=\"7\">Zero-shot tagging</td><td colspan=\"7\">Generalized zero-shot tagging</td></tr><tr><td rowspan=\"2\">MiAP</td><td colspan=\"3\">K=3</td><td colspan=\"3\">K=5</td><td rowspan=\"2\">MiAP</td><td colspan=\"3\">K=3</td><td colspan=\"3\">K=5</td></tr><tr><td>P</td><td>R</td><td>F1</td><td>P</td><td>R</td><td>F1</td><td>P</td><td>R</td><td>F1</td><td>P</td><td>R</td><td>F1</td></tr><tr><td>ConSE [29]</td><td>18.91</td><td>8.39</td><td>14.30</td><td>10.58</td><td>7.16</td><td>20.33</td><td>10.59</td><td>7.27</td><td>2.11</td><td>3.59</td><td>2.65</td><td>8.82</td><td>5.69</td><td>6.92</td></tr><tr><td>Fast0Tag [10]</td><td>24.73</td><td>13.21</td><td>22.51</td><td>16.65</td><td>11.00</td><td>31.23</td><td>16.27</td><td>10.36</td><td>5.21</td><td>8.88</td><td>6.57</td><td>12.41</td><td>8.00</td><td>9.73</td></tr><tr><td>Baseline</td><td>29.75</td><td>16.64</td><td>28.34</td><td>20.97</td><td>13.49</td><td>38.32</td><td>19.96</td><td>12.07</td><td>5.99</td><td>10.20</td><td>7.54</td><td>14.28</td><td>9.21</td><td>11.20</td></tr><tr><td>Ours (Bag: 32)</td><td>37.50</td><td>21.16</td><td>36.06</td><td>26.67</td><td>16.62</td><td>47.20</td><td>24.59</td><td>20.55</td><td>27.66</td><td>10.70</td><td>15.43</td><td>23.67</td><td>15.27</td><td>18.56</td></tr><tr><td>Ours (Bag: 64)</td><td>39.01</td><td>22.05</td><td>37.56</td><td>27.79</td><td>17.26</td><td>49.01</td><td>25.53</td><td>20.32</td><td>27.09</td><td>10.48</td><td>15.12</td><td>23.27</td><td>15.01</td><td>18.25</td></tr></table>", "caption": "Table 2: Results for zero-shot and generalize zero-shot tagging tasks. ", "list_citation_info": ["[10] Zhang, Z., Saligrama, V.: Zero-shot learning via joint latent similarity embedding. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (June 2016)", "[29] Norouzi, M., Mikolov, T., Bengio, S., Singer, Y., Shlens, J., Frome, A., Corrado, G.S., Dean, J.: Zeroshot learning by convex combination of semantic embeddings. In: In Proceedings of ICLR. (2014)"]}, {"table": "<table><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">MiAP</td><td colspan=\"3\">K=3</td><td colspan=\"3\">K=5</td></tr><tr><td>P</td><td>R</td><td>F1</td><td>P</td><td>R</td><td>F1</td></tr><tr><td>ConSE [29]</td><td>0.36</td><td>0.08</td><td>0.06</td><td>0.07</td><td>0.10</td><td>0.13</td><td>0.11</td></tr><tr><td>Fast0Tag [10]</td><td>3.26</td><td>3.15</td><td>2.40</td><td>2.72</td><td>2.51</td><td>3.18</td><td>2.81</td></tr><tr><td>Baseline</td><td>3.61</td><td>3.51</td><td>2.67</td><td>3.04</td><td>2.83</td><td>3.59</td><td>3.16</td></tr><tr><td>Ours (Bag: 32)</td><td>5.85</td><td>5.42</td><td>4.12</td><td>4.68</td><td>4.42</td><td>5.60</td><td>4.94</td></tr><tr><td>Ours (Bag: 64)</td><td>5.52</td><td>5.01</td><td>3.81</td><td>4.33</td><td>4.10</td><td>5.20</td><td>4.59</td></tr></table>", "caption": "Table 4: Results for zero-shot tagging task with 4,084 unseen tags.", "list_citation_info": ["[10] Zhang, Z., Saligrama, V.: Zero-shot learning via joint latent similarity embedding. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (June 2016)", "[29] Norouzi, M., Mikolov, T., Bengio, S., Singer, Y., Shlens, J., Frome, A., Corrado, G.S., Dean, J.: Zeroshot learning by convex combination of semantic embeddings. In: In Proceedings of ICLR. (2014)"]}, {"table": "<table><tr><td>Top1 Accuracy</td><td>Network</td><td>w2v</td><td>glo</td></tr><tr><td>Akata\u201916 [7]</td><td>V</td><td>33.90</td><td>-</td></tr><tr><td>DMaP-I\u201917[5]</td><td>G+V</td><td>26.38</td><td>30.34</td></tr><tr><td>SCoRe\u201917[6]</td><td>G</td><td>31.51</td><td>-</td></tr><tr><td>Akata\u201915 [42]</td><td>G</td><td>28.40</td><td>24.20</td></tr><tr><td>LATEM\u201916 [41]</td><td>G</td><td>31.80</td><td>32.50</td></tr><tr><td>DMaP-I\u201917 [5]</td><td>G</td><td>26.28</td><td>23.69</td></tr><tr><td>Ours (Bag size: 32)</td><td>R</td><td>31.77</td><td>29.56</td></tr><tr><td>Ours (Bag size: 64)</td><td>R</td><td>36.55</td><td>33.00</td></tr></table>", "caption": "Table 5: Zero shot recognition on CUB using mean pooling based MIL. For fairness, we only compared our results with the inductive setting of other methods without per image part annotation and description. We refer investigated network structures as V=VGG, R=ResNet, G=GoogLeNet.", "list_citation_info": ["[5] Li, Y., Wang, D., Hu, H., Lin, Y., Zhuang, Y.: Zero-shot recognition using dual visual-semantic mapping paths. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (July 2017)", "[42] Akata, Z., Reed, S., Walter, D., Lee, H., Schiele, B.: Evaluation of output embeddings for fine-grained image classification. In: Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition. Volume 07-12-June-2015. (2015) 2927\u20132936", "[6] Morgado, P., Vasconcelos, N.: Semantically consistent regularization for zero-shot recognition. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (July 2017)", "[7] Akata, Z., Malinowski, M., Fritz, M., Schiele, B.: Multi-cue zero-shot learning with strong supervision. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (June 2016)", "[41] Xian, Y., Akata, Z., Sharma, G., Nguyen, Q., Hein, M., Schiele, B.: Latent embeddings for zero-shot classification. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). (June 2016)"]}]}