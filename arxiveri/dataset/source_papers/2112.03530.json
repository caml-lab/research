{"title": "A conditional point diffusion-refinement paradigm for 3d point cloud completion", "abstract": "3D point cloud is an important 3D representation for capturing real world 3D objects. However, real-scanned 3D point clouds are often incomplete, and it is important to recover complete point clouds for downstream applications. Most existing point cloud completion methods use Chamfer Distance (CD) loss for training. The CD loss estimates correspondences between two point clouds by searching nearest neighbors, which does not capture the overall point density distribution on the generated shape, and therefore likely leads to non-uniform point cloud generation. To tackle this problem, we propose a novel Point Diffusion-Refinement (PDR) paradigm for point cloud completion. PDR consists of a Conditional Generation Network (CGNet) and a ReFinement Network (RFNet). The CGNet uses a conditional generative model called the denoising diffusion probabilistic model (DDPM) to generate a coarse completion conditioned on the partial observation. DDPM establishes a one-to-one pointwise mapping between the generated point cloud and the uniform ground truth, and then optimizes the mean squared error loss to realize uniform generation. The RFNet refines the coarse output of the CGNet and further improves quality of the completed point cloud. Furthermore, we develop a novel dual-path architecture for both networks. The architecture can (1) effectively and efficiently extract multi-level features from partially observed point clouds to guide completion, and (2) accurately manipulate spatial locations of 3D points to obtain smooth surfaces and sharp details. Extensive experimental results on various benchmark datasets show that our PDR paradigm outperforms previous state-of-the-art methods for point cloud completion. Remarkably, with the help of the RFNet, we can accelerate the iterative generation process of the DDPM by up to 50 times without much performance drop.", "authors": ["Zhaoyang Lyu", " Zhifeng Kong", " Xudong Xu", " Liang Pan", " Dahua Lin"], "pdf_url": "https://arxiv.org/abs/2112.03530", "list_table_and_caption": [{"table": "<table><tr><td> </td><td colspan=\"3\">MVP</td><td colspan=\"3\">MVP40 (50\\% missing)</td><td colspan=\"3\">MVP40 (12.5\\% missing)</td><td colspan=\"3\">Completion3D</td></tr><tr><td>Method</td><td>CD</td><td>EMD</td><td>F1</td><td>CD</td><td>EMD</td><td>F1</td><td>CD</td><td>EMD</td><td>F1</td><td>CD</td><td>EMD</td><td>F1</td></tr><tr><td>PCN  (Yuan et al., 2018)</td><td>8.65</td><td>1.95</td><td>0.342</td><td>39.67</td><td>6.37</td><td>0.581</td><td>32.56</td><td>6.18</td><td>0.619</td><td>8.81</td><td>3.03</td><td>0.315</td></tr><tr><td>TopNet (Tchapmi et al., 2019)</td><td>10.19</td><td>2.44</td><td>0.299</td><td>48.52</td><td>8.75</td><td>0.506</td><td>40.12</td><td>9.08</td><td>0.542</td><td>11.56</td><td>3.69</td><td>0.257</td></tr><tr><td>FoldingNet (Yang et al., 2018)</td><td>10.54</td><td>3.64</td><td>0.256</td><td>51.89</td><td>11.66</td><td>0.441</td><td>46.03</td><td>8.93</td><td>0.480</td><td>14.32</td><td>4.81</td><td>0.186</td></tr><tr><td>MSN (Liu et al., 2020)</td><td>7.08</td><td>1.71</td><td>0.434</td><td>34.33</td><td>9.70</td><td>0.646</td><td>20.20</td><td>4.54</td><td>0.728</td><td>8.88</td><td>2.69</td><td>0.359</td></tr><tr><td>Cascade (Wang et al., 2020)</td><td>6.83</td><td>2.14</td><td>0.436</td><td>34.16</td><td>15.40</td><td>0.635</td><td>26.73</td><td>5.71</td><td>0.657</td><td>7.31</td><td>2.70</td><td>0.408</td></tr><tr><td>ECG (Pan, 2020)</td><td>7.06</td><td>2.36</td><td>0.443</td><td>34.06</td><td>16.19</td><td>0.671</td><td>40.00</td><td>6.98</td><td>0.597</td><td>10.43</td><td>3.63</td><td>0.300</td></tr><tr><td>GRNet (Xie et al., 2020)</td><td>7.61</td><td>2.36</td><td>0.353</td><td>35.99</td><td>12.33</td><td>0.589</td><td>22.04</td><td>6.43</td><td>0.646</td><td>8.54</td><td>2.87</td><td>0.314</td></tr><tr><td>PMPNet (Wen et al., 2021)</td><td>5.85</td><td>3.42</td><td>0.475</td><td>25.41</td><td>29.92</td><td>0.721</td><td>13.00</td><td>8.92</td><td>0.815</td><td>7.45</td><td>4.85</td><td>0.386</td></tr><tr><td>VRCNet (Pan et al., 2021)</td><td>5.82</td><td>2.31</td><td>0.495</td><td>25.70</td><td>18.40</td><td>0.736</td><td>14.20</td><td>5.90</td><td>0.807</td><td>6.69</td><td>3.57</td><td>0.433</td></tr><tr><td>PDR paradigm (Ours)</td><td>5.66</td><td>1.37</td><td>0.499</td><td>27.20</td><td>2.68</td><td>0.739</td><td>12.70</td><td>1.39</td><td>0.827</td><td>7.10</td><td>1.75</td><td>0.451</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 1: Point cloud completion results on MVP, MVP-40 and Completion3D datasets at the resolution of 2048 points. CD loss is multiplied by 10^{4}. EMD loss is multiplied by 10^{2}.Scale factors of the two losses are the same in all the other tables. The two losses are the lower the better, while F1 score is the higher the better.Note that MVP-40 dataset has larger CD and EMD losses because objects in it have larger scales than the other two datasets.Results of MVP-40 dataset at 25% missing ratio is complemented in Appendix Table 5.", "list_citation_info": ["Pan (2020) Liang Pan. Ecg: Edge-aware point cloud completion with graph convolution. IEEE Robotics and Automation Letters, 2020.", "Liu et al. (2020) Minghua Liu, Lu Sheng, Sheng Yang, Jing Shao, and Shi-Min Hu. Morphing and sampling network for dense point cloud completion. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 11596\u201311603, 2020.", "Xie et al. (2020) Haozhe Xie, Hongxun Yao, Shangchen Zhou, Jiageng Mao, Shengping Zhang, and Wenxiu Sun. Grnet: Gridding residual network for dense point cloud completion. arXiv preprint arXiv:2006.03761, 2020.", "Wen et al. (2021) Xin Wen, Peng Xiang, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, and Yu-Shen Liu. Pmp-net: Point cloud completion by learning multi-step point moving paths. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7443\u20137452, 2021.", "Tchapmi et al. (2019) Lyne P Tchapmi, Vineet Kosaraju, Hamid Rezatofighi, Ian Reid, and Silvio Savarese. Topnet: Structural point cloud decoder. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 383\u2013392, 2019.", "Wang et al. (2020) Xiaogang Wang, Marcelo H Ang Jr, and Gim Hee Lee. Cascaded refinement network for point cloud completion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 790\u2013799, 2020.", "Yang et al. (2018) Yaoqing Yang, Chen Feng, Yiru Shen, and Dong Tian. Foldingnet: Point cloud auto-encoder via deep grid deformation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 206\u2013215, 2018.", "Yuan et al. (2018) Wentao Yuan, Tejas Khot, David Held, Christoph Mertz, and Martial Hebert. Pcn: Point completion network. In 2018 International Conference on 3D Vision (3DV), pp. 728\u2013737. IEEE, 2018.", "Pan et al. (2021) Liang Pan, Xinyi Chen, Zhongang Cai, Junzhe Zhang, Haiyu Zhao, Shuai Yi, and Ziwei Liu. Variational relational point completion network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8524\u20138533, 2021."]}, {"table": "<table><tr><td> </td><td colspan=\"3\">MVP40 (50\\% missing)</td><td colspan=\"3\">MVP40 (25\\% missing)</td><td colspan=\"3\">MVP40 (12.5\\% missing)</td></tr><tr><td>Method</td><td>CD</td><td>EMD</td><td>F1</td><td>CD</td><td>EMD</td><td>F1</td><td>CD</td><td>EMD</td><td>F1</td></tr><tr><td>PCN  (Yuan et al., 2018)</td><td>39.67</td><td>6.37</td><td>0.581</td><td>34.40</td><td>6.21</td><td>0.606</td><td>32.56</td><td>6.18</td><td>0.619</td></tr><tr><td>TopNet (Tchapmi et al., 2019)</td><td>48.52</td><td>8.75</td><td>0.506</td><td>42.39</td><td>10.25</td><td>0.520</td><td>40.12</td><td>9.08</td><td>0.542</td></tr><tr><td>FoldingNet (Yang et al., 2018)</td><td>51.89</td><td>11.66</td><td>0.441</td><td>45.99</td><td>9.85</td><td>0.475</td><td>46.03</td><td>8.93</td><td>0.480</td></tr><tr><td>MSN (Liu et al., 2020)</td><td>34.33</td><td>9.70</td><td>0.646</td><td>23.14</td><td>6.59</td><td>0.712</td><td>20.20</td><td>4.54</td><td>0.728</td></tr><tr><td>Cascade (Wang et al., 2020)</td><td>34.16</td><td>15.40</td><td>0.635</td><td>29.13</td><td>8.16</td><td>0.647</td><td>26.73</td><td>5.71</td><td>0.657</td></tr><tr><td>ECG (Pan, 2020)</td><td>34.06</td><td>16.19</td><td>0.671</td><td>28.01</td><td>10.79</td><td>0.717</td><td>16.90</td><td>6.20</td><td>0.774</td></tr><tr><td>GRNet (Xie et al., 2020)</td><td>35.99</td><td>12.33</td><td>0.589</td><td>25.84</td><td>8.43</td><td>0.626</td><td>22.04</td><td>6.43</td><td>0.646</td></tr><tr><td>PMPNet (Wen et al., 2021)</td><td>25.41</td><td>29.92</td><td>0.721</td><td>15.73</td><td>16.08</td><td>0.815</td><td>13.00</td><td>8.92</td><td>0.815</td></tr><tr><td>VRCNet (Pan et al., 2021)</td><td>25.70</td><td>18.40</td><td>0.736</td><td>18.28</td><td>10.96</td><td>0.776</td><td>14.20</td><td>5.90</td><td>0.807</td></tr><tr><td>PDR paradigm (Ours)</td><td>27.20</td><td>2.68</td><td>0.739</td><td>16.54</td><td>1.68</td><td>0.800</td><td>12.70</td><td>1.39</td><td>0.827</td></tr><tr><td> </td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>", "caption": "Table 5: Complete Point cloud completion results on MVP-40 dataset. The missing ratio is at 50%, 25% and 12.5%, respectively. CD loss is multiplied by 10^{4}. EMD loss is multiplied by 10^{2}.", "list_citation_info": ["Pan (2020) Liang Pan. Ecg: Edge-aware point cloud completion with graph convolution. IEEE Robotics and Automation Letters, 2020.", "Liu et al. (2020) Minghua Liu, Lu Sheng, Sheng Yang, Jing Shao, and Shi-Min Hu. Morphing and sampling network for dense point cloud completion. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 11596\u201311603, 2020.", "Xie et al. (2020) Haozhe Xie, Hongxun Yao, Shangchen Zhou, Jiageng Mao, Shengping Zhang, and Wenxiu Sun. Grnet: Gridding residual network for dense point cloud completion. arXiv preprint arXiv:2006.03761, 2020.", "Wen et al. (2021) Xin Wen, Peng Xiang, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, and Yu-Shen Liu. Pmp-net: Point cloud completion by learning multi-step point moving paths. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7443\u20137452, 2021.", "Tchapmi et al. (2019) Lyne P Tchapmi, Vineet Kosaraju, Hamid Rezatofighi, Ian Reid, and Silvio Savarese. Topnet: Structural point cloud decoder. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 383\u2013392, 2019.", "Wang et al. (2020) Xiaogang Wang, Marcelo H Ang Jr, and Gim Hee Lee. Cascaded refinement network for point cloud completion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 790\u2013799, 2020.", "Yang et al. (2018) Yaoqing Yang, Chen Feng, Yiru Shen, and Dong Tian. Foldingnet: Point cloud auto-encoder via deep grid deformation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 206\u2013215, 2018.", "Yuan et al. (2018) Wentao Yuan, Tejas Khot, David Held, Christoph Mertz, and Martial Hebert. Pcn: Point completion network. In 2018 International Conference on 3D Vision (3DV), pp. 728\u2013737. IEEE, 2018.", "Pan et al. (2021) Liang Pan, Xinyi Chen, Zhongang Cai, Junzhe Zhang, Haiyu Zhao, Shuai Yi, and Ziwei Liu. Variational relational point completion network. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8524\u20138533, 2021."]}]}