{"title": "Zero-shot object detection", "abstract": "Current Zero-Shot Learning (ZSL) approaches are restricted to recognition of a single dominant unseen object category in a test image. We hypothesize that this setting is ill-suited for real-world applications where unseen objects appear only as a part of a complex scene, warranting both the `recognition' and `localization' of an unseen category. To address this limitation, we introduce a new \\emph{`Zero-Shot Detection'} (ZSD) problem setting, which aims at simultaneously recognizing and locating object instances belonging to novel categories without any training examples. We also propose a new experimental protocol for ZSD based on the highly challenging ILSVRC dataset, adhering to practical issues, e.g., the rarity of unseen objects. To the best of our knowledge, this is the first end-to-end deep network for ZSD that jointly models the interplay between visual and semantic domain information. To overcome the noise in the automatically derived semantic descriptions, we utilize the concept of meta-classes to design an original loss function that achieves synergy between max-margin class separation and semantic space clustering. Furthermore, we present a baseline approach extended from recognition to detection setting. Our extensive experiments show significant performance boost over the baseline on the imperative yet difficult ZSD problem.", "authors": ["Shafin Rahman", " Salman Khan", " Fatih Porikli"], "pdf_url": "https://arxiv.org/abs/1803.06049", "list_table_and_caption": [{"table": "<table><tr><td>Top1 Accuracy</td><td>Network</td><td>w2v</td><td>glo</td></tr><tr><td>Akata\u201916 [1]</td><td>V</td><td>33.90</td><td>-</td></tr><tr><td>DMaP-I\u201917[24]</td><td>G+V</td><td>26.38</td><td>30.34</td></tr><tr><td>SCoRe\u201917[32]</td><td>G</td><td>31.51</td><td>-</td></tr><tr><td>Akata\u201915 [3]</td><td>G</td><td>28.40</td><td>24.20</td></tr><tr><td>LATEM\u201916 [46]</td><td>G</td><td>31.80</td><td>32.50</td></tr><tr><td>DMaP-I\u201917 [24]</td><td>G</td><td>26.28</td><td>23.69</td></tr><tr><td>Ours</td><td>R</td><td>36.77</td><td>36.82</td></tr></table>", "caption": "Table 3: Zero shot recognition on CUB using \\lambda=1 because no meta-class assignment is done here. For fairness, we only compared our result with the inductive setting of other methods without per image part annotation and description. We refer V=VGG, R=ResNet, G=GoogLeNet.", "list_citation_info": ["[32] P. Morgado and N. Vasconcelos. Semantically consistent regularization for zero-shot recognition. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.", "[3] Z. Akata, S. Reed, D. Walter, H. Lee, and B. Schiele. Evaluation of output embeddings for fine-grained image classification. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 07-12-June-2015, pages 2927\u20132936, 2015.", "[24] Y. Li, D. Wang, H. Hu, Y. Lin, and Y. Zhuang. Zero-shot recognition using dual visual-semantic mapping paths. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.", "[46] Y. Xian, Z. Akata, G. Sharma, Q. Nguyen, M. Hein, and B. Schiele. Latent embeddings for zero-shot classification. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.", "[1] Z. Akata, M. Malinowski, M. Fritz, and B. Schiele. Multi-cue zero-shot learning with strong supervision. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016."]}]}