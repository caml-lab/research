{"title": "Relaxed Transformer Decoders for Direct Action Proposal Generation", "abstract": "Temporal action proposal generation is an important and challenging task in video understanding, which aims at detecting all temporal segments containing action instances of interest. The existing proposal generation approaches are generally based on pre-defined anchor windows or heuristic bottom-up boundary matching strategies. This paper presents a simple and efficient framework (RTD-Net) for direct action proposal generation, by re-purposing a Transformer-alike architecture. To tackle the essential visual difference between time and space, we make three important improvements over the original transformer detection framework (DETR). First, to deal with slowness prior in videos, we replace the original Transformer encoder with a boundary attentive module to better capture long-range temporal information. Second, due to the ambiguous temporal boundary and relatively sparse annotations, we present a relaxed matching scheme to relieve the strict criteria of single assignment to each groundtruth. Finally, we devise a three-branch head to further improve the proposal confidence estimation by explicitly predicting its completeness. Extensive experiments on THUMOS14 and ActivityNet-1.3 benchmarks demonstrate the effectiveness of RTD-Net, on both tasks of temporal action proposal generation and temporal action detection. Moreover, due to its simplicity in design, our framework is more efficient than previous proposal generation methods, without non-maximum suppression post-processing. The code and models are made available at https://github.com/MCG-NJU/RTD-Action.", "authors": ["Jing Tan", " Jiaqi Tang", " Limin Wang", " Gangshan Wu"], "pdf_url": "https://arxiv.org/abs/2102.01894", "list_table_and_caption": [{"table": "<table><thead><tr><th>Method</th><th>@50</th><th>@100</th><th>@200</th><th>@500</th></tr></thead><tbody><tr><td>TAG+NMS [48]</td><td>18.55</td><td>29.00</td><td>39.61</td><td>-</td></tr><tr><td>TURN+NMS [15]</td><td>21.86</td><td>31.89</td><td>43.02</td><td>57.63</td></tr><tr><td>CTAP+NMS [13]</td><td>32.49</td><td>42.61</td><td>51.97</td><td>-</td></tr><tr><td>BSN+SNMS [26]</td><td>37.46</td><td>46.06</td><td>53.21</td><td>60.64</td></tr><tr><td>BSN*+SNMS</td><td>36.73</td><td>44.14</td><td>49.12</td><td>52.26</td></tr><tr><td>MGG [27]</td><td>39.93</td><td>47.75</td><td>54.65</td><td>61.36</td></tr><tr><td>BMN+SNMS [24]</td><td>39.36</td><td>47.72</td><td>54.70</td><td>62.07</td></tr><tr><td>BMN*+SNMS</td><td>37.03</td><td>44.12</td><td>49.49</td><td>54.27</td></tr><tr><td>DBG+SNMS [23]</td><td>37.32</td><td>46.67</td><td>54.50</td><td>62.21</td></tr><tr><td>RapNet+SNMS [14]</td><td>40.35</td><td>48.23</td><td>54.92</td><td>61.41</td></tr><tr><td>BC-GNN+SNMS [2]</td><td>40.50</td><td>49.60</td><td>56.33</td><td>62.80</td></tr><tr><td>RTD-Net*</td><td>41.52</td><td>49.32</td><td>56.41</td><td>62.91</td></tr></tbody></table><ul><li>\u2022<p>* results are reported based on P-GCN I3D features.</p></li></ul>", "caption": "Table 1: Comparison with other state-of-the-art proposal generation methods on the test set of THUMOS14 in terms of AR@AN. SNMS stands for Soft-NMS.", "list_citation_info": ["[2] Yueran Bai, Yingying Wang, Yunhai Tong, Yang Yang, Qiyue Liu, and Junhui Liu. Boundary content graph neural network for temporal action proposal generation. In ECCV (28), volume 12373 of Lecture Notes in Computer Science, pages 121\u2013137. Springer, 2020.", "[13] Jiyang Gao, Kan Chen, and Ram Nevatia. CTAP: complementary temporal action proposal generation. In ECCV, pages 70\u201385. Springer, 2018.", "[27] Yuan Liu, Lin Ma, Yifeng Zhang, Wei Liu, and Shih-Fu Chang. Multi-granularity generator for temporal action proposal. In CVPR, pages 3604\u20133613, 2019.", "[15] Jiyang Gao, Zhenheng Yang, Chen Sun, Kan Chen, and Ram Nevatia. TURN TAP: temporal unit regression network for temporal action proposals. In ICCV, pages 3648\u20133656, 2017.", "[14] Jialin Gao, Zhixiang Shi, Guanshuo Wang, Jiani Li, Yufeng Yuan, Shiming Ge, and Xi Zhou. Accurate temporal action proposal generation with relation-aware pyramid network. In AAAI, pages 10810\u201310817, 2020.", "[48] Yue Zhao, Yuanjun Xiong, Limin Wang, Zhirong Wu, Xiaoou Tang, and Dahua Lin. Temporal action detection with structured segment networks. In ICCV, pages 2933\u20132942, 2017.", "[23] Chuming Lin, Jian Li, Yabiao Wang, Ying Tai, Donghao Luo, Zhipeng Cui, Chengjie Wang, Jilin Li, Feiyue Huang, and Rongrong Ji. Fast learning of temporal action proposal via dense boundary generator. In AAAI, pages 11499\u201311506. AAAI Press, 2020.", "[24] Tianwei Lin, Xiao Liu, Xin Li, Errui Ding, and Shilei Wen. BMN: boundary-matching network for temporal action proposal generation. In ICCV, pages 3888\u20133897, 2019.", "[26] Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, and Ming Yang. BSN: boundary sensitive network for temporal action proposal generation. In ECCV, pages 3\u201321, 2018."]}, {"table": "<table><thead><tr><th>Method</th><th>[25]</th><th>CTAP [13]</th><th>BSN [26]</th><th>MGG [27]</th><th>BMN [24]</th><th>RTD-Net</th></tr></thead><tbody><tr><th>AR@1 (val)</th><th>-</th><td>-</td><td>32.17</td><td>-</td><td>-</td><td>33.05</td></tr><tr><th>AR@100 (val)</th><th>73.01</th><td>73.17</td><td>74.16</td><td>74.54</td><td>75.01</td><td>73.21</td></tr><tr><th>AUC (val)</th><th>64.40</th><td>65.72</td><td>66.17</td><td>66.43</td><td>67.10</td><td>65.78</td></tr></tbody></table>", "caption": "Table 2: Comparison with other state-of-the-art proposal generation methods on validation set of ActivityNet-1.3 in terms of AR@AN and AUC. Among them, only RTD-Net is free of NMS.", "list_citation_info": ["[13] Jiyang Gao, Kan Chen, and Ram Nevatia. CTAP: complementary temporal action proposal generation. In ECCV, pages 70\u201385. Springer, 2018.", "[27] Yuan Liu, Lin Ma, Yifeng Zhang, Wei Liu, and Shih-Fu Chang. Multi-granularity generator for temporal action proposal. In CVPR, pages 3604\u20133613, 2019.", "[25] Tianwei Lin, Xu Zhao, and Zheng Shou. Temporal convolution based action proposal: Submission to activitynet 2017. CoRR, abs/1707.06750, 2017.", "[24] Tianwei Lin, Xiao Liu, Xin Li, Errui Ding, and Shilei Wen. BMN: boundary-matching network for temporal action proposal generation. In ICCV, pages 3888\u20133897, 2019.", "[26] Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, and Ming Yang. BSN: boundary sensitive network for temporal action proposal generation. In ECCV, pages 3\u201321, 2018."]}, {"table": "<table><tbody><tr><td>Method</td><td>Classifier</td><td>0.7</td><td>0.6</td><td>0.5</td><td>0.4</td><td>0.3</td></tr><tr><td>SST [3]</td><td>UNet</td><td>4.7</td><td>10.9</td><td>20.0</td><td>31.5</td><td>41.2</td></tr><tr><td>TURN [15]</td><td>UNet</td><td>6.3</td><td>14.1</td><td>24.5</td><td>35.3</td><td>46.3</td></tr><tr><td>BSN [26]</td><td>UNet</td><td>20.0</td><td>28.4</td><td>36.9</td><td>45.0</td><td>53.5</td></tr><tr><td>MGG [27]</td><td>UNet</td><td>21.3</td><td>29.5</td><td>37.4</td><td>46.8</td><td>53.9</td></tr><tr><td>BMN [24]</td><td>UNet</td><td>20.5</td><td>29.7</td><td>38.8</td><td>47.4</td><td>56.0</td></tr><tr><td>DBG [23]</td><td>UNet</td><td>21.7</td><td>30.2</td><td>39.8</td><td>49.4</td><td>57.8</td></tr><tr><td>G-TAD [42]</td><td>UNet</td><td>23.4</td><td>30.8</td><td>40.2</td><td>47.6</td><td>54.5</td></tr><tr><td>BC-GNN [2]</td><td>UNet</td><td>23.1</td><td>31.2</td><td>40.4</td><td>49.1</td><td>57.1</td></tr><tr><td>RTD-Net</td><td>UNet</td><td>25.0</td><td>36.4</td><td>45.1</td><td>53.1</td><td>58.5</td></tr><tr><td>BSN [26]</td><td>P-GCN</td><td>-</td><td>-</td><td>49.1</td><td>57.8</td><td>63.6</td></tr><tr><td>G-TAD [42]</td><td>P-GCN</td><td>22.9</td><td>37.6</td><td>51.6</td><td>60.4</td><td>66.4</td></tr><tr><td>RTD-Net</td><td>P-GCN</td><td>23.7</td><td>38.8</td><td>51.9</td><td>62.3</td><td>68.3</td></tr></tbody></table>", "caption": "Table 7: Temporal action detection results on the test set of THUMOS14 in terms of mAP at different tIoU thresholds. Proposals are combined with the classifiers of UntrimmedNet [39] and P-GCN [43].", "list_citation_info": ["[43] Runhao Zeng, Wenbing Huang, Chuang Gan, Mingkui Tan, Yu Rong, Peilin Zhao, and Junzhou Huang. Graph convolutional networks for temporal action localization. In ICCV, pages 7093\u20137102, 2019.", "[3] Shyamal Buch, Victor Escorcia, Bernard Ghanem, Li Fei-Fei, and Juan Carlos Niebles. End-to-end, single-stream temporal action detection in untrimmed videos. In BMVC, 2017.", "[2] Yueran Bai, Yingying Wang, Yunhai Tong, Yang Yang, Qiyue Liu, and Junhui Liu. Boundary content graph neural network for temporal action proposal generation. In ECCV (28), volume 12373 of Lecture Notes in Computer Science, pages 121\u2013137. Springer, 2020.", "[42] Mengmeng Xu, Chen Zhao, David S. Rojas, Ali K. Thabet, and Bernard Ghanem. G-TAD: sub-graph localization for temporal action detection. In CVPR, pages 10153\u201310162, 2020.", "[27] Yuan Liu, Lin Ma, Yifeng Zhang, Wei Liu, and Shih-Fu Chang. Multi-granularity generator for temporal action proposal. In CVPR, pages 3604\u20133613, 2019.", "[39] Limin Wang, Yuanjun Xiong, Dahua Lin, and Luc Van Gool. Untrimmednets for weakly supervised action recognition and detection. In CVPR, pages 6402\u20136411, 2017.", "[15] Jiyang Gao, Zhenheng Yang, Chen Sun, Kan Chen, and Ram Nevatia. TURN TAP: temporal unit regression network for temporal action proposals. In ICCV, pages 3648\u20133656, 2017.", "[23] Chuming Lin, Jian Li, Yabiao Wang, Ying Tai, Donghao Luo, Zhipeng Cui, Chengjie Wang, Jilin Li, Feiyue Huang, and Rongrong Ji. Fast learning of temporal action proposal via dense boundary generator. In AAAI, pages 11499\u201311506. AAAI Press, 2020.", "[24] Tianwei Lin, Xiao Liu, Xin Li, Errui Ding, and Shilei Wen. BMN: boundary-matching network for temporal action proposal generation. In ICCV, pages 3888\u20133897, 2019.", "[26] Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, and Ming Yang. BSN: boundary sensitive network for temporal action proposal generation. In ECCV, pages 3\u201321, 2018."]}, {"table": "<table><thead><tr><th>Method</th><th>0.95</th><th>0.75</th><th>0.5</th><th>Average</th></tr></thead><tbody><tr><td>SCC [17]</td><td>4.70</td><td>17.90</td><td>40.00</td><td>21.70</td></tr><tr><td>CDC [32]</td><td>0.21</td><td>25.88</td><td>43.83</td><td>22.77</td></tr><tr><td>SSN [48]</td><td>5.49</td><td>23.48</td><td>39.12</td><td>23.98</td></tr><tr><td>Lin et al.[25]</td><td>7.09</td><td>29.65</td><td>44.39</td><td>29.17</td></tr><tr><td>BSN [26]</td><td>8.02</td><td>29.96</td><td>46.45</td><td>30.03</td></tr><tr><td>BMN [24]</td><td>8.29</td><td>34.78</td><td>50.07</td><td>33.85</td></tr><tr><td>RTD-Net</td><td>8.61</td><td>30.68</td><td>47.21</td><td>30.83</td></tr></tbody></table>", "caption": "Table 8: Temporal action detection results on the validation set of ActivityNet-1.3 in terms of mAP at different tIoU thresholds. Proposals are combined with the classifier of UntrimmedNet [39].", "list_citation_info": ["[32] Zheng Shou, Jonathan Chan, Alireza Zareian, Kazuyuki Miyazawa, and Shih-Fu Chang. CDC: convolutional-de-convolutional networks for precise temporal action localization in untrimmed videos. In CVPR, pages 1417\u20131426, 2017.", "[39] Limin Wang, Yuanjun Xiong, Dahua Lin, and Luc Van Gool. Untrimmednets for weakly supervised action recognition and detection. In CVPR, pages 6402\u20136411, 2017.", "[48] Yue Zhao, Yuanjun Xiong, Limin Wang, Zhirong Wu, Xiaoou Tang, and Dahua Lin. Temporal action detection with structured segment networks. In ICCV, pages 2933\u20132942, 2017.", "[17] Fabian Caba Heilbron, Wayner Barrios, Victor Escorcia, and Bernard Ghanem. SCC: semantic context cascade for efficient action detection. In CVPR, pages 3175\u20133184, 2017.", "[25] Tianwei Lin, Xu Zhao, and Zheng Shou. Temporal convolution based action proposal: Submission to activitynet 2017. CoRR, abs/1707.06750, 2017.", "[24] Tianwei Lin, Xiao Liu, Xin Li, Errui Ding, and Shilei Wen. BMN: boundary-matching network for temporal action proposal generation. In ICCV, pages 3888\u20133897, 2019.", "[26] Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, and Ming Yang. BSN: boundary sensitive network for temporal action proposal generation. In ECCV, pages 3\u201321, 2018."]}, {"table": "<table><thead><tr><th>Method</th><th>TAG+NMS [48]</th><th>BSN+SNMS [26]</th><th>RTD-Net</th></tr></thead><tbody><tr><td>AR@1 (val)</td><td>-</td><td>-</td><td>16.34</td></tr><tr><td>AR@100 (val)</td><td>55.88</td><td>63.62</td><td>61.11</td></tr><tr><td>AUC (val)</td><td>49.15</td><td>53.41</td><td>53.41</td></tr></tbody></table>", "caption": "Table J: Comparison with other state-of-the-art proposal generation methods on validation set of HACS Segments in terms of AR@AN and AUC. Among them, only RTD-Net is free of NMS.", "list_citation_info": ["[48] Yue Zhao, Yuanjun Xiong, Limin Wang, Zhirong Wu, Xiaoou Tang, and Dahua Lin. Temporal action detection with structured segment networks. In ICCV, pages 2933\u20132942, 2017.", "[26] Tianwei Lin, Xu Zhao, Haisheng Su, Chongjing Wang, and Ming Yang. BSN: boundary sensitive network for temporal action proposal generation. In ECCV, pages 3\u201321, 2018."]}]}