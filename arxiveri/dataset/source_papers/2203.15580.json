{"title": "Learning a structured latent space for unsupervised point cloud completion", "abstract": "Unsupervised point cloud completion aims at estimating the corresponding complete point cloud of a partial point cloud in an unpaired manner. It is a crucial but challenging problem since there is no paired partial-complete supervision that can be exploited directly. In this work, we propose a novel framework, which learns a unified and structured latent space that encoding both partial and complete point clouds. Specifically, we map a series of related partial point clouds into multiple complete shape and occlusion code pairs and fuse the codes to obtain their representations in the unified latent space. To enforce the learning of such a structured latent space, the proposed method adopts a series of constraints including structured ranking regularization, latent code swapping constraint, and distribution supervision on the related partial point clouds. By establishing such a unified and structured latent space, better partial-complete geometry consistency and shape completion accuracy can be achieved. Extensive experiments show that our proposed method consistently outperforms state-of-the-art unsupervised methods on both synthetic ShapeNet and real-world KITTI, ScanNet, and Matterport3D datasets.", "authors": ["Yingjie Cai", " Kwan-Yee Lin", " Chao Zhang", " Qiang Wang", " Xiaogang Wang", " Hongsheng Li"], "pdf_url": "https://arxiv.org/abs/2203.15580", "list_table_and_caption": [{"table": "<table><tr><td>Methods</td><td>Plane</td><td>Cabinet</td><td>Car</td><td>Chair</td><td>Lamp</td><td>Sofa</td><td>Table</td><td>Boat</td><td>Average</td></tr><tr><td>Pcl2pcl [6]</td><td>9.7/89.1</td><td>27.1/68.4</td><td>15.8/80.8</td><td>26.9/70.4</td><td>25.7/70.4</td><td>34.1/58.4</td><td>23.6/79.0</td><td>15.7/77.8</td><td>22.4/74.2</td></tr><tr><td>Cycle. [41]</td><td>5.2/94.0</td><td>14.7/82.1</td><td>12.4/82.1</td><td>18.0/77.5</td><td>17.3/77.4</td><td>21.0/75.2</td><td>18.9/81.2</td><td>11.5/84.8</td><td>14.9/81.8</td></tr><tr><td>Inversion. [52]</td><td>5.6/94.3</td><td>16.1/77.2</td><td>13.0/85.8</td><td>15.4/81.2</td><td>18.0/81.7</td><td>24.6/78.4</td><td>16.2/85.5</td><td>10.1/87.0</td><td>14.9/83.9</td></tr><tr><td>Ours</td><td>3.9/95.9</td><td>13.5/83.3</td><td>8.7/90.4</td><td>13.9/82.3</td><td>15.8/81.0</td><td>14.8/81.6</td><td>17.1/82.6</td><td>10.0/87.6</td><td>12.2/85.6</td></tr></table>", "caption": "Table 1: Shape completion performance on CRN benchmark. The numbers shown are [CD\\downarrow /F1\\uparrow], where CD is scaled by 10^{4}.", "list_citation_info": ["[41] Xin Wen, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, and Yu-Shen Liu. Cycle4completion: Unpaired point cloud completion using cycle transformation with missing region coding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13080\u201313089, 2021.", "[52] Junzhe Zhang, Xinyi Chen, Zhongang Cai, Liang Pan, Haiyu Zhao, Shuai Yi, Chai Kiat Yeo, Bo Dai, and Chen Change Loy. Unsupervised 3d shape completion through gan inversion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1768\u20131777, 2021.", "[6] Xuelin Chen, Baoquan Chen, and Niloy J Mitra. Unpaired point cloud completion on real scans using adversarial training. arXiv preprint arXiv:1904.00069, 2019."]}, {"table": "<table><tr><td>Methods</td><td>Plane</td><td>Cabinet</td><td>Car</td><td>Chair</td><td>Lamp</td><td>Sofa</td><td>Table</td><td>Boat</td><td>Average</td></tr><tr><td>Pcl2pcl [6]</td><td>4.0/\u2013</td><td>19.0/\u2013</td><td>10.0/\u2013</td><td>20.0/\u2013</td><td>23.0/\u2013</td><td>26.0/\u2013</td><td>26.0/\u2013</td><td>11.0/\u2013</td><td>17.4/\u2013</td></tr><tr><td>Cycle. [41]</td><td>3.7/96.4</td><td>12.6/87.1</td><td>8.1/91.8</td><td>14.6/84.2</td><td>18.2/80.6</td><td>26.2/71.7</td><td>22.5/82.7</td><td>8.7/89.8</td><td>14.3/85.5</td></tr><tr><td>Inversion. [52]</td><td>4.3/96.2</td><td>20.7/79.4</td><td>11.9/86.0</td><td>20.6/81.1</td><td>25.9/78.4</td><td>54.8/74.7</td><td>38.0/80.2</td><td>12.8/85.2</td><td>23.6/82.7</td></tr><tr><td>Ours</td><td>3.5/96.8</td><td>12.2/86.4</td><td>9.0/88.4</td><td>12.1/86.4</td><td>17.6/81.6</td><td>26.0/75.5</td><td>19.8/85.5</td><td>8.6/89.8</td><td>13.6/86.3</td></tr></table>", "caption": "Table 2: Shape completion performance on 3D-EPN benchmark. The numbers shown are [CD\\downarrow /F1\\uparrow], where CD is scaled by 10^{4}.", "list_citation_info": ["[41] Xin Wen, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, and Yu-Shen Liu. Cycle4completion: Unpaired point cloud completion using cycle transformation with missing region coding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13080\u201313089, 2021.", "[52] Junzhe Zhang, Xinyi Chen, Zhongang Cai, Liang Pan, Haiyu Zhao, Shuai Yi, Chai Kiat Yeo, Bo Dai, and Chen Change Loy. Unsupervised 3d shape completion through gan inversion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1768\u20131777, 2021.", "[6] Xuelin Chen, Baoquan Chen, and Niloy J Mitra. Unpaired point cloud completion on real scans using adversarial training. arXiv preprint arXiv:1904.00069, 2019."]}, {"table": "<table><tr><td>Methods</td><td>Chair</td><td>Lamp</td><td>Table</td><td>Average</td></tr><tr><td>Pcl2pcl [6]</td><td>1.90</td><td>2.50</td><td>1.90</td><td>2.10</td></tr><tr><td>MPC [44]</td><td>1.52</td><td>1.97</td><td>1.46</td><td>1.65</td></tr><tr><td>Cycle. [41]</td><td>1.71</td><td>3.46</td><td>1.56</td><td>2.24</td></tr><tr><td>Inversion. [52]</td><td>1.68</td><td>2.54</td><td>1.74</td><td>1.98</td></tr><tr><td>Ours</td><td>1.43</td><td>1.95</td><td>1.37</td><td>1.58</td></tr></table>", "caption": "Table 3: Shape completion performance on PartNet benchmark. We evaluate the results with MMD\\downarrow, which is scaled by 10^{2}.", "list_citation_info": ["[41] Xin Wen, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, and Yu-Shen Liu. Cycle4completion: Unpaired point cloud completion using cycle transformation with missing region coding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13080\u201313089, 2021.", "[52] Junzhe Zhang, Xinyi Chen, Zhongang Cai, Liang Pan, Haiyu Zhao, Shuai Yi, Chai Kiat Yeo, Bo Dai, and Chen Change Loy. Unsupervised 3d shape completion through gan inversion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1768\u20131777, 2021.", "[44] Rundi Wu, Xuelin Chen, Yixin Zhuang, and Baoquan Chen. Multimodal shape completion via conditional generative adversarial networks. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part IV 16, pages 281\u2013296. Springer, 2020.", "[6] Xuelin Chen, Baoquan Chen, and Niloy J Mitra. Unpaired point cloud completion on real scans using adversarial training. arXiv preprint arXiv:1904.00069, 2019."]}, {"table": "<table><tr><td rowspan=\"2\">Methods</td><td rowspan=\"2\">sup.</td><td colspan=\"2\">ScanNet</td><td colspan=\"2\">MatterPort3D</td><td>KITTI</td></tr><tr><td>Chair</td><td>Table</td><td>Chair</td><td>Table</td><td>Car</td></tr><tr><td>GRNet [48]</td><td>yes</td><td>1.6</td><td>1.6</td><td>1.6</td><td>1.5</td><td>2.2</td></tr><tr><td>PoinTr [50]</td><td>yes</td><td>1.7</td><td>1.5</td><td>1.8</td><td>1.3</td><td>1.9</td></tr><tr><td>Pcl2pcl [6]</td><td>no</td><td>17.3</td><td>9.1</td><td>15.9</td><td>6.0</td><td>9.2</td></tr><tr><td>Cycle. [41]</td><td>no</td><td>9.4</td><td>4.3</td><td>4.9</td><td>4.9</td><td>9.4</td></tr><tr><td>Inversion. [52]</td><td>no</td><td>3.2</td><td>3.3</td><td>3.6</td><td>3.1</td><td>2.9</td></tr><tr><td>Ours</td><td>no</td><td>3.2</td><td>2.7</td><td>3.3</td><td>2.7</td><td>4.2</td></tr><tr><td>Ours + Inversion</td><td>no</td><td>1.1</td><td>0.87</td><td>1.1</td><td>0.87</td><td>0.76</td></tr></table>", "caption": "Table 4: Shape completion performance on the real scans. The results are evaluated by UCD\\downarrow, where UCD is scaled by 10^{4}. sup.: supervised methods.", "list_citation_info": ["[50] Xumin Yu, Yongming Rao, Ziyi Wang, Zuyan Liu, Jiwen Lu, and Jie Zhou. Pointr: Diverse point cloud completion with geometry-aware transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 12498\u201312507, 2021.", "[48] Haozhe Xie, Hongxun Yao, Shangchen Zhou, Jiageng Mao, Shengping Zhang, and Wenxiu Sun. Grnet: Gridding residual network for dense point cloud completion. In European Conference on Computer Vision, pages 365\u2013381. Springer, 2020.", "[6] Xuelin Chen, Baoquan Chen, and Niloy J Mitra. Unpaired point cloud completion on real scans using adversarial training. arXiv preprint arXiv:1904.00069, 2019.", "[41] Xin Wen, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, and Yu-Shen Liu. Cycle4completion: Unpaired point cloud completion using cycle transformation with missing region coding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13080\u201313089, 2021.", "[52] Junzhe Zhang, Xinyi Chen, Zhongang Cai, Liang Pan, Haiyu Zhao, Shuai Yi, Chai Kiat Yeo, Bo Dai, and Chen Change Loy. Unsupervised 3d shape completion through gan inversion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1768\u20131777, 2021."]}, {"table": "<table><tr><td rowspan=\"2\">Methods</td><td rowspan=\"2\">sup.</td><td colspan=\"2\">ScanNet</td><td colspan=\"2\">MatterPort3D</td><td>KITTI</td></tr><tr><td>Chair</td><td>Table</td><td>Chair</td><td>Table</td><td>Car</td></tr><tr><td>GRNet [48]</td><td>yes</td><td>6.070</td><td>6.302</td><td>6.147</td><td>6.911</td><td>2.845</td></tr><tr><td>PoinTr [50]</td><td>yes</td><td>6.001</td><td>6.089</td><td>6.248</td><td>6.648</td><td>2.790</td></tr><tr><td>Cycle. [41]</td><td>no</td><td>6.278</td><td>5.727</td><td>6.022</td><td>6.535</td><td>3.033</td></tr><tr><td>Inversion. [52]</td><td>no</td><td>6.370</td><td>6.222</td><td>6.360</td><td>7.110</td><td>2.850</td></tr><tr><td>Ours</td><td>no</td><td>5.893</td><td>5.541</td><td>5.770</td><td>6.076</td><td>2.742</td></tr></table>", "caption": "Table 5: Shape completion performance on the real scans. We evaluate the results with MMD\\downarrow, where MMD is scaled by 10^{2}. sup.: supervised methods.", "list_citation_info": ["[50] Xumin Yu, Yongming Rao, Ziyi Wang, Zuyan Liu, Jiwen Lu, and Jie Zhou. Pointr: Diverse point cloud completion with geometry-aware transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 12498\u201312507, 2021.", "[41] Xin Wen, Zhizhong Han, Yan-Pei Cao, Pengfei Wan, Wen Zheng, and Yu-Shen Liu. Cycle4completion: Unpaired point cloud completion using cycle transformation with missing region coding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13080\u201313089, 2021.", "[48] Haozhe Xie, Hongxun Yao, Shangchen Zhou, Jiageng Mao, Shengping Zhang, and Wenxiu Sun. Grnet: Gridding residual network for dense point cloud completion. In European Conference on Computer Vision, pages 365\u2013381. Springer, 2020.", "[52] Junzhe Zhang, Xinyi Chen, Zhongang Cai, Liang Pan, Haiyu Zhao, Shuai Yi, Chai Kiat Yeo, Bo Dai, and Chen Change Loy. Unsupervised 3d shape completion through gan inversion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1768\u20131777, 2021."]}]}