{"title": "LAION-5B: An open large-scale dataset for training next generation image-text models", "abstract": "Groundbreaking language-vision architectures like CLIP and DALL-E proved the utility of training on large amounts of noisy image-text data, without relying on expensive accurate labels used in standard vision unimodal supervised learning. The resulting models showed capabilities of strong text-guided image generation and transfer to downstream tasks, while performing remarkably at zero-shot classification with noteworthy out-of-distribution robustness. Since then, large-scale language-vision models like ALIGN, BASIC, GLIDE, Flamingo and Imagen made further improvements. Studying the training and capabilities of such models requires datasets containing billions of image-text pairs. Until now, no datasets of this size have been made openly available for the broader research community. To address this problem and democratize research on large-scale multi-modal models, we present LAION-5B - a dataset consisting of 5.85 billion CLIP-filtered image-text pairs, of which 2.32B contain English language. We show successful replication and fine-tuning of foundational models like CLIP, GLIDE and Stable Diffusion using the dataset, and discuss further experiments enabled with an openly available dataset of this scale. Additionally we provide several nearest neighbor indices, an improved web-interface for dataset exploration and subset generation, and detection scores for watermark, NSFW, and toxic content detection. Announcement page https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/", "authors": ["Christoph Schuhmann", " Romain Beaumont", " Richard Vencu", " Cade Gordon", " Ross Wightman", " Mehdi Cherti", " Theo Coombes", " Aarush Katta", " Clayton Mullis", " Mitchell Wortsman", " Patrick Schramowski", " Srivatsa Kundurthy", " Katherine Crowson", " Ludwig Schmidt", " Robert Kaczmarczyk", " Jenia Jitsev"], "pdf_url": "https://arxiv.org/abs/2210.08402", "list_table_and_caption": [{"table": "<table><tbody><tr><th>Model</th><th>Pre-training</th><td>  <p>INet</p></td><td>  <p>INet-v2</p></td><td>  <p>INet-R</p></td><td>  <p>INet-S</p></td><td>  <p>ObjNet</p></td><td>  <p>VTAB+</p></td></tr><tr><th>B/32</th><th>CLIP WIT</th><td>63.3</td><td>56.0</td><td>69.4</td><td>42.3</td><td>44.2</td><td>45.4</td></tr><tr><th></th><th>LAION-400M</th><td>{62.9}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.4}}</td><td>{55.1}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.9}}</td><td>{73.4}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.0}}</td><td>{49.4}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+7.1}}</td><td>{43.9}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.3}}</td><td>{45.6}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.2}}</td></tr><tr><th></th><th>LAION-2B-en</th><td>{65.7}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+2.4}}</td><td>{57.4}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.4}}</td><td>{75.9}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+6.5}}</td><td>{52.9}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+10.6}}</td><td>{48.7}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.5}}</td><td>{47.9}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+2.5}}</td></tr><tr><th>B/16</th><th>CLIP WIT</th><td>68.3</td><td>61.9</td><td>77.7</td><td>48.2</td><td>55.3</td><td>47.5</td></tr><tr><th></th><th>LAION-400M</th><td>{67.0}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.3}}</td><td>{59.6}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.3}}</td><td>{77.9}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.2}}</td><td>{52.4}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.2}}</td><td>{51.5}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.8}}</td><td>{48.3}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.8}}</td></tr><tr><th>B/16+</th><th>LAION-400M</th><td>69.2</td><td>61.5</td><td>80.5</td><td>54.4</td><td>53.9</td><td>49.2</td></tr><tr><th>L/14</th><th>CLIP WIT</th><td>75.6</td><td>69.8</td><td>87.9</td><td>59.6</td><td>69.0</td><td>55.7</td></tr><tr><th></th><th>LAION-400M</th><td>{72.8}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.8}}</td><td>{65.4}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-4.4}}</td><td>{84.7}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.2}}</td><td>59.6</td><td>{59.9}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-9.1}}</td><td>{51.8}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.9}}</td></tr><tr><th></th><th>LAION-2B-en</th><td>{\\color[rgb]{0,0,0}{75.2}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.3}}</td><td>{\\color[rgb]{0,0,0}{67.7}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.0}}</td><td>{\\color[rgb]{0,0,0}{87.4}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.5}}</td><td>{\\color[rgb]{0,0,0}{63.3}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+3.7}}</td><td>{\\color[rgb]{0,0,0}{65.5}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.6}}</td><td>{\\color[rgb]{0,0,0}{54.6}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.2}}</td></tr></tbody></table>", "caption": "Table 1: Comparison between CLIP models trained on LAION (400M, 2B) and the original CLIP models [58] trained on OpenAI\u2019s WebImageText (WIT) dataset. We show zero-shot top-1 classification accuracy (%) on various datasets including ImageNet, four ImageNet distribution shift datasets, and a benchmark we call VTAB+, where we average performance over 35 tasks. See Appendix E.3for more details about the datasets used for evaluation and the results.", "list_citation_info": ["Radford et al. [2021b] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, pages 8748\u20138763. PMLR, 2021b."]}, {"table": "<table><thead><tr><th>Model (data size)</th><th>BS. (global)</th><th>#GPUs</th><th>LR.</th><th>Warm.</th><th>Ep.</th><th>Time (hrs.)</th></tr></thead><tbody><tr><td>B/32 (400M)</td><td>256 (32768)</td><td>128</td><td>5\\text{e-}4</td><td>2K</td><td>32</td><td>36</td></tr><tr><td>B/32 (2B)</td><td>416 (46592)</td><td>112</td><td>5.5\\text{e-}4</td><td>10K</td><td>16</td><td>210</td></tr><tr><td>B/16 (400M)</td><td>192 (33792)</td><td>176</td><td>5\\text{e-}4</td><td>2K</td><td>32</td><td>61</td></tr><tr><td>B/16+(400M)</td><td>160 (35840)</td><td>224</td><td>7\\text{e-}4</td><td>5K</td><td>32</td><td>61</td></tr><tr><td>L/14 (400M)</td><td>96 (38400)</td><td>400</td><td>6\\text{e-}4</td><td>5K</td><td>32</td><td>88</td></tr></tbody></table>", "caption": "Table 3: Training hyper-parameters and resources used to reproduce CLIP [58] models on LAION 400M and 2B subsets. Note that BS refer to batch size per GPU worker (with global the corresponding global batch size), LR to base learning rate, Warm to the total number of warmup steps, Ep to the total number of training epochs, and Time to total training time in hours.", "list_citation_info": ["Radford et al. [2021b] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, pages 8748\u20138763. PMLR, 2021b."]}, {"table": "<table><thead><tr><th></th><th colspan=\"3\">B/32</th><th colspan=\"2\">B/16</th><th>B/16+</th><th colspan=\"2\">L/14</th></tr><tr><th>Dataset</th><th>CLIP WIT</th><th>LAION-400M</th><th>LAION-2B</th><th>CLIP WIT</th><th>LAION-400M</th><th>LAION-400M</th><th>CLIP WIT</th><th>LAION-400M</th></tr></thead><tbody><tr><td>INet</td><td>63.3</td><td>{\\color[rgb]{0,0,0}{62.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.4}}</td><td>{\\color[rgb]{0,0,0}{65.7}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+2.4}}</td><td>68.3</td><td>{\\color[rgb]{0,0,0}{67.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.3}}</td><td>69.2</td><td>75.6</td><td>{\\color[rgb]{0,0,0}{72.8}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.8}}</td></tr><tr><td>INet-v2</td><td>56.0</td><td>{\\color[rgb]{0,0,0}{55.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.9}}</td><td>{\\color[rgb]{0,0,0}{57.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.4}}</td><td>61.9</td><td>{\\color[rgb]{0,0,0}{59.6}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.3}}</td><td>61.5</td><td>69.8</td><td>{\\color[rgb]{0,0,0}{65.4}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-4.4}}</td></tr><tr><td>INet-R</td><td>69.4</td><td>{\\color[rgb]{0,0,0}{73.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.0}}</td><td>{\\color[rgb]{0,0,0}{75.9}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+6.5}}</td><td>77.7</td><td>{\\color[rgb]{0,0,0}{77.9}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.2}}</td><td>80.5</td><td>87.9</td><td>{\\color[rgb]{0,0,0}{84.7}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.2}}</td></tr><tr><td>INet-S</td><td>42.3</td><td>{\\color[rgb]{0,0,0}{49.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+7.1}}</td><td>{\\color[rgb]{0,0,0}{52.9}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+10.6}}</td><td>48.2</td><td>{\\color[rgb]{0,0,0}{52.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.2}}</td><td>54.4</td><td>59.6</td><td>59.6</td></tr><tr><td>ObjNet</td><td>44.2</td><td>{\\color[rgb]{0,0,0}{43.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.3}}</td><td>{\\color[rgb]{0,0,0}{48.7}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.5}}</td><td>55.3</td><td>{\\color[rgb]{0,0,0}{51.5}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.8}}</td><td>53.9</td><td>69.0</td><td>{\\color[rgb]{0,0,0}{59.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-9.1}}</td></tr><tr><td>INet-A</td><td>31.6</td><td>{\\color[rgb]{0,0,0}{21.7}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-9.9}}</td><td>{\\color[rgb]{0,0,0}{26.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-5.5}}</td><td>49.9</td><td>{\\color[rgb]{0,0,0}{33.2}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-16.7}}</td><td>36.9</td><td>70.8</td><td>{\\color[rgb]{0,0,0}{46.5}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-24.3}}</td></tr><tr><td>CIFAR-10</td><td>89.8</td><td>{\\color[rgb]{0,0,0}{90.7}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.9}}</td><td>{\\color[rgb]{0,0,0}{94.0}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.2}}</td><td>90.8</td><td>{\\color[rgb]{0,0,0}{91.7}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.9}}</td><td>92.7</td><td>95.6</td><td>{\\color[rgb]{0,0,0}{94.6}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.0}}</td></tr><tr><td>CIFAR-100</td><td>64.2</td><td>{\\color[rgb]{0,0,0}{70.3}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+6.1}}</td><td>{\\color[rgb]{0,0,0}{75.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+11.2}}</td><td>66.9</td><td>{\\color[rgb]{0,0,0}{71.2}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.3}}</td><td>73.8</td><td>75.9</td><td>{\\color[rgb]{0,0,0}{77.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.5}}</td></tr><tr><td>MNIST</td><td>48.2</td><td>{\\color[rgb]{0,0,0}{37.4}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-10.8}}</td><td>{\\color[rgb]{0,0,0}{63.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+15.2}}</td><td>51.8</td><td>{\\color[rgb]{0,0,0}{66.3}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+14.5}}</td><td>57.0</td><td>76.4</td><td>{\\color[rgb]{0,0,0}{76.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.4}}</td></tr><tr><td>Flowers102</td><td>66.5</td><td>{\\color[rgb]{0,0,0}{68.1}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.6}}</td><td>{\\color[rgb]{0,0,0}{69.0}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+2.5}}</td><td>71.2</td><td>{\\color[rgb]{0,0,0}{69.3}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.9}}</td><td>71.1</td><td>79.2</td><td>{\\color[rgb]{0,0,0}{75.6}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.6}}</td></tr><tr><td>Cars</td><td>59.6</td><td>{\\color[rgb]{0,0,0}{79.3}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+19.7}}</td><td>{\\color[rgb]{0,0,0}{84.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+24.8}}</td><td>64.7</td><td>{\\color[rgb]{0,0,0}{83.7}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+19.0}}</td><td>84.5</td><td>77.9</td><td>{\\color[rgb]{0,0,0}{89.6}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+11.7}}</td></tr><tr><td>SVHN</td><td>13.4</td><td>{\\color[rgb]{0,0,0}{27.7}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+14.3}}</td><td>{\\color[rgb]{0,0,0}{38.8}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+25.4}}</td><td>31.3</td><td>{\\color[rgb]{0,0,0}{38.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+7.2}}</td><td>36.2</td><td>57.0</td><td>{\\color[rgb]{0,0,0}{38.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-19.0}}</td></tr><tr><td>FER2013</td><td>41.4</td><td>{\\color[rgb]{0,0,0}{43.0}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.6}}</td><td>{\\color[rgb]{0,0,0}{48.1}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+6.7}}</td><td>46.3</td><td>{\\color[rgb]{0,0,0}{43.2}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.1}}</td><td>44.5</td><td>50.1</td><td>{\\color[rgb]{0,0,0}{50.3}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.2}}</td></tr><tr><td>RenderedSST2</td><td>58.6</td><td>{\\color[rgb]{0,0,0}{52.3}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-6.3}}</td><td>{\\color[rgb]{0,0,0}{54.3}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-4.3}}</td><td>60.5</td><td>{\\color[rgb]{0,0,0}{54.4}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-6.1}}</td><td>57.9</td><td>68.9</td><td>{\\color[rgb]{0,0,0}{56.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-12.9}}</td></tr><tr><td>Pets</td><td>87.3</td><td>{\\color[rgb]{0,0,0}{86.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.4}}</td><td>{\\color[rgb]{0,0,0}{89.2}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.9}}</td><td>89.0</td><td>{\\color[rgb]{0,0,0}{89.2}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.2}}</td><td>90.3</td><td>93.3</td><td>{\\color[rgb]{0,0,0}{91.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.4}}</td></tr><tr><td>Caltech-101</td><td>81.6</td><td>{\\color[rgb]{0,0,0}{83.2}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.6}}</td><td>{\\color[rgb]{0,0,0}{83.1}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.5}}</td><td>82.2</td><td>{\\color[rgb]{0,0,0}{83.6}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.4}}</td><td>83.2</td><td>83.3</td><td>{\\color[rgb]{0,0,0}{84.0}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.7}}</td></tr><tr><td>VOC2007-Cl</td><td>76.4</td><td>{\\color[rgb]{0,0,0}{75.8}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.6}}</td><td>{\\color[rgb]{0,0,0}{78.8}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+2.4}}</td><td>78.3</td><td>{\\color[rgb]{0,0,0}{76.8}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.5}}</td><td>76.4</td><td>78.3</td><td>{\\color[rgb]{0,0,0}{75.6}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.7}}</td></tr><tr><td>SUN397</td><td>62.5</td><td>{\\color[rgb]{0,0,0}{67.0}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.5}}</td><td>{\\color[rgb]{0,0,0}{68.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+6.0}}</td><td>64.4</td><td>{\\color[rgb]{0,0,0}{69.6}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+5.2}}</td><td>69.8</td><td>67.6</td><td>{\\color[rgb]{0,0,0}{72.6}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+5.0}}</td></tr><tr><td>FGVC Aircraft</td><td>19.6</td><td>{\\color[rgb]{0,0,0}{16.7}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.9}}</td><td>{\\color[rgb]{0,0,0}{23.1}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+3.5}}</td><td>24.3</td><td>{\\color[rgb]{0,0,0}{17.7}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-6.6}}</td><td>18.5</td><td>31.8</td><td>{\\color[rgb]{0,0,0}{25.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-6.8}}</td></tr><tr><td>Country211</td><td>17.2</td><td>{\\color[rgb]{0,0,0}{14.8}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.4}}</td><td>{\\color[rgb]{0,0,0}{16.5}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.7}}</td><td>22.8</td><td>{\\color[rgb]{0,0,0}{18.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-4.7}}</td><td>18.9</td><td>31.9</td><td>{\\color[rgb]{0,0,0}{23.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-8.9}}</td></tr><tr><td>DTD</td><td>44.3</td><td>{\\color[rgb]{0,0,0}{54.6}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+10.3}}</td><td>{\\color[rgb]{0,0,0}{53.9}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+9.6}}</td><td>44.9</td><td>{\\color[rgb]{0,0,0}{51.3}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+6.4}}</td><td>55.5</td><td>55.3</td><td>{\\color[rgb]{0,0,0}{60.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+5.2}}</td></tr><tr><td>GTSRB</td><td>32.6</td><td>{\\color[rgb]{0,0,0}{42.0}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+9.4}}</td><td>{\\color[rgb]{0,0,0}{36.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+3.9}}</td><td>43.3</td><td>{\\color[rgb]{0,0,0}{43.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.2}}</td><td>49.4</td><td>50.6</td><td>{\\color[rgb]{0,0,0}{49.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.7}}</td></tr><tr><td>STL10</td><td>97.1</td><td>{\\color[rgb]{0,0,0}{95.6}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.5}}</td><td>{\\color[rgb]{0,0,0}{96.5}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.6}}</td><td>98.2</td><td>{\\color[rgb]{0,0,0}{97.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.2}}</td><td>97.0</td><td>99.4</td><td>{\\color[rgb]{0,0,0}{98.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.3}}</td></tr><tr><td>Retino</td><td>45.5</td><td>{\\color[rgb]{0,0,0}{24.2}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-21.3}}</td><td>{\\color[rgb]{0,0,0}{19.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-26.4}}</td><td>3.3</td><td>{\\color[rgb]{0,0,0}{7.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.1}}</td><td>9.2</td><td>73.3</td><td>{\\color[rgb]{0,0,0}{6.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-67.3}}</td></tr><tr><td>EuroSAT</td><td>50.4</td><td>{\\color[rgb]{0,0,0}{51.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.1}}</td><td>{\\color[rgb]{0,0,0}{50.3}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.1}}</td><td>55.9</td><td>{\\color[rgb]{0,0,0}{50.3}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-5.6}}</td><td>58.2</td><td>62.6</td><td>{\\color[rgb]{0,0,0}{62.3}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.3}}</td></tr><tr><td>RESISC45</td><td>53.6</td><td>{\\color[rgb]{0,0,0}{54.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.9}}</td><td>{\\color[rgb]{0,0,0}{61.9}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+8.3}}</td><td>58.2</td><td>{\\color[rgb]{0,0,0}{58.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.3}}</td><td>61.4</td><td>63.4</td><td>{\\color[rgb]{0,0,0}{67.4}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.0}}</td></tr><tr><td>PCAM</td><td>62.3</td><td>{\\color[rgb]{0,0,0}{55.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-6.4}}</td><td>{\\color[rgb]{0,0,0}{50.7}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-11.6}}</td><td>50.7</td><td>{\\color[rgb]{0,0,0}{59.6}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+8.9}}</td><td>55.2</td><td>52.0</td><td>{\\color[rgb]{0,0,0}{49.6}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.4}}</td></tr><tr><td>CLEVR Counts</td><td>23.2</td><td>{\\color[rgb]{0,0,0}{16.2}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-7.0}}</td><td>{\\color[rgb]{0,0,0}{19.2}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-4.0}}</td><td>21.2</td><td>{\\color[rgb]{0,0,0}{28.7}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+7.5}}</td><td>23.9</td><td>19.4</td><td>{\\color[rgb]{0,0,0}{24.2}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+4.8}}</td></tr><tr><td>CLEVR Dist</td><td>16.3</td><td>{\\color[rgb]{0,0,0}{15.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.4}}</td><td>{\\color[rgb]{0,0,0}{16.8}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.5}}</td><td>15.8</td><td>{\\color[rgb]{0,0,0}{24.5}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+8.7}}</td><td>15.9</td><td>16.1</td><td>{\\color[rgb]{0,0,0}{14.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.2}}</td></tr><tr><td>DSPRITES Orient</td><td>2.4</td><td>{\\color[rgb]{0,0,0}{1.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.5}}</td><td>{\\color[rgb]{0,0,0}{2.3}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.1}}</td><td>2.3</td><td>{\\color[rgb]{0,0,0}{2.9}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.6}}</td><td>2.7</td><td>2.3</td><td>{\\color[rgb]{0,0,0}{2.6}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.3}}</td></tr><tr><td>DSPRITES pos</td><td>3.6</td><td>{\\color[rgb]{0,0,0}{2.8}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.8}}</td><td>{\\color[rgb]{0,0,0}{3.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.5}}</td><td>3.0</td><td>{\\color[rgb]{0,0,0}{3.2}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.2}}</td><td>4.3</td><td>3.2</td><td>{\\color[rgb]{0,0,0}{3.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.2}}</td></tr><tr><td>SmallNORB Elv</td><td>12.7</td><td>{\\color[rgb]{0,0,0}{9.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.8}}</td><td>{\\color[rgb]{0,0,0}{11.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.7}}</td><td>12.2</td><td>{\\color[rgb]{0,0,0}{10.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.2}}</td><td>11.0</td><td>11.5</td><td>{\\color[rgb]{0,0,0}{11.0}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.5}}</td></tr><tr><td>SmallNORB Azim</td><td>6.1</td><td>{\\color[rgb]{0,0,0}{4.5}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.6}}</td><td>{\\color[rgb]{0,0,0}{5.2}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.9}}</td><td>5.2</td><td>{\\color[rgb]{0,0,0}{6.0}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.8}}</td><td>5.5</td><td>4.5</td><td>{\\color[rgb]{0,0,0}{5.3}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.8}}</td></tr><tr><td>DMLAB</td><td>19.3</td><td>{\\color[rgb]{0,0,0}{17.3}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-2.0}}</td><td>{\\color[rgb]{0,0,0}{18.9}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.4}}</td><td>15.5</td><td>{\\color[rgb]{0,0,0}{15.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-0.4}}</td><td>14.8</td><td>16.3</td><td>{\\color[rgb]{0,0,0}{18.7}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+2.4}}</td></tr><tr><td>KITTI Dist</td><td>27.4</td><td>{\\color[rgb]{0,0,0}{28.8}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+1.4}}</td><td>{\\color[rgb]{0,0,0}{17.6}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-9.8}}</td><td>26.4</td><td>{\\color[rgb]{0,0,0}{18.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-8.3}}</td><td>28.1</td><td>21.8</td><td>{\\color[rgb]{0,0,0}{20.1}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-1.7}}</td></tr><tr><td>VTAB+(Avg.)</td><td>45.4</td><td>{\\color[rgb]{0,0,0}{45.6}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.2}}</td><td>{\\color[rgb]{0,0,0}{47.9}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+2.5}}</td><td>47.5</td><td>{\\color[rgb]{0,0,0}{48.3}}^{\\tiny\\color[rgb]{0,0.88,0}\\textbf{+0.8}}</td><td>49.2</td><td>55.7</td><td>{\\color[rgb]{0,0,0}{51.8}}^{\\tiny\\color[rgb]{1,0,0}\\textbf{-3.9}}</td></tr></tbody></table>", "caption": "Table 6: Comparison between CLIP models trained on LAION (400M, 2B) and the original CLIP models [58] trained on OpenAI\u2019s WebImageText (WIT) dataset. We show zero-shot top-1 classification accuracy (%) on the 35 datasets that are part of VTAB+. We highlight the difference (+/-) between LAION models and original CLIP WIT models for each model size (except B/16+, for which there is no CLIP WIT checkpoint).", "list_citation_info": ["Radford et al. [2021b] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, pages 8748\u20138763. PMLR, 2021b."]}]}