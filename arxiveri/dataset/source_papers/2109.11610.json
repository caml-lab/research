{"title": "Spnet: Multi-shell kernel convolution for point cloud semantic segmentation", "abstract": "Feature encoding is essential for point cloud analysis. In this paper, we propose a novel point convolution operator named Shell Point Convolution (SPConv) for shape encoding and local context learning. Specifically, SPConv splits 3D neighborhood space into shells, aggregates local features on manually designed kernel points, and performs convolution on the shells. Moreover, SPConv incorporates a simple yet effective attention module that enhances local feature aggregation. Based upon SPConv, a deep neural network named SPNet is constructed to process large-scale point clouds. Poisson disk sampling and feature propagation are incorporated in SPNet for better efficiency and accuracy. We provided details of the shell design and conducted extensive experiments on challenging large-scale point cloud datasets. Experimental results show that SPConv is effective in local shape encoding, and our SPNet is able to achieve top-ranking performances in semantic segmentation tasks.", "authors": ["Yuyan Li", " Chuanmao Fan", " Xu Wang", " Ye Duan"], "pdf_url": "https://arxiv.org/abs/2109.11610", "list_table_and_caption": [{"table": "<table><thead><tr><th><p>Methods</p></th><th><p>S3DIS(mIoU)</p></th><th><p>S3DIS(mIoU)</p></th><th><p>ScanNet</p></th></tr></thead><tbody><tr><td></td><th><p>Area5</p></th><th><p>6-fold</p></th><th><p>(OA)</p></th></tr><tr><td><p>PointNet [23]</p></td><td><p>41.1</p></td><td><p>47.6</p></td><td><p>-</p></td></tr><tr><td><p>PointNet++ [24]</p></td><td><p>-</p></td><td><p>54.5</p></td><td><p>84.5</p></td></tr><tr><td><p>DGCNN [26]</p></td><td><p>-</p></td><td><p>56.1</p></td><td><p>-</p></td></tr><tr><td><p>SPGraph [15]</p></td><td><p>58.0</p></td><td><p>62.1</p></td><td><p>-</p></td></tr><tr><td><p>ShellNet [36]</p></td><td><p>-</p></td><td><p>66.8</p></td><td><p>85.2</p></td></tr><tr><td><p>PointWeb [37]</p></td><td><p>60.3</p></td><td><p>66.7</p></td><td><p>85.9</p></td></tr><tr><td><p>GACNet [30]</p></td><td><p>62.9</p></td><td><p>-</p></td><td><p>-</p></td></tr><tr><td><p>RandLA-Net [11]</p></td><td><p>-</p></td><td><p>68.5</p></td><td><p>-</p></td></tr><tr><td><p>SPH3D-GCN [17]</p></td><td><p>59.5</p></td><td><p>68.9</p></td><td><p>-</p></td></tr><tr><td><p>Point2Node [7]</p></td><td><p>63.0</p></td><td><p>70.0</p></td><td><p>86.3</p></td></tr><tr><td><p>KPConv(R) [29]</p></td><td><p>65.4</p></td><td><p>69.6</p></td><td><p>-</p></td></tr><tr><td><p>KPConv(D) [29]</p></td><td><p>67.1</p></td><td><p>70.6</p></td><td><p>-</p></td></tr><tr><td><p>Minkowski [2]</p></td><td><p>65.4</p></td><td><p>-</p></td><td><p>-</p></td></tr><tr><td>Ours</td><td>69.9</td><td>73.7</td><td>89.5</td></tr></tbody></table>", "caption": "Table 1: Comparative 3D scene segmentation scores on S3DIS [1], ScanNet [3] datasets. S3DIS [1] scores are reported in metric of mean Intersection over Union(mIoU) including Area5 and 6-fold cross validation. ScanNet [3] scores are reported as Overall Accuracy(OA) and mIoU. The symbol {}^{\\prime}-^{\\prime} means the results are not available.", "list_citation_info": ["[23] Qi, C.R., Su, H., Mo, K., Guibas, L.J.: Pointnet: Deep learning on point sets for 3d classification and segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 652\u2013660 (2017)", "[3] Dai, A., Chang, A.X., Savva, M., Halber, M., Funkhouser, T., Nie\u00dfner, M.: Scannet: Richly-annotated 3d reconstructions of indoor scenes. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 5828\u20135839 (2017)", "[1] Armeni, I., Sax, S., Zamir, A.R., Savarese, S.: Joint 2d-3d-semantic data for indoor scene understanding. arXiv preprint arXiv:1702.01105 (2017)", "[7] Han, W., Wen, C., Wang, C., Li, X., Li, Q.: Point2node: Correlation learning of dynamic-node for point cloud feature modeling. arXiv preprint arXiv:1912.10775 (2019)", "[11] Hu, Q., Yang, B., Xie, L., Rosa, S., Guo, Y., Wang, Z., Trigoni, N., Markham, A.: Randla-net: Efficient semantic segmentation of large-scale point clouds. arXiv preprint arXiv:1911.11236 (2019)", "[15] Landrieu, L., Simonovsky, M.: Large-scale point cloud semantic segmentation with superpoint graphs. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4558\u20134567 (2018)", "[24] Qi, C.R., Yi, L., Su, H., Guibas, L.J.: Pointnet++: Deep hierarchical feature learning on point sets in a metric space. In: Advances in neural information processing systems. pp. 5099\u20135108 (2017)", "[2] Choy, C., Gwak, J., Savarese, S.: 4d spatio-temporal convnets: Minkowski convolutional neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 3075\u20133084 (2019)", "[17] Lei, H., Akhtar, N., Mian, A.: Spherical kernel for efficient graph convolution on 3d point clouds. arXiv preprint arXiv:1909.09287 (2019)", "[36] Zhang, Z., Hua, B.S., Yeung, S.K.: Shellnet: Efficient point cloud convolutional neural networks using concentric shells statistics. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 1607\u20131616 (2019)", "[30] Wang, L., Huang, Y., Hou, Y., Zhang, S., Shan, J.: Graph attention convolution for point cloud semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 10296\u201310305 (2019)", "[29] Thomas, H., Qi, C.R., Deschaud, J.E., Marcotegui, B., Goulette, F., Guibas, L.J.: Kpconv: Flexible and deformable convolution for point clouds. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 6411\u20136420 (2019)", "[26] Simonovsky, M., Komodakis, N.: Dynamic edge-conditioned filters in convolutional neural networks on graphs. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 3693\u20133702 (2017)", "[37] Zhao, H., Jiang, L., Fu, C.W., Jia, J.: Pointweb: Enhancing local neighborhood features for point cloud processing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 5565\u20135573 (2019)"]}, {"table": "<table><thead><tr><th><p>Method</p></th><th><p>mIoU</p></th><th><p>OA</p></th><th><p>ceil.</p></th><th><p>floor</p></th><th><p>wall</p></th><th><p>beam</p></th><th><p>col.</p></th><th><p>wind.</p></th><th><p>door</p></th><th><p>chair</p></th><th><p>table</p></th><th><p>book.</p></th><th><p>sofa</p></th><th><p>board</p></th><th><p>clut.  </p></th></tr></thead><tbody><tr><th><p>PointNet [23]</p></th><th><p>41.1</p></th><th><p>49.0</p></th><td><p>88.8</p></td><td><p>97.3</p></td><td><p>69.8</p></td><td><p>0.1</p></td><td><p>3.9</p></td><td><p>46.3</p></td><td><p>10.8</p></td><td><p>52.6</p></td><td><p>58.9</p></td><td><p>40.3</p></td><td><p>5.9</p></td><td><p>26.4</p></td><td><p>33.2  </p></td></tr><tr><th><p>PointWeb [37]</p></th><th><p>60.3</p></th><th><p>87.0</p></th><td><p>91.9</p></td><td><p>\\mathbf{98.5}</p></td><td><p>79.4</p></td><td><p>0.0</p></td><td><p>21.1</p></td><td><p>59.7</p></td><td><p>34.8</p></td><td><p>76.3</p></td><td><p>88.3</p></td><td><p>46.9</p></td><td><p>69.3</p></td><td><p>64.9</p></td><td><p>52.5</p></td></tr><tr><th><p>Point2Node [7]</p></th><th><p>62.9</p></th><th><p>88.8</p></th><td><p>93.8</p></td><td><p>98.3</p></td><td><p>83.3</p></td><td><p>0.0</p></td><td><p>35.6</p></td><td><p>55.3</p></td><td><p>58.8</p></td><td><p>79.5</p></td><td><p>84.7</p></td><td><p>44.1</p></td><td><p>71.1</p></td><td><p>58.7</p></td><td><p>55.2</p></td></tr><tr><th><p>KPConv(R) [29]</p></th><th><p>65.4</p></th><th><p>-</p></th><td><p>92.6</p></td><td><p>97.3</p></td><td><p>81.4</p></td><td><p>0.0</p></td><td><p>16.5</p></td><td><p>54.5</p></td><td><p>69.5</p></td><td><p>90.1</p></td><td><p>80.2</p></td><td><p>74.6</p></td><td><p>66.4</p></td><td><p>63.7</p></td><td><p>58.1  </p></td></tr><tr><th><p>KPConv(D) [29]</p></th><th><p>67.1</p></th><th><p>-</p></th><td><p>92.8</p></td><td><p>97.3</p></td><td><p>82.4</p></td><td><p>0.0</p></td><td><p>23.9</p></td><td><p>58.0</p></td><td><p>69.0</p></td><td><p>\\mathbf{91.0}</p></td><td><p>\\mathbf{81.5}</p></td><td><p>\\mathbf{75.3}</p></td><td><p>75.4</p></td><td><p>66.7</p></td><td><p>58.9  </p></td></tr><tr><th>Ours</th><th><p>\\mathbf{69.9}</p></th><th><p>\\mathbf{90.3}</p></th><td><p>\\mathbf{94.5}</p></td><td><p>98.3</p></td><td><p>\\mathbf{84.0}</p></td><td><p>0.0</p></td><td><p>24.0</p></td><td><p>59.7</p></td><td><p>\\mathbf{79.8}</p></td><td><p>89.6</p></td><td><p>81.0</p></td><td><p>75.2</p></td><td><p>\\mathbf{82.4}</p></td><td><p>\\mathbf{80.4}</p></td><td><p>\\mathbf{60.4}</p></td></tr></tbody></table>", "caption": "Table 2: Semantic segmentation mIoU and OA scores on S3DIS [1] Area 5. ", "list_citation_info": ["[23] Qi, C.R., Su, H., Mo, K., Guibas, L.J.: Pointnet: Deep learning on point sets for 3d classification and segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 652\u2013660 (2017)", "[1] Armeni, I., Sax, S., Zamir, A.R., Savarese, S.: Joint 2d-3d-semantic data for indoor scene understanding. arXiv preprint arXiv:1702.01105 (2017)", "[7] Han, W., Wen, C., Wang, C., Li, X., Li, Q.: Point2node: Correlation learning of dynamic-node for point cloud feature modeling. arXiv preprint arXiv:1912.10775 (2019)", "[29] Thomas, H., Qi, C.R., Deschaud, J.E., Marcotegui, B., Goulette, F., Guibas, L.J.: Kpconv: Flexible and deformable convolution for point clouds. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 6411\u20136420 (2019)", "[37] Zhao, H., Jiang, L., Fu, C.W., Jia, J.: Pointweb: Enhancing local neighborhood features for point cloud processing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 5565\u20135573 (2019)"]}, {"table": "<table><thead><tr><th><p>Method</p></th><th><p>mIoU</p></th><th><p>OA</p></th><th><p>ceil.</p></th><th><p>floor</p></th><th><p>wall</p></th><th><p>beam</p></th><th><p>col.</p></th><th><p>wind.</p></th><th><p>door</p></th><th><p>chair</p></th><th><p>table</p></th><th><p>book.</p></th><th><p>sofa</p></th><th><p>board</p></th><th><p>clut.  </p></th></tr></thead><tbody><tr><th><p>PointNet [23]</p></th><th><p>47.8</p></th><th><p>78.5</p></th><td><p>88.0</p></td><td><p>88.7</p></td><td><p>69.3</p></td><td><p>42.4</p></td><td><p>23.1</p></td><td><p>47.5</p></td><td><p>51.6</p></td><td><p>54.1</p></td><td><p>42.0</p></td><td><p>9.6</p></td><td><p>38.2</p></td><td><p>29.4</p></td><td><p>35.2  </p></td></tr><tr><th><p>SPGraph [15]</p></th><th><p>62.1</p></th><th><p>85.5</p></th><td><p>89.9</p></td><td><p>95.1</p></td><td><p>76.4</p></td><td><p>62.8</p></td><td><p>47.1</p></td><td><p>55.3</p></td><td><p>68.4</p></td><td><p>69.2</p></td><td><p>73.5</p></td><td><p>45.9</p></td><td><p>63.2</p></td><td><p>8.7</p></td><td><p>52.9</p></td></tr><tr><th><p>PointCNN [18]</p></th><th><p>65.4</p></th><th><p>88.1</p></th><td><p>\\mathbf{94.8}</p></td><td><p>\\mathbf{97.3}</p></td><td><p>75.8</p></td><td><p>63.3</p></td><td><p>51.7</p></td><td><p>58.4</p></td><td><p>57.2</p></td><td><p>69.1</p></td><td><p>71.6</p></td><td><p>61.2</p></td><td><p>39.1</p></td><td><p>52.2</p></td><td><p>58.6</p></td></tr><tr><th><p>PointWeb [37]</p></th><th><p>66.7</p></th><th><p>87.3</p></th><td><p>93.5</p></td><td><p>94.2</p></td><td><p>80.8</p></td><td><p>52.4</p></td><td><p>41.3</p></td><td><p>64.9</p></td><td><p>68.1</p></td><td><p>71.4</p></td><td><p>67.1</p></td><td><p>50.3</p></td><td><p>62.7</p></td><td><p>62.2</p></td><td><p>58.5</p></td></tr><tr><th><p>KPConv(R) [29]</p></th><th><p>69.6</p></th><th><p>-</p></th><td><p>93.7</p></td><td><p>92.0</p></td><td><p>82.5</p></td><td><p>62.5</p></td><td><p>49.5</p></td><td><p>65.7</p></td><td><p>\\mathbf{77.3}</p></td><td><p>57.8</p></td><td><p>64.0</p></td><td><p>68.8</p></td><td><p>71.7</p></td><td><p>60.1</p></td><td><p>59.6</p></td></tr><tr><th><p>Point2Node [7]</p></th><th><p>70.0</p></th><th><p>89.0</p></th><td><p>94.1</p></td><td><p>97.3</p></td><td><p>83.4</p></td><td><p>62.7</p></td><td><p>52.3</p></td><td><p>72.3</p></td><td><p>64.3</p></td><td><p>75.8</p></td><td><p>70.8</p></td><td><p>65.7</p></td><td><p>49.8</p></td><td><p>60.3</p></td><td><p>60.9</p></td></tr><tr><th><p>KPConv(D) [29]</p></th><th><p>70.6</p></th><th><p>-</p></th><td><p>93.6</p></td><td><p>92.4</p></td><td><p>83.1</p></td><td><p>63.9</p></td><td><p>54.3</p></td><td><p>66.1</p></td><td><p>76.6</p></td><td><p>57.8</p></td><td><p>64.0</p></td><td><p>69.3</p></td><td><p>\\mathbf{74.9}</p></td><td><p>61.3</p></td><td><p>60.3</p></td></tr><tr><th>Ours</th><th><p>\\mathbf{73.7}</p></th><th><p>\\mathbf{90.9}</p></th><td><p>94.6</p></td><td><p>\\mathbf{97.3}</p></td><td><p>\\mathbf{85.0}</p></td><td><p>45.2</p></td><td><p>56.9</p></td><td><p>\\mathbf{82.1}</p></td><td><p>63.4</p></td><td><p>\\mathbf{73.1}</p></td><td><p>\\mathbf{83.4}</p></td><td><p>\\mathbf{71.5}</p></td><td><p>68.8</p></td><td><p>\\mathbf{68.6}</p></td><td><p>\\mathbf{67.8}</p></td></tr></tbody></table>", "caption": "Table 3: Semantic segmentation mIoU and OA scores on S3DIS [1] 6-fold. ", "list_citation_info": ["[23] Qi, C.R., Su, H., Mo, K., Guibas, L.J.: Pointnet: Deep learning on point sets for 3d classification and segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 652\u2013660 (2017)", "[1] Armeni, I., Sax, S., Zamir, A.R., Savarese, S.: Joint 2d-3d-semantic data for indoor scene understanding. arXiv preprint arXiv:1702.01105 (2017)", "[7] Han, W., Wen, C., Wang, C., Li, X., Li, Q.: Point2node: Correlation learning of dynamic-node for point cloud feature modeling. arXiv preprint arXiv:1912.10775 (2019)", "[15] Landrieu, L., Simonovsky, M.: Large-scale point cloud semantic segmentation with superpoint graphs. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 4558\u20134567 (2018)", "[29] Thomas, H., Qi, C.R., Deschaud, J.E., Marcotegui, B., Goulette, F., Guibas, L.J.: Kpconv: Flexible and deformable convolution for point clouds. In: Proceedings of the IEEE International Conference on Computer Vision. pp. 6411\u20136420 (2019)", "[18] Li, Y., Bu, R., Sun, M., Wu, W., Di, X., Chen, B.: Pointcnn: Convolution on x-transformed points. In: Advances in neural information processing systems. pp. 820\u2013830 (2018)", "[37] Zhao, H., Jiang, L., Fu, C.W., Jia, J.: Pointweb: Enhancing local neighborhood features for point cloud processing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 5565\u20135573 (2019)"]}, {"table": "<table><tbody><tr><td></td><th><p>mIoU</p></th><th><p>Gain\\Delta</p></th></tr><tr><td><p>Baseline + grid sampling</p></td><td><p>65.4</p></td><td><p>-</p></td></tr><tr><td><p>Baseline + grid sampling + FP</p></td><td><p>65.4</p></td><td><p>-</p></td></tr><tr><td><p>Baseline + PDS</p></td><td><p>66.0</p></td><td><p>+0.6</p></td></tr><tr><td><p>Baseline + PDS + FP</p></td><td><p>67.7</p></td><td><p>+2.3</p></td></tr><tr><td><p>SPConv + PDS + FP</p></td><td><p>68.8</p></td><td><p>+3.4</p></td></tr><tr><td><p>Baseline + Attention + PDS + FP</p></td><td><p>68.3</p></td><td><p>+2.9</p></td></tr><tr><td><p>SPConv + Attention + PDS + FP</p></td><td><p>69.9</p></td><td><p>+4.5</p></td></tr></tbody></table>", "caption": "Table 4: Ablation studies evaluated on Area 5 of S3DIS [1].", "list_citation_info": ["[1] Armeni, I., Sax, S., Zamir, A.R., Savarese, S.: Joint 2d-3d-semantic data for indoor scene understanding. arXiv preprint arXiv:1702.01105 (2017)"]}]}