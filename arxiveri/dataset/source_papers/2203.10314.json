{"title": "Voxel Set Transformer: A Set-to-Set Approach to 3D Object Detection from Point Clouds", "abstract": "Transformer has demonstrated promising performance in many 2D vision tasks. However, it is cumbersome to compute the self-attention on large-scale point cloud data because point cloud is a long sequence and unevenly distributed in 3D space. To solve this issue, existing methods usually compute self-attention locally by grouping the points into clusters of the same size, or perform convolutional self-attention on a discretized representation. However, the former results in stochastic point dropout, while the latter typically has narrow attention fields. In this paper, we propose a novel voxel-based architecture, namely Voxel Set Transformer (VoxSeT), to detect 3D objects from point clouds by means of set-to-set translation. VoxSeT is built upon a voxel-based set attention (VSA) module, which reduces the self-attention in each voxel by two cross-attentions and models features in a hidden space induced by a group of latent codes. With the VSA module, VoxSeT can manage voxelized point clusters with arbitrary size in a wide range, and process them in parallel with linear complexity. The proposed VoxSeT integrates the high performance of transformer with the efficiency of voxel-based model, which can be used as a good alternative to the convolutional and point-based backbones. VoxSeT reports competitive results on the KITTI and Waymo detection benchmarks. The source codes can be found at \\url{https://github.com/skyhehe123/VoxSeT}.", "authors": ["Chenhang He", " Ruihuang Li", " Shuai Li", " Lei Zhang"], "pdf_url": "https://arxiv.org/abs/2203.10314", "list_table_and_caption": [{"table": "<p>MethodBackbone3D mAPBEV mAPOverall0-30m30-50m50m-infOverall0-30m30-50m50m-infLEVEL_1 (IoU=0.7):PointPillar [12] (CVPR19)CNN56.6281.0151.7527.9475.5792.1074.0655.47MVF [50] (CoRL20)CNN62.9386.3060.0236.0280.4093.5979.2163.09PV-RCNN [32] (CVPR20)SpCNN70.3091.9269.2142.1782.9697.3582.9964.97Voxel-RCNN [5] (AAAI21)SpCNN75.5992.4974.0953.1588.1997.6287.3477.70VoTR-TSD [21] (ICCV21)Transformer74.9592.2873.3651.09----CT3D [31] (ICCV21)SpCNN76.3092.5175.0755.3690.5097.6488.0678.89VoxSeT (ours)Transformer76.0291.1375.7554.2389.1295.1287.3677.78VoxSeT + CT3D (RoI head)Transformer77.8292.7877.2154.4190.3196.1188.1277.98LEVEL_2 (IoU=0.7):PV-RCNN [32] (CVPR20)SpCNN65.3691.5865.1336.4677.4594.6480.3955.39Voxel-RCNN [5] (AAAI21)SpCNN66.5991.7467.8940.8081.0796.9981.3763.26VoTR-TSD [21] (ICCV21)Transformer65.91-------CT3D [31] (ICCV21)SpCNN69.0491.7668.9342.6081.7497.0582.2264.34VoxSeT (ours)Transformer68.1691.0367.1342.2376.1394.1381.7858.13VoxSeT + CT3D (RoI head)Transformer70.2192.0570.1043.2080.5696.7980.4462.37</p>", "caption": "Table 1: Performance comparison with state-of-the-art methods on the Waymo dataset with 202 validation sequences (\\sim 40k samples) for vehicle detection.", "list_citation_info": ["[21] Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang, Hang Xu, and Chunjing Xu. Voxel transformer for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 3164\u20133173, October 2021.", "[31] Hualian Sheng, Sijia Cai, Yuan Liu, Bing Deng, Jianqiang Huang, Xian-Sheng Hua, and Min-Jian Zhao. Improving 3d object detection with channel-wise transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 2743\u20132752, October 2021.", "[32] Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li. Pv-rcnn: Point-voxel feature set abstraction for 3d object detection. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.", "[50] Yin Zhou, Pei Sun, Yu Zhang, Dragomir Anguelov, Jiyang Gao, Tom Ouyang, James Guo, Jiquan Ngiam, and Vijay Vasudevan. End-to-end multi-view fusion for 3d object detection in lidar point clouds, 2019.", "[5] Jiajun Deng, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, and Houqiang Li. Voxel r-cnn: Towards high performance voxel-based 3d object detection. AAAI, 2021.", "[12] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019."]}, {"table": "<p>MethodVehiclePedestrianCyclistEasyModerateHardEasyModerateHardEasyModerateHardSECOND [42]88.6178.6277.2256.5552.9847.7380.5867.1563.10PointPillars [12]86.4677.2874.6557.7552.2947.9080.0462.6159.52VoxSeT (single-stage)88.4578.4877.0760.6254.7450.3984.0768.1165.14Improvements-0.16-0.14-0.152.871.762.493.490.962.04</p>", "caption": "Table 2: Performance comparison with traditional single-stage baseline models on the KITTI validation set. The results are reported by the mAP with 11 recall points.", "list_citation_info": ["[12] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019.", "[42] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018."]}, {"table": "<p>Method3DEasyModerateHardLiDAR + RGB:MV3D[3] (CVPR17)74.9763.6354.00ContFuse[17] (ECCV18)83.6868.7861.67AVOD-FPN[11] (IROS18)83.0771.7665.73F-PointNet[27] (CVPR18)82.1969.7960.59MMF [16] (CVPR19)88.4077.4370.223D-CVF[46] (ECCV20)89.2080.0573.11CLOCs [24] (IROS20)88.9480.6777.15LiDAR only:VoxelNet[51] (CVPR18)77.4765.1157.73SECOND[42] (Sensor18)83.3472.5565.82PointPillars[12] (CVPR19)82.5874.3168.99STD[45] (ICCV19)87.9579.7175.09PointRCNN[33] (CVPR19)86.9675.6470.70SA-SSD[10] (CVPR20)88.7579.7974.163DSSD[45] (CVPR20)88.3679.5774.55PV-RCNN[45] (CVPR20)90.2581.4376.82Voxel-RCNN[45] (AAAI21)87.9579.7175.09CT3D [31] (ICCV21)87.8381.7777.16VoTR-TSD [21] (ICCV21)89.9082.0979.14VoxSeT (ours)88.5382.0677.46</p>", "caption": "Table 3: Performance comparison with state-of-the-art methods on the KITTI test set. The results are reported by the mAP with 0.7 IoU threshold and 40 recall points.", "list_citation_info": ["[42] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018.", "[46] Jin Hyeok Yoo, Yecheol Kim, Jisong Kim, and Jun Won Choi. 3d-cvf: Generating joint camera and lidar features using cross-view spatial feature fusion for 3d object detection. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXVII 16, pages 720\u2013736. Springer, 2020.", "[21] Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang, Hang Xu, and Chunjing Xu. Voxel transformer for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 3164\u20133173, October 2021.", "[33] Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li. Pointrcnn: 3d object proposal generation and detection from point cloud. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770\u2013779, 2019.", "[27] Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas. Frustum pointnets for 3d object detection from rgb-d data. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 918\u2013927, 2018.", "[31] Hualian Sheng, Sijia Cai, Yuan Liu, Bing Deng, Jianqiang Huang, Xian-Sheng Hua, and Min-Jian Zhao. Improving 3d object detection with channel-wise transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 2743\u20132752, October 2021.", "[3] Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1907\u20131915, 2017.", "[12] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019.", "[24] Su Pang, Daniel Morris, and Hayder Radha. Clocs: Camera-lidar object candidates fusion for 3d object detection. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 10386\u201310393. IEEE, 2020.", "[11] Jason Ku, Melissa Mozifian, Jungwook Lee, Ali Harakeh, and Steven L Waslander. Joint 3d proposal generation and object detection from view aggregation. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 1\u20138. IEEE, 2018.", "[10] Chenhang He, Hui Zeng, Jianqiang Huang, Xian-Sheng Hua, and Lei Zhang. Structure aware single-stage 3d object detection from point cloud. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11873\u201311882, 2020.", "[45] Zetong Yang, Yanan Sun, Shu Liu, Xiaoyong Shen, and Jiaya Jia. STD: sparse-to-dense 3d object detector for point cloud. In Proceedings of the IEEE international conference on computer vision (ICCV), 2019.", "[17] Ming Liang, Bin Yang, Shenlong Wang, and Raquel Urtasun. Deep continuous fusion for multi-sensor 3d object detection. In Proceedings of the European Conference on Computer Vision (ECCV), pages 641\u2013656, 2018.", "[16] Ming Liang, Bin Yang, Yun Chen, Rui Hu, and Raquel Urtasun. Multi-task multi-sensor fusion for 3d object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7345\u20137353, 2019.", "[51] Yin Zhou and Oncel Tuzel. Voxelnet: End-to-end learning for point cloud based 3d object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4490\u20134499, 2018."]}, {"table": "<p>Method3DEasyModerateHardLiDAR + RGB:MV3D[3] (CVPR17)71.2962.6856.56F-PointNet[27] (CVPR18)83.7670.9263.653D-CVF[46] (ECCV20)89.6779.8878.47LiDAR only:SECOND[42] (Sensor18)88.6178.6277.22PointPillars[12] (CVPR19)86.6276.0668.91STD[45] (ICCV19)89.7079.8079.30PointRCNN[33] (CVPR19)88.8878.6377.38SA-SSD[10] (CVPR20)90.1579.9178.783DSSD[45] (CVPR20)89.7179.4578.67PV-RCNN[45] (CVPR20)89.3583.6978.70Voxel-RCNN[45] (AAAI21)89.4184.5278.93CT3D [31] (ICCV21)89.5486.0678.99VoTR-TSD [21] (ICCV21)89.0484.0478.68VoxSeT (ours)89.2186.7178.56</p>", "caption": "Table 4: Performance comparison with state-of-the-art methods on the KITTI validation set. The results are reported by the mAP with 0.7 IoU threshold and 11 recall points.", "list_citation_info": ["[46] Jin Hyeok Yoo, Yecheol Kim, Jisong Kim, and Jun Won Choi. 3d-cvf: Generating joint camera and lidar features using cross-view spatial feature fusion for 3d object detection. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXVII 16, pages 720\u2013736. Springer, 2020.", "[21] Jiageng Mao, Yujing Xue, Minzhe Niu, Haoyue Bai, Jiashi Feng, Xiaodan Liang, Hang Xu, and Chunjing Xu. Voxel transformer for 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 3164\u20133173, October 2021.", "[33] Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li. Pointrcnn: 3d object proposal generation and detection from point cloud. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770\u2013779, 2019.", "[27] Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas. Frustum pointnets for 3d object detection from rgb-d data. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 918\u2013927, 2018.", "[31] Hualian Sheng, Sijia Cai, Yuan Liu, Bing Deng, Jianqiang Huang, Xian-Sheng Hua, and Min-Jian Zhao. Improving 3d object detection with channel-wise transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 2743\u20132752, October 2021.", "[3] Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1907\u20131915, 2017.", "[10] Chenhang He, Hui Zeng, Jianqiang Huang, Xian-Sheng Hua, and Lei Zhang. Structure aware single-stage 3d object detection from point cloud. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11873\u201311882, 2020.", "[45] Zetong Yang, Yanan Sun, Shu Liu, Xiaoyong Shen, and Jiaya Jia. STD: sparse-to-dense 3d object detector for point cloud. In Proceedings of the IEEE international conference on computer vision (ICCV), 2019.", "[42] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018.", "[12] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019."]}, {"table": "<p>SettingsEasyModerateHardPointRCNN88.5278.9577.81VSA-PointRCNN89.6180.1478.69</p>", "caption": "Table 7: Comparison of PointRCNN [33] detectors with VoxSeT and PointNet++ backbones. The mAP (11 recall points) on KITTI val are reported.", "list_citation_info": ["[33] Shaoshuai Shi, Xiaogang Wang, and Hongsheng Li. Pointrcnn: 3d object proposal generation and detection from point cloud. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770\u2013779, 2019."]}, {"table": "<p>ModelsLatencyMemory (runtime)SECOND [42]48 ms6093MBPointPillars [12]22ms1508 MBVoxSeT (single-stage)34 ms2381 MB</p>", "caption": "Table 8: The latency and runtime memory on the KITTI dataset, tested by NVIDIA 2080Ti GPU. ", "list_citation_info": ["[12] Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 12697\u201312705, 2019.", "[42] Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embedded convolutional detection. Sensors, 18(10):3337, 2018."]}]}