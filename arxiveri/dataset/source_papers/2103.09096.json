{"title": "Frequency-aware discriminative feature learning supervised by single-center loss for face forgery detection", "abstract": "Face forgery detection is raising ever-increasing interest in computer vision since facial manipulation technologies cause serious worries. Though recent works have reached sound achievements, there are still unignorable problems: a) learned features supervised by softmax loss are separable but not discriminative enough, since softmax loss does not explicitly encourage intra-class compactness and interclass separability; and b) fixed filter banks and hand-crafted features are insufficient to capture forgery patterns of frequency from diverse inputs. To compensate for such limitations, a novel frequency-aware discriminative feature learning framework is proposed in this paper. Specifically, we design a novel single-center loss (SCL) that only compresses intra-class variations of natural faces while boosting inter-class differences in the embedding space. In such a case, the network can learn more discriminative features with less optimization difficulty. Besides, an adaptive frequency feature generation module is developed to mine frequency clues in a completely data-driven fashion. With the above two modules, the whole framework can learn more discriminative features in an end-to-end manner. Extensive experiments demonstrate the effectiveness and superiority of our framework on three versions of the FF++ dataset.", "authors": ["Jiaming Li", " Hongtao Xie", " Jiahong Li", " Zhongyuan Wang", " Yongdong Zhang"], "pdf_url": "https://arxiv.org/abs/2103.09096", "list_table_and_caption": [{"table": "<table><tbody><tr><th rowspan=\"2\">Methods</th><td colspan=\"3\">c0</td><td colspan=\"3\">c23</td><td colspan=\"3\">c40</td></tr><tr><td>Acc</td><td>AUC</td><td>pAUC{}_{0.1}</td><td>Acc</td><td>AUC</td><td>pAUC{}_{0.1}</td><td>Acc</td><td>AUC</td><td>pAUC{}_{0.1}</td></tr><tr><th>Steg. Features + SVM[14]</th><td>97.63\\%</td><td>-</td><td>-</td><td>70.97\\%</td><td>-</td><td>-</td><td>55.98\\%</td><td>-</td><td>-</td></tr><tr><th>Cozzolino et al.[8]</th><td>98.57\\%</td><td>-</td><td>-</td><td>78.45\\%</td><td>-</td><td>-</td><td>58.69\\%</td><td>-</td><td>-</td></tr><tr><th>Bayar and Stamm[6]</th><td>98.75\\%</td><td>-</td><td>-</td><td>82.97\\%</td><td>-</td><td>-</td><td>66.84\\%</td><td>-</td><td>-</td></tr><tr><th>Rahmouni et al.[34]</th><td>97.03\\%</td><td>-</td><td>-</td><td>79.08\\%</td><td>-</td><td>-</td><td>61.18\\%</td><td>-</td><td>-</td></tr><tr><th>DSP-FWA[25]</th><td>-</td><td>-</td><td>-</td><td>-</td><td>0.575</td><td>0.516</td><td>-</td><td>0.623</td><td>0.519</td></tr><tr><th>MesoNet[4]</th><td>95.23\\%</td><td>-</td><td>-</td><td>83.10\\%</td><td>-</td><td>-</td><td>70.47\\%</td><td>-</td><td>-</td></tr><tr><th>Xception[36]</th><td>99.26\\%</td><td>-</td><td>-</td><td>95.73\\%</td><td>-</td><td>-</td><td>81.00\\%</td><td>-</td><td>-</td></tr><tr><th>Face X-ray[24]</th><td>-</td><td>0.988</td><td>-</td><td>-</td><td>0.874</td><td>-</td><td>-</td><td>0.616</td><td>-</td></tr><tr><th>Two-branch[29]</th><td>-</td><td>-</td><td>-</td><td>96.43\\%</td><td>0.991</td><td>0.984</td><td>86.34\\%</td><td>0.911</td><td>0.766</td></tr><tr><th>Xception[36] {\\dagger}</th><td>98.14\\%</td><td>0.997{}^{*}</td><td>0.995</td><td>94.24\\%</td><td>0.972</td><td>0.903</td><td>86.14\\%</td><td>0.861</td><td>0.652</td></tr><tr><th>FDFL(our)</th><td>99.43\\%</td><td>0.997{}^{*}</td><td>0.998</td><td>96.69\\%</td><td>0.993</td><td>0.985</td><td>89.00\\%</td><td>0.924</td><td>0.810</td></tr></tbody></table>", "caption": "Table 4: Quantitative results on the FF++ dataset with all three versions.c0 represents videos without compression, c23 represents videos with light compression, c40 represents videos with heavy compression and {\\dagger} represents the results of our baseline.Two-branch [29] is a video-based detection method and all others are image-based detection methods.The bold results are the best. The symbol * represents there is a difference at the fourth decimal place andmore precise data are provided in the supplementary material.", "list_citation_info": ["[29] Iacopo Masi, Aditya Killekar, Royston Marian Mascarenhas, Shenoy Pratik Gurudatt, and Wael AbdAlmageed. Two-branch recurrent network for isolating deepfakes in videos. arXiv preprint arXiv:2008.03412, 2020.", "[25] Yuezun Li and Siwei Lyu. Exposing deepfake videos by detecting face warping artifacts. arXiv preprint arXiv:1811.00656, 2018.", "[4] Darius Afchar, Vincent Nozick, Junichi Yamagishi, and Isao Echizen. Mesonet: a compact facial video forgery detection network. In 2018 IEEE International Workshop on Information Forensics and Security (WIFS), pages 1\u20137. IEEE, 2018.", "[8] Davide Cozzolino, Giovanni Poggi, and Luisa Verdoliva. Recasting residual-based local descriptors as convolutional neural networks: an application to image forgery detection. In Proceedings of the 5th ACM Workshop on Information Hiding and Multimedia Security, pages 159\u2013164, 2017.", "[24] Lingzhi Li, Jianmin Bao, Ting Zhang, Hao Yang, Dong Chen, Fang Wen, and Baining Guo. Face x-ray for more general face forgery detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5001\u20135010, 2020.", "[6] Belhassen Bayar and Matthew C Stamm. A deep learning approach to universal image manipulation detection using a new convolutional layer. In Proceedings of the 4th ACM Workshop on Information Hiding and Multimedia Security, pages 5\u201310, 2016.", "[34] Nicolas Rahmouni, Vincent Nozick, Junichi Yamagishi, and Isao Echizen. Distinguishing computer graphics from natural images using convolution neural networks. In 2017 IEEE Workshop on Information Forensics and Security (WIFS), pages 1\u20136. IEEE, 2017.", "[36] Andreas Rossler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nie\u00dfner. Faceforensics++: Learning to detect manipulated facial images. In Proceedings of the IEEE International Conference on Computer Vision, pages 1\u201311, 2019.", "[14] Jessica Fridrich and Jan Kodovsky. Rich models for steganalysis of digital images. IEEE Transactions on Information Forensics and Security, 7(3):868\u2013882, 2012."]}]}