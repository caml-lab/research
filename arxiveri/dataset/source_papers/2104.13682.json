{"title": "Hotr: End-to-end human-object interaction detection with transformers", "abstract": "Human-Object Interaction (HOI) detection is a task of identifying \"a set of interactions\" in an image, which involves the i) localization of the subject (i.e., humans) and target (i.e., objects) of interaction, and ii) the classification of the interaction labels. Most existing methods have indirectly addressed this task by detecting human and object instances and individually inferring every pair of the detected instances. In this paper, we present a novel framework, referred to by HOTR, which directly predicts a set of <human, object, interaction> triplets from an image based on a transformer encoder-decoder architecture. Through the set prediction, our method effectively exploits the inherent semantic relationships in an image and does not require time-consuming post-processing which is the main bottleneck of existing methods. Our proposed algorithm achieves the state-of-the-art performance in two HOI detection benchmarks with an inference time under 1 ms after object detection.", "authors": ["Bumsoo Kim", " Junhyun Lee", " Jaewoo Kang", " Eun-Sol Kim", " Hyunwoo J. Kim"], "pdf_url": "https://arxiv.org/abs/2104.13682", "list_table_and_caption": [{"table": "<table><tbody><tr><th>Method</th><th>Backbone</th><td>AP_{\\text{role}}^{\\#1}</td><td>AP_{\\text{role}}^{\\#2}</td></tr><tr><th colspan=\"4\">Models with external features</th></tr><tr><th>TIN (R\\text{P}_{\\text{D}}\\text{C}_{\\text{D}}) [18]</th><th>R50</th><td>47.8</td><td></td></tr><tr><th>Verb Embedding [31]</th><th>R50</th><td>45.9</td><td></td></tr><tr><th>RPNN [33]</th><th>R50</th><td>-</td><td>47.5</td></tr><tr><th>PMFNet [27]</th><th>R50-FPN</th><td>52.0</td><td></td></tr><tr><th>PastaNet [17]</th><th>R50-FPN</th><td>51.0</td><td>57.5</td></tr><tr><th>PD-Net [32]</th><th>R50</th><td>52.0</td><td>-</td></tr><tr><th>ACP [13]</th><th>R152</th><td>53.0</td><td></td></tr><tr><th>FCMNet [20]</th><th>R50</th><td>53.1</td><td>-</td></tr><tr><th>ConsNet [21]</th><th>R50-FPN</th><td>53.2</td><td>-</td></tr><tr><th colspan=\"4\">Sequential HOI Detectors</th></tr><tr><th>VSRL [8]</th><th>R50-FPN</th><td>31.8</td><td>-</td></tr><tr><th>InteractNet [6]</th><th>R50-FPN</th><td>40.0</td><td>48.0</td></tr><tr><th>BAR-CNN [14]</th><th>R50-FPN</th><td>43.6</td><td>-</td></tr><tr><th>GPNN [24]</th><th>R152</th><td>44.0</td><td>-</td></tr><tr><th>iCAN [5]</th><th>R50</th><td>45.3</td><td>52.4</td></tr><tr><th>TIN (R\\text{C}_{\\text{D}}) [18]</th><th>R50</th><td>43.2</td><td>-</td></tr><tr><th>DCA [29]</th><th>R50</th><td>47.3</td><td>-</td></tr><tr><th>VSGNet [26]</th><th>R152</th><td>51.8</td><td>57.0</td></tr><tr><th>VCL [10]</th><th>R50-FPN</th><td>48.3</td><td></td></tr><tr><th>DRG [4]</th><th>R50-FPN</th><td>51.0</td><td></td></tr><tr><th>IDN [16]</th><th>R50</th><td>53.3</td><td>60.3</td></tr><tr><th colspan=\"4\">Parallel HOI Detectors</th></tr><tr><th>IPNet [30]</th><th>HG104</th><td>51.0</td><td>-</td></tr><tr><th>UnionDet [12]</th><th>R50-FPN</th><td>47.5</td><td>56.2</td></tr><tr><th>Ours</th><th>R50</th><td>55.2</td><td>64.4</td></tr></tbody></table>", "caption": "Table 1: Comparison of performance on V-COCO test set. AP_{\\text{role}}^{\\#1}, AP_{\\text{role}}^{\\#2} denotes the performance under Scenario1 and Scenario2 in V-COCO, respectively.", "list_citation_info": ["[27] Bo Wan, Desen Zhou, Yongfei Liu, Rongjie Li, and Xuming He. Pose-aware multi-level feature network for human object interaction detection. In Proceedings of the IEEE International Conference on Computer Vision, pages 9469\u20139478, 2019.", "[32] Xubin Zhong, Changxing Ding, Xian Qu, and Dacheng Tao. Polysemy deciphering network for human-object interaction detection. In Proc. Eur. Conf. Comput. Vis, 2020.", "[5] Chen Gao, Yuliang Zou, and Jia-Bin Huang. ican: Instance-centric attention network for human-object interaction detection. arXiv preprint arXiv:1808.10437, 2018.", "[14] Alexander Kolesnikov, Alina Kuznetsova, Christoph Lampert, and Vittorio Ferrari. Detecting visual relationships using box attention. In Proceedings of the IEEE International Conference on Computer Vision Workshops, pages 0\u20130, 2019.", "[12] Bumsoo Kim, Taeho Choi, Jaewoo Kang, and Hyunwoo Kim. Uniondet: Union-level detection towards real-time human-object interaction detection. In Proceedings of the European conference on computer vision (ECCV), 2020.", "[30] Tiancai Wang, Tong Yang, Martin Danelljan, Fahad Shahbaz Khan, Xiangyu Zhang, and Jian Sun. Learning human-object interaction detection using interaction points. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4116\u20134125, 2020.", "[26] Oytun Ulutan, ASM Iftekhar, and Bangalore S Manjunath. Vsgnet: Spatial attention network for detecting human object interactions using graph convolutions. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13617\u201313626, 2020.", "[18] Yong-Lu Li, Siyuan Zhou, Xijie Huang, Liang Xu, Ze Ma, Hao-Shu Fang, Yanfeng Wang, and Cewu Lu. Transferable interactiveness knowledge for human-object interaction detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3585\u20133594, 2019.", "[6] Georgia Gkioxari, Ross Girshick, Piotr Doll\u00e1r, and Kaiming He. Detecting and recognizing human-object interactions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8359\u20138367, 2018.", "[21] Ye Liu, Junsong Yuan, and Chang Wen Chen. Consnet: Learning consistency graph for zero-shot human-object interaction detection. In Proceedings of the 28th ACM International Conference on Multimedia, pages 4235\u20134243, 2020.", "[20] Y Liu, Q Chen, and A Zisserman. Amplifying key cues for human-object-interaction detection. Lecture Notes in Computer Science, 2020.", "[4] Chen Gao, Jiarui Xu, Yuliang Zou, and Jia-Bin Huang. Drg: Dual relation graph for human-object interaction detection. In European Conference on Computer Vision, pages 696\u2013712. Springer, 2020.", "[16] Yong-Lu Li, Xinpeng Liu, Xiaoqian Wu, Yizhuo Li, and Cewu Lu. Hoi analysis: Integrating and decomposing human-object interaction. Advances in Neural Information Processing Systems, 33, 2020.", "[31] Bingjie Xu, Yongkang Wong, Junnan Li, Qi Zhao, and Mohan S Kankanhalli. Learning to detect human-object interactions with knowledge. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019.", "[29] Tiancai Wang, Rao Muhammad Anwer, Muhammad Haris Khan, Fahad Shahbaz Khan, Yanwei Pang, Ling Shao, and Jorma Laaksonen. Deep contextual attention for human-object interaction detection. arXiv preprint arXiv:1910.07721, 2019.", "[24] Siyuan Qi, Wenguan Wang, Baoxiong Jia, Jianbing Shen, and Song-Chun Zhu. Learning human-object interactions by graph parsing neural networks. In Proceedings of the European Conference on Computer Vision (ECCV), pages 401\u2013417, 2018.", "[10] Zhi Hou, Xiaojiang Peng, Yu Qiao, and Dacheng Tao. Visual compositional learning for human-object interaction detection. arXiv preprint arXiv:2007.12407, 2020.", "[13] Dong-Jin Kim, Xiao Sun, Jinsoo Choi, Stephen Lin, and In So Kweon. Detecting human-object interactions with action co-occurrence priors. arXiv preprint arXiv:2007.08728, 2020.", "[17] Yong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue Xu, Shiyi Wang, Hao-Shu Fang, Ze Ma, Mingyang Chen, and Cewu Lu. Pastanet: Toward human activity knowledge engine. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 382\u2013391, 2020.", "[8] Jitendra Gupta, Saurabh Malik. Visual semantic role labeling. arXiv preprint arXiv:1505.04474, 2015.", "[33] Penghao Zhou and Mingmin Chi. Relation parsing neural network for human-object interaction detection. In Proceedings of the IEEE International Conference on Computer Vision, pages 843\u2013851, 2019."]}, {"table": "<table><tbody><tr><th colspan=\"4\"></th><td colspan=\"3\">Default</td></tr><tr><th>Method</th><td>    Detector</td><td>Backbone</td><td>    Feature</td><td>    Full</td><td>  Rare</td><td>Non Rare</td></tr><tr><th colspan=\"7\">Sequential HOI Detectors</th></tr><tr><th>InteractNet [6]</th><td>COCO</td><td>R50-FPN</td><td>A</td><td>9.94</td><td>7.16</td><td>10.77</td></tr><tr><th>GPNN [24]</th><td>COCO</td><td>R101</td><td>A</td><td>13.11</td><td>9.41</td><td>14.23</td></tr><tr><th>iCAN [5]</th><td>COCO</td><td>R50</td><td>A+S</td><td>14.84</td><td>10.45</td><td>16.15</td></tr><tr><th>DCA [29]</th><td>COCO</td><td>R50</td><td>A+S</td><td>16.24</td><td>11.16</td><td>17.75</td></tr><tr><th>TIN [18]</th><td>COCO</td><td>R50</td><td>A+S+P</td><td>17.03</td><td>13.42</td><td>18.11</td></tr><tr><th>RPNN [33]</th><td>COCO</td><td>R50</td><td>A+P</td><td>17.35</td><td>12.78</td><td>18.71</td></tr><tr><th>PMFNet [27]</th><td>COCO</td><td>R50-FPN</td><td>A+S+P</td><td>17.46</td><td>15.65</td><td>18.00</td></tr><tr><th>No-Frills HOI [9]</th><td>COCO</td><td>R152</td><td>A+S+P</td><td>17.18</td><td>12.17</td><td>18.68</td></tr><tr><th>DRG [4]</th><td>COCO</td><td>R50-FPN</td><td>A+S+L</td><td>19.26</td><td>17.74</td><td>19.71</td></tr><tr><th>VCL [10]</th><td>COCO</td><td>R50</td><td>A+S</td><td>19.43</td><td>16.55</td><td>20.29</td></tr><tr><th>VSGNet [26]</th><td>COCO</td><td>R152</td><td>A+S</td><td>19.80</td><td>16.05</td><td>20.91</td></tr><tr><th>FCMNet [20]</th><td>COCO</td><td>R50</td><td>A+S+P</td><td>20.41</td><td>17.34</td><td>21.56</td></tr><tr><th>ACP [13]</th><td>COCO</td><td>R152</td><td>A+S+P</td><td>20.59</td><td>15.92</td><td>21.98</td></tr><tr><th>PD-Net [32]</th><td>COCO</td><td>R50</td><td>A+S+P+L</td><td>20.81</td><td>15.90</td><td>22.28</td></tr><tr><th>DJ-RN [15]</th><td>COCO</td><td>R50</td><td>A+S+V</td><td>21.34</td><td>18.53</td><td>22.18</td></tr><tr><th>ConsNet [21]</th><td>COCO</td><td>R50-FPN</td><td>A+S+L</td><td>22.15</td><td>17.12</td><td>23.65</td></tr><tr><th>PastaNet [17]</th><td>COCO</td><td>R50</td><td>A+S+P+L</td><td>22.65</td><td>21.17</td><td>23.09</td></tr><tr><th>IDN [16]</th><td>COCO</td><td>R50</td><td>A+S</td><td>23.36</td><td>22.47</td><td>23.63</td></tr><tr><th>Functional Gen. [1]</th><td>HICO-DET</td><td>R101</td><td>A+S+L</td><td>21.96</td><td>16.43</td><td>23.62</td></tr><tr><th>TIN [18]</th><td>HICO-DET</td><td>R50</td><td>A+S+P</td><td>22.90</td><td>14.97</td><td>25.26</td></tr><tr><th>VCL [10]</th><td>HICO-DET</td><td>R50</td><td>A+S</td><td>23.63</td><td>17.21</td><td>25.55</td></tr><tr><th>ConsNet [21]</th><td>HICO-DET</td><td>R50-FPN</td><td>A+S+L</td><td>24.39</td><td>17.10</td><td>26.56</td></tr><tr><th>DRG [4]</th><td>HICO-DET</td><td>R50-FPN</td><td>A+S</td><td>24.53</td><td>19.47</td><td>26.04</td></tr><tr><th>IDN [16]</th><td>HICO-DET</td><td>R50</td><td>A+S</td><td>24.58</td><td>20.33</td><td>25.86</td></tr><tr><th colspan=\"7\">Parallel HOI Detectors</th></tr><tr><th>UnionDet [12]</th><td>COCO</td><td>R50-FPN</td><td>A</td><td>14.25</td><td>10.23</td><td>15.46</td></tr><tr><th>IPNet [30]</th><td>COCO</td><td>R50-FPN</td><td>A</td><td>19.56</td><td>12.79</td><td>21.58</td></tr><tr><th>Ours</th><td>COCO</td><td>R50</td><td>A</td><td>23.46</td><td>16.21</td><td>25.62</td></tr><tr><th>UnionDet [12]</th><td>HICO-DET</td><td>R50-FPN</td><td>A</td><td>17.58</td><td>11.72</td><td>19.33</td></tr><tr><th>PPDM [19]</th><td>HICO-DET</td><td>HG104</td><td>A</td><td>21.10</td><td>14.46</td><td>23.09</td></tr><tr><th>Ours</th><td>HICO-DET</td><td>R50</td><td>A</td><td>25.10</td><td>17.34</td><td>27.42</td></tr></tbody></table>", "caption": "Table 2: Performance comparison in HICO-DET. The Detector column is denoted as \u2018COCO\u2019 for the models that freeze the object detectors with the weights pre-trained in MS-COCO and \u2018HICO-DET\u2019 if the object detector is fine-tuned with the HICO-DET train set. The each letter in Feature column stands for A: Appearance (Visual features), S: Interaction Patterns (Spatial Correlations [5]), P: Pose Estimation, L: Linguistic Priors, V: Volume [15].", "list_citation_info": ["[27] Bo Wan, Desen Zhou, Yongfei Liu, Rongjie Li, and Xuming He. Pose-aware multi-level feature network for human object interaction detection. In Proceedings of the IEEE International Conference on Computer Vision, pages 9469\u20139478, 2019.", "[32] Xubin Zhong, Changxing Ding, Xian Qu, and Dacheng Tao. Polysemy deciphering network for human-object interaction detection. In Proc. Eur. Conf. Comput. Vis, 2020.", "[5] Chen Gao, Yuliang Zou, and Jia-Bin Huang. ican: Instance-centric attention network for human-object interaction detection. arXiv preprint arXiv:1808.10437, 2018.", "[15] Yong-Lu Li, Xinpeng Liu, Han Lu, Shiyi Wang, Junqi Liu, Jiefeng Li, and Cewu Lu. Detailed 2d-3d joint representation for human-object interaction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10166\u201310175, 2020.", "[1] Ankan Bansal, Sai Saketh Rambhatla, Abhinav Shrivastava, and Rama Chellappa. Detecting human-object interactions via functional generalization. In AAAI, pages 10460\u201310469, 2020.", "[12] Bumsoo Kim, Taeho Choi, Jaewoo Kang, and Hyunwoo Kim. Uniondet: Union-level detection towards real-time human-object interaction detection. In Proceedings of the European conference on computer vision (ECCV), 2020.", "[30] Tiancai Wang, Tong Yang, Martin Danelljan, Fahad Shahbaz Khan, Xiangyu Zhang, and Jian Sun. Learning human-object interaction detection using interaction points. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4116\u20134125, 2020.", "[26] Oytun Ulutan, ASM Iftekhar, and Bangalore S Manjunath. Vsgnet: Spatial attention network for detecting human object interactions using graph convolutions. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13617\u201313626, 2020.", "[18] Yong-Lu Li, Siyuan Zhou, Xijie Huang, Liang Xu, Ze Ma, Hao-Shu Fang, Yanfeng Wang, and Cewu Lu. Transferable interactiveness knowledge for human-object interaction detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3585\u20133594, 2019.", "[6] Georgia Gkioxari, Ross Girshick, Piotr Doll\u00e1r, and Kaiming He. Detecting and recognizing human-object interactions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8359\u20138367, 2018.", "[21] Ye Liu, Junsong Yuan, and Chang Wen Chen. Consnet: Learning consistency graph for zero-shot human-object interaction detection. In Proceedings of the 28th ACM International Conference on Multimedia, pages 4235\u20134243, 2020.", "[19] Yue Liao, Si Liu, Fei Wang, Yanjie Chen, Chen Qian, and Jiashi Feng. Ppdm: Parallel point detection and matching for real-time human-object interaction detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 482\u2013490, 2020.", "[9] Tanmay Gupta, Alexander Schwing, and Derek Hoiem. No-frills human-object interaction detection: Factorization, layout encodings, and training techniques. In Proceedings of the IEEE International Conference on Computer Vision, pages 9677\u20139685, 2019.", "[20] Y Liu, Q Chen, and A Zisserman. Amplifying key cues for human-object-interaction detection. Lecture Notes in Computer Science, 2020.", "[4] Chen Gao, Jiarui Xu, Yuliang Zou, and Jia-Bin Huang. Drg: Dual relation graph for human-object interaction detection. In European Conference on Computer Vision, pages 696\u2013712. Springer, 2020.", "[16] Yong-Lu Li, Xinpeng Liu, Xiaoqian Wu, Yizhuo Li, and Cewu Lu. Hoi analysis: Integrating and decomposing human-object interaction. Advances in Neural Information Processing Systems, 33, 2020.", "[29] Tiancai Wang, Rao Muhammad Anwer, Muhammad Haris Khan, Fahad Shahbaz Khan, Yanwei Pang, Ling Shao, and Jorma Laaksonen. Deep contextual attention for human-object interaction detection. arXiv preprint arXiv:1910.07721, 2019.", "[24] Siyuan Qi, Wenguan Wang, Baoxiong Jia, Jianbing Shen, and Song-Chun Zhu. Learning human-object interactions by graph parsing neural networks. In Proceedings of the European Conference on Computer Vision (ECCV), pages 401\u2013417, 2018.", "[10] Zhi Hou, Xiaojiang Peng, Yu Qiao, and Dacheng Tao. Visual compositional learning for human-object interaction detection. arXiv preprint arXiv:2007.12407, 2020.", "[13] Dong-Jin Kim, Xiao Sun, Jinsoo Choi, Stephen Lin, and In So Kweon. Detecting human-object interactions with action co-occurrence priors. arXiv preprint arXiv:2007.08728, 2020.", "[17] Yong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue Xu, Shiyi Wang, Hao-Shu Fang, Ze Ma, Mingyang Chen, and Cewu Lu. Pastanet: Toward human activity knowledge engine. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 382\u2013391, 2020.", "[33] Penghao Zhou and Mingmin Chi. Relation parsing neural network for human-object interaction detection. In Proceedings of the IEEE International Conference on Computer Vision, pages 843\u2013851, 2019."]}]}