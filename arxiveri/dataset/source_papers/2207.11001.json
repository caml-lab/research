{"title": "Pop: Mining potential performance of new fashion products via webly cross-modal query expansion", "abstract": "We propose a data-centric pipeline able to generate exogenous observation data for the New Fashion Product Performance Forecasting (NFPPF) problem, i.e., predicting the performance of a brand-new clothing probe with no available past observations. Our pipeline manufactures the missing past starting from a single, available image of the clothing probe. It starts by expanding textual tags associated with the image, querying related fashionable or unfashionable images uploaded on the web at a specific time in the past. A binary classifier is robustly trained on these web images by confident learning, to learn what was fashionable in the past and how much the probe image conforms to this notion of fashionability. This compliance produces the POtential Performance (POP) time series, indicating how performing the probe could have been if it were available earlier. POP proves to be highly predictive for the probe's future performance, ameliorating the sales forecasts of all state-of-the-art models on the recent VISUELLE fast-fashion dataset. We also show that POP reflects the ground-truth popularity of new styles (ensembles of clothing items) on the Fashion Forward benchmark, demonstrating that our webly-learned signal is a truthful expression of popularity, accessible by everyone and generalizable to any time of analysis. Forecasting code, data and the POP time series are available at: https://github.com/HumaticsLAB/POP-Mining-POtential-Performance", "authors": ["Christian Joppi", " Geri Skenderi", " Marco Cristani"], "pdf_url": "https://arxiv.org/abs/2207.11001", "list_table_and_caption": [{"table": "<table><tr><td colspan=\"16\">First Order Setup (K_{best} = 28 weeks)</td></tr><tr><td>Exogenous</td><td colspan=\"3\">Gradient</td><td colspan=\"3\">Concat</td><td colspan=\"3\">Residual</td><td colspan=\"3\">X-Attention</td><td colspan=\"3\">GTM</td></tr><tr><td>Signal</td><td colspan=\"3\">Boosting</td><td colspan=\"3\">MM RNN</td><td colspan=\"3\">MM RNN</td><td colspan=\"3\">RNN</td><td colspan=\"3\">Transformer</td></tr><tr><td></td><td colspan=\"3\">[15] 2020</td><td colspan=\"3\">[9] 2020</td><td colspan=\"3\">[9] 2020</td><td colspan=\"3\">[9] 2020</td><td colspan=\"3\">[35] 2021</td></tr><tr><td></td><td>W</td><td>M</td><td>ERP</td><td>W</td><td>M</td><td>ERP</td><td>W</td><td>M</td><td>ERP</td><td>W</td><td>M</td><td>ERP</td><td>W</td><td>M</td><td>ERP</td></tr><tr><td> NoSignal </td><td>64.10</td><td>35.02</td><td>0.43</td><td>63.31</td><td>34.41</td><td>0.42</td><td>64.26</td><td>34.92</td><td>0.44</td><td>59.49</td><td>32.33</td><td>0.38</td><td>56.62</td><td>30.93</td><td>0.37</td></tr><tr><td> GoogleTrends </td><td>64.29</td><td>35.12</td><td>0.43</td><td>64.11</td><td>34.84</td><td>0.43</td><td>68.11</td><td>37.02</td><td>0.47</td><td>58.70</td><td>31.90</td><td>0.38</td><td>56.83</td><td>31.05</td><td>0.35</td></tr><tr><td> POPSignal </td><td>63.75</td><td>34.83</td><td>0.42</td><td>58.09</td><td>31.73</td><td>0.39</td><td>58.88</td><td>32.16</td><td>0.39</td><td>57.78</td><td>31.56</td><td>0.38</td><td>53.41</td><td>29.18</td><td>0.32</td></tr></table>", "caption": "Table 1: Results on VISUELLE with the first order setup; \u201cW\u201d stands for WAPE, \u201cM\u201d for MAE. Lower is better for all metrics.", "list_citation_info": ["[9] Ekambaram, V., Manglik, K., Mukherjee, S., Sajja, S.S.K., Dwivedi, S., Raykar, V.: Attention based Multi-Modal New Product Sales Time-series Forecasting. In: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, Virtual Event CA USA (Aug 2020). https://doi.org/10.1145/3394486.3403362, https://dl.acm.org/doi/10.1145/3394486.3403362", "[15] Ilic, I., G\u00f6rg\u00fcl\u00fc, B., Cevik, M., Baydo\u011fan, M.G.: Explainable boosted linear regression for time series forecasting. Pattern Recognition (2021)", "[35] Skenderi, G., Joppi, C., Denitto, M., Cristani, M.: Well googled is half done: Multimodal forecasting of new fashion product sales with image-based google trends. arXiv preprint arXiv:2109.09824 (2021)"]}, {"table": "<table><tr><td colspan=\"16\">Release Setup (K_{best} = 52 weeks)</td></tr><tr><td>Exogenous</td><td colspan=\"3\">Gradient</td><td colspan=\"3\">Concat</td><td colspan=\"3\">Residual</td><td colspan=\"3\">X-Attention</td><td colspan=\"3\">GTM</td></tr><tr><td>Signal</td><td colspan=\"3\">Boosting</td><td colspan=\"3\">MM RNN</td><td colspan=\"3\">MM RNN</td><td colspan=\"3\">RNN</td><td colspan=\"3\">Transformer</td></tr><tr><td></td><td colspan=\"3\">[15] 2020</td><td colspan=\"3\">[9] 2020</td><td colspan=\"3\">[9] 2020</td><td colspan=\"3\">[9] 2020</td><td colspan=\"3\">[35] 2021</td></tr><tr><td></td><td>W</td><td>M</td><td>ERP</td><td>W</td><td>M</td><td>ERP</td><td>W</td><td>M</td><td>ERP</td><td>W</td><td>M</td><td>ERP</td><td>W</td><td>M</td><td>ERP</td></tr><tr><td> NoSignal </td><td>64.10</td><td>35.02</td><td>0.43</td><td>63.31</td><td>34.41</td><td>0.42</td><td>64.26</td><td>34.92</td><td>0.44</td><td>59.49</td><td>32.33</td><td>0.38</td><td>56.62</td><td>30.93</td><td>0.37</td></tr><tr><td> GoogleTrends </td><td>63.52</td><td>34.70</td><td>0.42</td><td>65.87</td><td>35.80</td><td>0.44</td><td>68.46</td><td>37.21</td><td>0.48</td><td>59.02</td><td>32.08</td><td>0.38</td><td>55.24</td><td>30.18</td><td>0.33</td></tr><tr><td> POPSignal </td><td>63.38</td><td>34.62</td><td>0.42</td><td>57.43</td><td>31.37</td><td>0.36</td><td>58.38</td><td>31.89</td><td>0.39</td><td>57.36</td><td>31.33</td><td>0.36</td><td>52.39</td><td>28.62</td><td>0.29</td></tr></table>", "caption": "Table 2: Results on VISUELLE with the release setup; \u201cW\u201d stands for WAPE, \u201cM\u201d for MAE. Lower is better for all metrics.", "list_citation_info": ["[9] Ekambaram, V., Manglik, K., Mukherjee, S., Sajja, S.S.K., Dwivedi, S., Raykar, V.: Attention based Multi-Modal New Product Sales Time-series Forecasting. In: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, Virtual Event CA USA (Aug 2020). https://doi.org/10.1145/3394486.3403362, https://dl.acm.org/doi/10.1145/3394486.3403362", "[15] Ilic, I., G\u00f6rg\u00fcl\u00fc, B., Cevik, M., Baydo\u011fan, M.G.: Explainable boosted linear regression for time series forecasting. Pattern Recognition (2021)", "[35] Skenderi, G., Joppi, C., Denitto, M., Cristani, M.: Well googled is half done: Multimodal forecasting of new fashion product sales with image-based google trends. arXiv preprint arXiv:2109.09824 (2021)"]}, {"table": "<table><tr><td colspan=\"5\">Time Dependent Query Expansion</td></tr><tr><td></td><td colspan=\"2\">Release Setup</td><td colspan=\"2\">First Order Setup</td></tr><tr><td>Strategy</td><td>W</td><td>M</td><td>W</td><td>M</td></tr><tr><td>No Expansion</td><td>53.12</td><td>29.02</td><td>54.47</td><td>29.77</td></tr><tr><td>Misaligned past</td><td>53.02</td><td>28.96</td><td>53.63</td><td>29.30</td></tr><tr><td colspan=\"5\">Learning With Noisy Labels</td></tr><tr><td></td><td colspan=\"2\">Release Setup</td><td colspan=\"2\">First Order Setup</td></tr><tr><td>Strategy</td><td>W</td><td>M</td><td>W</td><td>M</td></tr><tr><td>No Learning</td><td>53.03</td><td>28.97</td><td>53.83</td><td>29.41</td></tr><tr><td>No Robust Learning</td><td>52.81</td><td>28.85</td><td>53.59</td><td>29.28</td></tr><tr><td>Symmetric Cross Entropy [39]</td><td>52.63</td><td>28.75</td><td>53.58</td><td>29.27</td></tr><tr><td>SELFIE [36]</td><td>52.56</td><td>28.71</td><td>53.51</td><td>29.23</td></tr><tr><td>POP</td><td>52.39</td><td>28.62</td><td>53.41</td><td>29.18</td></tr></table>", "caption": "Table 3: Alternative versions of our pipeline (Fig. 2) on both the release and first order  setups; \u201cW\u201d stands for WAPE, \u201cM\u201d for MAE. Lower is better for all metrics.", "list_citation_info": ["[36] Song, H., Kim, M., Lee, J.G.: Selfie: Refurbishing unclean samples for robust deep learning. In: International Conference on Machine Learning. PMLR (2019)", "[39] Wang, Y., Ma, X., Chen, Z., Luo, Y., Yi, J., Bailey, J.: Symmetric cross entropy for robust learning with noisy labels. In: Proceedings of the IEEE/CVF International Conference on Computer Vision (2019)"]}, {"table": "<table><tr><td colspan=\"13\">Global Average</td></tr><tr><td>Signals</td><td colspan=\"2\">Mean</td><td colspan=\"2\">Last</td><td colspan=\"2\">Drift</td><td colspan=\"2\">AR</td><td colspan=\"2\">ARIMA</td><td colspan=\"2\">SES</td></tr><tr><td></td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td></tr><tr><td>Oracle</td><td>0.136</td><td>0.170</td><td>0.093</td><td>0.114</td><td>0.174</td><td>0.222</td><td>0.271</td><td>0.403</td><td>0.136</td><td>0.167</td><td>0.094</td><td>0.116</td></tr><tr><td>GoogleTrends</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td></tr><tr><td>POP</td><td>0.152</td><td>0.192</td><td>0.116</td><td>0.144</td><td>0.182</td><td>0.229</td><td>0.281</td><td>0.418</td><td>0.235</td><td>0.293</td><td>0.125</td><td>0.156</td></tr><tr><td colspan=\"13\">Dresses</td></tr><tr><td>Signals</td><td colspan=\"2\">Mean</td><td colspan=\"2\">Last</td><td colspan=\"2\">Drift</td><td colspan=\"2\">AR</td><td colspan=\"2\">ARIMA</td><td colspan=\"2\">SES</td></tr><tr><td></td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td></tr><tr><td>Oracle</td><td>0.155</td><td>0.197</td><td>0.130</td><td>0.158</td><td>0.203</td><td>0.263</td><td>0.307</td><td>0.409</td><td>0.173</td><td>0.209</td><td>0.129</td><td>0.157</td></tr><tr><td>GoogleTrends</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td></tr><tr><td>POP</td><td>0.119</td><td>0.157</td><td>0.108</td><td>0.127</td><td>0.173</td><td>0.216</td><td>0.229</td><td>0.334</td><td>0.162</td><td>0.193</td><td>0.109</td><td>0.130</td></tr></table>", "caption": "Table 4: Average results over all Fashion Forward [1] dataset partitions and specific results for the Dresses partition, where POP outperforms even the original GT style popularity time series (Oracle).", "list_citation_info": ["[1] Al-Halah, Z., Stiefelhagen, R., Grauman, K.: Fashion forward: Forecasting visual style in fashion. In: ICCV (2017)"]}, {"table": "<table><tr><td colspan=\"13\">Global Average</td></tr><tr><td>Signals</td><td colspan=\"2\">Mean</td><td colspan=\"2\">Last</td><td colspan=\"2\">Drift</td><td colspan=\"2\">AR</td><td colspan=\"2\">ARIMA</td><td colspan=\"2\">SES</td></tr><tr><td></td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td></tr><tr><td>Oracle</td><td>0.136</td><td>0.170</td><td>0.093</td><td>0.114</td><td>0.174</td><td>0.222</td><td>0.271</td><td>0.403</td><td>0.136</td><td>0.167</td><td>0.094</td><td>0.116</td></tr><tr><td>GoogleTrends</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td><td>0.846</td><td>1.000</td></tr><tr><td>POP</td><td>0.152</td><td>0.192</td><td>0.116</td><td>0.144</td><td>0.182</td><td>0.229</td><td>0.281</td><td>0.418</td><td>0.235</td><td>0.293</td><td>0.125</td><td>0.156</td></tr><tr><td colspan=\"13\">Dresses</td></tr><tr><td>Signals</td><td colspan=\"2\">Mean</td><td colspan=\"2\">Last</td><td colspan=\"2\">Drift</td><td colspan=\"2\">AR</td><td colspan=\"2\">ARIMA</td><td colspan=\"2\">SES</td></tr><tr><td></td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td></tr><tr><td>Oracle</td><td>0.155</td><td>0.197</td><td>0.130</td><td>0.158</td><td>0.203</td><td>0.263</td><td>0.307</td><td>0.409</td><td>0.173</td><td>0.209</td><td>0.129</td><td>0.157</td></tr><tr><td>GoogleTrends</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td><td>0.849</td><td>1.000</td></tr><tr><td>POP</td><td>0.119</td><td>0.157</td><td>0.108</td><td>0.127</td><td>0.173</td><td>0.216</td><td>0.229</td><td>0.334</td><td>0.162</td><td>0.193</td><td>0.109</td><td>0.130</td></tr><tr><td colspan=\"13\">Shirts</td></tr><tr><td>Signals</td><td colspan=\"2\">Mean</td><td colspan=\"2\">Last</td><td colspan=\"2\">Drift</td><td colspan=\"2\">AR</td><td colspan=\"2\">ARIMA</td><td colspan=\"2\">SES</td></tr><tr><td></td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td></tr><tr><td>Oracle</td><td>0.122</td><td>0.149</td><td>0.075</td><td>0.097</td><td>0.148</td><td>0.190</td><td>0.301</td><td>0.371</td><td>0.126</td><td>0.159</td><td>0.080</td><td>0.103</td></tr><tr><td>GoogleTrends</td><td>0.840</td><td>1.000</td><td>0.840</td><td>1.000</td><td>0.840</td><td>1.000</td><td>0.840</td><td>1.000</td><td>0.840</td><td>1.000</td><td>0.840</td><td>1.000</td></tr><tr><td>POP</td><td>0.144</td><td>0.175</td><td>0.109</td><td>0.152</td><td>0.166</td><td>0.215</td><td>0.274</td><td>0.336</td><td>0.139</td><td>0.189</td><td>0.111</td><td>0.151</td></tr><tr><td colspan=\"13\">Tops&amp;Tees</td></tr><tr><td>Signals</td><td colspan=\"2\">Mean</td><td colspan=\"2\">Last</td><td colspan=\"2\">Drift</td><td colspan=\"2\">AR</td><td colspan=\"2\">ARIMA</td><td colspan=\"2\">SES</td></tr><tr><td></td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td><td>MAE</td><td>MAPE</td></tr><tr><td>Oracle</td><td>0.132</td><td>0.165</td><td>0.074</td><td>0.087</td><td>0.172</td><td>0.212</td><td>0.206</td><td>0.429</td><td>0.108</td><td>0.133</td><td>0.073</td><td>0.087</td></tr><tr><td>GoogleTrends</td><td>0.848</td><td>1.000</td><td>0.848</td><td>1.000</td><td>0.848</td><td>1.000</td><td>0.848</td><td>1.000</td><td>0.848</td><td>1.000</td><td>0.848</td><td>1.000</td></tr><tr><td>POP</td><td>0.193</td><td>0.245</td><td>0.131</td><td>0.153</td><td>0.206</td><td>0.257</td><td>0.341</td><td>0.585</td><td>0.405</td><td>0.497</td><td>0.156</td><td>0.186</td></tr></table>", "caption": "Table 6: Results across all the Fashion Forward [1] datasets.", "list_citation_info": ["[1] Al-Halah, Z., Stiefelhagen, R., Grauman, K.: Fashion forward: Forecasting visual style in fashion. In: ICCV (2017)"]}]}