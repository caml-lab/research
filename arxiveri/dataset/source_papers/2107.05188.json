{"title": "TransClaw U-Net: Claw U-Net with transformers for medical image segmentation", "abstract": "In recent years, computer-aided diagnosis has become an increasingly popular topic. Methods based on convolutional neural networks have achieved good performance in medical image segmentation and classification. Due to the limitations of the convolution operation, the long-term spatial features are often not accurately obtained. Hence, we propose a TransClaw U-Net network structure, which combines the convolution operation with the transformer operation in the encoding part. The convolution part is applied for extracting the shallow spatial features to facilitate the recovery of the image resolution after upsampling. The transformer part is used to encode the patches, and the self-attention mechanism is used to obtain global information between sequences. The decoding part retains the bottom upsampling structure for better detail segmentation performance. The experimental results on Synapse Multi-organ Segmentation Datasets show that the performance of TransClaw U-Net is better than other network structures. The ablation experiments also prove the generalization performance of TransClaw U-Net.", "authors": ["Yao Chang", " Hu Menghan", " Zhai Guangtao", " Zhang Xiao-Ping"], "pdf_url": "https://arxiv.org/abs/2107.05188", "list_table_and_caption": [{"table": "<table><thead><tr><th>Model</th><th>DSC</th><th>HD</th><th>Aorta</th><th>Gallbladder</th><th>Kidney(L)</th><th>Kidney(R)</th><th>Liver</th><th>Pancreas</th><th>Spleen</th><th>Stomach</th></tr></thead><tbody><tr><th>V-Net [29]</th><td>68.81</td><td>-</td><td>75.34</td><td>51.87</td><td>77.10</td><td>80.75</td><td>87.84</td><td>40.05</td><td>80.56</td><td>56.98</td></tr><tr><th>DARR [30]</th><td>69.77</td><td>-</td><td>74.74</td><td>53.77</td><td>72.31</td><td>73.24</td><td>94.08</td><td>54.18</td><td>89.90</td><td>45.96</td></tr><tr><th>U-Net [3]</th><td>76.85</td><td>39.70</td><td>89.07</td><td>69.72</td><td>77.77</td><td>68.60</td><td>93.43</td><td>53.98</td><td>86.67</td><td>75.58</td></tr><tr><th>R50 U-Net [13]</th><td>74.68</td><td>36.87</td><td>87.74</td><td>63.66</td><td>80.60</td><td>78.19</td><td>93.74</td><td>56.90</td><td>85.87</td><td>74.16</td></tr><tr><th>R50 Att-UNet [13]</th><td>75.57</td><td>36.97</td><td>55.92</td><td>63.91</td><td>79.20</td><td>72.71</td><td>93.56</td><td>49.37</td><td>87.19</td><td>74.95</td></tr><tr><th>R50 ViT [13]</th><td>71.29</td><td>32.87</td><td>73.73</td><td>55.13</td><td>75.80</td><td>72.20</td><td>91.51</td><td>45.99</td><td>81.99</td><td>73.95</td></tr><tr><th>TransUNet [13]</th><td>77.48</td><td>31.69</td><td>87.23</td><td>63.13</td><td>81.87</td><td>77.02</td><td>94.08</td><td>55.86</td><td>85/08</td><td>75.62</td></tr><tr><th>TransClaw U-Net</th><td>78.09</td><td>26.38</td><td>85.87</td><td>61.38</td><td>84.83</td><td>79.36</td><td>94.28</td><td>57.65</td><td>87.74</td><td>73.55</td></tr></tbody></table>", "caption": "Table 1: Comparison of model performance on the Synapse multi-organ CT dataset. The best performers are highlighted in bold.", "list_citation_info": ["[30] Shuhao Fu, Yongyi Lu, Yan Wang, Yuyin Zhou, Wei Shen, Elliot Fishman, and Alan Yuille, \u201cDomain adaptive relational reasoning for 3d multi-organ segmentation,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2020, pp. 656\u2013666.", "[29] Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi, \u201cV-net: Fully convolutional neural networks for volumetric medical image segmentation,\u201d in 2016 fourth international conference on 3D vision (3DV). IEEE, 2016, pp. 565\u2013571.", "[13] Jieneng Chen, Yongyi Lu, Qihang Yu, Xiangde Luo, Ehsan Adeli, Yan Wang, Le Lu, Alan L Yuille, and Yuyin Zhou, \u201cTransunet: Transformers make strong encoders for medical image segmentation,\u201d arXiv preprint arXiv:2102.04306, 2021.", "[3] Olaf Ronneberger, Philipp Fischer, and Thomas Brox, \u201cU-net: Convolutional networks for biomedical image segmentation,\u201d in International Conference on Medical image computing and computer-assisted intervention. Springer, 2015, pp. 234\u2013241."]}]}