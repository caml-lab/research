{"title": "Sketch2Model: View-Aware 3D Modeling from Single Free-Hand Sketches", "abstract": "We investigate the problem of generating 3D meshes from single free-hand sketches, aiming at fast 3D modeling for novice users. It can be regarded as a single-view reconstruction problem, but with unique challenges, brought by the variation and conciseness of sketches. Ambiguities in poorly-drawn sketches could make it hard to determine how the sketched object is posed. In this paper, we address the importance of viewpoint specification for overcoming such ambiguities, and propose a novel view-aware generation approach. By explicitly conditioning the generation process on a given viewpoint, our method can generate plausible shapes automatically with predicted viewpoints, or with specified viewpoints to help users better express their intentions. Extensive evaluations on various datasets demonstrate the effectiveness of our view-aware design in solving sketch ambiguities and improving reconstruction quality.", "authors": ["Song-Hai Zhang", " Yuan-Chen Guo", " Qing-Wen Gu"], "pdf_url": "https://arxiv.org/abs/2105.06663", "list_table_and_caption": [{"table": "<table><thead><tr><th>Category</th><th>airplane</th><th>bench</th><th>cabinet</th><th>car</th><th>chair</th><th>display</th><th>lamp</th><th>loudspeaker</th><th>rifle</th><th>sofa</th><th>table</th><th>telephone</th><th>watercraft</th><th>mean</th></tr></thead><tbody><tr><th>Retrieval</th><td>0.411</td><td>0.219</td><td>0.409</td><td>0.626</td><td>0.238</td><td>0.338</td><td>0.223</td><td>0.365</td><td>0.413</td><td>0.431</td><td>0.232</td><td>0.536</td><td>0.369</td><td>0.370</td></tr><tr><th>SoftRas</th><td>0.469</td><td>0.347</td><td>0.545</td><td>0.648</td><td>0.361</td><td>0.472</td><td>0.328</td><td>0.533</td><td>0.541</td><td>0.534</td><td>0.359</td><td>0.537</td><td>0.456</td><td>0.472</td></tr><tr><th>Ours (pred)</th><td>0.479</td><td>0.357</td><td>0.547</td><td>0.649</td><td>0.383</td><td>0.435</td><td>0.336</td><td>0.526</td><td>0.510</td><td>0.528</td><td>0.361</td><td>0.551</td><td>0.450</td><td>0.470</td></tr><tr><th>Ours (gt)</th><td>0.487</td><td>0.366</td><td>0.568</td><td>0.659</td><td>0.393</td><td>0.479</td><td>0.338</td><td>0.544</td><td>0.534</td><td>0.534</td><td>0.357</td><td>0.554</td><td>0.466</td><td>0.483</td></tr><tr><th>Ours + DA (pred)</th><td>0.515</td><td>0.362</td><td>-</td><td>0.659</td><td>0.385</td><td>-</td><td>-</td><td>-</td><td>0.511</td><td>0.533</td><td>0.360</td><td>-</td><td>-</td><td>0.475</td></tr><tr><th>Ours + DA (gt)</th><td>0.526</td><td>0.367</td><td>-</td><td>0.679</td><td>0.398</td><td>-</td><td>-</td><td>-</td><td>0.535</td><td>0.548</td><td>0.357</td><td>-</td><td>-</td><td>0.489</td></tr></tbody></table>", "caption": "Table 3: Mean voxel IoU on ShapeNet-Sketch dataset. We apply domain adaptation (DA) on 7 of the classes, which have considerable amount of sketches in the Sketchy database [30] and Tu-Berlin dataset [7]. Our method with domain adaptation achieves the highest IoU score, and shows significant improvement on airplane, car and sofa.", "list_citation_info": ["[30] Patsorn Sangkloy, Nathan Burnell, Cusuh Ham, and James Hays. The sketchy database: learning to retrieve badly drawn bunnies. ACM Transactions on Graphics (TOG), 35(4):1\u201312, 2016.", "[7] Mathias Eitz, James Hays, and Marc Alexa. How do humans sketch objects? ACM Transactions on graphics (TOG), 31(4):1\u201310, 2012."]}]}