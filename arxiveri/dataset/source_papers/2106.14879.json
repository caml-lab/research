{"title": "Modeling clothing as a separate layer for an animatable human avatar", "abstract": "We have recently seen great progress in building photorealistic animatable full-body codec avatars, but generating high-fidelity animation of clothing is still difficult. To address these difficulties, we propose a method to build an animatable clothed body avatar with an explicit representation of the clothing on the upper body from multi-view captured videos. We use a two-layer mesh representation to register each 3D scan separately with the body and clothing templates. In order to improve the photometric correspondence across different frames, texture alignment is then performed through inverse rendering of the clothing geometry and texture predicted by a variational autoencoder. We then train a new two-layer codec avatar with separate modeling of the upper clothing and the inner body layer. To learn the interaction between the body dynamics and clothing states, we use a temporal convolution network to predict the clothing latent code based on a sequence of input skeletal poses. We show photorealistic animation output for three different actors, and demonstrate the advantage of our clothed-body avatars over the single-layer avatars used in previous work. We also show the benefit of an explicit clothing model that allows the clothing texture to be edited in the animation output.", "authors": ["Donglai Xiang", " Fabian Prada", " Timur Bagautdinov", " Weipeng Xu", " Yuan Dong", " He Wen", " Jessica Hodgins", " Chenglei Wu"], "pdf_url": "https://arxiv.org/abs/2106.14879", "list_table_and_caption": [{"table": "<table><thead><tr><th rowspan=\"2\">Sequence</th><th colspan=\"2\">(Bagautdinov et al., 2021)</th><th colspan=\"2\">Ours</th></tr><tr><th><p>MSE\\downarrow</p></th><th><p>SSIM\\uparrow</p></th><th><p>MSE\\downarrow</p></th><th><p>SSIM\\uparrow</p></th></tr></thead><tbody><tr><th>Subject 1</th><td><p>100.57</p></td><td><p>0.8720</p></td><td>74.73</td><td>0.8816</td></tr><tr><th>Subject 2</th><td><p>81.95</p></td><td><p>0.8804</p></td><td>58.14</td><td>0.8917</td></tr><tr><th>Subject 3</th><td><p>456.20</p></td><td><p>0.8159</p></td><td>356.52</td><td>0.8230</td></tr></tbody></table>", "caption": "Table 1. Quantitative comparison between our proposed method and the previous work. We report Mean Square Error (lower better) and the Structural Similarity Index Measure (higher better) on all three testing sequences.", "list_citation_info": ["Bagautdinov et al. (2021) Timur Bagautdinov, Chenglei Wu, Tomas Simon, Fabian Prada, Takaaki Shiratori, Shih-En Wei, Weipeng Xu, Yaser Sheikh, and Jason Saragih. 2021. Driving-signal aware full-body avatars. ACM Transactions on Graphics (TOG) 40, 4 (2021), 1\u201317."]}]}