{"title": "Shelf-supervised mesh prediction in the wild", "abstract": "We aim to infer 3D shape and pose of object from a single image and propose a learning-based approach that can train from unstructured image collections, supervised by only segmentation outputs from off-the-shelf recognition systems (i.e. 'shelf-supervised'). We first infer a volumetric representation in a canonical frame, along with the camera pose. We enforce the representation geometrically consistent with both appearance and masks, and also that the synthesized novel views are indistinguishable from image collections. The coarse volumetric prediction is then converted to a mesh-based representation, which is further refined in the predicted camera frame. These two steps allow both shape-pose factorization from image collections and per-instance reconstruction in finer details. We examine the method on both synthetic and real-world datasets and demonstrate its scalability on 50 categories in the wild, an order of magnitude more classes than existing works.", "authors": ["Yufei Ye", " Shubham Tulsiani", " Abhinav Gupta"], "pdf_url": "https://arxiv.org/abs/2102.06195", "list_table_and_caption": [{"table": "<table><tbody><tr><td></td><td><p>[15]</p></td><td><p>[24]</p></td><td><p>[17]</p></td><td><p>[19]</p></td><td><p>[46]</p></td><td><p>[52]</p></td><td><p>[35]</p></td><td><p>[8]</p></td><td><p>[28]</p></td><td>ours</td></tr><tr><td>pose</td><td><p>\u2713</p></td><td></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>template</td><td></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>semantic</td><td></td><td></td><td><p>\u2713</p></td><td></td><td></td><td></td><td></td><td></td><td><p>(\u2713)</p></td><td></td></tr><tr><td>multi-view</td><td></td><td></td><td></td><td></td><td><p>\u2713</p></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>mask</td><td><p>(\u2713)</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td></td><td></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td>\u2713</td></tr><tr><td>3D recon.</td><td></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>(\u2713)</p></td><td></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td>\u2713</td></tr><tr><td>topology</td><td></td><td></td><td></td><td></td><td><p>\u2713</p></td><td></td><td></td><td><p>\u2713</p></td><td></td><td>\u2713</td></tr><tr><td>texture</td><td><p>\u2713</p></td><td></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td><p>\u2713</p></td><td></td><td><p>\u2713</p></td><td>\u2713</td></tr></tbody></table>", "caption": "Table 1: Comparing ours to other image-based supervised works in terms of supervision and outputs.", "list_citation_info": ["[19] Hiroharu Kato and Tatsuya Harada. Learning view priors for single-view 3d reconstruction. In CVPR, 2019.", "[17] Angjoo Kanazawa, Shubham Tulsiani, Alexei A. Efros, and Jitendra Malik. Learning category-specific mesh reconstruction from image collections. In ECCV, 2018.", "[24] Nilesh Kulkarni, Abhinav Gupta, David Fouhey, and Shubham Tulsiani. Articulation-aware canonical surface mapping. In CVPR, 2020.", "[8] Matheus Gadelha, Subhransu Maji, and Rui Wang. 3d shape induction from 2d views of multiple objects. In 3DV, 2017.", "[52] Shangzhe Wu, Christian Rupprecht, and Andrea Vedaldi. Unsupervised learning of probably symmetric deformable 3d objects from images in the wild. In CVPR, 2020.", "[15] Paul Henderson, Vagia Tsiminaki, and Christoph H Lampert. Leveraging 2d data to learn textured 3d mesh generation. In CVPR, 2020.", "[35] Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, and Yong-Liang Yang. Hologan: Unsupervised learning of 3d representations from natural images. In ICCV, 2019.", "[46] Shubham Tulsiani, Tinghui Zhou, Alexei A. Efros, and Jitendra Malik. Multi-view supervision for single-view reconstruction via differentiable ray consistency. TPAMI, 2019.", "[28] Xueting Li, Sifei Liu, Kihwan Kim, Shalini De Mello, Varun Jampani, Ming-Hsuan Yang, and Jan Kautz. Self-supervised single-view 3d reconstruction via semantic consistency. arXiv preprint arXiv:2003.06473, 2020."]}, {"table": "<table><tbody><tr><th></th><td>airplane</td><td>car</td><td>chair</td></tr><tr><th>HoloGAN [35]</th><td>0.28/ 0.31</td><td>0.43 / 0.44</td><td>0.26 / 0.25</td></tr><tr><th>PrGAN [8]</th><td>0.29/ 0.18</td><td>0.48 / 0.37</td><td>0.28 / 0.28</td></tr><tr><th>Ours</th><td>0.33 / 0.46</td><td>0.55 / 0.43</td><td>0.31 / 0.29</td></tr><tr><th>Ours (refined)</th><td>\u2014- / 0.49</td><td>\u2014- / 0.42</td><td>\u2014- / 0.31</td></tr></tbody></table>", "caption": "Table 2: Quantitative results (3D IoU / F-score) on synthetic data comparing different methods for shape reconstruction. ", "list_citation_info": ["[8] Matheus Gadelha, Subhransu Maji, and Rui Wang. 3d shape induction from 2d views of multiple objects. In 3DV, 2017.", "[35] Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, and Yong-Liang Yang. Hologan: Unsupervised learning of 3d representations from natural images. In ICCV, 2019."]}]}