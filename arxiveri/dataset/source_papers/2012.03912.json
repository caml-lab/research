{"title": "Multion: Benchmarking Semantic Map Memory Using Multi-Object Navigation", "abstract": "Navigation tasks in photorealistic 3D environments are challenging because they require perception and effective planning under partial observability. Recent work shows that map-like memory is useful for long-horizon navigation tasks. However, a focused investigation of the impact of maps on navigation tasks of varying complexity has not yet been performed. We propose the multiON task, which requires navigation to an episode-specific sequence of objects in a realistic environment. MultiON generalizes the ObjectGoal navigation task and explicitly tests the ability of navigation agents to locate previously observed goal objects. We perform a set of multiON experiments to examine how a variety of agent models perform across a spectrum of navigation task complexities. Our experiments show that: i) navigation performance degrades dramatically with escalating task complexity; ii) a simple semantic map agent performs surprisingly well relative to more complex neural image feature map agents; and iii) even oracle map agents achieve relatively low performance, indicating the potential for future work in training embodied navigation agents using maps. Video summary: https://youtu.be/yqTlHNIcgnY", "authors": ["Saim Wani", " Shivansh Patel", " Unnat Jain", " Angel X. Chang", " Manolis Savva"], "pdf_url": "https://arxiv.org/abs/2012.03912", "list_table_and_caption": [{"table": "<table><thead><tr><th>Task</th><th>Environment</th><th>Position control</th><th># Objects</th><th>Goal</th><th>Evaluation</th></tr></thead><tbody><tr><th>Search Fang et al. (2019)</th><td>Synthetic</td><td>\u2717</td><td>6</td><td>all in any order</td><td>reward, classes found</td></tr><tr><th>Ordered k-item Beeching et al. (2019)</th><td>VizDoom Kempka et al. (2016)</td><td>\u2713</td><td>4 or 6</td><td>fixed set, in order</td><td>reward</td></tr><tr><th>MultiON (ours)</th><td>Habitat Savva et al. (2019)</td><td>\u2713</td><td>arbitrary</td><td>episode-specific ordered set</td><td>success &amp; efficiency metrics</td></tr></tbody></table>", "caption": "Table 1: Comparison of multiON to navigation tasks with multiple object goals from prior work. Note that prior work does not adopt a found action, so incidental navigation to a goal is treated as success. Moreover, the set of objects is held fixed, with no episode-specifity for the goal objects.", "list_citation_info": ["Beeching et al. [2019] E. Beeching, C. Wolf, J. Dibangoye, and O. Simonin. Deep reinforcement learning on a budget: 3D control and reasoning without a supercomputer. arXiv preprint arXiv:1904.01806, 2019.", "Kempka et al. [2016] M. Kempka, M. Wydmuch, G. Runc, J. Toczek, and W. Jakowski. VizDoom: A Doom-based AI research platform for visual reinforcement learning. In Proc. IEEE Conf. on Computational Intelligence and Games, 2016.", "Fang et al. [2019] K. Fang, A. Toshev, L. Fei-Fei, and S. Savarese. Scene memory transformer for embodied agents in long-horizon tasks. In CVPR, 2019.", "Savva et al. [2019] M. Savva, A. Kadian, O. Maksymets, Y. Zhao, E. Wijmans, B. Jain, J. Straub, J. Liu, V. Koltun, J. Malik, D. Parikh, and D. Batra. Habitat: A platform for embodied AI research. In ICCV, 2019."]}, {"table": "<table><tbody><tr><th></th><th></th><td colspan=\"3\">Success (%)</td><td colspan=\"3\">Progress (%)</td><td colspan=\"3\">SPL (%)</td><td colspan=\"3\">PPL (%)</td></tr><tr><th></th><th></th><td>1-ON</td><td>2-ON</td><td>3-ON</td><td>1-ON</td><td>2-ON</td><td>3-ON</td><td>1-ON</td><td>2-ON</td><td>3-ON</td><td>1-ON</td><td>2-ON</td><td>3-ON</td></tr><tr><th></th><th>Rand</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><th></th><th>Rand+OracleFound</th><td>26</td><td>8</td><td>2</td><td>26</td><td>16</td><td>12</td><td>8</td><td>2</td><td>1</td><td>8</td><td>5</td><td>4</td></tr><tr><th rowspan=\"3\">NoMap</th><th>NoMap(RNN)</th><td>62</td><td>24</td><td>10</td><td>62</td><td>39</td><td>24</td><td>35</td><td>13</td><td>4</td><td>35</td><td>21</td><td>14</td></tr><tr><th>FRMQN Oh et al. (2016)</th><td>62</td><td>29</td><td>13</td><td>62</td><td>42</td><td>29</td><td>50</td><td>24</td><td>11</td><td>50</td><td>33</td><td>24</td></tr><tr><th>SMT Fang et al. (2019)</th><td>63</td><td>28</td><td>9</td><td>63</td><td>44</td><td>22</td><td>48</td><td>26</td><td>7</td><td>48</td><td>36</td><td>18</td></tr><tr><th rowspan=\"4\">Oracle</th><th>OracleMap (Occ+Obj)</th><td>94</td><td>74</td><td>48</td><td>94</td><td>79</td><td>62</td><td>77</td><td>59</td><td>38</td><td>77</td><td>63</td><td>49</td></tr><tr><th>OracleMap (Occ)</th><td>66</td><td>34</td><td>16</td><td>66</td><td>47</td><td>36</td><td>48</td><td>25</td><td>12</td><td>48</td><td>35</td><td>27</td></tr><tr><th>OracleMap (Obj)</th><td>94</td><td>82</td><td>59</td><td>94</td><td>86</td><td>70</td><td>79</td><td>65</td><td>42</td><td>79</td><td>67</td><td>50</td></tr><tr><th>OracleEgoMap (Occ+Obj)</th><td>83</td><td>64</td><td>37</td><td>83</td><td>71</td><td>54</td><td>65</td><td>49</td><td>25</td><td>65</td><td>54</td><td>36</td></tr><tr><th rowspan=\"3\">Learned</th><th>EgoMap Beeching et al. (2020)</th><td>69</td><td>46</td><td>26</td><td>69</td><td>59</td><td>44</td><td>49</td><td>31</td><td>\\mathbf{18}</td><td>49</td><td>42</td><td>30</td></tr><tr><th>ProjNeuralMap</th><td>70</td><td>45</td><td>\\mathbf{27}</td><td>70</td><td>57</td><td>\\mathbf{46}</td><td>51</td><td>30</td><td>\\mathbf{18}</td><td>51</td><td>39</td><td>\\mathbf{31}</td></tr><tr><th>ObjRecogMap</th><td>\\mathbf{79}</td><td>\\mathbf{51}</td><td>22</td><td>\\mathbf{79}</td><td>\\mathbf{62}</td><td>40</td><td>\\mathbf{56}</td><td>\\mathbf{38}</td><td>17</td><td>\\mathbf{56}</td><td>\\mathbf{45}</td><td>30</td></tr></tbody></table>", "caption": "Table 2: Agent performance on 1-ON, 2-ON and 3-ON test set (maximum 2@500 steps). The multiON task is challenging with Rand+OracleFound achieving 26\\% success (SPL 8\\%) for 1-ON, and Rand failing completely. Performance decreases for all agents as we add more objects. Overall, maps help considerably, with the ability to represent goal objects in the map being particularly valuable (compare OracleMap (Obj) and OracleMap (Occ) as well as ObjRecogMap and ProjNeuralMap).", "list_citation_info": ["Fang et al. [2019] K. Fang, A. Toshev, L. Fei-Fei, and S. Savarese. Scene memory transformer for embodied agents in long-horizon tasks. In CVPR, 2019.", "Beeching et al. [2020] E. Beeching, C. Wolf, J. Dibangoye, and O. Simonin. EgoMap: Projective mapping and structured egocentric memory for deep RL. arXiv preprint arXiv:2002.02286, 2020.", "Oh et al. [2016] J. Oh, V. Chockalingam, S. Singh, and H. Lee. Control of memory, active perception, and action in minecraft. In ICML, 2016."]}]}