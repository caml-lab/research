{"title": "Polarity loss for zero-shot object detection", "abstract": "Conventional object detection models require large amounts of training data. In comparison, humans can recognize previously unseen objects by merely knowing their semantic description. To mimic similar behaviour, zero-shot object detection aims to recognize and localize 'unseen' object instances by using only their semantic information. The model is first trained to learn the relationships between visual and semantic domains for seen objects, later transferring the acquired knowledge to totally unseen objects. This setting gives rise to the need for correct alignment between visual and semantic concepts, so that the unseen objects can be identified using only their semantic attributes. In this paper, we propose a novel loss function called 'Polarity loss', that promotes correct visual-semantic alignment for an improved zero-shot object detection. On one hand, it refines the noisy semantic embeddings via metric learning on a 'Semantic vocabulary' of related concepts to establish a better synergy between visual and semantic domains. On the other hand, it explicitly maximizes the gap between positive and negative predictions to achieve better discrimination between seen, unseen and background objects. Our approach is inspired by embodiment theories in cognitive science, that claim human semantic understanding to be grounded in past experiences (seen objects), related linguistic concepts (word vocabulary) and visual perception (seen/unseen object images). We conduct extensive evaluations on MS-COCO and Pascal VOC datasets, showing significant improvements over state of the art.", "authors": ["Shafin Rahman", " Salman Khan", " Nick Barnes"], "pdf_url": "https://arxiv.org/abs/1811.08982", "list_table_and_caption": [{"table": "<table><tr><td><p>Method</p></td><td><p>Seen</p></td><td><p>Unseen</p></td><td><p>aeroplane</p></td><td><p>bicycle</p></td><td><p>bird</p></td><td><p>boat</p></td><td><p>bottle</p></td><td><p>bus</p></td><td><p>cat</p></td><td><p>chair</p></td><td><p>cow</p></td><td><p>d.table</p></td><td><p>horse</p></td><td><p>motrobike</p></td><td><p>person</p></td><td><p>p.plant</p></td><td><p>sheep</p></td><td><p>tvmonitor</p></td><td><p>car</p></td><td><p>dog</p></td><td><p>sofa</p></td><td><p>train</p></td></tr><tr><td>Demirel et al.[3]</td><td>57.9</td><td>54.5</td><td>68.0</td><td>72.0</td><td>74.0</td><td>48.0</td><td>41.0</td><td>61.0</td><td>48.0</td><td>25.0</td><td>48.0</td><td>73.0</td><td>75.0</td><td>71.0</td><td>73.0</td><td>33.0</td><td>59.0</td><td>57.0</td><td>55.0</td><td>82.0</td><td>55.0</td><td>26.0</td></tr><tr><td>Ours</td><td>63.5</td><td>62.1</td><td>74.4</td><td>71.2</td><td>67.0</td><td>50.1</td><td>50.8</td><td>67.6</td><td>84.7</td><td>44.8</td><td>68.6</td><td>39.6</td><td>74.9</td><td>76.0</td><td>79.5</td><td>39.6</td><td>61.6</td><td>66.1</td><td>63.7</td><td>87.2</td><td>53.2</td><td>44.1</td></tr></table>", "caption": "TABLE II: mAP scores of Pascal VOC\u201907. Italic classes are unseen.", "list_citation_info": ["[3] B. Demirel, R. G. Cinbis, and N. Ikizler-Cinbis, \u201cZero-shot object detection by hybrid region embedding,\u201d in British Machine Vision Conference (BMVC), Sep. 2018."]}]}