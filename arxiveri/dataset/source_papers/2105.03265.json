{"title": "LatentSLAM: unsupervised multi-sensor representation learning for localization and mapping", "abstract": "Biologically inspired algorithms for simultaneous localization and mapping (SLAM) such as RatSLAM have been shown to yield effective and robust robot navigation in both indoor and outdoor environments. One drawback however is the sensitivity to perceptual aliasing due to the template matching of low-dimensional sensory templates. In this paper, we propose an unsupervised representation learning method that yields low-dimensional latent state descriptors that can be used for RatSLAM. Our method is sensor agnostic and can be applied to any sensor modality, as we illustrate for camera images, radar range-doppler maps and lidar scans. We also show how combining multiple sensors can increase the robustness, by reducing the number of false matches. We evaluate on a dataset captured with a mobile robot navigating in a warehouse-like environment, moving through different aisles with similar appearance, making it hard for the SLAM algorithms to disambiguate locations.", "authors": ["Ozan \u00c7atal", " Wouter Jansen", " Tim Verbelen", " Bart Dhoedt", " Jan Steckel"], "pdf_url": "https://arxiv.org/abs/2105.03265", "list_table_and_caption": [{"table": "<table><thead><tr><th></th><th>scenario 3A</th><th>scenario 3B</th><th>scenario 5</th><th>scenario 6</th></tr></thead><tbody><tr><th><p>RTAB-Map [28]</p></th><td><img/></td><td><img/></td><td><img/></td><td><img/></td></tr><tr><th><p>RatSLAM [4]</p></th><td><img/></td><td><img/></td><td><img/></td><td><img/></td></tr><tr><th><p>odometry</p></th><td><img/></td><td><img/></td><td><img/></td><td><img/></td></tr><tr><th><p>LatentSLAM</p><p>camera</p></th><td><img/></td><td><img/></td><td><img/></td><td><img/></td></tr><tr><th><p>LatentSLAM</p><p>range-doppler</p></th><td><img/></td><td><img/></td><td><img/></td><td><img/></td></tr><tr><th><p>LatentSLAM</p><p>camera \\oplus range-doppler</p></th><td><img/></td><td><img/></td><td><img/></td><td><img/></td></tr><tr><th><p>LatentSLAM</p><p>max(camera \\oplus ran-dop), lidar)</p></th><td><img/></td><td><img/></td><td><img/></td><td><img/></td></tr></tbody></table>", "caption": "TABLE I: Resulting maps created by LatentSLAM using camera, range-doppler, lidar or a combination thereof. We compare against RTAB-Map [28], RatSLAM [4] and raw odometry.", "list_citation_info": ["[4] M. J. Milford, G. F. Wyeth, and D. Prasser, \u201cRatslam: a hippocampal model for simultaneous localization and mapping,\u201d in IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA \u201904. 2004, vol. 1, 2004, pp. 403\u2013408 Vol.1.", "[28] M. Labb\u00e9 and F. Michaud, \u201cRtab-map as an open-source lidar and visual simultaneous localization and mapping library for large-scale and long-term online operation,\u201d Journal of Field Robotics, vol. 36, no. 2, pp. 416\u2013446, 2019. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21831"]}]}