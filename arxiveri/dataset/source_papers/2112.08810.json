{"title": "Pure Noise to the Rescue of Insufficient Data: Improving Imbalanced Classification by Training on Random Noise Images", "abstract": "Despite remarkable progress on visual recognition tasks, deep neural-nets still struggle to generalize well when training data is scarce or highly imbalanced, rendering them extremely vulnerable to real-world examples. In this paper, we present a surprisingly simple yet highly effective method to mitigate this limitation: using pure noise images as additional training data. Unlike the common use of additive noise or adversarial noise for data augmentation, we propose an entirely different perspective by directly training on pure random noise images. We present a new Distribution-Aware Routing Batch Normalization layer (DAR-BN), which enables training on pure noise images in addition to natural images within the same network. This encourages generalization and suppresses overfitting. Our proposed method significantly improves imbalanced classification performance, obtaining state-of-the-art results on a large variety of long-tailed image classification datasets (CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, Places-LT, and CelebA-5). Furthermore, our method is extremely simple and easy to use as a general new augmentation tool (on top of existing augmentations), and can be incorporated in any training scheme. It does not require any specialized data generation or training procedures, thus keeping training fast and efficient.", "authors": ["Shiran Zada", " Itay Benou", " Michal Irani"], "pdf_url": "https://arxiv.org/abs/2112.08810", "list_table_and_caption": [{"table": "MethodsCIFAR-10-LTCIFAR-100-LTCelebA-5IR=100IR=50IR=100IR=50IR=10.7ERM79.6\\pm0.284.9\\pm0.447.0\\pm0.552.4\\pm0.478.6 \\pm0.1Oversampling75.1\\pm0.482.2\\pm0.442.5\\pm0.348.0\\pm0.276.4 \\pm0.2LADM-DRW{}^{\\lx@sectionsign}80.5\\pm0.685.3\\pm0.246.8\\pm0.252.6\\pm0.278.5\\pm0.5M2m{}^{\\lx@sectionsign}81.3\\pm0.485.5\\pm0.346.5\\pm0.552.9\\pm0.276.9\\pm0.4MiSLAS{}{}^{\\odot}82.185.747.052.3-OPeN84.6\\pm0.287.9\\pm0.251.5\\pm0.456.3\\pm0.479.7\\pm0.2ERM + AA81.4\\pm0.386.4\\pm0.249.9\\pm0.455.7\\pm0.479.3\\pm0.5BALMS + AA{}^{\\odot}84.9-50.8--OPeN + AA86.1\\pm0.189.2\\pm0.254.2\\pm0.559.8\\pm0.580.9\\pm0.4MethodsImageNet-LTERM51.1Oversampling      49.0BALMS{}^{\\diamondsuit}52.1LADE{}^{\\diamondsuit}53.0MisLAS{}^{\\odot}52.7MisLAS {}^{\\lx@sectionsign}53.7OPeN55.1<table><thead><tr><th>Methods</th><th>Places-LT</th></tr></thead><tbody><tr><th>ERM</th><td>29.9</td></tr><tr><th>Oversampling</th><td>38.1</td></tr><tr><th>BALMS{}^{\\odot}</th><td>38.7</td></tr><tr><th>LADE{}^{\\odot}</th><td>38.8</td></tr><tr><th>MiSLAS{}^{\\odot}</th><td>40.4</td></tr><tr><th>OPeN</th><td>40.5</td></tr></tbody></table>", "caption": "Table 1: Comparisons on CIFAR-10-LT, CIFAR-100-LT, CelebA-5. Rows with \\odot denote results as reported in the original papers. Rows with \\lx@sectionsign denote results reproduced with the same architecture as in our experiments, for fair comparison (new results are higher than reported in the original papers). AA stands for AutoAugment optimized on CIFAR-10. Missing results indicate datasets not evaluated in the cited papers. AA is not a legal augmentation for CIFAR-10-LT and ImageNet-LT (as it was optimized on their full balanced datasets). Top part of the table is thus without AA. However, since BALMS was trained with AA, we add such a comparison in the bottom part of the table.", "list_citation_info": ["Hong et al. (2021) Hong, Y., Han, S., Choi, K., Seo, S., Kim, B., and Chang, B. Disentangling label distribution for long-tailed visual recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6626\u20136636, 2021."]}, {"table": "<table><thead><tr><th>Norm Layer</th><th>CIFAR-10-LT</th><th>CIFAR-100-LT</th></tr></thead><tbody><tr><th>Standard BN (Ioffe &amp; Szegedy, 2015)</th><td>81.45\\pm0.70</td><td>49.18\\pm0.54</td></tr><tr><th>Auxiliary BN (Xie et al., 2020)</th><td>83.38\\pm0.16</td><td>50.13\\pm0.06</td></tr><tr><th>DAR-BN</th><td>84.64\\pm0.16</td><td>51.50\\pm0.44</td></tr></tbody></table>", "caption": "Table 4: Ablation study: Comparing different Batch-Norm layers.Mean accuracy on CIFAR-10/100-LT with IR=100. Each type of BN is plugged into OPeN (with same training parameters). DAR-BN outperforms the other normalization layers.", "list_citation_info": ["Xie et al. (2020) Xie, C., Tan, M., Gong, B., Wang, J., Yuille, A. L., and Le, Q. V. Adversarial examples improve image recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 819\u2013828, 2020.", "Ioffe & Szegedy (2015) Ioffe, S. and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift, 2015."]}, {"table": "<table><tbody><tr><th>Dataset</th><td># of classes</td><td>Imbalance-ratio (IR)</td><td>Largest class size</td><td>Smallest class size</td><td># of samples</td></tr><tr><th>CIFAR-10-LT (Cao et al., 2019)</th><td>10</td><td>{50\u2004,\u2004100}</td><td>5,000</td><td>{100\u2004,\u200450}</td><td>{13,996\u2004,\u200412,406}</td></tr><tr><th>CIFAR-100-LT (Cao et al., 2019)</th><td>100</td><td>{50\u2004,\u2004100}</td><td>500</td><td>{10\u2004,\u20045}</td><td>{12,608\u2004,\u200410,847}</td></tr><tr><th>ImageNet-LT (Liu et al., 2019)</th><td>1,000</td><td>256</td><td>1,200</td><td>5</td><td>115,846</td></tr><tr><th>Places-LT (Liu et al., 2019)</th><td>365</td><td>996</td><td>4,980</td><td>5</td><td>62,500</td></tr><tr><th>CelebA-5 (Kim et al., 2020)</th><td>5</td><td>10.7</td><td>2423</td><td>227</td><td>6651</td></tr></tbody></table>", "caption": "Table 5: Long-tailed datasets. Summary of the long-tailed datasets we used for evaluation.(see Sec. 4 below for a detailed explanation).", "list_citation_info": ["Liu et al. (2019) Liu, Z., Miao, Z., Zhan, X., Wang, J., Gong, B., and Yu, S. X. Large-scale long-tailed recognition in an open world. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2537\u20132546, 2019.", "Kim et al. (2020) Kim, J., Jeong, J., and Shin, J. M2m: Imbalanced classification via major-to-minor translation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 13896\u201313905, 2020.", "Cao et al. (2019) Cao, K., Wei, C., Gaidon, A., Arechiga, N., and Ma, T. Learning imbalanced datasets with label-distribution-aware margin loss. In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 1567\u20131578, 2019."]}]}