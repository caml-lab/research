{"title": "Cdec-net: Composite Deformable Cascade Network for Table Detection in Document Images", "abstract": "Localizing page elements/objects such as tables, figures, equations, etc. is the primary step in extracting information from document images. We propose a novel end-to-end trainable deep network, (CDeC-Net) for detecting tables present in the documents. The proposed network consists of a multistage extension of Mask R-CNN with a dual backbone having deformable convolution for detecting tables varying in scale with high detection accuracy at higher IoU threshold. We empirically evaluate CDeC-Net on all the publicly available benchmark datasets - ICDAR-2013, ICDAR-2017, ICDAR-2019,UNLV, Marmot, PubLayNet, and TableBank - with extensive experiments.\n  Our solution has three important properties: (i) a single trained model CDeC-Net\u2021 performs well across all the popular benchmark datasets; (ii) we report excellent performances across multiple, including higher, thresholds of IoU; (iii) by following the same protocol of the recent papers for each of the benchmarks, we consistently demonstrate the superior quantitative performance. Our code and models will be publicly released for enabling the reproducibility of the results.", "authors": ["Madhav Agarwal", " Ajoy Mondal", " C. V. Jawahar"], "pdf_url": "https://arxiv.org/abs/2008.10831", "list_table_and_caption": [{"table": "<table><thead><tr><th>Dataset</th><th>Method</th><th colspan=\"4\">Score</th></tr><tr><th></th><th></th><th>R\\uparrow</th><th>P\\uparrow</th><th>F1\\uparrow</th><th>mAP\\uparrow</th></tr></thead><tbody><tr><th>icdar-2013</th><th>decnt [3]</th><td>0.996{}^{*}</td><td>0.996{}^{*}</td><td>0.996{}^{*}</td><td>-</td></tr><tr><th></th><th>cdec-net{}^{\\ddagger} (our)</th><td>0.942</td><td>0.993</td><td>0.968</td><td>0.942</td></tr><tr><th>icadr-2017</th><th>yolov3 [18]</th><td>0.968</td><td>0.975</td><td>0.971</td><td>-</td></tr><tr><th></th><th>cdec-net{}^{\\ddagger} (our)</th><td>0.899</td><td>0.969</td><td>0.934</td><td>0.880</td></tr><tr><th>icadr-2019</th><th>tableradar [13]</th><td>0.940</td><td>0.950</td><td>0.945</td><td>-</td></tr><tr><th></th><th>cdec-net{}^{\\ddagger} (our)</th><td>0.930</td><td>0.971</td><td>0.950</td><td>0.913</td></tr><tr><th>unlv</th><th>god [10]</th><td>0.910</td><td>0.946</td><td>0.928</td><td>-</td></tr><tr><th></th><th>cdec-net{}^{\\ddagger} (our)</th><td>0.915</td><td>0.970</td><td>0.943</td><td>0.912</td></tr><tr><th>marmot</th><th>decnt [3]</th><td>0.946</td><td>0.849</td><td>0.895</td><td>-</td></tr><tr><th></th><th>cdec-net{}^{\\ddagger} (our)</th><td>0.779</td><td>0.943</td><td>0.861</td><td>0.756</td></tr><tr><th>tablebank</th><th>Li et al. [7]</th><td>0.975</td><td>0.987</td><td>0.981</td><td>-</td></tr><tr><th></th><th>cdec-net{}^{\\ddagger} (our)</th><td>0.970</td><td>0.990</td><td>0.980</td><td>0.965</td></tr><tr><th>publaynet</th><th>m-rcnn [9]</th><td>-</td><td>-</td><td>-</td><td>0.960</td></tr><tr><th></th><th>cdec-net{}^{\\ddagger} (our)</th><td>0.975</td><td>0.993</td><td>0.984</td><td>0.978</td></tr></tbody></table>", "caption": "TABLE I: Illustrates comparison between our single model cdec-net{}^{\\ddagger} and state-of-the-art techniques on existing benchmark datasets. We create the single model cdec-net{}^{\\ddagger} by training cdec-net with iiit-ar-13k and fine-tuning with training set of respective datasets. *: indicates the authors reported 0.996 in table however in discussion they mentioned 0.994. ", "list_citation_info": ["[7] M. Li, L. Cui, S. Huang, F. Wei, M. Zhou, and Z. Li, \u201cTableBank: Table benchmark for image-based table detection and recognition,\u201d arXiv, 2019.", "[13] L. Gao, Y. Huang, H. D\u00e9jean, J.-L. Meunier, Q. Yan, Y. Fang, F. Kleber, and E. Lang, \u201cICDAR 2019 competition on table detection and recognition (cTDaR),\u201d in ICDAR, 2019.", "[3] S. A. Siddiqui, M. I. Malik, S. Agne, A. Dengel, and S. Ahmed, \u201cDeCNT: Deep deformable CNN for table detection,\u201d IEEE Access, 2018.", "[9] X. Zhong, J. Tang, and A. J. Yepes, \u201cPubLayNet: largest dataset ever for document layout analysis,\u201d in ICDAR, 2019.", "[10] R. Saha, A. Mondal, and C. V. Jawahar, \u201cGraphical object detection in document images,\u201d in ICDAR, 2019.", "[18] Y. Huang, Q. Yan, Y. Li, Y. Chen, X. Wang, L. Gao, and Z. Tang, \u201cA YOLO-based table detection method,\u201d in ICDAR, 2019."]}, {"table": "<table><thead><tr><th>Dataset</th><th>Method</th><th colspan=\"4\">Score</th></tr><tr><th></th><th></th><th>R\\uparrow</th><th>P\\uparrow</th><th>F1\\uparrow</th><th>mAP\\uparrow</th></tr></thead><tbody><tr><th>icdar-2013</th><th>decnt [3]</th><td>0.996</td><td>0.996</td><td>0.996</td><td>-</td></tr><tr><th></th><th>cdec-net (our)</th><td>1.000</td><td>1.000</td><td>1.000</td><td>1.000</td></tr><tr><th>icadr-2017</th><th>yolov3 [18]</th><td>0.968</td><td>0.975</td><td>0.971</td><td>-</td></tr><tr><th></th><th>cdec-net (our)</th><td>0.924</td><td>0.970</td><td>0.947</td><td>0.912</td></tr><tr><th>icadr-2019</th><th>tableradar [13]</th><td>0.940</td><td>0.950</td><td>0.945</td><td>-</td></tr><tr><th></th><th>cdec-net (our)</th><td>0.934</td><td>0.953</td><td>0.944</td><td>0.922</td></tr><tr><th>unlv</th><th>god [10]</th><td>0.910</td><td>0.946</td><td>0.928</td><td>-</td></tr><tr><th></th><th>cdec-net (our)</th><td>0.925</td><td>0.952</td><td>0.938</td><td>0.912</td></tr><tr><th>marmot</th><th>decnt [3]</th><td>0.946</td><td>0.849</td><td>0.895</td><td>-</td></tr><tr><th></th><th>cdec-net (our)</th><td>0.930</td><td>0.975</td><td>0.952</td><td>0.911</td></tr><tr><th>tablebank</th><th>Li et al. [7]</th><td>0.975</td><td>0.987</td><td>0.981</td><td>-</td></tr><tr><th></th><th>cdec-net (our)</th><td>0.979</td><td>0.995</td><td>0.987</td><td>0.976</td></tr><tr><th>publaynet</th><th>m-rcnn [9]</th><td>-</td><td>-</td><td>-</td><td>0.960</td></tr><tr><th></th><th>cdec-net (our)</th><td>0.970</td><td>0.988</td><td>0.978</td><td>0.967</td></tr></tbody></table>", "caption": "TABLE III: Illustrates comparison between cdec-net and state-of-the-art techniques on the existing benchmark datasets. ", "list_citation_info": ["[7] M. Li, L. Cui, S. Huang, F. Wei, M. Zhou, and Z. Li, \u201cTableBank: Table benchmark for image-based table detection and recognition,\u201d arXiv, 2019.", "[13] L. Gao, Y. Huang, H. D\u00e9jean, J.-L. Meunier, Q. Yan, Y. Fang, F. Kleber, and E. Lang, \u201cICDAR 2019 competition on table detection and recognition (cTDaR),\u201d in ICDAR, 2019.", "[3] S. A. Siddiqui, M. I. Malik, S. Agne, A. Dengel, and S. Ahmed, \u201cDeCNT: Deep deformable CNN for table detection,\u201d IEEE Access, 2018.", "[9] X. Zhong, J. Tang, and A. J. Yepes, \u201cPubLayNet: largest dataset ever for document layout analysis,\u201d in ICDAR, 2019.", "[10] R. Saha, A. Mondal, and C. V. Jawahar, \u201cGraphical object detection in document images,\u201d in ICDAR, 2019.", "[18] Y. Huang, Q. Yan, Y. Li, Y. Chen, X. Wang, L. Gao, and Z. Tang, \u201cA YOLO-based table detection method,\u201d in ICDAR, 2019."]}, {"table": "<table><tbody><tr><td>Method</td><td colspan=\"2\">Training</td><td colspan=\"2\">Fine-tuning</td><td colspan=\"2\">Test</td><td>IoU</td><td colspan=\"4\">Score</td></tr><tr><td></td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td></td><td>R\\uparrow</td><td>P\\uparrow</td><td>F1\\uparrow</td><td>mAP\\uparrow</td></tr><tr><td>decnt [3]</td><td>d1</td><td>4808</td><td>-</td><td>-</td><td>icdar-2013</td><td>238</td><td>0.5</td><td>0.996{}^{*}</td><td>0.996{}^{*}</td><td>0.996{}^{*}</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>d1</td><td>4808</td><td>-</td><td>-</td><td>icdar-2013</td><td>238</td><td>0.5</td><td>1.000</td><td>1.000</td><td>1.000</td><td>1.000</td></tr><tr><td>god [10]</td><td>Marmot</td><td>2K</td><td>-</td><td>-</td><td>icdar-2013</td><td>238</td><td>0.5</td><td>1.000</td><td>0.982</td><td>0.991</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Marmot</td><td>2K</td><td>-</td><td>-</td><td>icdar-2013</td><td>238</td><td>0.5</td><td>1.000</td><td>0.981</td><td>0.991</td><td>0.995</td></tr><tr><td>f-rcnn [9]</td><td>publaynet</td><td>340K</td><td>icadr-2013</td><td>170</td><td>icadr-2013</td><td>238</td><td>0.5</td><td>0.964</td><td>0.972</td><td>0.968</td><td></td></tr><tr><td>m-rcnn [9]</td><td>publaynet</td><td>340K</td><td>icadr-2013</td><td>170</td><td>icadr-2013</td><td>238</td><td>0.5</td><td>0.955</td><td>0.940</td><td>0.947</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>publaynet</td><td>340K</td><td>icadr-2013</td><td>170</td><td>icadr-2013</td><td>238</td><td>0.5</td><td>0.968</td><td>0.987</td><td>0.977</td><td>0.959</td></tr><tr><td>yolov3+a+pg [18]</td><td>icdar-2017</td><td>1.6K</td><td>-</td><td>-</td><td>icadr-2013</td><td>238</td><td>0.5</td><td>0.949</td><td>1.000</td><td>0.973</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>icdar-2017</td><td>1.6K</td><td>-</td><td>-</td><td>icadr-2013</td><td>238</td><td>0.5</td><td>1.000</td><td>1.000</td><td>1.000</td><td>1.000</td></tr><tr><td>Khan et al. [46]</td><td>Marmot</td><td>2K</td><td>icdar-2013</td><td>204</td><td>icdar-2013</td><td>34</td><td>0.5</td><td>0.901</td><td>0.969</td><td>0.934</td><td>-</td></tr><tr><td>tablenet+sf [47]</td><td>Marmot</td><td>2K</td><td>icdar-2013</td><td>204</td><td>icdar-2013</td><td>34</td><td>0.5</td><td>0.963</td><td>0.970</td><td>0.966</td><td>-</td></tr><tr><td>deepdesrt [2]</td><td>Marmot</td><td>2K</td><td>icdar-2013</td><td>204</td><td>icdar-2013</td><td>34</td><td>0.5</td><td>0.962</td><td>0.974</td><td>0.968</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Marmot</td><td>2K</td><td>icdar-2013</td><td>204</td><td>icdar-2013</td><td>34</td><td>0.5</td><td>1.000</td><td>1.000</td><td>1.000</td><td>1.000</td></tr><tr><td>m-rcnn [11]</td><td>Pascel voc</td><td>16K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.770</td><td>0.140</td><td>0.230</td><td>-</td></tr><tr><td>retinanet [11]</td><td>Pascel voc</td><td>16K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.580</td><td>0.560</td><td>0.570</td><td>-</td></tr><tr><td>ssd [11]</td><td>Pascel voc</td><td>16K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.680</td><td>0.540</td><td>0.600</td><td>-</td></tr><tr><td>yolo [11]</td><td>Pascel voc</td><td>16K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.580</td><td>0.920</td><td>0.750</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Pascel voc</td><td>16K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.844</td><td>1.000</td><td>0.922</td><td>0.844</td></tr><tr><td>m-rcnn [11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.970</td><td>0.700</td><td>0.810</td><td>-</td></tr><tr><td>retinanet [11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.770</td><td>0.830</td><td>0.800</td><td>-</td></tr><tr><td>ssd [11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.680</td><td>0.620</td><td>0.650</td><td>-</td></tr><tr><td>yolo [11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.650</td><td>1.000</td><td>0.780</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>tablebank-latex</td><td>199K</td><td>icdar-2013</td><td>178</td><td>icdar-2013</td><td>60</td><td>0.6</td><td>0.933</td><td>1.000</td><td>0.967</td><td>0.933</td></tr><tr><td>Kavasidis et al. [48]</td><td>Custom dataset</td><td>45K</td><td>-</td><td>-</td><td>icdar-2013</td><td>238</td><td>0.5</td><td>0.981</td><td>0.975</td><td>0.978</td><td>-</td></tr><tr><td>pftd [49]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>icadr-2013</td><td>238</td><td>0.5</td><td>0.915</td><td>0.939</td><td>0.926</td><td>-</td></tr><tr><td>Tran et al. [50]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>icdar-2013</td><td>238</td><td>0.5</td><td>0.964</td><td>0.952</td><td>0.958</td><td>-</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>icdar-2013</td><td>238</td><td>0.5</td><td>0.942</td><td>0.993</td><td>0.968</td><td>0.942</td></tr></tbody></table>", "caption": "TABLE IV: Illustrates comparison between the proposed cdec-net and state-of-the-art techniques on icdar-2013 dataset. a: indicates anchor optimization, pg: indicates post-processing technique, sf: indicates semantic features, d1: indicates Marmot+unlv+icdar-2017, *: indicates the authors reported 0.996 in table however in discussion they mentioned 0.994. cdec-net{}^{\\ddagger}: indicates a single model which is trained with iiit-ar-13k dataset. ", "list_citation_info": ["[50] D. N. Tran, T. A. Tran, A. Oh, S. H. Kim, and I. S. Na, \u201cTable detection from document image using vertical arrangement of text blocks,\u201d International Journal of Contents, 2015.", "[3] S. A. Siddiqui, M. I. Malik, S. Agne, A. Dengel, and S. Ahmed, \u201cDeCNT: Deep deformable CNN for table detection,\u201d IEEE Access, 2018.", "[47] S. S. Paliwal, D. Vishwanath, R. Rahul, M. Sharma, and L. Vig, \u201cTableNet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images,\u201d in ICDAR, 2019.", "[49] L. Melinda and C. Bhagvati, \u201cParameter-free table detection method,\u201d in ICDAR, 2019.", "[46] S. A. Khan, S. M. D. Khalid, M. A. Shahzad, and F. Shafait, \u201cTable structure extraction with bi-directional gated recurrent unit networks,\u201d in ICDAR, 2019.", "[2] S. Schreiber, S. Agne, I. Wolf, A. Dengel, and S. Ahmed, \u201cDeepDeSRT: Deep learning for detection and structure recognition of tables in document images,\u201d in ICDAR, 2017.", "[9] X. Zhong, J. Tang, and A. J. Yepes, \u201cPubLayNet: largest dataset ever for document layout analysis,\u201d in ICDAR, 2019.", "[11] \u00c1. Casado-Garc\u00eda, C. Dom\u00ednguez, J. Heras, E. Mata, and V. Pascual, \u201cThe benefits of close-domain fine-tuning for table detection in document images,\u201d arXiv, 2019.", "[10] R. Saha, A. Mondal, and C. V. Jawahar, \u201cGraphical object detection in document images,\u201d in ICDAR, 2019.", "[18] Y. Huang, Q. Yan, Y. Li, Y. Chen, X. Wang, L. Gao, and Z. Tang, \u201cA YOLO-based table detection method,\u201d in ICDAR, 2019.", "[48] I. Kavasidis, S. Palazzo, C. Spampinato, C. Pino, D. Giordano, D. Giuffrida, and P. Messina, \u201cA saliency-based convolutional neural network for table and chart detection in digitized documents,\u201d arXiv, 2018."]}, {"table": "<table><tbody><tr><td>Method</td><td colspan=\"2\">Training</td><td colspan=\"2\">Fine-tuning</td><td colspan=\"2\">Test</td><td>IoU</td><td colspan=\"4\">Score</td></tr><tr><td></td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td></td><td>R\\uparrow</td><td>P\\uparrow</td><td>F1\\uparrow</td><td>mAP\\uparrow</td></tr><tr><td>tableradar [13]</td><td>icdar-2019</td><td>1200</td><td>-</td><td>-</td><td>icdar-2019</td><td>439</td><td>0.8</td><td>0.940</td><td>0.950</td><td>0.945</td><td>-</td></tr><tr><td>nlpr-pal [13]</td><td>icdar-2019</td><td>1200</td><td></td><td></td><td>icdar-2019</td><td>439</td><td>0.8</td><td>0.930</td><td>0.930</td><td>0.930</td><td>-</td></tr><tr><td>lenovo ocean [13]</td><td>icdar-2019</td><td>1200</td><td>-</td><td>-</td><td>icdar-2019</td><td>439</td><td>0.8</td><td>0.860</td><td>0.880</td><td>0.870</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>icdar-2019</td><td>1200</td><td>-</td><td>-</td><td>icdar-2019</td><td>439</td><td>0.8</td><td>0.934</td><td>0.953</td><td>0.944</td><td>0.922</td></tr><tr><td>tableradar [13]</td><td>icdar-2019</td><td>1200</td><td>-</td><td>-</td><td>icdar-2019</td><td>439</td><td>0.9</td><td>0.890</td><td>0.900</td><td>0.895</td><td>-</td></tr><tr><td>nlpr-pal [13]</td><td>icdar-2019</td><td>1200</td><td>-</td><td>-</td><td>icdar-2019</td><td>439</td><td>0.9</td><td>0.860</td><td>0.860</td><td>0.860</td><td>-</td></tr><tr><td>lenovo ocean [13]</td><td>icdar-2019</td><td>1200</td><td>-</td><td>-</td><td>icdar-2019</td><td>439</td><td>0.9</td><td>0.810</td><td>0.820</td><td>0.815</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>icdar-2019</td><td>1200</td><td>-</td><td>-</td><td>icdar-2019</td><td>439</td><td>0.9</td><td>0.904</td><td>0.922</td><td>0.913</td><td>0.843</td></tr><tr><td>m-rcnn [11]</td><td>Pascel voc</td><td>16K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.640</td><td>0.600</td><td>0.620</td><td>-</td></tr><tr><td>retinanet [11]</td><td>Pascel voc</td><td>16K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.660</td><td>0.860</td><td>0.740</td><td>-</td></tr><tr><td>ssd [11]</td><td>Pascel voc</td><td>16K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.350</td><td>0.310</td><td>0.330</td><td>-</td></tr><tr><td>yolo [11]</td><td>Pascel voc</td><td>16K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.910</td><td>0.950</td><td>0.930</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Pascel voc</td><td>16K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.962</td><td>0.981</td><td>0.971</td><td>0.949</td></tr><tr><td>m-rcnn [11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.850</td><td>0.760</td><td>0.810</td><td>-</td></tr><tr><td>retinanet [11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.740</td><td>0.910</td><td>0.820</td><td>-</td></tr><tr><td>ssd [11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.350</td><td>0.350</td><td>0.350</td><td>-</td></tr><tr><td>yolo [11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.950</td><td>0.950</td><td>0.950</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>tablebank-latex</td><td>199K</td><td>icdar-2019 (archive)</td><td>599</td><td>icdar-2019 (archive)</td><td>198</td><td>0.6</td><td>0.924</td><td>0.984</td><td>0.954</td><td>0.909</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>icdar-2019</td><td>439</td><td>0.8</td><td>0.625</td><td>0.871</td><td>0.748</td><td>0.551</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>icdar-2019</td><td>1200</td><td>icdar-2019</td><td>439</td><td>0.8</td><td>0.930</td><td>0.971</td><td>0.950</td><td>0.913</td></tr></tbody></table>", "caption": "TABLE V: Illustrates comparison between the proposed cdec-net and state-of-the-art techniques on icdar-2019 dataset. cdec-net{}^{\\ddagger}: indicates a single model which is trained with iiit-ar-13k dataset. ", "list_citation_info": ["[11] \u00c1. Casado-Garc\u00eda, C. Dom\u00ednguez, J. Heras, E. Mata, and V. Pascual, \u201cThe benefits of close-domain fine-tuning for table detection in document images,\u201d arXiv, 2019.", "[13] L. Gao, Y. Huang, H. D\u00e9jean, J.-L. Meunier, Q. Yan, Y. Fang, F. Kleber, and E. Lang, \u201cICDAR 2019 competition on table detection and recognition (cTDaR),\u201d in ICDAR, 2019."]}, {"table": "<table><tbody><tr><td>Method</td><td colspan=\"2\">Training</td><td colspan=\"2\">Fine-tuning</td><td colspan=\"2\">Test</td><td>IoU</td><td colspan=\"4\">Score</td></tr><tr><td></td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td></td><td>R\\uparrow</td><td>P\\uparrow</td><td>F1\\uparrow</td><td>mAP\\uparrow</td></tr><tr><td>god [10]</td><td>Marmot</td><td>2K</td><td>unlv</td><td>340</td><td>unlv</td><td>84</td><td>0.5</td><td>0.910</td><td>0.946</td><td>0.928</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Marmot</td><td>2K</td><td>unlv</td><td>340</td><td>unlv</td><td>84</td><td>0.5</td><td>0.925</td><td>0.952</td><td>0.938</td><td>0.912</td></tr><tr><td>Gilani et al. [1]</td><td>unlv</td><td>340</td><td>-</td><td>-</td><td>unlv</td><td>84</td><td>0.5</td><td>0.907</td><td>0.823</td><td>0.863</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>unlv</td><td>340</td><td>-</td><td>-</td><td>unlv</td><td>84</td><td>0.5</td><td>0.906</td><td>0.914</td><td>0.910</td><td>0.861</td></tr><tr><td>Arif and Shafait [6]</td><td>private</td><td>1019</td><td>-</td><td>-</td><td>unlv</td><td>427</td><td>0.5</td><td>0.932</td><td>0.863</td><td>0.896</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>private</td><td>1019</td><td>-</td><td>-</td><td>unlv</td><td>427</td><td>0.5</td><td>0.745</td><td>0.912</td><td>0.829</td><td>0.711</td></tr><tr><td>decnt [3]</td><td>d4</td><td>4622</td><td>-</td><td>-</td><td>unlv</td><td>424</td><td>0.5</td><td>0.749</td><td>0.786</td><td>0.767</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>d4</td><td>4622</td><td>-</td><td>-</td><td>unlv</td><td>424</td><td>0.5</td><td>0.736</td><td>0.852</td><td>0.794</td><td>0.657</td></tr><tr><td>m-rcnn [11]</td><td>Pascel voc</td><td>16K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.580</td><td>0.290</td><td>0.390</td><td>-</td></tr><tr><td>retinanet [11]</td><td>Pascel voc</td><td>16K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.830</td><td>0.810</td><td>0.820</td><td>-</td></tr><tr><td>ssd [11]</td><td>Pascel voc</td><td>16K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.640</td><td>0.660</td><td>0.650</td><td>-</td></tr><tr><td>yolo [11]</td><td>Pascel voc</td><td>16K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.950</td><td>0.910</td><td>0.930</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Pascel voc</td><td>16K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.805</td><td>0.961</td><td>0.883</td><td>0.788</td></tr><tr><td>m-rcnn [11]</td><td>tablebank-latex</td><td>199K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.830</td><td>0.660</td><td>0.740</td><td>-</td></tr><tr><td>retinanet [11]</td><td>tablebank-latex</td><td>199K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.830</td><td>0.810</td><td>0.820</td><td>-</td></tr><tr><td>ssd [11]</td><td>tablebank-latex</td><td>199K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.660</td><td>0.720</td><td>0.690</td><td>-</td></tr><tr><td>yolo [11]</td><td>tablebank-latex</td><td>199K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.950</td><td>0.930</td><td>0.940</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>tablebank-latex</td><td>199K</td><td>unlv</td><td>302</td><td>unlv</td><td>101</td><td>0.6</td><td>0.894</td><td>0.991</td><td>0.943</td><td>0.889</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td></td><td></td><td>unlv</td><td>424</td><td>0.5</td><td>0.770</td><td>0.96</td><td>0.865</td><td>0.742</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>private</td><td>1019</td><td>unlv</td><td>427</td><td>0.5</td><td>0.776</td><td>0.958</td><td>0.866</td><td>0.750</td></tr></tbody></table>", "caption": "TABLE VI: Illustrates comparison between the proposed cdec-net and state-of-the-art techniques on unlv dataset. d4: indicates icdar-2013+icdar-2017+Marmot. cdec-net{}^{\\ddagger}: indicates a single model which is trained with iiit-ar-13k dataset. ", "list_citation_info": ["[1] A. Gilani, S. R. Qasim, I. Malik, and F. Shafait, \u201cTable detection using deep learning,\u201d in ICDAR, 2017.", "[3] S. A. Siddiqui, M. I. Malik, S. Agne, A. Dengel, and S. Ahmed, \u201cDeCNT: Deep deformable CNN for table detection,\u201d IEEE Access, 2018.", "[6] S. Arif and F. Shafait, \u201cTable detection in document images using foreground and background features,\u201d in DICTA, 2018.", "[11] \u00c1. Casado-Garc\u00eda, C. Dom\u00ednguez, J. Heras, E. Mata, and V. Pascual, \u201cThe benefits of close-domain fine-tuning for table detection in document images,\u201d arXiv, 2019.", "[10] R. Saha, A. Mondal, and C. V. Jawahar, \u201cGraphical object detection in document images,\u201d in ICDAR, 2019."]}, {"table": "<table><tbody><tr><td>Method</td><td colspan=\"2\">Training</td><td colspan=\"2\">Fine-tuning</td><td colspan=\"2\">Test</td><td>IoU</td><td colspan=\"4\">Score</td></tr><tr><td></td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td></td><td>R\\uparrow</td><td>P\\uparrow</td><td>F1\\uparrow</td><td>mAP\\uparrow</td></tr><tr><td>Li et al. [7]</td><td>tablebank-latex</td><td>253K</td><td>-</td><td>-</td><td>tablebank-word</td><td>1K</td><td>0.5</td><td>0.956</td><td>0.826</td><td>0.886</td><td>-</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>tablebank-latex</td><td>1K</td><td>0.5</td><td>0.975</td><td>0.987</td><td>0.981</td><td>-</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>tablebank-both</td><td>2K</td><td>0.5</td><td>0.962</td><td>0.872</td><td>0.915</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>tablebank-latex</td><td>253K</td><td>-</td><td>-</td><td>tablebank-word</td><td>1K</td><td>0.5</td><td>0.868</td><td>0.873</td><td>0.871</td><td>0.762</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>tablebank-latex</td><td>1K</td><td>0.5</td><td>0.979</td><td>0.995</td><td>0.987</td><td>0.976</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>tablebank-both</td><td>2K</td><td>0.5</td><td>0.924</td><td>0.934</td><td>0.929</td><td>0.898</td></tr><tr><td>m-rcnn [11]</td><td>tablebank-latex</td><td>199K</td><td>-</td><td>-</td><td>tablebank-latex</td><td>1K</td><td>0.6</td><td>0.980</td><td>0.960</td><td>0.940</td><td>-</td></tr><tr><td>retinanet [11]</td><td>tablebank-latex</td><td>199K</td><td>-</td><td>-</td><td>tablebank-latex</td><td>1K</td><td>0.6</td><td>0.860</td><td>0.980</td><td>0.920</td><td>-</td></tr><tr><td>ssd [11]</td><td>tablebank-latex</td><td>199K</td><td>-</td><td>-</td><td>tablebank-latex</td><td>1K</td><td>0.6</td><td>0.970</td><td>0.960</td><td>0.965</td><td>-</td></tr><tr><td>yolo [11]</td><td>tablebank-latex</td><td>199K</td><td>-</td><td>-</td><td>tablebank-latex</td><td>1K</td><td>0.6</td><td>0.990</td><td>0.980</td><td>0.985</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>tablebank-latex</td><td>199K</td><td>-</td><td>-</td><td>tablebank-latex</td><td>1K</td><td>0.6</td><td>0.978</td><td>0.995</td><td>0.986</td><td>0.974</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td></td><td></td><td>tablebank-latex</td><td>1K</td><td>0.6</td><td>0.779</td><td>0.961</td><td>0.870</td><td>0.759</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>tablebank-latex</td><td>199K</td><td>tablebank-latex</td><td>1K</td><td>0.6</td><td>0.970</td><td>0.990</td><td>0.980</td><td>0.965</td></tr></tbody></table>", "caption": "TABLE VII: Illustrates comparison between the proposed cdec-net (our) and state-of-the-art techniques on tablebank dataset. cdec-net{}^{\\ddagger}: indicates a single model which is trained with iiit-ar-13k dataset. ", "list_citation_info": ["[11] \u00c1. Casado-Garc\u00eda, C. Dom\u00ednguez, J. Heras, E. Mata, and V. Pascual, \u201cThe benefits of close-domain fine-tuning for table detection in document images,\u201d arXiv, 2019.", "[7] M. Li, L. Cui, S. Huang, F. Wei, M. Zhou, and Z. Li, \u201cTableBank: Table benchmark for image-based table detection and recognition,\u201d arXiv, 2019."]}, {"table": "<table><tbody><tr><td>Method</td><td colspan=\"2\">Training</td><td colspan=\"2\">Fine-tuning</td><td colspan=\"2\">Test</td><td>IoU</td><td colspan=\"4\">Score</td></tr><tr><td></td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td></td><td>R\\uparrow</td><td>P\\uparrow</td><td>F1\\uparrow</td><td>mAP\\uparrow</td></tr><tr><td>fastdetectors{}^{\\dagger}[16]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.940</td><td>0.903</td><td>0.921</td><td>0.925</td></tr><tr><td>pal{}^{\\dagger}[16]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.953</td><td>0.968</td><td>0.960</td><td>0.933</td></tr><tr><td>god{}^{\\dagger}[10]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>-</td><td>-</td><td>0.971</td><td>0.989</td></tr><tr><td>dsp-sc{}^{\\dagger} [51]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.962</td><td>0.974</td><td>0.968</td><td>0.946</td></tr><tr><td>yolov3{}^{\\dagger}+a+p[18]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.972</td><td>0.978</td><td>0.975</td><td>-</td></tr><tr><td>cdec-net{}^{\\dagger} (our)</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.931</td><td>0.977</td><td>0.954</td><td>0.920</td></tr><tr><td>fastdetectors{}^{\\dagger}[16]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.915</td><td>0.879</td><td>0.896</td><td>0.884</td></tr><tr><td>pal{}^{\\dagger}[16]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.943</td><td>0.958</td><td>0.951</td><td>0.911</td></tr><tr><td>god{}^{\\dagger}[10]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>-</td><td>-</td><td>0.968</td><td>0.974</td></tr><tr><td>dsp-sc{}^{\\dagger} [51]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.953</td><td>0.965</td><td>0.959</td><td>0.923</td></tr><tr><td>yolov3{}^{\\dagger}+a+p[18]</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.968</td><td>0.975</td><td>0.971</td><td>-</td></tr><tr><td>cdec-net{}^{\\dagger} (our)</td><td>icdar-pod-2017</td><td>1600</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.924</td><td>0.970</td><td>0.947</td><td>0.912</td></tr><tr><td>decnt[3]</td><td>d2</td><td>4229</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.971</td><td>0.965</td><td>0.968</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>d2</td><td>4229</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.943</td><td>0.977</td><td>0.960</td><td>0.938</td></tr><tr><td>decnt[3]</td><td>d2</td><td>4229</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.937</td><td>0.967</td><td>0.952</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>d2</td><td>4229</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.918</td><td>0.951</td><td>0.935</td><td>0.895</td></tr><tr><td>faster r-cnn+cl[4]</td><td>icdar-pod-2017</td><td>549</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>243</td><td>0.6</td><td>0.956</td><td>0.943</td><td>0.949</td><td>-</td></tr><tr><td>f+m-rcnn [52]</td><td>icdar-pod-2017</td><td>549</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>243</td><td>0.6</td><td>0.944</td><td>0.944</td><td>0.944</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>icdar-pod-2017</td><td>549</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>243</td><td>0.6</td><td>0.943</td><td>0.974</td><td>0.959</td><td>0.9308</td></tr><tr><td>f+m-rcnn [52]</td><td>icdar-pod-2017</td><td>549</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>243</td><td>0.8</td><td>0.903</td><td>0.903</td><td>0.903</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>icdar-pod-2017</td><td>549</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>243</td><td>0.8</td><td>0.928</td><td>0.958</td><td>0.943</td><td>0.9023</td></tr><tr><td>m-rcnn[11]</td><td>Pascel voc</td><td>16K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.850</td><td>0.320</td><td>0.460</td><td>-</td></tr><tr><td>retinanet[11]</td><td>Pascel voc</td><td>16K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.860</td><td>0.650</td><td>0.740</td><td>-</td></tr><tr><td>ssd[11]</td><td>Pascel voc</td><td>16K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.710</td><td>0.490</td><td>0.580</td><td>-</td></tr><tr><td>yolo[11]</td><td>Pascel voc</td><td>16K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.940</td><td>0.900</td><td>0.920</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Pascel voc</td><td>16K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.932</td><td>0.981</td><td>0.956</td><td>0.925</td></tr><tr><td>m-rcnn[11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.950</td><td>0.720</td><td>0.820</td><td>-</td></tr><tr><td>retinanet[11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.870</td><td>0.920</td><td>0.890</td><td>-</td></tr><tr><td>ssd[11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.710</td><td>0.550</td><td>0.620</td><td>-</td></tr><tr><td>yolo[11]</td><td>tablebank-latex</td><td>199K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.940</td><td>0.940</td><td>0.940</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>tablebank-latex</td><td>199K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.914</td><td>0.980</td><td>0.947</td><td>0.905</td></tr><tr><td>cdec-net{}^{\\ddagger\\dagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.776</td><td>0.928</td><td>0.852</td><td>0.731</td></tr><tr><td>cdec-net{}^{\\ddagger\\dagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>icdar-pod-2017</td><td>1600</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.931</td><td>0.987</td><td>0.959</td><td>0.927</td></tr><tr><td>cdec-net{}^{\\ddagger\\dagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.625</td><td>0.747</td><td>0.686</td><td>0.487</td></tr><tr><td>cdec-net{}^{\\ddagger\\dagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>icdar-pod-2017</td><td>1600</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.928</td><td>0.983</td><td>0.955</td><td>0.924</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>d2</td><td>4229</td><td>icdar-pod-2017</td><td>817</td><td>0.6</td><td>0.921</td><td>0.957</td><td>0.939</td><td>0.897</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>d2</td><td>4229</td><td>icdar-pod-2017</td><td>817</td><td>0.8</td><td>0.909</td><td>0.944</td><td>0.926</td><td>0.877</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>243</td><td>0.6</td><td>0.751</td><td>0.971</td><td>0.861</td><td>0.739</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>icdar-pod-2017</td><td>549</td><td>icdar-pod-2017</td><td>243</td><td>0.6</td><td>0.946</td><td>0.984</td><td>0.965</td><td>0.934</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>243</td><td>0.8</td><td>0.640</td><td>0.829</td><td>0.735</td><td>0.549</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>icdar-pod-2017</td><td>549</td><td>icdar-pod-2017</td><td>243</td><td>0.8</td><td>0.937</td><td>0.974</td><td>0.955</td><td>0.917</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.772</td><td>0.954</td><td>0.863</td><td>0.754</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>icdar-pod-2017</td><td>1200</td><td>icdar-pod-2017</td><td>400</td><td>0.6</td><td>0.944</td><td>0.975</td><td>0.960</td><td>0.930</td></tr></tbody></table>", "caption": "TABLE X: Illustrates comparison between the proposed cdec-net and state-of-the-art techniques on icdar-pod-2017. d2: indicates icdar-2013+icdar-pod-2017+unlv+Marmot.\\dagger: indicates model trained with multiple categories. cdec-net{}^{\\ddagger}: indicates a single model which is trained with iiit-ar-13k dataset. ", "list_citation_info": ["[52] Y. Li, L. Gao, Z. Tang, Q. Yan, and Y. Huang, \u201cA GAN-based feature generator for table detection,\u201d in ICDAR, 2019.", "[51] X.-H. Li, F. Yin, and C.-L. Liu, \u201cPage object detection from PDF document images by deep structured prediction and supervised clustering,\u201d in ICPR, 2018."]}, {"table": "<table><tbody><tr><td>Method</td><td colspan=\"2\">Training</td><td colspan=\"2\">Fine-tuning</td><td colspan=\"2\">Test</td><td>IoU</td><td colspan=\"4\">Score</td></tr><tr><td></td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td>Dataset</td><td>#Image</td><td></td><td>R\\uparrow</td><td>P\\uparrow</td><td>F1\\uparrow</td><td>mAP\\uparrow</td></tr><tr><td>decnt[3]</td><td>d3</td><td>3079</td><td>-</td><td>-</td><td>Marmot</td><td>1967</td><td>0.5</td><td>0.946</td><td>0.849</td><td>0.895</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>d3</td><td>3079</td><td></td><td></td><td>Marmot</td><td>1967</td><td>0.5</td><td>0.930</td><td>0.975</td><td>0.952</td><td>0.911</td></tr><tr><td>mfcn+contour+crf [53]</td><td>Various Doc</td><td>130</td><td>-</td><td>-</td><td>Marmot</td><td>2000</td><td>0.8</td><td>0.731</td><td>0.762</td><td>0.747</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Various Doc</td><td>130</td><td></td><td></td><td>Marmot</td><td>2000</td><td>0.8</td><td>0.836</td><td>0.845</td><td>0.840</td><td>0.716</td></tr><tr><td>mfcn+contour+crf [53]</td><td>Various Doc</td><td>130</td><td>-</td><td>-</td><td>Marmot</td><td>2000</td><td>0.9</td><td>0.471</td><td>0.481</td><td>0.476</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Various Doc</td><td>130</td><td></td><td></td><td>Marmot</td><td>2000</td><td>0.9</td><td>0.765</td><td>0.774</td><td>0.769</td><td>0.600</td></tr><tr><td>m-rcnn[11]</td><td>Pascel voc</td><td>16K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.750</td><td>0.370</td><td>0.490</td><td>-</td></tr><tr><td>retinanet[11]</td><td>Pascel voc</td><td>16K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.860</td><td>0.750</td><td>0.800</td><td>-</td></tr><tr><td>ssd[11]</td><td>Pascel voc</td><td>16K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.760</td><td>0.670</td><td>0.710</td><td>-</td></tr><tr><td>yolo[11]</td><td>Pascel voc</td><td>16K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.960</td><td>0.900</td><td>0.930</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Pascel voc</td><td>16K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.946</td><td>0.993</td><td>0.969</td><td>0.942</td></tr><tr><td>m-rcnn[11]</td><td>tablebank-latex</td><td>199K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.930</td><td>0.720</td><td>0.810</td><td>-</td></tr><tr><td>retinanet[11]</td><td>tablebank-latex</td><td>199K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.860</td><td>0.930</td><td>0.900</td><td>-</td></tr><tr><td>ssd[11]</td><td>tablebank-latex</td><td>199K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.750</td><td>0.710</td><td>0.730</td><td>-</td></tr><tr><td>yolo[11]</td><td>tablebank-latex</td><td>199K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.970</td><td>0.950</td><td>0.960</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>tablebank-latex</td><td>199K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.925</td><td>0.993</td><td>0.959</td><td>0.924</td></tr><tr><td>m-rcnn[11]</td><td>Pascel voc</td><td>16K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.830</td><td>0.520</td><td>0.640</td><td>-</td></tr><tr><td>retinanet[11]</td><td>Pascel voc</td><td>16K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.850</td><td>0.780</td><td>0.810</td><td>-</td></tr><tr><td>ssd[11]</td><td>Pascel voc</td><td>16K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.700</td><td>0.570</td><td>0.630</td><td>-</td></tr><tr><td>yolo[11]</td><td>Pascel voc</td><td>16K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.960</td><td>0.950</td><td>0.960</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>Pascel voc</td><td>16K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.966</td><td>0.988</td><td>0.977</td><td>0.959</td></tr><tr><td>m-rcnn[11]</td><td>tablebank-latex</td><td>199K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.980</td><td>0.820</td><td>0.890</td><td>-</td></tr><tr><td>retinanet[11]</td><td>tablebank-latex</td><td>199K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.870</td><td>0.870</td><td>0.870</td><td>-</td></tr><tr><td>ssd[11]</td><td>tablebank-latex</td><td>199K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.670</td><td>0.610</td><td>0.640</td><td>-</td></tr><tr><td>yolo[11]</td><td>tablebank-latex</td><td>199K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.930</td><td>0.970</td><td>0.950</td><td>-</td></tr><tr><td>cdec-net (our)</td><td>tablebank-latex</td><td>199K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.966</td><td>0.994</td><td>0.980</td><td>0.962</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>Marmot</td><td>1967</td><td>0.5</td><td>0.779</td><td>0.943</td><td>0.861</td><td>0.756</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>d3</td><td>3079</td><td>Marmot</td><td>1967</td><td>0.5</td><td>0.916</td><td>0.991</td><td>0.953</td><td>0.909</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>Marmot</td><td>2000</td><td>0.8</td><td>0.578</td><td>0.682</td><td>0.632</td><td>0.427</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>Marmot</td><td>2000</td><td>0.9</td><td>0.271</td><td>0.322</td><td>0.296</td><td>0.108</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>Various Doc</td><td>130</td><td>Marmot</td><td>2000</td><td>0.8</td><td>0.833</td><td>0.837</td><td>0.835</td><td>0.710</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>Various Doc</td><td>130</td><td>Marmot</td><td>2000</td><td>0.9</td><td>0.772</td><td>0.775</td><td>0.773</td><td>0.603</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.912</td><td>0.964</td><td>0.938</td><td>0.906</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>Marmot (English)</td><td>744</td><td>Marmot (English)</td><td>249</td><td>0.6</td><td>0.952</td><td>1.000</td><td>0.976</td><td>0.952</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>-</td><td>-</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.791</td><td>0.921</td><td>0.856</td><td>0.736</td></tr><tr><td>cdec-net{}^{\\ddagger} (our)</td><td>iiit-ar-13k</td><td>9K</td><td>Marmot (Chinese)</td><td>754</td><td>Marmot (Chinese)</td><td>252</td><td>0.6</td><td>0.944</td><td>0.988</td><td>0.966</td><td>0.935</td></tr></tbody></table>", "caption": "TABLE XII: Illustrates comparison between the proposed cdec-net and state-of-the-art techniques on marmot dataset. d3: indicates icdar-2013+icdar-2017+unlv. cdec-net{}^{\\ddagger}: indicates a single model which is trained with iiit-ar-13k dataset. ", "list_citation_info": ["[53] D. He, S. Cohen, B. Price, D. Kifer, and C. L. Giles, \u201cMulti-scale multi-task FCN for semantic page segmentation and table detection,\u201d in ICDAR, 2017."]}]}