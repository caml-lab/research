{"title": "Bootstrapping Semantic Segmentation with Regional Contrast", "abstract": "We present ReCo, a contrastive learning framework designed at a regional level to assist learning in semantic segmentation. ReCo performs semi-supervised or supervised pixel-level contrastive learning on a sparse set of hard negative pixels, with minimal additional memory footprint. ReCo is easy to implement, being built on top of off-the-shelf segmentation networks, and consistently improves performance in both semi-supervised and supervised semantic segmentation methods, achieving smoother segmentation boundaries and faster convergence. The strongest effect is in semi-supervised learning with very few labels. With ReCo, we achieve high-quality semantic segmentation models, requiring only 5 examples of each semantic class. Code is available at https://github.com/lorenmt/reco.", "authors": ["Shikun Liu", " Shuaifeng Zhi", " Edward Johns", " Andrew J. Davison"], "pdf_url": "https://arxiv.org/abs/2104.04465", "list_table_and_caption": [{"table": "<table><tr><td>Pascal VOC</td><td>1/16 [92]</td><td>1/8 [183]</td><td>1/4 [366]</td><td>1/2 [732]</td></tr><tr><td>AdvSemSeg [12]</td><td>39.69</td><td>47.58</td><td>59.97</td><td>65.27</td></tr><tr><td>Mean Teacher [29]</td><td>48.70</td><td>55.81</td><td>63.01</td><td>69.16</td></tr><tr><td>CCT [25]</td><td>33.10</td><td>47.60</td><td>58.80</td><td>62.10</td></tr><tr><td>GCT [13]</td><td>46.04</td><td>54.98</td><td>64.71</td><td>70.67</td></tr><tr><td>VAT [22]</td><td>36.92</td><td>49.35</td><td>56.88</td><td>63.34</td></tr><tr><td>CutMix [9]</td><td>55.58</td><td>63.20</td><td>68.36</td><td>69.87</td></tr><tr><td>PseudoSeg [38]</td><td>57.60</td><td>65.50</td><td>69.14</td><td>72.41</td></tr><tr><td>ReCo + ClassMix</td><td>64.78</td><td>72.02</td><td>73.14</td><td>74.69</td></tr></table>", "caption": "Table 2: mean IoU validation performance for Pascal VOC with data partition and training strategy proposed in PseudoSeg [38]. The percentage and the number of labelled data used are listed in the first row.", "list_citation_info": ["[12] Wei Chih Hung, Yi Hsuan Tsai, Yan Ting Liou, Yen Yu Lin, and Ming Hsuan Yang. Adversarial learning for semi-supervised semantic segmentation. In Proceedings of the British Machine Vision Conference (BMVC), 2019.", "[25] Yassine Ouali, C\u00e9line Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistency training. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.", "[29] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In Advances in Neural Information Processing Systems (NeurIPS), 2017.", "[38] Yuliang Zou, Zizhao Zhang, Han Zhang, Chun-Liang Li, Xiao Bian, Jia-Bin Huang, and Tomas Pfister. Pseudoseg: Designing pseudo labels for semantic segmentation. In Proceedings of the International Conference on Learning Representations (ICLR), 2021.", "[9] Geoff French, Timo Aila, Samuli Laine, Michal Mackiewicz, and Graham Finlayson. Semi-supervised semantic segmentation needs strong, high-dimensional perturbations. In Proceedings of the British Machine Vision Conference (BMVC), 2020.", "[22] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2018.", "[13] Zhanghan Ke, Di Qiu, Kaican Li, Qiong Yan, and Rynson W.H. Lau. Guided collaborative training for pixel-wise semi-supervised learning. In Proceedings of the European Conference on Computer Vision (ECCV), 2020."]}, {"table": "<table><tr><td>Pascal VOC</td><td>Backbone</td><td>1/106 [100]</td><td>1/50 [212]</td><td>1/20 [529]</td><td>1/8 [1323]</td><td>Full [10582]</td></tr><tr><td>AdvSemSeg [12]</td><td>DeepLabv2</td><td>-</td><td>57.20_{(17.70)}</td><td>64.70_{(10.20)}</td><td>69.50_{(5.40)}</td><td>74.90</td></tr><tr><td>S4GAN [21]</td><td>DeepLabv2</td><td>-</td><td>63.30_{(12.30)}</td><td>67.20_{(8.40)}</td><td>71.40_{(4.20)}</td><td>75.60</td></tr><tr><td>CutMix [9]</td><td>DeepLabv2</td><td>53.79_{(18.71)}</td><td>64.81_{(7.73)}</td><td>66.48_{(6.06)}</td><td>67.60_{(4.94)}</td><td>72.54</td></tr><tr><td>ClassMix [24]</td><td>DeepLabv2</td><td>54.18_{(19.95)}</td><td>66.15_{(7.98)}</td><td>67.77_{(6.36)}</td><td>71.00_{(3.13)}</td><td>74.13</td></tr><tr><td>CCT [25]</td><td>PSPNet</td><td>-</td><td>-</td><td>-</td><td>70.45_{(4.80)}</td><td>75.25</td></tr><tr><td>GCT [13]</td><td>DeepLabv2</td><td>-</td><td>-</td><td>-</td><td>70.57_{(3.49)}</td><td>74.06</td></tr><tr><td>DMT [8]</td><td>DeepLabv2</td><td>63.04_{(11.71)}</td><td>67.15_{(7.60)}</td><td>69.92_{(4.83)}</td><td>72.70_{(2.05)}</td><td>74.75</td></tr><tr><td>ReCo</td><td>DeepLabv2</td><td>63.16_{(11.20)}</td><td>66.41_{(7.95)}</td><td>68.85_{(5.51)}</td><td>71.00_{(3.36)}</td><td>74.36</td></tr><tr><td>ReCo</td><td>DeepLabv3+</td><td>63.60_{(14.15)}</td><td>72.14_{(5.61)}</td><td>73.66_{(4.09)}</td><td>74.62_{(3.13)}</td><td>77.75</td></tr><tr><td>CityScapes</td><td>Backbone</td><td>1/30 [100]</td><td>1/8 [372]</td><td>1/4 [744]</td><td>1/2 [1488]</td><td>Full [2975]</td></tr><tr><td>AdvSemSeg [12]</td><td>DeepLabv2</td><td>-</td><td>58.80_{(7.60)}</td><td>62.30_{(4.10)}</td><td>65.70_{(0.70)}</td><td>66.40</td></tr><tr><td>S4GAN [21]</td><td>DeepLabv2</td><td>-</td><td>59.30_{(6.50)}</td><td>61.90_{(3.90)}</td><td>-</td><td>65.80</td></tr><tr><td>CutMix [25]</td><td>DeepLabv2</td><td>51.20_{(16.33)}</td><td>60.34_{(7.19)}</td><td>63.87_{(3.66)}</td><td>-</td><td>67.53</td></tr><tr><td>ClassMix [24]</td><td>DeepLabv2</td><td>54.07_{(12.12)}</td><td>61.35_{(4.84)}</td><td>63.63_{(2.56)}</td><td>66.29_{(-0.10)}</td><td>66.19</td></tr><tr><td>DMT [8]</td><td>DeepLabv2</td><td>54.81_{(13.36)}</td><td>63.03_{(5.13)}</td><td>-</td><td>-</td><td>68.16</td></tr><tr><td>ECS{}^{\\ast} [20]</td><td>DeepLabv3+</td><td>-</td><td>67.38_{(7.38)}</td><td>70.70_{(4.06)}</td><td>72.89_{(1.87)}</td><td>74.76</td></tr><tr><td>ReCo</td><td>DeepLabv2</td><td>56.53_{(12.07)}</td><td>64.94_{(3.66)}</td><td>67.53_{(1.07)}</td><td>68.69_{(-0.09)}</td><td>68.60</td></tr><tr><td>ReCo</td><td>DeepLabv3+</td><td>60.28_{(10.20)}</td><td>66.44_{(4.04)}</td><td>68.50_{(1.98)}</td><td>70.63_{(-0.15)}</td><td>70.48</td></tr></table>", "caption": "Table 5: mean IoU validation performance in semi-supervsed Pascal VOC and CityScapes datasets. We list the percentage along with the number of labelled training images at the top of each column. The first and second best performances in each setting are coloured in red and orange respectively. \\ast trained images in doubled resolution. All results were taken from the corresponding publications.", "list_citation_info": ["[8] Zhengyang Feng, Qianyu Zhou, Qiqi Gu, Xin Tan, Guangliang Cheng, Xuequan Lu, Jianping Shi, and Lizhuang Ma. Dmt: Dynamic mutual training for semi-supervised learning. arXiv preprint arXiv:2004.08514, 2020.", "[12] Wei Chih Hung, Yi Hsuan Tsai, Yan Ting Liou, Yen Yu Lin, and Ming Hsuan Yang. Adversarial learning for semi-supervised semantic segmentation. In Proceedings of the British Machine Vision Conference (BMVC), 2019.", "[25] Yassine Ouali, C\u00e9line Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistency training. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.", "[20] Robert Mendel, Luis Antonio de Souza, David Rauber, Jo\u00e3o Paulo Papa, and Christoph Palm. Semi-supervised segmentation based on error-correcting supervision. In Proceedings of the European Conference on Computer Vision (ECCV), 2020.", "[24] Viktor Olsson, Wilhelm Tranheden, Juliano Pinto, and Lennart Svensson. Classmix: Segmentation-based data augmentation for semi-supervised learning. In IEEE Winter Conference on Applications of Computer Vision (WACV), 2021.", "[9] Geoff French, Timo Aila, Samuli Laine, Michal Mackiewicz, and Graham Finlayson. Semi-supervised semantic segmentation needs strong, high-dimensional perturbations. In Proceedings of the British Machine Vision Conference (BMVC), 2020.", "[21] Sudhanshu Mittal, Maxim Tatarchenko, and Thomas Brox. Semi-supervised semantic segmentation with high-and low-level consistency. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2019.", "[13] Zhanghan Ke, Di Qiu, Kaican Li, Qiong Yan, and Rynson W.H. Lau. Guided collaborative training for pixel-wise semi-supervised learning. In Proceedings of the European Conference on Computer Vision (ECCV), 2020."]}]}