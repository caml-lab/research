{"title": "Co-domain Symmetry for Complex-Valued Deep Learning", "abstract": "We study complex-valued scaling as a type of symmetry natural and unique to complex-valued measurements and representations. Deep Complex Networks (DCN) extends real-valued algebra to the complex domain without addressing complex-valued scaling. SurReal takes a restrictive manifold view of complex numbers, adopting a distance metric to achieve complex-scaling invariance while losing rich complex-valued information. We analyze complex-valued scaling as a co-domain transformation and design novel equivariant and invariant neural network layer functions for this special transformation. We also propose novel complex-valued representations of RGB images, where complex-valued scaling indicates hue shift or correlated changes across color channels. Benchmarked on MSTAR, CIFAR10, CIFAR100, and SVHN, our co-domain symmetric (CDS) classifiers deliver higher accuracy, better generalization, robustness to co-domain transformations, and lower model bias and variance than DCN and SurReal with far fewer parameters.", "authors": ["Utkarsh Singhal", " Yifei Xing", " Stella X. Yu"], "pdf_url": "https://arxiv.org/abs/2112.01525", "list_table_and_caption": [{"table": "<table><tr><td>Method</td><td># Param</td><td colspan=\"3\">CIFAR10</td><td colspan=\"3\">CIFAR100</td><td colspan=\"3\">SVHN</td></tr><tr><td></td><td></td><td>RGB</td><td>LAB</td><td>Sliding</td><td>RGB</td><td>LAB</td><td>Sliding</td><td>RGB</td><td>LAB</td><td>Sliding</td></tr><tr><td>DCN [16]</td><td>66,858</td><td>65.17</td><td>58.64</td><td>63.83</td><td>32.52</td><td>27.36</td><td>28.87</td><td>85.26</td><td>84.43</td><td>87.44</td></tr><tr><td>SurReal [18]</td><td>35,274</td><td>50.68</td><td>53.02</td><td>54.61</td><td>23.57</td><td>25.97</td><td>26.66</td><td>80.51</td><td>53.48</td><td>80.79</td></tr><tr><td>Real-valued CNN</td><td>34,282</td><td>64.43</td><td>63</td><td>63.43</td><td>31.93</td><td>31.72</td><td>31.93</td><td>87.47</td><td>84.93</td><td>87.37</td></tr><tr><td>Ours (Type-I)</td><td>24,241</td><td>69.23</td><td>67.17</td><td>68.7</td><td>36.92</td><td>37.81</td><td>38.51</td><td>89.39</td><td>88.86</td><td>90.25</td></tr><tr><td>Ours (Type-E)</td><td>25,745</td><td>68.48</td><td>67.58</td><td>69.19</td><td>41.83</td><td>39.55</td><td>42.08</td><td>77.19</td><td>74.21</td><td>88.39</td></tr></table>", "caption": "Table 1: Our models outperform the baselines\u2019 CIFARnet versions on real-valued datasets. Type-I model performs better on easier datasets like SVHN, and Type-E performs better on difficult datasets like CIFAR100. In contrast, SurReal does not scale to large datasets.", "list_citation_info": ["[16] Chiheb Trabelsi, Olexa Bilaniuk, Ying Zhang, Dmitriy Serdyuk, Sandeep Subramanian, Jo\u00e3o Felipe Santos, Soroush Mehri, Negar Rostamzadeh, Yoshua Bengio, and Christopher J Pal. Deep complex networks. arXiv preprint arXiv:1705.09792, 2017.", "[18] Rudrasis Chakraborty, Yifei Xing, and Stella Yu. Surreal: Complex-valued deep learning as principled transformations on a rotational lie group. arXiv preprint arXiv:1910.11334, 2019."]}, {"table": "<br/><table><tr><td>Model</td><td># Params</td><td>5%</td><td>10%</td><td>50%</td><td>90%</td><td>100%</td></tr><tr><td>Real</td><td>33,050</td><td>47.4</td><td>46.6</td><td>60.6</td><td>73</td><td>66.9</td></tr><tr><td>SurReal [18]</td><td>63,690</td><td>61.1</td><td>68</td><td>90.3</td><td>95.6</td><td>94.9</td></tr><tr><td>DCN [16]</td><td>863,587</td><td>49.8</td><td>47</td><td>81.9</td><td>89.1</td><td>89.1</td></tr><tr><td>Ours</td><td>29,536</td><td>69.5</td><td>78.3</td><td>91.3</td><td>95.2</td><td>96.1</td></tr></table>", "caption": "Table 2: Our method achieves the best accuracy and generalization with the fewest parameters. We report accuracy on varying proportions of MSTAR training data. The performance gap is wider for smaller train-sets, with Real-CNN and DCN failing to generalize.", "list_citation_info": ["[16] Chiheb Trabelsi, Olexa Bilaniuk, Ying Zhang, Dmitriy Serdyuk, Sandeep Subramanian, Jo\u00e3o Felipe Santos, Soroush Mehri, Negar Rostamzadeh, Yoshua Bengio, and Christopher J Pal. Deep complex networks. arXiv preprint arXiv:1705.09792, 2017.", "[18] Rudrasis Chakraborty, Yifei Xing, and Stella Yu. Surreal: Complex-valued deep learning as principled transformations on a rotational lie group. arXiv preprint arXiv:1910.11334, 2019."]}]}