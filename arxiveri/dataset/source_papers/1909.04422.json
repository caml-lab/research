{"title": "The Mapillary Traffic Sign Dataset for Detection and Classification on a Global Scale", "abstract": "Traffic signs are essential map features globally in the era of autonomous driving and smart cities. To develop accurate and robust algorithms for traffic sign detection and classification, a large-scale and diverse benchmark dataset is required. In this paper, we introduce a traffic sign benchmark dataset of 100K street-level images around the world that encapsulates diverse scenes, wide coverage of geographical locations, and varying weather and lighting conditions and covers more than 300 manually annotated traffic sign classes. The dataset includes 52K images that are fully annotated and 48K images that are partially annotated. This is the largest and the most diverse traffic sign dataset consisting of images from all over world with fine-grained annotations of traffic sign classes. We have run extensive experiments to establish strong baselines for both the detection and the classification tasks. In addition, we have verified that the diversity of this dataset enables effective transfer learning for existing large-scale benchmark datasets on traffic sign detection and classification. The dataset is freely available for academic research: https://www.mapillary.com/dataset/trafficsign.", "authors": ["Christian Ertler", " Jerneja Mislej", " Tobias Ollmann", " Lorenzo Porzi", " Gerhard Neuhold", " Yubin Kuang"], "pdf_url": "https://arxiv.org/abs/1909.04422", "list_table_and_caption": [{"table": "<table><tr><td>Dataset</td><td>#Images</td><td>#Classes</td><td>#Signs</td><td>Attributes</td><td>Region</td><td>BBoxes</td><td>Unique</td></tr><tr><td>MTSD (TRAIN+VAL)MTSD </td><td> 41,907100,000</td><td>313</td><td> <sup>1</sup><sup>1</sup>footnotemark: 1206,388325,172</td><td> occluded, exterior,out-of-frame, dummy,ambiguous, included </td><td>world-wide</td><td>\u2713</td><td> \u2713\u2717<sup>4</sup><sup>4</sup>footnotemark: 4 </td></tr><tr><td>TT100K [36]</td><td><sup>2</sup><sup>2</sup>footnotemark: 2 100,000</td><td><sup>6</sup><sup>6</sup>footnotemark: 6 221</td><td>26,349</td><td>\u2717</td><td>China</td><td>\u2713</td><td>\u2713</td></tr><tr><td>MVD [21]</td><td>20,000</td><td><sup>2</sup><sup>2</sup>footnotemark: 22</td><td>174,541</td><td>\u2717</td><td>world-wide</td><td>\u2713</td><td>\u2713</td></tr><tr><td>GTSDB [9]</td><td>900</td><td>43</td><td>852</td><td>\u2717</td><td>Germany</td><td>\u2713</td><td>\u2717</td></tr><tr><td>RTSD [25]</td><td><sup>3</sup><sup>3</sup>footnotemark: 3179,138</td><td>156</td><td><sup>3</sup><sup>3</sup>footnotemark: 3104,358</td><td>\u2717</td><td>Russia</td><td>\u2713</td><td>\u2717</td></tr><tr><td>STS [12]</td><td>3777</td><td>20</td><td>5582</td><td>\u2717</td><td>Sweden</td><td>\u2713</td><td>\u2717</td></tr><tr><td>LISA [20]</td><td>6610</td><td>47</td><td>7855</td><td>\u2717</td><td>USA</td><td>\u2713</td><td>\u2717</td></tr><tr><td>GTSRB [30]</td><td>\u2717</td><td>43</td><td>39,210</td><td>\u2717</td><td>Germany</td><td>\u2717</td><td>\u2717</td></tr><tr><td>BelgiumTS [31]</td><td>\u2717</td><td>108</td><td>8851</td><td>\u2717</td><td>Belgium</td><td>\u2717</td><td>\u2717</td></tr></table>", "caption": "Table 1: Overview of traffic sign datasets. The numbers include only publicly available images and annotations (e.g. we only report numbers for the training and validation set for MTSD). Unique refers to datasets where each traffic sign bounding box corresponds to a unique traffic sign instance (i.e. no sequences showing the same sign again and again). <sup>1</sup><sup>1</sup>footnotemark: 166,138 signs are within the taxonomy. <sup>2</sup><sup>2</sup>footnotemark: 2 TT100K contains only 10,000 images containing traffic signs. <sup>6</sup><sup>6</sup>footnotemark: 6 only 45 classes have more than 100 examples. <sup>2</sup><sup>2</sup>footnotemark: 2 MVD contains only back vs. front classes. <sup>3</sup><sup>3</sup>footnotemark: 3video-frames covering only 15,630 unique signs. <sup>4</sup><sup>4</sup>footnotemark: 4signs within the partially annotated set correspond to signs within the training set.", "list_citation_info": ["[31] R. Timofte, K. Zimmermann, and L. Van Gool. Multi-view traffic sign detection, recognition, and 3d localisation. Machine vision and applications, 25(3):633\u2013647, 2014.", "[12] F. Larsson, M. Felsberg, and P.-E. Forssen. Correlating Fourier descriptors of local patches for road sign recognition. IET Computer Vision, 5(4):244\u2013254, 2011.", "[9] S. Houben, J. Stallkamp, J. Salmen, M. Schlipsing, and C. Igel. Detection of traffic signs in real-world images: The German Traffic Sign Detection Benchmark. In International Joint Conference on Neural Networks, number 1288, 2013.", "[30] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition. Neural Networks, (0):\u2013, 2012.", "[36] Z. Zhu, D. Liang, S. Zhang, X. Huang, B. Li, and S. Hu. Traffic-sign detection and classification in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2110\u20132118, 2016.", "[20] A. Mogelmose, M. M. Trivedi, and T. B. Moeslund. Vision-based traffic sign detection and analysis for intelligent driver assistance systems: Perspectives and survey. IEEE Transactions on Intelligent Transportation Systems, 13(4):1484\u20131497, 2012.", "[25] V. Shakhuro and A. Konushin. Russian traffic sign images dataset. Computer Optics, 40(2):294\u2013300, 2016.", "[21] G. Neuhold, T. Ollmann, S. Rota Bulo, and P. Kontschieder. The mapillary vistas dataset for semantic understanding of street scenes. In Proceedings of the IEEE International Conference on Computer Vision, pages 4990\u20134999, 2017."]}, {"table": "<table><tr><td></td><td colspan=\"4\">Max 4000px</td><td colspan=\"4\">Max 2048px</td></tr><tr><td></td><td>\\mathrm{AP}</td><td>\\mathrm{AP}_{\\mathrm{s}}</td><td>\\mathrm{AP}_{\\mathrm{m}}</td><td>\\mathrm{AP}_{\\mathrm{l}}</td><td>\\mathrm{AP}</td><td>\\mathrm{AP}_{\\mathrm{s}}</td><td>\\mathrm{AP}_{\\mathrm{m}}</td><td>\\mathrm{AP}_{\\mathrm{l}}</td></tr><tr><td colspan=\"9\">MTSD</td></tr><tr><td>ResNet50 FPN</td><td>87.3</td><td>73.03</td><td>91.91</td><td>93.56</td><td>80.22</td><td>52.31</td><td>88.87</td><td>94.73</td></tr><tr><td>ResNet101 FPN</td><td>88.44</td><td>74.00</td><td>92.14</td><td>93.70</td><td>81.80</td><td>56.55</td><td>89.22</td><td>94.82</td></tr><tr><td colspan=\"9\">TT100K</td></tr><tr><td>[36] multi-scale<sup>1</sup><sup>1</sup>footnotemark: 1</td><td>91.79</td><td>84.56</td><td>96.40</td><td>92.60</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>ResNet50 FPN</td><td>-</td><td>-</td><td>-</td><td>-</td><td>91.27</td><td>84.01</td><td>95.87</td><td>90.13</td></tr><tr><td> + pre-trained on MTSD</td><td></td><td>-</td><td>-</td><td>-</td><td>97.60 (+6.33)</td><td>93.13</td><td>99.03</td><td>98.44</td></tr><tr><td colspan=\"9\">MVD (traffic signs)</td></tr><tr><td>ResNet50 FPN</td><td>72.90</td><td>46.60</td><td>79.93</td><td>85.42</td><td>64.00</td><td>30.70</td><td>75.28</td><td>86.50</td></tr><tr><td> + pre-trained on MTSD</td><td>76.31 (+3.41)</td><td>51.00</td><td>83.49</td><td>88.33</td><td>68.29 (+4.29)</td><td>33.60</td><td>79.45</td><td>89.53</td></tr></table>", "caption": "Table 3: Detection results on MTSD, TT100K and MVD. Numbers in brackets refer to absolute improvements when pre-training on MTSD in comparison to ImageNet. <sup>1</sup><sup>1</sup>footnotemark: 1 They evaluate using multi-scale inference with scales 0.5, 1, 2, and 4.", "list_citation_info": ["[36] Z. Zhu, D. Liang, S. Zhang, X. Huang, B. Li, and S. Hu. Traffic-sign detection and classification in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2110\u20132118, 2016."]}, {"table": "<table><tr><td></td><td>\\mathrm{mAP}</td><td>\\mathrm{mAP}_{\\mathrm{s}}</td><td>\\mathrm{mAP}_{\\mathrm{m}}</td><td>\\mathrm{mAP}_{\\mathrm{l}}</td></tr><tr><td colspan=\"5\">MTSD</td></tr><tr><td>FPN50 + classifier</td><td>81.1</td><td>69.4</td><td>85.0</td><td>87.2</td></tr><tr><td>FPN101 + classifier</td><td>83.4</td><td>76.4</td><td>85.8</td><td>87.3</td></tr><tr><td colspan=\"5\">TT100K</td></tr><tr><td>[36] multi-scale</td><td>81.6</td><td>68.3</td><td>86.5</td><td>85.7</td></tr><tr><td>FPN50 + classifier</td><td>89.9 (+8.3)</td><td>83.9</td><td>93.0</td><td>84.3</td></tr><tr><td>+ det pre-trained</td><td>93.4 (+11.8)</td><td>88.2</td><td>94.8</td><td>93.6</td></tr><tr><td>+ cls pre-trained</td><td>95.7 (+14.1)</td><td>91.3</td><td>96.9</td><td>96.7</td></tr></table>", "caption": "Table 4: Simultaneous detection and classification results. The numbers in brackets are absolute improvements over [36]. det pre-trained and cls  pre-trained refer to experiments with additionally MTSD pre-trained detector and classifier, respectively.", "list_citation_info": ["[36] Z. Zhu, D. Liang, S. Zhang, X. Huang, B. Li, and S. Hu. Traffic-sign detection and classification in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2110\u20132118, 2016."]}]}