{"title": "Visual Transformer with Statistical Test for COVID-19 Classification", "abstract": "With the massive damage in the world caused by Coronavirus Disease 2019 SARS-CoV-2 (COVID-19), many related research topics have been proposed in the past two years. The Chest Computed Tomography (CT) scans are the most valuable materials to diagnose the COVID-19 symptoms. However, most schemes for COVID-19 classification of Chest CT scan is based on a single-slice level, implying that the most critical CT slice should be selected from the original CT scan volume manually. We simultaneously propose 2-D and 3-D models to predict the COVID-19 of CT scan to tickle this issue. In our 2-D model, we introduce the Deep Wilcoxon signed-rank test (DWCC) to determine the importance of each slice of a CT scan to overcome the issue mentioned previously. Furthermore, a Convolutional CT scan-Aware Transformer (CCAT) is proposed to discover the context of the slices fully. The frame-level feature is extracted from each CT slice based on any backbone network and followed by feeding the features to our within-slice-Transformer (WST) to discover the context information in the pixel dimension. The proposed Between-Slice-Transformer (BST) is used to aggregate the extracted spatial-context features of every CT slice. A simple classifier is then used to judge whether the Spatio-temporal features are COVID-19 or non-COVID-19. The extensive experiments demonstrated that the proposed CCAT and DWCC significantly outperform the state-of-the-art methods.", "authors": ["Chih-Chung Hsu", " Guan-Lin Chen", " Mei-Hsuan Wu"], "pdf_url": "https://arxiv.org/abs/2107.05334", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Method</td><td>Acc.</td><td>P</td><td>R</td><td>F1</td></tr><tr><td>Baseline [8]</td><td>0.724</td><td>0.731</td><td>0.688</td><td>0.700</td></tr><tr><td>DenseNet201 [5]</td><td>0.732</td><td>0.714</td><td>0.703</td><td>0.708</td></tr><tr><td>Proposed DWCC</td><td>0.919</td><td>0.931</td><td>0.911</td><td>0.917</td></tr><tr><td>Proposed CCAT</td><td>0.933</td><td>0.935</td><td>0.929</td><td>0.932</td></tr><tr><td>Model ensemble</td><td>0.941</td><td>0.947</td><td>0.935</td><td>0.939</td></tr></tbody></table>", "caption": "Table 1: Performance evaluation of validation set of the proposed methods and other peer methods in terms accuracy, macro-precision, macro-recall, macro-F1-score (results in blue indicates the implemented ourselves).", "list_citation_info": ["[8] Dimitrios Kollias, Anastasios Arsenos, Levon Soukissian, and Stefanos Kollias. Mia-cov19d: Covid-19 detection through 3-d chest ct image analysis. arXiv preprint arXiv:2106.07524, 2021.", "[5] Shaoping Hu, Yuan Gao, Zhangming Niu, Yinghui Jiang, Lao Li, Xianglu Xiao, Minhao Wang, Evandro Fei Fang, Wade Menpes-Smith, Jun Xia, et al. Weakly supervised deep learning for covid-19 infection detection and classification from ct images. IEEE Access, 8:118869\u2013118883, 2020."]}]}