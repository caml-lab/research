{"title": "Enhance to read better: A multi-task adversarial network for handwritten document image enhancement", "abstract": "Handwritten document images can be highly affected by degradation for different reasons: Paper ageing, daily-life scenarios (wrinkles, dust, etc.), bad scanning process and so on. These artifacts raise many readability issues for current Handwritten Text Recognition (HTR) algorithms and severely devalue their efficiency. In this paper, we propose an end to end architecture based on Generative Adversarial Networks (GANs) to recover the degraded documents into a clean and readable form. Unlike the most well-known document binarization methods, which try to improve the visual quality of the degraded document, the proposed architecture integrates a handwritten text recognizer that promotes the generated document image to be more readable. To the best of our knowledge, this is the first work to use the text information while binarizing handwritten documents. Extensive experiments conducted on degraded Arabic and Latin handwritten documents demonstrate the usefulness of integrating the recognizer within the GAN architecture, which improves both the visual quality and the readability of the degraded document images. Moreover, we outperform the state of the art in H-DIBCO challenges, after fine tuning our pre-trained model with synthetically degraded Latin handwritten images, on this task.", "authors": ["Sana Khamekhem Jemni", " Mohamed Ali Souibgui", " Yousri Kessentini", " Alicia Forn\u00e9s"], "pdf_url": "https://arxiv.org/abs/2105.12710", "list_table_and_caption": [{"table": "<table><tbody><tr><td></td><td colspan=\"4\"><p>Binarization Performance</p><p>(Visual Quality)</p></td><td colspan=\"2\">Reco. CRNN1 %</td><td colspan=\"2\">Reco. CRNN2 %</td></tr><tr><td>Method</td><td>PSNR</td><td>FM</td><td>Fps</td><td>DRD</td><td>CER</td><td>WER</td><td>CER</td><td>WER</td></tr><tr><td><p>CRNN flor2020CRNN </p><p>(GT \\rightarrow GT)</p></td><td>ND</td><td>ND</td><td>ND</td><td>ND</td><td>12.04</td><td>32.39</td><td>-</td><td>-</td></tr><tr><td><p>CRNN flor2020CRNN </p><p>(Deg. \\rightarrow Deg.)</p></td><td>4.80</td><td>25.45</td><td>25.70</td><td>107.22</td><td>30.34</td><td>54.44</td><td>-</td><td>-</td></tr><tr><td><p>CRNN flor2020CRNN </p><p>(GT \\rightarrow Deg.)</p></td><td>4.80</td><td>25.45</td><td>25.70</td><td>107.22</td><td>91.18</td><td>100</td><td>-</td><td>-</td></tr><tr><td>Baseline cGAN</td><td>15.52</td><td>75.01</td><td>75.11</td><td>6.05</td><td>29.24</td><td>53.68</td><td>-</td><td>-</td></tr><tr><td>cGAN souibgui2020conditional </td><td>15.10</td><td>75.56</td><td>75.75</td><td>11.78</td><td>28.84</td><td>54.37</td><td>-</td><td>-</td></tr><tr><td>Ours (S1)</td><td>15.45</td><td>77.45</td><td>77.60</td><td>7.97</td><td>27.03</td><td>52.84</td><td>24.33</td><td>47.67</td></tr><tr><td>Ours (S2)</td><td>15.44</td><td>74.52</td><td>74.62</td><td>6.18</td><td>27.90</td><td>53.49</td><td>25.31</td><td>48.48</td></tr></tbody></table>", "caption": "Table 1: Image binarization results for the test set (degraded-KHATT database). (A \\rightarrow B): The CRNN is trained on images from the domain A and tested on images from the domain B. Deg.: Degraded images. Reco.: Recognition performance. ", "list_citation_info": ["(27) A. F. S. Neto, B. L. D. Bezerra, A. H. Toselli, E. B. Lima, HTR-Flor: a deep learning system for offline handwritten text recognition, in: 2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI), 2020, pp. 54\u201361. doi:10.1109/SIBGRAPI51738.2020.00016.", "(3) M. A. Souibgui, Y. Kessentini, A. Forn\u00e9s, A conditional gan based approach for distorted camera captured documents recovery, in: Mediterranean Conference on Pattern Recognition and Artificial Intelligence, Springer, 2020."]}, {"table": "<table><tbody><tr><td></td><td colspan=\"4\"><p>Binarization Performance</p><p>(Visual Quality)</p></td><td colspan=\"2\">Reco. CRNN1 %</td><td colspan=\"2\">Reco. CRNN2 %</td></tr><tr><td>Method</td><td>PSNR</td><td>FM</td><td>Fps</td><td>DRD</td><td>CER</td><td>WER</td><td>CER</td><td>WER</td></tr><tr><td><p>CRNN flor2020CRNN </p><p>(GT \\rightarrow GT)</p></td><td>ND</td><td>ND</td><td>ND</td><td>ND</td><td>11.92</td><td>36.07</td><td>-</td><td>-</td></tr><tr><td><p>CRNN flor2020CRNN </p><p>(Deg. \\rightarrow Deg.)</p></td><td>6.01</td><td>26.13</td><td>26.12</td><td>70.81</td><td>40.34</td><td>74.05</td><td>-</td><td>-</td></tr><tr><td><p>CRNN flor2020CRNN </p><p>(GT \\rightarrow Deg.)</p></td><td>6.01</td><td>26.13</td><td>26.12</td><td>70.81</td><td>90.46</td><td>99.50</td><td>-</td><td>-</td></tr><tr><td>Baseline cGAN</td><td>14.99</td><td>75.44</td><td>75.01</td><td>5.91</td><td>31.51</td><td>60.95</td><td>-</td><td>-</td></tr><tr><td>cGAN souibgui2020conditional </td><td>15.86</td><td>80.89</td><td>80.83</td><td>5.00</td><td>27.55</td><td>58.08</td><td>-</td><td>-</td></tr><tr><td>Ours (S1)</td><td>15.97</td><td>81.69</td><td>81.55</td><td>4.83</td><td>26.05</td><td>56.07</td><td>21.98</td><td>49.74</td></tr><tr><td>Ours (S2)</td><td>15.87</td><td>81.12</td><td>81.16</td><td>5.09</td><td>27.48</td><td>58.35</td><td>23.07</td><td>51.15</td></tr></tbody></table>", "caption": "Table 3: Image binarization results for the test set (degraded-IAM database).(A \\rightarrow B): The CRNN is trained on images from the domain A and tested on images from the domain B. Deg.: Degraded images. Reco.: Recognition performance.", "list_citation_info": ["(27) A. F. S. Neto, B. L. D. Bezerra, A. H. Toselli, E. B. Lima, HTR-Flor: a deep learning system for offline handwritten text recognition, in: 2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI), 2020, pp. 54\u201361. doi:10.1109/SIBGRAPI51738.2020.00016.", "(3) M. A. Souibgui, Y. Kessentini, A. Forn\u00e9s, A conditional gan based approach for distorted camera captured documents recovery, in: Mediterranean Conference on Pattern Recognition and Artificial Intelligence, Springer, 2020."]}, {"table": "<table><thead><tr><th><p>Dataset</p></th><th><p>Binarization Method</p></th><th><p>CER%</p></th><th><p>WER%</p></th></tr></thead><tbody><tr><td rowspan=\"5\">degraded-KHATT</td><td><p>Otsu otsu1979threshold </p></td><td><p>54.28</p></td><td><p>85.42</p></td></tr><tr><td><p>Sauvola sauvola2000adaptive </p></td><td><p>58.42</p></td><td><p>99.57</p></td></tr><tr><td><p>cGAN souibgui2020conditional </p></td><td><p>28.32</p></td><td><p>53.96</p></td></tr><tr><td><p>Baseline cGAN</p></td><td><p>28.61</p></td><td><p>53.73</p></td></tr><tr><td>Ours (S1)</td><td>26.57</td><td>52.31</td></tr><tr><td rowspan=\"5\">degraded-IAM</td><td><p>Otsu otsu1979threshold </p></td><td><p>62.62</p></td><td><p>81.96</p></td></tr><tr><td><p>Sauvola sauvola2000adaptive </p></td><td><p>72.48</p></td><td><p>98.00</p></td></tr><tr><td><p>cGAN souibgui2020conditional </p></td><td><p>27.21</p></td><td><p>58.18</p></td></tr><tr><td><p>Baseline cGAN</p></td><td><p>31.31</p></td><td><p>61.79</p></td></tr><tr><td>Ours (S1)</td><td>25.79</td><td>56.43</td></tr></tbody></table>", "caption": "Table 4: Impact of the proposed binarization method (scenario S1) on the recognition performance by a HTR system.", "list_citation_info": ["(11) J. Sauvola, M. Pietik\u00e4inen, Adaptive document image binarization, Pattern recognition 33 (2) (2000) 225\u2013236.", "(10) N. Otsu, A threshold selection method from gray-level histograms, IEEE transactions on systems, man, and cybernetics 9 (1) (1979) 62\u201366.", "(3) M. A. Souibgui, Y. Kessentini, A. Forn\u00e9s, A conditional gan based approach for distorted camera captured documents recovery, in: Mediterranean Conference on Pattern Recognition and Artificial Intelligence, Springer, 2020."]}, {"table": "<table><tbody><tr><td>Method</td><td>PSNR</td><td>FM</td><td>Fps</td><td>DRD</td><td>Avg</td></tr><tr><td>Otsu otsu1979threshold </td><td>15.03</td><td>80.18</td><td>82.65</td><td>26.46</td><td>62.85</td></tr><tr><td>Sauvola et al. sauvola2000adaptive </td><td>16.71</td><td>82.89</td><td>87.95</td><td>6.59</td><td>70.24</td></tr><tr><td>Guo et al. Guo2019 </td><td>17.86</td><td>86.40</td><td>89.00</td><td>4.67</td><td>72.14</td></tr><tr><td>Zhao et al. zhao2019document </td><td>21.91</td><td>94.96</td><td>96.15</td><td>1.55</td><td>77.86</td></tr><tr><td>Competition winner Pratikakis2012ICFHR </td><td>21.80</td><td>89.47</td><td>90.18</td><td>3.44</td><td>74.50</td></tr><tr><td>Kang et al. kang2021complex </td><td>21.37</td><td>95.16</td><td>96.44</td><td>1.13</td><td>77.96</td></tr><tr><td>Ours (S1)</td><td>16.29</td><td>79.25</td><td>85.96</td><td>7.33</td><td>68.54</td></tr><tr><td>Ours (S1) + Fine-tuning</td><td>22.00</td><td>95.18</td><td>94.63</td><td>1.62</td><td>77.54</td></tr></tbody></table>", "caption": "Table 5: Comparative results of our proposed method on H-DIBCO 2012 Dataset for document binarization. Avg = (PSNR + FM + Fps + (100 - DRD)) / 4.", "list_citation_info": ["(8) J. Zhao, C. Shi, F. Jia, Y. Wang, B. Xiao, Document image binarization with cascaded generators of conditional generative adversarial networks, Pattern Recognition 96 (2019) 106968.", "(7) S. Kang, B. K. Iwana, S. Uchida, Complex image processing with less data document image binarization by integrating multiple pretrained u-net modules, Pattern Recognition 109 (2021) 107577.", "(11) J. Sauvola, M. Pietik\u00e4inen, Adaptive document image binarization, Pattern recognition 33 (2) (2000) 225\u2013236.", "(31) I. Pratikakis, B. Gatos and K. Ntirogiannis, ICFHR 2012 competition on handwritten document image binarization (H-DIBCO 2012), in: Proceedings of the International Conference on Frontiers in Handwriting Recognition, IEEE, 2012, pp. 817\u2013\u2013822.", "(38) J. Guo, C. He, X. Zhang, Nonlinear edge-preserving diffusion with adaptive source for document images binarization, Appl. Math. and Comput. 351 (2019) 8\u201322. doi:10.1016/j.amc.2019.01.021.", "(10) N. Otsu, A threshold selection method from gray-level histograms, IEEE transactions on systems, man, and cybernetics 9 (1) (1979) 62\u201366."]}, {"table": "<table><tbody><tr><td>Method</td><td>PSNR</td><td>FM</td><td>Fps</td><td>DRD</td><td>Avg</td></tr><tr><td>Otsu otsu1979threshold </td><td>17.80</td><td>86.61</td><td>88.67</td><td>7.46</td><td>71.40</td></tr><tr><td>Sauvola et al. sauvola2000adaptive </td><td>16.42</td><td>82.52</td><td>86.85</td><td>5.56</td><td>70.05</td></tr><tr><td>Vo et al. Vo2018 </td><td>19.01</td><td>90.10</td><td>93.57</td><td>3.58</td><td>74.77</td></tr><tr><td>Guo et al. Guo2019 </td><td>18.42</td><td>88.51</td><td>90.46</td><td>4.13</td><td>73.31</td></tr><tr><td>He and Schomaker He2019 </td><td>19.60</td><td>91.40</td><td>94.30</td><td>2.90</td><td>75.6</td></tr><tr><td>Zhao et al. zhao2019document </td><td>19.64</td><td>91.66</td><td>94.58</td><td>2.82</td><td>75.76</td></tr><tr><td>Competition winner Pratikakis2016 </td><td>18.11</td><td>87.61</td><td>91.28</td><td>5.21</td><td>72.94</td></tr><tr><td>Bera et al. Bera2021 </td><td>18.94</td><td>90.43</td><td>91.66</td><td>3.51</td><td>74.38</td></tr><tr><td>Kang et al. kang2021complex </td><td>19.18</td><td>93.09</td><td>94.85</td><td>3.03</td><td>76.02</td></tr><tr><td>Ours (S1)</td><td>14.26</td><td>69.52</td><td>78.01</td><td>12.11</td><td>62.42</td></tr><tr><td>Ours (S1) + Fine-tuning</td><td>21.85</td><td>94.95</td><td>94.55</td><td>1.56</td><td>77.44</td></tr></tbody></table>", "caption": "Table 6: Comparative results of our proposed method on H-DIBCO 2016 Dataset for document binarization. Avg = (PSNR + FM + Fps + (100 - DRD)) / 4.", "list_citation_info": ["(8) J. Zhao, C. Shi, F. Jia, Y. Wang, B. Xiao, Document image binarization with cascaded generators of conditional generative adversarial networks, Pattern Recognition 96 (2019) 106968.", "(7) S. Kang, B. K. Iwana, S. Uchida, Complex image processing with less data document image binarization by integrating multiple pretrained u-net modules, Pattern Recognition 109 (2021) 107577.", "(41) Q.N. Vo, S.H. Kim, H.J. Yang, G. Lee, Binarization of degraded document images based on hierarchical deep supervised network, Pattern Recognition 74 (2018) 568\u2013\u2013586. doi:doi:10.1016/j.patcog.2017.08.025.", "(11) J. Sauvola, M. Pietik\u00e4inen, Adaptive document image binarization, Pattern recognition 33 (2) (2000) 225\u2013236.", "(40) I. Pratikakis, K. Zagoris, G. Barlas, B. Gatos, ICFHR 2016 handwritten document image binarization contest (H-DIBCO 2016), in: 2016 International Conference on Frontiers in Handwriting Recognition, IEEE, 2016, pp. 619\u2013\u2013623. doi:10.1109/icfhr.2016.0118.", "(38) J. Guo, C. He, X. Zhang, Nonlinear edge-preserving diffusion with adaptive source for document images binarization, Appl. Math. and Comput. 351 (2019) 8\u201322. doi:10.1016/j.amc.2019.01.021.", "(23) He, Sheng and Schomaker, Lambert, Deepotsu: Document enhancement and binarization using iterative deep learning, Pattern Recognition 91 (2019) 379\u2013390. doi:10.1016/j.patcog.2019.01.025.", "(42) S. K. Bera, S. Ghosh, S. Bhowmik, et al., A non-parametric binarization method based on ensemble of clustering algorithms, Multimedia Tools and Applications 80 (2021) 7653\u20137673. doi:10.1007/s11042-020-09836-z.", "(10) N. Otsu, A threshold selection method from gray-level histograms, IEEE transactions on systems, man, and cybernetics 9 (1) (1979) 62\u201366."]}, {"table": "<table><tbody><tr><td>Method</td><td>PSNR</td><td>FM</td><td>Fps</td><td>DRD</td><td>Avg</td></tr><tr><td>Otsu otsu1979threshold </td><td>13.85</td><td>77.73</td><td>77.89</td><td>15.54</td><td>63.48</td></tr><tr><td>Sauvola et al. sauvola2000adaptive </td><td>14.25</td><td>77.11</td><td>84.1</td><td>8.85</td><td>66.65</td></tr><tr><td>Zhao et al. zhao2019document </td><td>17.83</td><td>90.73</td><td>92.58</td><td>3.58</td><td>74.39</td></tr><tr><td>Competition winner Pratikakis2017 </td><td>18.28</td><td>91.04</td><td>92.86</td><td>3.40</td><td>74.69</td></tr><tr><td>Kang et al. kang2021complex </td><td>15.85</td><td>91.57</td><td>93.55</td><td>2.92</td><td>74.51</td></tr><tr><td>Bera et al. Bera2021 </td><td>15.45</td><td>83.38</td><td>89.43</td><td>6.71</td><td>70.38</td></tr><tr><td>Ours (S1)</td><td>13.54</td><td>71.13</td><td>80.39</td><td>9.60</td><td>63.86</td></tr><tr><td>Ours (S1) + Fine-tuning</td><td>17.45</td><td>89.8</td><td>89.95</td><td>4.03</td><td>73.29</td></tr></tbody></table>", "caption": "Table 7: Comparative results of our proposed method on DIBCO 2017 Dataset for document binarization. Avg = (PSNR + FM + Fps + (100 - DRD)) / 4.", "list_citation_info": ["(8) J. Zhao, C. Shi, F. Jia, Y. Wang, B. Xiao, Document image binarization with cascaded generators of conditional generative adversarial networks, Pattern Recognition 96 (2019) 106968.", "(7) S. Kang, B. K. Iwana, S. Uchida, Complex image processing with less data document image binarization by integrating multiple pretrained u-net modules, Pattern Recognition 109 (2021) 107577.", "(11) J. Sauvola, M. Pietik\u00e4inen, Adaptive document image binarization, Pattern recognition 33 (2) (2000) 225\u2013236.", "(39) I. Pratikakis, K. Zagoris, G. Barlas, B. Gatos, Icdar 2017 competition on document image binarization (dibco 2017), in: 2017 International Conference on Document Analysis and Recognition, IEEE, 2017, pp. 1395\u2013\u20131403. doi:10.1109/icdar.2017.228.", "(42) S. K. Bera, S. Ghosh, S. Bhowmik, et al., A non-parametric binarization method based on ensemble of clustering algorithms, Multimedia Tools and Applications 80 (2021) 7653\u20137673. doi:10.1007/s11042-020-09836-z.", "(10) N. Otsu, A threshold selection method from gray-level histograms, IEEE transactions on systems, man, and cybernetics 9 (1) (1979) 62\u201366."]}, {"table": "<table><tbody><tr><td>Method</td><td>PSNR</td><td>FM</td><td>Fps</td><td>DRD</td><td>Avg</td></tr><tr><td>Otsu otsu1979threshold </td><td>9.74</td><td>51.45</td><td>53.05</td><td>59.07</td><td>38.79</td></tr><tr><td>Sauvola et al. sauvola2000adaptive </td><td>13.78</td><td>67.81</td><td>74.08</td><td>17.69</td><td>59.50</td></tr><tr><td>Adak et al. Pratikakis2018icfhr </td><td>14.62</td><td>73.45</td><td>75.94</td><td>26.24</td><td>59.44</td></tr><tr><td>Souibgui et al. souibgui2020gan </td><td>16.16</td><td>77.59</td><td>85.74</td><td>7.93</td><td>67.89</td></tr><tr><td>Tamrin et al. tamrin2021 </td><td>17.04</td><td>83.08</td><td>88.46</td><td>5.09</td><td>70.87</td></tr><tr><td>Zhao et al. zhao2019document </td><td>18.37</td><td>87.73</td><td>90.6</td><td>4.58</td><td>73.03</td></tr><tr><td>Competition winner Pratikakis2018icfhr </td><td>19.11</td><td>88.34</td><td>90.24</td><td>4.92</td><td>73.19</td></tr><tr><td>Akbari et al. akbari2020binarization </td><td>19.17</td><td>89.05</td><td>93.65</td><td>4.80</td><td>74.26</td></tr><tr><td>Kang et al. kang2021complex </td><td>19.39</td><td>89.71</td><td>91.62</td><td>2.51</td><td>74.55</td></tr><tr><td>Dang et al. Dang2021Binarization </td><td>19.81</td><td>91.26</td><td>93.97</td><td>3.42</td><td>75.40</td></tr><tr><td>Bera et al. Bera2021 </td><td>15.31</td><td>76.84</td><td>83.58</td><td>9.58</td><td>66.53</td></tr><tr><td>Ours (S1)</td><td>13.88</td><td>65.06</td><td>73.46</td><td>12.86</td><td>59.89</td></tr><tr><td>Ours (S1) + Fine-tuning</td><td>20.18</td><td>92.41</td><td>94.35</td><td>2.60</td><td>76.08</td></tr></tbody></table>", "caption": "Table 8: Results for all methods on H-DIBCO 2018 Dataset for handwritten document binarization. Avg = (PSNR + FM + Fps + (100 - DRD)) / 4.", "list_citation_info": ["(8) J. Zhao, C. Shi, F. Jia, Y. Wang, B. Xiao, Document image binarization with cascaded generators of conditional generative adversarial networks, Pattern Recognition 96 (2019) 106968.", "(7) S. Kang, B. K. Iwana, S. Uchida, Complex image processing with less data document image binarization by integrating multiple pretrained u-net modules, Pattern Recognition 109 (2021) 107577.", "(11) J. Sauvola, M. Pietik\u00e4inen, Adaptive document image binarization, Pattern recognition 33 (2) (2000) 225\u2013236.", "(20) Y. Akbari, S. Al-Maadeed, K. Adam, Binarization of degraded document images using convolutional neural networks and wavelet-based multichannel images, IEEE Access 8 (2020) 153517\u2013153534. doi:10.1109/ACCESS.2020.3017783.", "(5) M. A. Souibgui, Y. Kessentini, De-gan: A conditional generative adversarial network for document enhancement, IEEE Transactions on Pattern Analysis and Machine Intelligence.", "(42) S. K. Bera, S. Ghosh, S. Bhowmik, et al., A non-parametric binarization method based on ensemble of clustering algorithms, Multimedia Tools and Applications 80 (2021) 7653\u20137673. doi:10.1007/s11042-020-09836-z.", "(10) N. Otsu, A threshold selection method from gray-level histograms, IEEE transactions on systems, man, and cybernetics 9 (1) (1979) 62\u201366.", "(6) M. O. Tamrin, M. El-Amine Ech-Cherif, M. Cheriet, A two-stage unsupervised deep learning framework for degradation removal in ancient documents, in: Pattern Recognition. ICPR International Workshops and Challenges, Springer International Publishing, 2021, pp. 292\u2013303.", "(25) Q.-V. Dang, G.-S. Lee, Document image binarization with stroke boundary feature guided network, IEEE Access 9 (2021) 36924\u201336936. doi:10.1109/ACCESS.2021.3062904.", "(2) I. Pratikakis, K. Zagori, P. Kaddas, B. Gatos, Icfhr 2018 competition on handwritten document image binarization (h-dibco 2018), in: 2018 16th International Conference on Frontiers in Handwriting Recognition (ICFHR), 2018, pp. 489\u2013493. doi:10.1109/ICFHR-2018.2018.00091."]}]}