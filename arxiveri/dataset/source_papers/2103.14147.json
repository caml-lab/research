{"title": "Equivariant Point Network for 3D Point Cloud Analysis", "abstract": "Features that are equivariant to a larger group of symmetries have been shown to be more discriminative and powerful in recent studies. However, higher-order equivariant features often come with an exponentially-growing computational cost. Furthermore, it remains relatively less explored how rotation-equivariant features can be leveraged to tackle 3D shape alignment tasks. While many past approaches have been based on either non-equivariant or invariant descriptors to align 3D shapes, we argue that such tasks may benefit greatly from an equivariant framework. In this paper, we propose an effective and practical SE(3) (3D translation and rotation) equivariant network for point cloud analysis that addresses both problems. First, we present SE(3) separable point convolution, a novel framework that breaks down the 6D convolution into two separable convolutional operators alternatively performed in the 3D Euclidean and SO(3) spaces. This significantly reduces the computational cost without compromising the performance. Second, we introduce an attention layer to effectively harness the expressiveness of the equivariant features. While jointly trained with the network, the attention layer implicitly derives the intrinsic local frame in the feature space and generates attention vectors that can be integrated into different alignment tasks. We evaluate our approach through extensive studies and visual interpretations. The empirical results demonstrate that our proposed model outperforms strong baselines in a variety of benchmarks", "authors": ["Haiwei Chen", " Shichen Liu", " Weikai Chen", " Hao Li"], "pdf_url": "https://arxiv.org/abs/2103.14147", "list_table_and_caption": [{"table": "<table><tr><td></td><td>Mean ({}^{\\circ})</td><td>Median ({}^{\\circ})</td><td>Max({}^{\\circ})</td></tr><tr><td>KPConv [43]</td><td>11.46</td><td>8.06</td><td>82.32</td></tr><tr><td>Ours-20</td><td>1.36</td><td>1.16</td><td>8.30</td></tr><tr><td>Ours-60</td><td>1.25</td><td>1.11</td><td>6.63</td></tr></table>", "caption": "Table 1: Angular errors in point cloud pose estimation.", "list_citation_info": ["[43] Hugues Thomas, Charles R Qi, Jean-Emmanuel Deschaud, Beatriz Marcotegui, Fran\u00e7ois Goulette, and Leonidas J Guibas. Kpconv: Flexible and deformable convolution for point clouds. arXiv preprint arXiv:1904.08889, 2019."]}, {"table": "<table><tr><td>Representation</td><td>Methods</td><td>Acc (%)</td><td> Retrieval(mAP) </td></tr><tr><td rowspan=\"2\">3D Surface</td><td>RotationNet [26]</td><td>80.0</td><td>74.2</td></tr><tr><td>Sph. CNN [12]</td><td>86.9</td><td>-</td></tr><tr><td rowspan=\"6\">Point cloud</td><td>QENet [55]</td><td>74.4</td><td>-</td></tr><tr><td>PointNet [36]</td><td>83.6</td><td>-</td></tr><tr><td>PointNet++ [38]</td><td>85.0</td><td>70.3</td></tr><tr><td>DGCNN [36]</td><td>81.1</td><td>-</td></tr><tr><td>PointCNN [38]</td><td>84.5</td><td>-</td></tr><tr><td>KPConv [43]</td><td>86.7</td><td>77.5</td></tr><tr><td></td><td>Ours</td><td>88.3</td><td>79.7</td></tr></table>", "caption": "Table 2: Results on shape classification and retrieval on randomly rotated objects of ModelNet40.", "list_citation_info": ["[55] Yongheng Zhao, Tolga Birdal, Jan Eric Lenssen, Emanuele Menegatti, Leonidas Guibas, and Federico Tombari. Quaternion equivariant capsule networks for 3d point clouds. arXiv preprint arXiv:1912.12098, 2019.", "[38] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in neural information processing systems, pages 5099\u20135108, 2017.", "[26] Asako Kanezaki, Yasuyuki Matsushita, and Yoshifumi Nishida. Rotationnet: Joint object categorization and pose estimation using multiviews from unsupervised viewpoints. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5010\u20135019, 2018.", "[12] Carlos Esteves, Christine Allen-Blanchette, Ameesh Makadia, and Kostas Daniilidis. Learning so (3) equivariant representations with spherical cnns. In Proceedings of the European Conference on Computer Vision (ECCV), pages 52\u201368, 2018.", "[43] Hugues Thomas, Charles R Qi, Jean-Emmanuel Deschaud, Beatriz Marcotegui, Fran\u00e7ois Goulette, and Leonidas J Guibas. Kpconv: Flexible and deformable convolution for point clouds. arXiv preprint arXiv:1904.08889, 2019.", "[36] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 652\u2013660, 2017."]}, {"table": "<table><tr><td></td><td>SHOT[45]</td><td>3DMatch[54]</td><td>CGF[27]</td><td>PPFNet[10]</td><td>PPFF[9]</td><td>3DSNet[17]</td><td>Li[32]</td><td>Li[32]{}^{\\flat}</td><td>Ours</td></tr><tr><td>Kitchen</td><td>74.3</td><td>58.3</td><td>60.3</td><td>89.7</td><td>78.7</td><td>97.5</td><td>92.1</td><td>99.4</td><td>99.0</td></tr><tr><td>Home 1</td><td>80.1</td><td>72.4</td><td>71.1</td><td>55.8</td><td>76.3</td><td>96.2</td><td>91.0</td><td>98.7</td><td>99.4</td></tr><tr><td>Home 2</td><td>70.7</td><td>61.5</td><td>56.7</td><td>59.1</td><td>61.5</td><td>93.2</td><td>85.6</td><td>94.7</td><td>96.2</td></tr><tr><td>Hotel 1</td><td>77.4</td><td>54.9</td><td>57.1</td><td>58.0</td><td>68.1</td><td>97.4</td><td>95.1</td><td>99.6</td><td>99.6</td></tr><tr><td>Hotel 2</td><td>72.1</td><td>48.1</td><td>53.8</td><td>57.7</td><td>71.2</td><td>92.8</td><td>91.3</td><td>100.0</td><td>97.1</td></tr><tr><td>Hotel 3</td><td>85.2</td><td>61.1</td><td>83.3</td><td>61.1</td><td>94.4</td><td>98.2</td><td>96.3</td><td>100.0</td><td>100.0</td></tr><tr><td>Study</td><td>64.0</td><td>51.7</td><td>37.7</td><td>53.4</td><td>62.0</td><td>95.0</td><td>91.8</td><td>95.5</td><td>96.2</td></tr><tr><td>MIT Lab</td><td>62.3</td><td>50.7</td><td>45.5</td><td>63.6</td><td>62.3</td><td>94.1</td><td>84.4</td><td>92.2</td><td>93.5</td></tr><tr><td>Average</td><td>73.3</td><td>57.3</td><td>58.2</td><td>62.3</td><td>71.8</td><td>95.6</td><td>91.0</td><td>97.5</td><td>97.6</td></tr></table>", "caption": "Table 4: Comparisons of average recall of keypoint correspondences on 3DMatch.Li [32]{}^{\\flat} denotes results tested with point normal information provided by the authors. All other results are tested on the official 3DMatch evaluation set without point normals.", "list_citation_info": ["[54] Andy Zeng, Shuran Song, Matthias Nie\u00dfner, Matthew Fisher, Jianxiong Xiao, and Thomas Funkhouser. 3dmatch: Learning local geometric descriptors from rgb-d reconstructions. In CVPR, 2017.", "[45] Federico Tombari, Samuele Salti, and Luigi Di Stefano. Unique shape context for 3d data description. In Proceedings of the ACM workshop on 3D object retrieval, pages 57\u201362. ACM, 2010.", "[10] Haowen Deng, Tolga Birdal, and Slobodan Ilic. Ppfnet: Global context aware local features for robust 3d point matching. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 195\u2013205, 2018.", "[27] Marc Khoury, Qian-Yi Zhou, and Vladlen Koltun. Learning compact geometric features. In Proceedings of the IEEE International Conference on Computer Vision, pages 153\u2013161, 2017.", "[32] Lei Li, Siyu Zhu, Hongbo Fu, Ping Tan, and Chiew-Lan Tai. End-to-end learning local multi-view descriptors for 3d point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1919\u20131928, 2020.", "[17] Zan Gojcic, Caifa Zhou, Jan D Wegner, and Andreas Wieser. The perfect match: 3d point cloud matching with smoothed densities. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5545\u20135554, 2019.", "[9] Haowen Deng, Tolga Birdal, and Slobodan Ilic. Ppf-foldnet: Unsupervised learning of rotation invariant 3d local descriptors. In Proceedings of the European Conference on Computer Vision (ECCV), pages 602\u2013618, 2018."]}]}