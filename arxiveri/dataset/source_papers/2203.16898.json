{"title": "Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis", "abstract": "Recent years have witnessed substantial progress in semantic image synthesis, it is still challenging in synthesizing photo-realistic images with rich details. Most previous methods focus on exploiting the given semantic map, which just captures an object-level layout for an image. Obviously, a fine-grained part-level semantic layout will benefit object details generation, and it can be roughly inferred from an object's shape. In order to exploit the part-level layouts, we propose a Shape-aware Position Descriptor (SPD) to describe each pixel's positional feature, where object shape is explicitly encoded into the SPD feature. Furthermore, a Semantic-shape Adaptive Feature Modulation (SAFM) block is proposed to combine the given semantic map and our positional features to produce adaptively modulated features. Extensive experiments demonstrate that the proposed SPD and SAFM significantly improve the generation of objects with rich details. Moreover, our method performs favorably against the SOTA methods in terms of quantitative and qualitative evaluation. The source code and model are available at https://github.com/cszy98/SAFM.", "authors": ["Zhengyao Lv", " Xiaoming Li", " Zhenxing Niu", " Bing Cao", " Wangmeng Zuo"], "pdf_url": "https://arxiv.org/abs/2203.16898", "list_table_and_caption": [{"table": "<table><tr><td></td><td colspan=\"3\">Cityscapes</td><td colspan=\"3\">ADE20K</td><td colspan=\"3\">COCO-Stuff</td></tr><tr><td rowspan=\"-2\"> Methods </td><td>mIoU \\uparrow</td><td>Acc \\uparrow</td><td>FID \\downarrow</td><td>mIoU \\uparrow</td><td>Acc \\uparrow</td><td>FID \\downarrow</td><td>mIoU \\uparrow</td><td>Acc \\uparrow</td><td>FID \\downarrow</td></tr><tr><td>CRN [7]</td><td>52.4</td><td>77.1</td><td>104.7</td><td>22.4</td><td>68.8</td><td>73.3</td><td>23.7</td><td>40.4</td><td>70.4</td></tr><tr><td>SIMS [29]</td><td>47.2</td><td>75.5</td><td>49.7</td><td>N/A</td><td>N/A</td><td>N/A</td><td>N/A</td><td>N/A</td><td>N/A</td></tr><tr><td>pix2pixHD [35]</td><td>58.3</td><td>81.4</td><td>95.0</td><td>20.3</td><td>69.2</td><td>81.8</td><td>14.6</td><td>45.7</td><td>111.5</td></tr><tr><td>SPADE [28]</td><td>62.3</td><td>81.9</td><td>71.8</td><td>38.5</td><td>79.9</td><td>33.9</td><td>37.4</td><td>67.9</td><td>22.6</td></tr><tr><td>CC-FPSE [21]</td><td>65.6</td><td>82.3</td><td>54.3</td><td>43.7</td><td>82.9</td><td>31.7</td><td>41.6</td><td>70.7</td><td>19.2</td></tr><tr><td>LGGAN [33]</td><td>68.4</td><td>83.0</td><td>57.7</td><td>41.6</td><td>81.8</td><td>31.6</td><td>N/A</td><td>N/A</td><td>N/A</td></tr><tr><td>OASIS [31]</td><td>69.3</td><td>N/A</td><td>47.7</td><td>48.3</td><td>N/A</td><td>28.3</td><td>44.1</td><td>N/A</td><td>17.0</td></tr><tr><td>SC-GAN [36]</td><td>66.9</td><td>82.5</td><td>49.5</td><td>45.2</td><td>83.8</td><td>29.3</td><td>42.0</td><td>72.0</td><td>18.1</td></tr><tr><td>Ours</td><td>70.4</td><td>83.1</td><td>49.5</td><td>50.1</td><td>86.6</td><td>32.8</td><td>43.3</td><td>73.4</td><td>24.6</td></tr></table>", "caption": "Table 1: The quantitative comparison with the competing methods on different datasets. \\uparrow (\\downarrow) indicates higher (lower) is better.", "list_citation_info": ["[35] Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. High-resolution image synthesis and semantic manipulation with conditional gans. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8798\u20138807, 2018.", "[28] Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu. Semantic image synthesis with spatially-adaptive normalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2337\u20132346, 2019.", "[33] Hao Tang, Dan Xu, Yan Yan, Philip HS Torr, and Nicu Sebe. Local class-specific and global image-level generative adversarial networks for semantic-guided scene generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7870\u20137879, 2020.", "[7] Qifeng Chen and Vladlen Koltun. Photographic image synthesis with cascaded refinement networks. In Proceedings of the IEEE international conference on computer vision, pages 1511\u20131520, 2017.", "[21] Xihui Liu, Guojun Yin, Jing Shao, Xiaogang Wang, and Hongsheng Li. Learning to predict layout-to-image conditional convolutions for semantic image synthesis. arXiv preprint arXiv:1910.06809, 2019.", "[31] Vadim Sushko, Edgar Sch\u00f6nfeld, Dan Zhang, Juergen Gall, Bernt Schiele, and Anna Khoreva. You only need adversarial supervision for semantic image synthesis. arXiv preprint arXiv:2012.04781, 2020.", "[36] Yi Wang, Lu Qi, Ying-Cong Chen, Xiangyu Zhang, and Jiaya Jia. Image synthesis via semantic composition. arXiv preprint arXiv:2109.07053, 2021.", "[29] Xiaojuan Qi, Qifeng Chen, Jiaya Jia, and Vladlen Koltun. Semi-parametric image synthesis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8808\u20138816, 2018."]}]}