{"title": "Table Structure Recognition Using Top-Down and Bottom-Up Cues", "abstract": "Tables are information-rich structured objects in document images. While significant work has been done in localizing tables as graphic objects in document images, only limited attempts exist on table structure recognition. Most existing literature on structure recognition depends on extraction of meta-features from the PDF document or on the optical character recognition (OCR) models to extract low-level layout features from the image. However, these methods fail to generalize well because of the absence of meta-features or errors made by the OCR when there is a significant variance in table layouts and text organization. In our work, we focus on tables that have complex structures, dense content, and varying layouts with no dependency on meta-features and/or OCR.\n  We present an approach for table structure recognition that combines cell detection and interaction modules to localize the cells and predict their row and column associations with other detected cells. We incorporate structural constraints as additional differential components to the loss function for cell detection. We empirically validate our method on the publicly available real-world datasets - ICDAR-2013, ICDAR-2019 (cTDaR) archival, UNLV, SciTSR, SciTSR-COMP, TableBank, and PubTabNet. Our attempt opens up a new direction for table structure recognition by combining top-down (table cells detection) and bottom-up (structure recognition) cues in visually understanding the tables.", "authors": ["Sachin Raja", " Ajoy Mondal", " C. V. Jawahar"], "pdf_url": "https://arxiv.org/abs/2010.04565", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Method</td><td colspan=\"2\">Training</td><td>Experimental</td><td>P\\uparrow</td><td>R\\uparrow</td><td>F1\\uparrow</td></tr><tr><td></td><td>Dataset</td><td>#Images</td><td>Setup</td><td></td><td></td><td></td></tr><tr><td>deepdesrt [7]</td><td>scitsr</td><td>12K</td><td>S-A</td><td>0.631</td><td>0.619</td><td>0.625</td></tr><tr><td>splerge [10]</td><td>scitsr</td><td>12K</td><td>S-A</td><td>0.883</td><td>0.875</td><td>0.879</td></tr><tr><td>split+heuristic [10]</td><td>Private [10]</td><td>83K</td><td>S-A</td><td>0.938</td><td>0.922</td><td>0.930</td></tr><tr><td>tabstruct-net (our)</td><td>scitsr</td><td>12K</td><td>S-A</td><td>0.915</td><td>0.897</td><td>0.906</td></tr><tr><td>tablenet [12]</td><td>Marmot Extended</td><td>1K</td><td>S-B</td><td>0.922</td><td>0.899</td><td>0.910</td></tr><tr><td>graphtsr [14]</td><td>scitsr</td><td>12K</td><td>S-B</td><td>0.885</td><td>0.860</td><td>0.872</td></tr><tr><td>split-pdf [10]</td><td>Private [10]</td><td>83K</td><td>S-B</td><td>0.920</td><td>0.913</td><td>0.916</td></tr><tr><td>split-pdf</td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>+heuristic [10]</td><td>Private [10]</td><td>83K</td><td>S-B</td><td>0.959</td><td>0.946</td><td>0.953</td></tr><tr><td>dgcnn [9]</td><td>scitsr</td><td>12K</td><td>S-B</td><td>0.972</td><td>0.983</td><td>0.977</td></tr><tr><td>tabstruct-net (our)</td><td>scitsr</td><td>12K</td><td>S-B</td><td>0.976</td><td>0.985</td><td>0.981</td></tr></tbody></table>", "caption": "Table 4: Comparison of results for physical structure recognition on icdar-2013 dataset. #Images: indicates number of table images in the training set. Heuristic: indicates dataset specific cell merging rules for various models in [10].", "list_citation_info": ["[7] Schreiber, S., Agne, S., Wolf, I., Dengel, A., Ahmed, S.: DeepDeSRT: Deep learning for detection and structure recognition of tables in document images. In: ICDAR. (2017)", "[14] Chi, Z., Huang, H., Xu, H.D., Yu, H., Yin, W., Mao, X.L.: Complicated table structure recognition. arXiv (2019)", "[12] Paliwal, S.S., Vishwanath, D., Rahul, R., Sharma, M., Vig, L.: TableNet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images. In: ICDAR. (2019)", "[9] Qasim, S.R., Mahmood, H., Shafait, F.: Rethinking table parsing using graph neural networks. In: ICDAR. (2019)", "[10] Tensmeyer, C., Morariu, V., Price, B., Cohen, S., Martinezp, T.: Deep splitting and merging for table structure decomposition. In: ICDAR. (2019)"]}, {"table": "<table><tbody><tr><td>Method</td><td colspan=\"2\">Training</td><td>Exp.</td><td>P\\uparrow</td><td>R\\uparrow</td><td>F1\\uparrow</td></tr><tr><td></td><td>Dataset</td><td>#Images</td><td>Setup</td><td></td><td></td><td></td></tr><tr><td>deepdesrt [7]</td><td>icdar-2013-partial</td><td>0.124K</td><td>S-A</td><td>0.959</td><td>0.874</td><td>0.914</td></tr><tr><td>splerge [10]</td><td>icdar-2013-partial</td><td>0.124K</td><td>S-A</td><td>0.917</td><td>0.911</td><td>0.914</td></tr><tr><td>Bi-directional gru [15]</td><td>icdar-2013-partial</td><td>0.124K</td><td>S-A</td><td>0.969</td><td>0.901</td><td>0.934</td></tr><tr><td>tabstruct-net (our)</td><td>icdar-2013-partial</td><td>0.124K</td><td>S-A</td><td>0.928</td><td>0.903</td><td>0.915</td></tr><tr><td>tabstruct-net (our)</td><td>scitsr</td><td>12.124K</td><td>S-A</td><td>0.930</td><td>0.908</td><td>0.919</td></tr><tr><td></td><td>+ icdar-2013-partial</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>tablenet [12]</td><td>Marmot extended</td><td>1.016K</td><td>S-B</td><td>0.931</td><td>0.900</td><td>0.915</td></tr><tr><td>graphtsr [14]</td><td>scitsr</td><td>12.124K</td><td>S-B</td><td>0.854</td><td>0.891</td><td>0.872</td></tr><tr><td></td><td>+ icdar-2013-partial</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>dgcnn [9]</td><td>scitsr</td><td>12.124K</td><td>S-B</td><td>0.986</td><td>0.990</td><td>0.988</td></tr><tr><td></td><td>+ icdar-2013-partial</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>tabstruct-net (our)</td><td>icdar-2013-partial</td><td>0.124K</td><td>S-B</td><td>0.991</td><td>0.989</td><td>0.990</td></tr><tr><td>tabstruct-net (our)</td><td>scitsr</td><td>12.124K</td><td>S-B</td><td>0.991</td><td>0.993</td><td>0.992</td></tr><tr><td></td><td>+ icdar-2013-partial</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table>", "caption": "Table 7: Comparison of results for physical structure recognition on icdar-2013-partial dataset. P: indicates precision, R: indicates recall, F1: indicates F1 Score and #Images: indicates number of table images in the training set. ", "list_citation_info": ["[15] Khan, S.A., Khalid, S.M.D., Shahzad, M.A., Shafait, F.: Table structure extraction with Bi-directional Gated Recurrent Unit networks. In: ICDAR. (2019)", "[7] Schreiber, S., Agne, S., Wolf, I., Dengel, A., Ahmed, S.: DeepDeSRT: Deep learning for detection and structure recognition of tables in document images. In: ICDAR. (2017)", "[12] Paliwal, S.S., Vishwanath, D., Rahul, R., Sharma, M., Vig, L.: TableNet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images. In: ICDAR. (2019)", "[14] Chi, Z., Huang, H., Xu, H.D., Yu, H., Yin, W., Mao, X.L.: Complicated table structure recognition. arXiv (2019)", "[9] Qasim, S.R., Mahmood, H., Shafait, F.: Rethinking table parsing using graph neural networks. In: ICDAR. (2019)", "[10] Tensmeyer, C., Morariu, V., Price, B., Cohen, S., Martinezp, T.: Deep splitting and merging for table structure decomposition. In: ICDAR. (2019)"]}, {"table": "<table><thead><tr><th>Method</th><th colspan=\"2\">Training</th><th>Exp.</th><th>P\\uparrow</th><th>R\\uparrow</th><th>F1\\uparrow</th></tr><tr><th></th><th>Dataset</th><th>#Images</th><th>Setup</th><th></th><th></th><th></th></tr></thead><tbody><tr><td>nlpr-pal [19]</td><td>ctdar</td><td>0.6K</td><td>S-A</td><td>0.720</td><td>0.770</td><td>0.745</td></tr><tr><td>dgcnn [9]</td><td>ctdar</td><td>0.6K</td><td>S-A</td><td>0.785</td><td>0.751</td><td>0.768</td></tr><tr><td>dgcnn [9]</td><td>scitsr</td><td>12.0K</td><td>S-A</td><td>0.552</td><td>0.519</td><td>0.535</td></tr><tr><td>dgcnn [9]</td><td>ctdar + scitsr</td><td>12.6K</td><td>S-A</td><td>0.803</td><td>0.778</td><td>0.790</td></tr><tr><td>splerge [10]</td><td>ctdar</td><td>0.6K</td><td>S-A</td><td>0.774</td><td>0.783</td><td>0.778</td></tr><tr><td>splerge [10]</td><td>scitsr</td><td>12.0K</td><td>S-A</td><td>0.559</td><td>0.572</td><td>0.565</td></tr><tr><td>splerge [10]</td><td>ctdar + scitsr</td><td>12.6K</td><td>S-A</td><td>0.792</td><td>0.800</td><td>0.796</td></tr><tr><td>tabstruct-net (our)</td><td>ctdar</td><td>0.6K</td><td>S-A</td><td>0.803</td><td>0.768</td><td>0.785</td></tr><tr><td>tabstruct-net (our)</td><td>scitsr</td><td>12.0K</td><td>S-A</td><td>0.595</td><td>0.572</td><td>0.583</td></tr><tr><td>tabstruct-net (our)</td><td>ctdar + scitsr</td><td>12.6K</td><td>S-A</td><td>0.822</td><td>0.787</td><td>0.804</td></tr></tbody></table>", "caption": "Table 8: Comparison of results for physical structure recognition on icdar-2019 (ctdar) archival dataset. For comparison against dgcnn [9], we use the cell bounding boxes detected from tabstruct-net for a fair comparison. P: indicates precision, R: indicates recall, F1: indicates F1 Score and #Images: indicates number of table images in the training set.", "list_citation_info": ["[9] Qasim, S.R., Mahmood, H., Shafait, F.: Rethinking table parsing using graph neural networks. In: ICDAR. (2019)", "[10] Tensmeyer, C., Morariu, V., Price, B., Cohen, S., Martinezp, T.: Deep splitting and merging for table structure decomposition. In: ICDAR. (2019)"]}, {"table": "<table><thead><tr><th>Method</th><th>Exp. Setup</th><th>P\\uparrow</th><th>R\\uparrow</th><th>F1\\uparrow</th></tr></thead><tbody><tr><th>deepdesrt [7]</th><th>S-A</th><td>0.554</td><td>0.529</td><td>0.541</td></tr><tr><th>splerge [10]</th><th>S-A</th><td>0.795</td><td>0.776</td><td>0.785</td></tr><tr><th>tabstruct-net (our)</th><th>S-A</th><td>0.849</td><td>0.828</td><td>0.839</td></tr><tr><th>graphtsr [14]</th><th>S-B</th><td>0.763</td><td>0.786</td><td>0.774</td></tr><tr><th>dgcnn [9]</th><th>S-B</th><td>0.921</td><td>0.898</td><td>0.909</td></tr><tr><th>tabstruct-net (our)</th><th>S-B</th><td>0.992</td><td>0.994</td><td>0.993</td></tr></tbody></table>", "caption": "Table 9: Comparison of results for physical structure recognition on unlv-partial dataset. P: indicates precision, R: indicates recall, F1: indicates F1 Score. All models are trained on scitsr and fine-tuned on unlv-partial datasets.", "list_citation_info": ["[7] Schreiber, S., Agne, S., Wolf, I., Dengel, A., Ahmed, S.: DeepDeSRT: Deep learning for detection and structure recognition of tables in document images. In: ICDAR. (2017)", "[9] Qasim, S.R., Mahmood, H., Shafait, F.: Rethinking table parsing using graph neural networks. In: ICDAR. (2019)", "[10] Tensmeyer, C., Morariu, V., Price, B., Cohen, S., Martinezp, T.: Deep splitting and merging for table structure decomposition. In: ICDAR. (2019)", "[14] Chi, Z., Huang, H., Xu, H.D., Yu, H., Yin, W., Mao, X.L.: Complicated table structure recognition. arXiv (2019)"]}, {"table": "<table><thead><tr><th>Method</th><th>Exp.</th><th colspan=\"6\">Evaluation on</th></tr><tr><th></th><th>Setup</th><th colspan=\"3\">SciTSR</th><th colspan=\"3\">SciTSR-COMP</th></tr><tr><th></th><th></th><th>P\\uparrow</th><th>R\\uparrow</th><th>F1\\uparrow</th><th>P\\uparrow</th><th>R\\uparrow</th><th>F1\\uparrow</th></tr></thead><tbody><tr><th>deepdesrt [7]</th><th>S-A</th><td>0.906</td><td>0.887</td><td>0.890</td><td>0.863</td><td>0.831</td><td>0.846</td></tr><tr><th>splerge [10]</th><th>S-A</th><td>0.922</td><td>0.915</td><td>0.918</td><td>0.911</td><td>0.880</td><td>0.895</td></tr><tr><th>tabstruct-net (our)</th><th>S-A</th><td>0.927</td><td>0.913</td><td>0.920</td><td>0.909</td><td>0.882</td><td>0.895</td></tr><tr><th>graphtsr [14]</th><th>S-B</th><td>0.959</td><td>0.948</td><td>0.953</td><td>0.964</td><td>0.945</td><td>0.955</td></tr><tr><th>dgcnn [9]</th><th>S-B</th><td>0.970</td><td>0.981</td><td>0.976</td><td>0.963</td><td>0.974</td><td>0.969</td></tr><tr><th>tabstruct-net (our)</th><th>S-B</th><td>0.989</td><td>0.993</td><td>0.991</td><td>0.981</td><td>0.987</td><td>0.984</td></tr></tbody></table>", "caption": "Table 10: Comparison of results for physical structure recognition on scitsr and scitsr-comp datasets. P: indicates precision, R: indicates recall, F1: indicates F1 Score. All the models are trained on scitsr dataset.", "list_citation_info": ["[7] Schreiber, S., Agne, S., Wolf, I., Dengel, A., Ahmed, S.: DeepDeSRT: Deep learning for detection and structure recognition of tables in document images. In: ICDAR. (2017)", "[9] Qasim, S.R., Mahmood, H., Shafait, F.: Rethinking table parsing using graph neural networks. In: ICDAR. (2019)", "[10] Tensmeyer, C., Morariu, V., Price, B., Cohen, S., Martinezp, T.: Deep splitting and merging for table structure decomposition. In: ICDAR. (2019)", "[14] Chi, Z., Huang, H., Xu, H.D., Yu, H., Yin, W., Mao, X.L.: Complicated table structure recognition. arXiv (2019)"]}, {"table": "<table><tbody><tr><td>Method</td><td colspan=\"3\">Training Set</td><td>Experimental</td><td colspan=\"3\">BLEU\\uparrow</td></tr><tr><td></td><td>Dataset</td><td>Type</td><td>#Images</td><td>Setup</td><td>Word</td><td>Latex</td><td>Both</td></tr><tr><td>Image-to-Text [12]</td><td>tablebank</td><td>Word</td><td>55.866K</td><td>S-A</td><td>0.751</td><td>0.673</td><td>0.7138</td></tr><tr><td>Image-to-Text [12]</td><td>tablebank</td><td>Latex</td><td>87.597K</td><td>S-A</td><td>0.405</td><td>0.765</td><td>0.582</td></tr><tr><td>Image-to-Text [12]</td><td>tablebank</td><td>Both</td><td>144.493K</td><td>S-A</td><td>0.712</td><td>0.765</td><td>0.738</td></tr><tr><td>tabstruct-net (our)</td><td>scitsr</td><td>Image</td><td>12K</td><td>S-A</td><td>0.914</td><td>0.937</td><td>0.916</td></tr></tbody></table>", "caption": "Table 11: Comparison of results for logical structure recognition on tablebank dataset.", "list_citation_info": ["[12] Paliwal, S.S., Vishwanath, D., Rahul, R., Sharma, M., Vig, L.: TableNet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images. In: ICDAR. (2019)"]}, {"table": "<table><tbody><tr><td>Method</td><td>Experimental Setup</td><td>Training Dataset</td><td>#Images</td><td>TEDS\\uparrow</td></tr><tr><td>Acrobat Pro [13]</td><td>S-A</td><td>-</td><td>-</td><td>0.537</td></tr><tr><td>wygiwys [13]</td><td>S-A</td><td>pubtabnet</td><td>399K</td><td>0.786</td></tr><tr><td>edd [13]</td><td>S-A</td><td>pubtabnet</td><td>399K</td><td>0.883</td></tr><tr><td>tabstruct-net (our)</td><td>S-A</td><td>scitsr [14]</td><td>12K</td><td>0.901</td></tr></tbody></table>", "caption": "Table 12: Comparison of results for logical structure recognition on pubtabnet dataset [13]. TEDS: indicates averaged tree edit distance based similarity [13].", "list_citation_info": ["[13] Zhong, X., ShafieiBavani, E., Yepes, A.J.: Image-based table recognition: data, model, and evaluation. arXiv (2019)", "[14] Chi, Z., Huang, H., Xu, H.D., Yu, H., Yin, W., Mao, X.L.: Complicated table structure recognition. arXiv (2019)"]}]}