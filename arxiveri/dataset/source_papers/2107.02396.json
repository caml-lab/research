{"title": "Semi-tcl: Semi-supervised Track Contrastive Representation Learning", "abstract": "Online tracking of multiple objects in videos requires strong capacity of modeling and matching object appearances. Previous methods for learning appearance embedding mostly rely on instance-level matching without considering the temporal continuity provided by videos. We design a new instance-to-track matching objective to learn appearance embedding that compares a candidate detection to the embedding of the tracks persisted in the tracker. It enables us to learn not only from videos labeled with complete tracks, but also unlabeled or partially labeled videos. We implement this learning objective in a unified form following the spirit of constrastive loss. Experiments on multiple object tracking datasets demonstrate that our method can effectively learning discriminative appearance embeddings in a semi-supervised fashion and outperform state of the art methods on representative benchmarks.", "authors": ["Wei Li", " Yuanjun Xiong", " Shuo Yang", " Mingze Xu", " Yongxin Wang", " Wei Xia"], "pdf_url": "https://arxiv.org/abs/2107.02396", "list_table_and_caption": [{"table": "<table><thead><tr><th colspan=\"7\">MOT15 test</th></tr></thead><tbody><tr><th><p>Methods</p></th><td><p>IDF1</p></td><td><p>MOTA</p></td><td><p>IDS</p></td><td><p>MT</p></td><td><p>ML</p></td><td><p>Frag</p></td></tr><tr><th><p>FairMOT[42]</p></th><td><p>64.7</p></td><td><p>60.6</p></td><td><p>591</p></td><td>343</td><td><p>79</p></td><td><p>1731</p></td></tr><tr><th><p>GSDT[34]</p></th><td><p>64.6</p></td><td>60.7</td><td>477</td><td><p>339</p></td><td><p>76</p></td><td><p>1705</p></td></tr><tr><th><p>TubeTK[22]</p></th><td><p>53.1</p></td><td><p>58.4</p></td><td><p>854</p></td><td><p>283</p></td><td><p>130</p></td><td>1194</td></tr><tr><th><p>Semi-TCL</p></th><td>64.9</td><td><p>60.6</p></td><td><p>551</p></td><td><p>344</p></td><td><p>88</p></td><td><p>1687</p></td></tr><tr><th colspan=\"7\">MOT16 test</th></tr><tr><th><p>Methods</p></th><td><p>IDF1</p></td><td><p>MOTA</p></td><td><p>IDS</p></td><td><p>MT</p></td><td><p>ML</p></td><td><p>Frag</p></td></tr><tr><th><p>DeepSort[36]</p></th><td><p>62.2</p></td><td><p>61.4</p></td><td>781</td><td>249</td><td><p>138</p></td><td><p>2008</p></td></tr><tr><th><p>TubeTK[22]</p></th><td><p>59.4</p></td><td><p>64.0</p></td><td><p>1117</p></td><td><p>254</p></td><td><p>147</p></td><td>1366</td></tr><tr><th><p>CTracker[23]</p></th><td><p>57.2</p></td><td><p>67.6</p></td><td><p>1897</p></td><td><p>250</p></td><td><p>175</p></td><td><p>3112</p></td></tr><tr><th><p>GSDT[34]</p></th><td><p>69.2</p></td><td><p>66.7</p></td><td><p>959</p></td><td><p>293</p></td><td><p>144</p></td><td><p>2596</p></td></tr><tr><th><p>FairMOT[42]</p></th><td><p>72.8</p></td><td>74.9</td><td><p>815</p></td><td><p>306</p></td><td><p>127</p></td><td><p>2399</p></td></tr><tr><th><p>Semi-TCL</p></th><td>73.9</td><td><p>74.8</p></td><td><p>925</p></td><td><p>322</p></td><td>130</td><td><p>2569</p></td></tr><tr><th colspan=\"7\">MOT17 test</th></tr><tr><th><p>Methods</p></th><td><p>IDF1</p></td><td><p>MOTA</p></td><td><p>IDS</p></td><td><p>MT</p></td><td><p>ML</p></td><td><p>Frag</p></td></tr><tr><th><p>SST[31]</p></th><td><p>49.5</p></td><td><p>52.4</p></td><td><p>8431</p></td><td>504</td><td><p>723</p></td><td><p>14797</p></td></tr><tr><th><p>TubeTK [22]</p></th><td><p>58.6</p></td><td><p>63.0</p></td><td><p>4137</p></td><td><p>735</p></td><td><p>468</p></td><td>5727</td></tr><tr><th><p>Ctr.Track [29]</p></th><td><p>64.7</p></td><td><p>67.8</p></td><td><p>3039</p></td><td><p>816</p></td><td><p>579</p></td><td><p>6102</p></td></tr><tr><th><p>CTracker [23]</p></th><td><p>57.4</p></td><td><p>66.6</p></td><td><p>5529</p></td><td><p>759</p></td><td><p>570</p></td><td><p>9114</p></td></tr><tr><th><p>GSDT [23]</p></th><td><p>66.5</p></td><td><p>73.2</p></td><td><p>3891</p></td><td><p>981</p></td><td><p>411</p></td><td><p>8604</p></td></tr><tr><th><p>FairMOT[42]</p></th><td><p>72.3</p></td><td>73.7</td><td><p>3303</p></td><td><p>1017</p></td><td>408</td><td><p>8073</p></td></tr><tr><th><p>Semi-TCL</p></th><td>73.3</td><td><p>73.3</p></td><td>2790</td><td><p>972</p></td><td><p>441</p></td><td><p>8010</p></td></tr><tr><th colspan=\"7\">MOT20 test</th></tr><tr><th><p>Methods</p></th><td><p>IDF1</p></td><td><p>MOTA</p></td><td><p>IDS</p></td><td><p>MT</p></td><td><p>ML</p></td><td><p>Frag</p></td></tr><tr><th><p>FairMOT[42]</p></th><td><p>67.3</p></td><td><p>61.8</p></td><td><p>5243</p></td><td><p>855</p></td><td>94</td><td>7874</td></tr><tr><th><p>GSDT [34]</p></th><td><p>67.5</p></td><td>67.1</td><td>3131</td><td>660</td><td><p>164</p></td><td><p>9875</p></td></tr><tr><th><p>Semi-TCL</p></th><td>70.1</td><td><p>65.2</p></td><td><p>4139</p></td><td><p>761</p></td><td><p>131</p></td><td><p>8508</p></td></tr></tbody></table>", "caption": "Table 1: Evaluating Semi-TCL the private detection tracks of the MOT challenge benchmarks. We report results evaluated by the public evaluation servers. Bold fonts mark the best results. ", "list_citation_info": ["[31] ShiJie Sun, Naveed Akhtar, HuanSheng Song, Ajmal Mian, and Mubarak Shah. Deep affinity network for multiple object tracking. IEEE transactions on pattern analysis and machine intelligence, 43(1):104\u2013119, 2019.", "[23] Jinlong Peng, Changan Wang, Fangbin Wan, Yang Wu, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, and Yanwei Fu. Chained-tracker: Chaining paired attentive regression results for end-to-end joint multiple-object detection and tracking. In European Conference on Computer Vision, pages 145\u2013161. Springer, 2020.", "[34] Yongxin Wang, Kris Kitani, and Xinshuo Weng. Joint object detection and multi-object tracking with graph neural networks. arXiv preprint arXiv:2006.13164, 5, 2020.", "[36] Nicolai Wojke, Alex Bewley, and Dietrich Paulus. Simple online and realtime tracking with a deep association metric. In 2017 IEEE international conference on image processing (ICIP), pages 3645\u20133649. IEEE, 2017.", "[42] Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng, and Wenyu Liu. Fairmot: On the fairness of detection and re-identification in multiple object tracking. arXiv preprint arXiv:2004.01888, 2020.", "[29] Robert Stone et al. Centertrack: An ip overlay network for tracking dos floods. In USENIX Security Symposium, volume 21, page 114, 2000.", "[22] Bo Pang, Yizhuo Li, Yifan Zhang, Muchen Li, and Cewu Lu. Tubetk: Adopting tubes to track multi-object in a one-step training model. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6308\u20136318, 2020."]}]}