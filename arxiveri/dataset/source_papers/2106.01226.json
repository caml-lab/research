{"title": "Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision", "abstract": "In this paper, we study the semi-supervised semantic segmentation problem via exploring both labeled data and extra unlabeled data. We propose a novel consistency regularization approach, called cross pseudo supervision (CPS). Our approach imposes the consistency on two segmentation networks perturbed with different initialization for the same input image. The pseudo one-hot label map, output from one perturbed segmentation network, is used to supervise the other segmentation network with the standard cross-entropy loss, and vice versa. The CPS consistency has two roles: encourage high similarity between the predictions of two perturbed networks for the same input image, and expand training data by using the unlabeled data with pseudo labels. Experiment results show that our approach achieves the state-of-the-art semi-supervised segmentation performance on Cityscapes and PASCAL VOC 2012. Code is available at https://git.io/CPS.", "authors": ["Xiaokang Chen", " Yuhui Yuan", " Gang Zeng", " Jingdong Wang"], "pdf_url": "https://arxiv.org/abs/2106.01226", "list_table_and_caption": [{"table": "<table><tbody><tr><th rowspan=\"2\">Method</th><td colspan=\"4\">ResNet-50</td><td colspan=\"4\">ResNet-101</td></tr><tr><td>1/16 (662)</td><td>1/8 (1323)</td><td>1/4 (2646)</td><td>1/2 (5291)</td><td>1/16 (662)</td><td>1/8 (1323)</td><td>1/4 (2646)</td><td>1/2 (5291)</td></tr><tr><th>MT [32]</th><td>66.77</td><td>70.78</td><td>73.22</td><td>75.41</td><td>70.59</td><td>73.20</td><td>76.62</td><td>77.61</td></tr><tr><th>CCT [27]</th><td>65.22</td><td>70.87</td><td>73.43</td><td>74.75</td><td>67.94</td><td>73.00</td><td>76.17</td><td>77.56</td></tr><tr><th>CutMix-Seg [11]</th><td>68.90</td><td>70.70</td><td>72.46</td><td>74.49</td><td>72.56</td><td>72.69</td><td>74.25</td><td>75.89</td></tr><tr><th>GCT [17]</th><td>64.05</td><td>70.47</td><td>73.45</td><td>75.20</td><td>69.77</td><td>73.30</td><td>75.25</td><td>77.14</td></tr><tr><th>Ours (w/o CutMix Aug.)</th><td>68.21</td><td>{73.20}</td><td>{74.24}</td><td>75.91</td><td>72.18</td><td>{75.83}</td><td>{77.55}</td><td>{78.64}</td></tr><tr><th>Ours (w/ CutMix Aug.)</th><td>\\mathbf{71.98}</td><td>\\mathbf{73.67}</td><td>\\mathbf{74.90}</td><td>\\mathbf{76.15}</td><td>\\bf{74.48}</td><td>\\bf{76.44}</td><td>\\bf{77.68}</td><td>\\bf{78.64}</td></tr></tbody></table>", "caption": "Table 1: Comparison with state-of-the-artson the PASCAL VOC 2012 val setunder different partition protocols.All the methods are based on DeepLabv3+.", "list_citation_info": ["[17] Zhanghan Ke, Di Qiu, Kaican Li, Qiong Yan, and Rynson WH Lau. Guided collaborative training for pixel-wise semi-supervised learning. In ECCV, 2020.", "[11] Geoff French, Timo Aila, Samuli Laine, Michal Mackiewicz, and Graham Finlayson. Semi-supervised semantic segmentation needs strong, high-dimensional perturbations. In BMVC, 2020.", "[27] Yassine Ouali, C\u00e9line Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistency training. In CVPR, pages 12674\u201312684, 2020.", "[32] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NIPS, 2017."]}, {"table": "<table><tbody><tr><th rowspan=\"2\">Method</th><td colspan=\"4\">ResNet-50</td><td colspan=\"4\">ResNet-101</td></tr><tr><td>1/16 (186)</td><td>1/8 (372)</td><td>1/4 (744)</td><td>1/2 (1488)</td><td>1/16 (186)</td><td>1/8 (372)</td><td>1/4 (744)</td><td>1/2 (1488)</td></tr><tr><th>MT [32]</th><td>66.14</td><td>72.03</td><td>74.47</td><td>77.43</td><td>68.08</td><td>73.71</td><td>76.53</td><td>78.59</td></tr><tr><th>CCT [27]</th><td>66.35</td><td>72.46</td><td>75.68</td><td>76.78</td><td>69.64</td><td>74.48</td><td>76.35</td><td>78.29</td></tr><tr><th>GCT [17]</th><td>65.81</td><td>71.33</td><td>75.30</td><td>77.09</td><td>66.90</td><td>72.96</td><td>76.45</td><td>78.58</td></tr><tr><th>Ours (w/o CutMix Aug.)</th><td>{69.79}</td><td>{74.39}</td><td>{76.85}</td><td>78.64</td><td>{70.50}</td><td>{75.71}</td><td>{77.41}</td><td>{80.08}</td></tr><tr><th>Ours (w/ CutMix Aug.)</th><td>\\mathbf{74.47}</td><td>\\mathbf{76.61}</td><td>\\mathbf{77.83}</td><td>\\mathbf{78.77}</td><td>\\mathbf{74.72}</td><td>\\mathbf{77.62}</td><td>\\mathbf{79.21}</td><td>\\mathbf{80.21}</td></tr></tbody></table>", "caption": "Table 2: Comparison with state-of-the-artson the Cityscapes val set underdifferent partition protocols.All the methods are based on DeepLabv3+.", "list_citation_info": ["[17] Zhanghan Ke, Di Qiu, Kaican Li, Qiong Yan, and Rynson WH Lau. Guided collaborative training for pixel-wise semi-supervised learning. In ECCV, 2020.", "[27] Yassine Ouali, C\u00e9line Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistency training. In CVPR, pages 12674\u201312684, 2020.", "[32] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NIPS, 2017."]}, {"table": "<table><thead><tr><th rowspan=\"2\">Method</th><th colspan=\"4\">\\#(labeled samples)</th></tr><tr><th>732</th><th>366</th><th>183</th><th>92</th></tr></thead><tbody><tr><th>AdvSemSeg [13]</th><td>65.27</td><td>59.97</td><td>47.58</td><td>39.69</td></tr><tr><th>CCT [27]</th><td>62.10</td><td>58.80</td><td>47.60</td><td>33.10</td></tr><tr><th>MT [32]</th><td>69.16</td><td>63.01</td><td>55.81</td><td>48.70</td></tr><tr><th>GCT [17]</th><td>70.67</td><td>64.71</td><td>54.98</td><td>46.04</td></tr><tr><th>VAT [26]</th><td>63.34</td><td>56.88</td><td>49.35</td><td>36.92</td></tr><tr><th>CutMix-Seg [11]</th><td>69.84</td><td>68.36</td><td>63.20</td><td>55.58</td></tr><tr><th>PseudoSeg [44]</th><td>72.41</td><td>69.14</td><td>65.50</td><td>57.60</td></tr><tr><th>Ours (w/ CutMix Aug.)</th><td>\\mathbf{75.88}</td><td>\\mathbf{71.71}</td><td>\\mathbf{67.42}</td><td>\\mathbf{64.07}</td></tr></tbody></table>", "caption": "Table 5: Comparison for few-supervision on PASCAL VOC 2012.We follow the same partition protocolsprovided in PseudoSeg [44].The results of all the other methods are from [44].", "list_citation_info": ["[13] Wei-Chih Hung, Yi-Hsuan Tsai, Yan-Ting Liou, Yen-Yu Lin, and Ming-Hsuan Yang. Adversarial learning for semi-supervised semantic segmentation. In BMVC, 2018.", "[17] Zhanghan Ke, Di Qiu, Kaican Li, Qiong Yan, and Rynson WH Lau. Guided collaborative training for pixel-wise semi-supervised learning. In ECCV, 2020.", "[27] Yassine Ouali, C\u00e9line Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistency training. In CVPR, pages 12674\u201312684, 2020.", "[26] Takeru Miyato, Shin-ichi Maeda, Shin Ishii, and Masanori Koyama. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. TPAMI, 2018.", "[44] Yuliang Zou, Zizhao Zhang, Han Zhang, Chun-Liang Li, Xiao Bian, Jia-Bin Huang, and Tomas Pfister. Pseudoseg: Designing pseudo labels for semantic segmentation. arXiv preprint arXiv:2010.09713, 2020.", "[32] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NIPS, 2017.", "[11] Geoff French, Timo Aila, Samuli Laine, Michal Mackiewicz, and Graham Finlayson. Semi-supervised semantic segmentation needs strong, high-dimensional perturbations. In BMVC, 2020."]}]}