{"title": "Scribble-Supervised Medical Image Segmentation via Dual-Branch Network and Dynamically Mixed Pseudo Labels Supervision", "abstract": "Medical image segmentation plays an irreplaceable role in computer-assisted diagnosis, treatment planning, and following-up. Collecting and annotating a large-scale dataset is crucial to training a powerful segmentation model, but producing high-quality segmentation masks is an expensive and time-consuming procedure. Recently, weakly-supervised learning that uses sparse annotations (points, scribbles, bounding boxes) for network training has achieved encouraging performance and shown the potential for annotation cost reduction. However, due to the limited supervision signal of sparse annotations, it is still challenging to employ them for networks training directly. In this work, we propose a simple yet efficient scribble-supervised image segmentation method and apply it to cardiac MRI segmentation. Specifically, we employ a dual-branch network with one encoder and two slightly different decoders for image segmentation and dynamically mix the two decoders' predictions to generate pseudo labels for auxiliary supervision. By combining the scribble supervision and auxiliary pseudo labels supervision, the dual-branch network can efficiently learn from scribble annotations end-to-end. Experiments on the public ACDC dataset show that our method performs better than current scribble-supervised segmentation methods and also outperforms several semi-supervised segmentation methods.", "authors": ["Xiangde Luo", " Minhao Hu", " Wenjun Liao", " Shuwei Zhai", " Tao Song", " Guotai Wang", " Shaoting Zhang"], "pdf_url": "https://arxiv.org/abs/2203.02106", "list_table_and_caption": [{"table": "<table><tr><td rowspan=\"2\">Type</td><td rowspan=\"2\">Method</td><td colspan=\"2\">RV</td><td colspan=\"2\">Myo</td><td colspan=\"2\">LV</td><td colspan=\"2\">Mean</td></tr><tr><td>DSC</td><td>HD_{95}</td><td>DSC</td><td>HD_{95}</td><td>DSC</td><td>HD_{95}</td><td>DSC</td><td>HD_{95}</td></tr><tr><td></td><td>pCE[16]</td><td>0.625(0.16)</td><td>187.2(35.2)</td><td>0.668(0.095)</td><td>165.1(34.4)</td><td>0.766(0.156)</td><td>167.7(55.0)</td><td>0.686(0.137)</td><td>173.3(41.5)</td></tr><tr><td></td><td>RW[9]</td><td>0.813(0.113)</td><td>11.1(17.3)</td><td>0.708(0.066)</td><td>9.8(8.9)</td><td>0.844(0.091)</td><td>9.2(13.0)</td><td>0.788(0.09)</td><td>10.0(13.1)</td></tr><tr><td></td><td>USTM[17]</td><td>0.815(0.115)</td><td>54.7(65.7)</td><td>0.756(0.081)</td><td>112.2(54.1)</td><td>0.785(0.162)</td><td>139.6(57.7)</td><td>0.786(0.119)</td><td>102.2(59.2 )</td></tr><tr><td rowspan=\"2\">WSL</td><td>S2L[15]</td><td>0.833(0.103)</td><td>14.6(30.9)</td><td>0.806(0.069)</td><td>37.1(49.4)</td><td>0.856(0.121)</td><td>65.2(65.1)</td><td>0.832(0.098)</td><td>38.9(48.5)</td></tr><tr><td>MLoss[13]</td><td>0.809(0.093)</td><td>17.1(30.8)</td><td>0.832(0.055)</td><td>28.2(43.2)</td><td>0.876(0.093)</td><td>37.9(59.6)</td><td>0.839(0.080)</td><td>27.7(44.5)</td></tr><tr><td></td><td>EM[10]</td><td>0.839(0.108)</td><td>25.7(44.5)</td><td>0.812(0.062)</td><td>47.4(50.6)</td><td>0.887(0.099)</td><td>43.8(57.6)</td><td>0.846(0.089)</td><td>39.0(50.9)</td></tr><tr><td></td><td>RLoss[27]</td><td>0.856(0.101)</td><td>7.9(12.6)</td><td>0.817(0.054)</td><td>6.0(6.9)</td><td>0.896(0.086)</td><td>7.0(13.5)</td><td>0.856(0.080)</td><td>6.9(11.0)</td></tr><tr><td></td><td>Ours</td><td>0.861(0.096)</td><td>7.9(12.5)</td><td>0.842(0.054){}^{\\textbf{*}}</td><td>9.7(23.2)</td><td>0.913(0.082){}^{\\textbf{*}}</td><td>12.1(27.2)</td><td>0.872(0.077){}^{\\textbf{*}}</td><td>9.9(21.0)</td></tr><tr><td></td><td>PS[25]</td><td>0.659(0.261)</td><td>26.8(30.4)</td><td>0.724(0.176)</td><td>16.0(21.6)</td><td>0.790(0.205)</td><td>24.5(30.4)</td><td>0.724(0.214)</td><td>22.5(27.5)</td></tr><tr><td rowspan=\"2\">SSL</td><td>DAN[38]</td><td>0.639(0.26)</td><td>20.6(21.4)</td><td>0.764(0.144)</td><td>9.4(12.4)</td><td>0.825(0.186)</td><td>15.9(20.8)</td><td>0.743(0.197)</td><td>15.3(18.2)</td></tr><tr><td>AdvEnt[31]</td><td>0.615(0.296)</td><td>20.2(19.4)</td><td>0.760(0.151)</td><td>8.5(8.3)</td><td>0.848(0.159)</td><td>11.7(18.1)</td><td>0.741(0.202)</td><td>13.5(15.3)</td></tr><tr><td></td><td>MT[28]</td><td>0.653(0.271)</td><td>18.6(22.0)</td><td>0.785(0.118)</td><td>11.4(17.0)</td><td>0.846(0.153)</td><td>19.0(26.7)</td><td>0.761(0.180)</td><td>16.3(21.9)</td></tr><tr><td></td><td>UAMT[35]</td><td>0.660(0.267)</td><td>22.3(22.9)</td><td>0.773(0.129)</td><td>10.3(14.8)</td><td>0.847(0.157)</td><td>17.1(23.9)</td><td>0.760(0.185)</td><td>16.6(20.5)</td></tr><tr><td>FSL</td><td>FullSup[25]</td><td>0.882(0.095)</td><td>6.9(10.8)</td><td>0.883(0.042)</td><td>5.9(15.2)</td><td>0.930(0.074)</td><td>8.1(20.9)</td><td>0.898(0.070)</td><td>7.0(15.6)</td></tr></table>", "caption": "Table 1: Comparison with existing weakly-/semi-supervised methods on the ACDC dataset. All results are based on the 5-fold cross-validation with same backbone (UNet). Mean and standard variance (in parentheses) values of 3D DSC and HD_{95} (mm) are presented in this table. {}^{*} denotes p-value &lt; 0.05 (paired t-test) when comparing with the second place method (RLoss [27]).", "list_citation_info": ["[27] Tang, M., Perazzi, F., Djelouah, A., Ben Ayed, I., Schroers, C., Boykov, Y.: On regularized losses for weakly-supervised cnn segmentation. In: ECCV. pp. 507\u2013522 (2018)", "[28] Tarvainen, A., Valpola, H.: Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In: NeurIPS. pp. 1195\u20131204 (2017)", "[16] Lin, D., Dai, J., Jia, J., He, K., Sun, J.: ScribbleSup: Scribble-supervised convolutional networks for semantic segmentation. In: CVPR. pp. 3159\u20133167 (2016)", "[35] Yu, L., Wang, S., Li, X., Fu, C.W., Heng, P.A.: Uncertainty-aware self-ensembling model for semi-supervised 3D left atrium segmentation. In: MICCAI. pp. 605\u2013613. Springer (2019)", "[15] Lee, H., Jeong, W.K.: Scribble2Label: Scribble-supervised cell segmentation via self-generating pseudo-labels with consistency. In: MICCAI. pp. 14\u201323. Springer (2020)", "[38] Zhang, Y., Yang, L., Chen, J., Fredericksen, M., Hughes, D.P., Chen, D.Z.: Deep adversarial networks for biomedical image segmentation utilizing unannotated images. In: MICCAI. pp. 408\u2013416. Springer (2017)", "[31] Vu, T.H., Jain, H., Bucher, M., Cord, M., P\u00e9rez, P.: Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation. In: CVPR. pp. 2517\u20132526 (2019)", "[10] Grandvalet, Y., Bengio, Y., et al.: Semi-supervised learning by entropy minimization. NeurIPS 367, 281\u2013296 (2005)", "[17] Liu, X., Yuan, Q., Gao, Y., He, K., Wang, S., Tang, X., Tang, J., Shen, D.: Weakly supervised segmentation of covid19 infection with scribble annotation on CT images. PR 122, 108341 (2022)", "[25] Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: MICCAI. pp. 234\u2013241 (2015)", "[13] Kim, B., Ye, J.C.: Mumford-Shah loss functional for image segmentation with deep learning. IEEE Transactions on Image Processing 29, 1856\u20131866 (2019)", "[9] Grady, L.: Random walks for image segmentation. TPAMI (11), 1768\u20131783 (2006)"]}, {"table": "<table><tr><td rowspan=\"2\">Method</td><td colspan=\"2\">RV</td><td colspan=\"2\">Myo</td><td colspan=\"2\">LV</td><td colspan=\"2\">Mean</td></tr><tr><td>DSC</td><td>HD_{95}</td><td>DSC</td><td>HD_{95}</td><td>DSC</td><td>HD_{95}</td><td>DSC</td><td>HD_{95}</td></tr><tr><td>Single[16]</td><td>0.625(0.16)</td><td>187.2(35.2)</td><td>0.668(0.095)</td><td>165.1(34.4)</td><td>0.766(0.156)</td><td>167.7(55.0)</td><td>0.686(0.137)</td><td>173.3(41.5)</td></tr><tr><td>Dual+CR[7]</td><td>0.844(0.106)</td><td>20.1(37.2)</td><td>0.798(0.07)</td><td>62.2(55.7)</td><td>0.873(0.101)</td><td>63.4(65.5)</td><td>0.838(0.092)</td><td>48.6(52.8)</td></tr><tr><td>Dual+CPS[34, 6]</td><td>0.849(0.099)</td><td>12.4(25.6)</td><td>0.833(0.056)</td><td>19.3(33.5)</td><td>0.905(0.091)</td><td>18.3(35.8)</td><td>0.863(0.082)</td><td>16.6(31.6)</td></tr><tr><td>Ours (\\alpha=0.5, \\theta_{d1})</td><td>0.855(0.101)</td><td>8.6( 13.9 )</td><td>0.837(0.053)</td><td>13.6(29.1)</td><td>0.908(0.086)</td><td>15.8(34.1)</td><td>0.866(0.08)</td><td>12.6(25.7)</td></tr><tr><td>Ours (\\alpha=random, \\theta_{d1})</td><td>0.861(0.096)</td><td>7.9(12.5)</td><td>0.842(0.054)</td><td>9.7(23.2)</td><td>0.913(0.082)</td><td>12.1(27.2)</td><td>0.872(0.077)</td><td>9.9(21.0)</td></tr><tr><td>Ours (\\alpha=random, \\theta_{d2})</td><td>0.861(0.098)</td><td>7.3(10.3)</td><td>0.840(0.058)</td><td>10.9(24.5)</td><td>0.911(0.086)</td><td>11.3(26.4)</td><td>0.871(0.08)</td><td>9.8(20.4)</td></tr></table>", "caption": "Table 2: Ablation study on different supervision strategies for the dual-branch network. Single denotes the baseline UNet [25] with pCE only. CR means consistency regularization between the main and auxiliary decoders [7]. CPS is the cross pseudo supervision strategy in [34, 6]. Ours is proposed PLS, \\theta_{d1} and \\theta_{d2} mean the prediction of main and auxiliary decoders, respectively.", "list_citation_info": ["[7] Dolz, J., Desrosiers, C., Ayed, I.B.: Teach me to segment with mixed supervision: Confident students become masters. In: IPMI. pp. 517\u2013529. Springer (2021)", "[34] Wu, Y., Xu, M., Ge, Z., Cai, J., Zhang, L.: Semi-supervised left atrium segmentation with mutual consistency training. In: MICCAI. pp. 297\u2013306. Springer (2021)", "[25] Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: MICCAI. pp. 234\u2013241 (2015)", "[16] Lin, D., Dai, J., Jia, J., He, K., Sun, J.: ScribbleSup: Scribble-supervised convolutional networks for semantic segmentation. In: CVPR. pp. 3159\u20133167 (2016)"]}]}