{"title": "Contextual Attention Network: Transformer Meets U-Net", "abstract": "Currently, convolutional neural networks (CNN) (e.g., U-Net) have become the de facto standard and attained immense success in medical image segmentation. However, as a downside, CNN based methods are a double-edged sword as they fail to build long-range dependencies and global context connections due to the limited receptive field that stems from the intrinsic characteristics of the convolution operation. Hence, recent articles have exploited Transformer variants for medical image segmentation tasks which open up great opportunities due to their innate capability of capturing long-range correlations through the attention mechanism. Although being feasibly designed, most of the cohort studies incur prohibitive performance in capturing local information, thereby resulting in less lucidness of boundary areas. In this paper, we propose a contextual attention network to tackle the aforementioned limitations. The proposed method uses the strength of the Transformer module to model the long-range contextual dependency. Simultaneously, it utilizes the CNN encoder to capture local semantic information. In addition, an object-level representation is included to model the regional interaction map. The extracted hierarchical features are then fed to the contextual attention module to adaptively recalibrate the representation space using the local information. Then, they emphasize the informative regions while taking into account the long-range contextual dependency derived by the Transformer module. We validate our method on several large-scale public medical image segmentation datasets and achieve state-of-the-art performance. We have provided the implementation code in https://github.com/rezazad68/TMUnet.", "authors": ["Reza Azad", " Moein Heidari", " Yuli Wu", " Dorit Merhof"], "pdf_url": "https://arxiv.org/abs/2203.01932", "list_table_and_caption": [{"table": "<table><thead><tr><th>Methods</th><th>mIOU</th></tr></thead><tbody><tr><td>Frequency recalibration U-Net [3]</td><td>0.9392</td></tr><tr><td>XLAB Insights [6]</td><td>0.9360</td></tr><tr><td>DSC-IITISM [6]</td><td>0.9356</td></tr><tr><td>Multi-scale attention deeplabv3+ [6]</td><td>0.9065</td></tr><tr><td>U-Net [25]</td><td>0.7665</td></tr><tr><td>Baseline</td><td>0.9172</td></tr><tr><td>Proposed</td><td>0.9395</td></tr></tbody></table>", "caption": "Table 2: Performance evaluation on the SegPC challenge (best result is highlighted).", "list_citation_info": ["[3] Azad, R., Bozorgpour, A., Asadi-Aghbolaghi, M., Merhof, D., Escalera, S.: Deep frequency re-calibration u-net for medical image segmentation. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 3274\u20133283 (2021)", "[25] Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: International Conference on Medical image computing and computer-assisted intervention. pp. 234\u2013241. Springer (2015)", "[6] Bozorgpour, A., Azad, R., Showkatian, E., Sulaiman, A.: Multi-scale regional attention deeplab3+: Multiple myeloma plasma cells segmentation in microscopic images. arXiv preprint arXiv:2105.06238 (2021)"]}]}