{"title": "Disentangling Monocular 3D Object Detection", "abstract": "In this paper we propose an approach for monocular 3D object detection from a single RGB image, which leverages a novel disentangling transformation for 2D and 3D detection losses and a novel, self-supervised confidence score for 3D bounding boxes. Our proposed loss disentanglement has the twofold advantage of simplifying the training dynamics in the presence of losses with complex interactions of parameters, and sidestepping the issue of balancing independent regression terms. Our solution overcomes these issues by isolating the contribution made by groups of parameters to a given loss, without changing its nature. We further apply loss disentanglement to another novel, signed Intersection-over-Union criterion-driven loss for improving 2D detection results. Besides our methodological innovations, we critically review the AP metric used in KITTI3D, which emerged as the most important dataset for comparing 3D detection results. We identify and resolve a flaw in the 11-point interpolated AP metric, affecting all previously published detection results and particularly biases the results of monocular 3D detection. We provide extensive experimental evaluations and ablation studies on the KITTI3D and nuScenes datasets, setting new state-of-the-art results on object category car by large margins.", "authors": ["Andrea Simonelli", " Samuel Rota Rota Bul\u00f2", " Lorenzo Porzi", " Manuel L\u00f3pez-Antequera", " Peter Kontschieder"], "pdf_url": "https://arxiv.org/abs/1905.12365", "list_table_and_caption": [{"table": "<table><tbody><tr><th></th><td colspan=\"3\">2D detection</td><td colspan=\"3\">3D detection</td><td colspan=\"3\">Bird\u2019s eye view</td></tr><tr><th>Method</th><td>Easy</td><td>Moderate</td><td>Hard</td><td>Easy</td><td>Moderate</td><td>Hard</td><td>Easy</td><td>Moderate</td><td>Hard</td></tr><tr><th>Regression</th><td>70.10</td><td>73.20</td><td>66.80</td><td>1.30</td><td>0.90</td><td>0.70</td><td>2.60</td><td>1.90</td><td>1.70</td></tr><tr><th>3D BB</th><td>74.30</td><td>77.10</td><td>69.50</td><td>3.90</td><td>2.70</td><td>2.50</td><td>6.90</td><td>5.10</td><td>4.40</td></tr><tr><th>Regression w/ IoUDIS, 3DConf</th><td>70.10</td><td>75.10</td><td>66.90</td><td>2.60</td><td>1.70</td><td>1.40</td><td>5.40</td><td>3.80</td><td>3.00</td></tr><tr><th>3D BB w/ IoUDIS, 3DConf</th><td>95.10</td><td>88.90</td><td>78.60</td><td>8.80</td><td>6.10</td><td>5.00</td><td>14.60</td><td>10.10</td><td>8.30</td></tr><tr><th>3D BB w/ disentangling</th><td>80.50</td><td>80.80</td><td>74.40</td><td>4.10</td><td>3.00</td><td>2.70</td><td>7.10</td><td>5.40</td><td>4.80</td></tr><tr><th>MonoDIS</th><td>94.96</td><td>89.22</td><td>80.58</td><td>11.06</td><td>7.60</td><td>6.37</td><td>18.45</td><td>12.58</td><td>10.66</td></tr><tr><th>OFTNet [33]</th><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>1.61</td><td>1.32</td><td>1.00</td><td>1.28</td><td>0.81</td><td>0.51</td></tr><tr><th>FQNet [20]</th><td>94.72</td><td>90.17</td><td>76.78</td><td>2.77</td><td>1.51</td><td>1.01</td><td>5.40</td><td>3.23</td><td>2.46</td></tr><tr><th>ROI-10D w/ Depth, Synthetic [23]</th><td>76.56</td><td>70.16</td><td>61.15</td><td>4.32</td><td>2.02</td><td>1.46</td><td>9.78</td><td>4.91</td><td>3.74</td></tr><tr><th>MonoGRNet [29]</th><td>88.65</td><td>77.94</td><td>63.31</td><td>9.61</td><td>5.74</td><td>4.25</td><td>18.19</td><td>11.17</td><td>8.73</td></tr><tr><th>MonoDIS</th><td>93.11</td><td>85.86</td><td>73.61</td><td>7.03</td><td>4.89</td><td>4.08</td><td>12.18</td><td>9.13</td><td>7.38</td></tr><tr><th>MonoDIS, larger training split</th><td>94.61</td><td>89.15</td><td>78.37</td><td>10.37</td><td>7.94</td><td>6.40</td><td>17.23</td><td>13.19</td><td>11.12</td></tr></tbody></table>", "caption": "Table 3: \\text{AP}|_{R_{40}} scores on KITTI3D: ablation results (white background), test set results of SOTA (grey background) and ours (green background).", "list_citation_info": ["[33] T. Roddick, A. Kendall, and R. Cipolla. Orthographic feature transform for monocular 3d object detection. CoRR, abs/1811.08188, 2018.", "[20] L. Liu, J. Lu, C. Xu, Q. Tian, and J. Zhou. Deep fitting degree scoring network for monocular 3d object detection. CoRR, abs/1904.12681, 2019.", "[29] Z. Qin, J. Wang, and Y. Lu. Monogrnet: A geometric reasoning network for 3d object localization. In (AAAI), 2019.", "[23] F. Manhardt, W. Kehl, and A. Gaidon. Roi-10d: Monocular lifting of 2d detection to 6d pose and metric shape. In (CVPR), 2019."]}, {"table": "<table><thead><tr><th></th><th colspan=\"3\">2D detection</th><th colspan=\"3\">3D detection</th><th colspan=\"3\">Bird\u2019s eye view</th></tr><tr><th>Method</th><th>Easy</th><th>Moderate</th><th>Hard</th><th>Easy</th><th>Moderate</th><th>Hard</th><th>Easy</th><th>Moderate</th><th>Hard</th></tr></thead><tbody><tr><th>OFTNet [33]</th><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>3.28</td><td>2.50</td><td>2.27</td><td>9.50</td><td>7.99</td><td>7.51</td></tr><tr><th>FQNet [20]</th><td>90.45</td><td>88.83</td><td>77.55</td><td>3.48</td><td>2.42</td><td>1.96</td><td>6.51</td><td>4.62</td><td>3.99</td></tr><tr><th>ROI-10D w/ Depth, Synthetic [23]</th><td>75.33</td><td>69.64</td><td>61.18</td><td>12.30</td><td>10.30</td><td>9.39</td><td>16.77</td><td>12.40</td><td>11.39</td></tr><tr><th>MonoGRNet [29]</th><td>87.23</td><td>77.46</td><td>61.12</td><td>11.29</td><td>12.90</td><td>11.34</td><td>20.55</td><td>16.37</td><td>15.16</td></tr><tr><th>MonoDIS</th><td>89.61</td><td>83.80</td><td>70.84</td><td>8.26</td><td>6.15</td><td>6.06</td><td>13.10</td><td>11.12</td><td>9.35</td></tr><tr><th>MonoDIS, larger training split</th><td>90.31</td><td>87.58</td><td>76.85</td><td>11.81</td><td>15.12</td><td>12.71</td><td>18.88</td><td>19.08</td><td>17.41</td></tr></tbody></table>", "caption": "Table 4: \\text{AP}|_{R_{11}} scores on KITTI3D: test set results of SOTA (grey background) and ours (green background).", "list_citation_info": ["[33] T. Roddick, A. Kendall, and R. Cipolla. Orthographic feature transform for monocular 3d object detection. CoRR, abs/1811.08188, 2018.", "[20] L. Liu, J. Lu, C. Xu, Q. Tian, and J. Zhou. Deep fitting degree scoring network for monocular 3d object detection. CoRR, abs/1904.12681, 2019.", "[29] Z. Qin, J. Wang, and Y. Lu. Monogrnet: A geometric reasoning network for 3d object localization. In (AAAI), 2019.", "[23] F. Manhardt, W. Kehl, and A. Gaidon. Roi-10d: Monocular lifting of 2d detection to 6d pose and metric shape. In (CVPR), 2019."]}, {"table": "<table><tbody><tr><th></th><td colspan=\"3\">2D detection</td><td colspan=\"3\">3D detection</td><td colspan=\"3\">Bird\u2019s eye view</td></tr><tr><th>Method</th><td>Easy</td><td>Moderate</td><td>Hard</td><td>Easy</td><td>Moderate</td><td>Hard</td><td>Easy</td><td>Moderate</td><td>Hard</td></tr><tr><th>Regression</th><td>66.50</td><td>72.30</td><td>66.00</td><td>1.60</td><td>1.50</td><td>1.20</td><td>2.70</td><td>2.10</td><td>2.30</td></tr><tr><th>3D BB</th><td>70.80</td><td>77.10</td><td>66.50</td><td>4.70</td><td>3.00</td><td>2.90</td><td>7.80</td><td>5.40</td><td>5.80</td></tr><tr><th>Regression w/ IoUDIS, 3DConf</th><td>67.20</td><td>73.60</td><td>65.50</td><td>3.20</td><td>2.90</td><td>2.00</td><td>5.80</td><td>4.80</td><td>4.30</td></tr><tr><th>3D BB w/ IoUDIS, 3DConf</th><td>90.20</td><td>88.40</td><td>78.40</td><td>15.40</td><td>13.60</td><td>12.00</td><td>20.50</td><td>16.20</td><td>15.70</td></tr><tr><th>3D BB w/ disentangling</th><td>76.40</td><td>80.30</td><td>73.20</td><td>4.90</td><td>3.40</td><td>3.10</td><td>7.30</td><td>5.70</td><td>6.30</td></tr><tr><th>MonoDIS</th><td>90.23</td><td>88.64</td><td>79.10</td><td>18.05</td><td>14.98</td><td>13.42</td><td>24.26</td><td>18.43</td><td>16.95</td></tr><tr><th>Single correct hypothesis per difficulty</th><td>9.09</td><td>9.09</td><td>9.09</td><td>9.09</td><td>9.09</td><td>9.09</td><td>9.09</td><td>9.09</td><td>9.09</td></tr><tr><th>OFTNet [33]</th><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>4.07</td><td>3.27</td><td>3.29</td><td>11.06</td><td>8.79</td><td>8.91</td></tr><tr><th>Xu et al. [42]</th><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>7.85</td><td>5.39</td><td>4.73</td><td>19.20</td><td>12.17</td><td>10.89</td></tr><tr><th>FQNet [20]</th><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>5.98</td><td>5.50</td><td>4.75</td><td>9.50</td><td>8.02</td><td>7.71</td></tr><tr><th>Mono3D [4]</th><td>93.89</td><td>88.67</td><td>79.68</td><td>2.53</td><td>2.31</td><td>2.31</td><td>5.22</td><td>5.19</td><td>4.13</td></tr><tr><th>Mono3D++ [11]</th><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>10.60</td><td>7.90</td><td>5.70</td><td>16.70</td><td>11.50</td><td>10.10</td></tr><tr><th>ROI-10D [23]</th><td>78.57</td><td>73.44</td><td>63.69</td><td>10.12</td><td>1.76</td><td>1.30</td><td>14.04</td><td>3.69</td><td>3.56</td></tr><tr><th>ROI-10D w/ Depth [23]</th><td>89.04</td><td>88.39</td><td>78.77</td><td>7.79</td><td>5.16</td><td>3.95</td><td>10.74</td><td>7.46</td><td>7.06</td></tr><tr><th>ROI-10D w/ Depth, Synthetic [23]</th><td>85.32</td><td>77.32</td><td>69.70</td><td>9.61</td><td>6.63</td><td>6.29</td><td>14.50</td><td>9.91</td><td>8.73</td></tr><tr><th>MonoGRNet [29]</th><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>13.88</td><td>10.19</td><td>7.62</td><td>\u2013</td><td>\u2013</td><td>\u2013</td></tr><tr><th>Best in [1]</th><td>\u2013</td><td>\u2013</td><td>\u2013</td><td>13.96</td><td>7.37</td><td>4.54</td><td>\u2013</td><td>\u2013</td><td>\u2013</td></tr></tbody></table>", "caption": "Table 5: \\text{AP}|_{R_{11}} scores on KITTI3D (0.7 IoU threshold): Ablation results (white background), val set results of SOTA (grey background).", "list_citation_info": ["[1] I. Barabanau, A. Artemov, E. Burnaev, and V. Murashkin. Monocular 3d object detection via geometric reasoning on keypoints. CoRR, abs/1905.05618, 2019.", "[4] X. Chen, K. Kundu, Z. Zhang, H. Ma, S. Fidler, and R. Urtasun. Monocular 3d object detection for autonomous driving. In (CVPR), 2016.", "[42] B. Xu and Z. Chen. Multi-level fusion based 3d object detection from monocular images. In (CVPR), June 2018.", "[11] T. He and S. Soatto. Mono3d++: Monocular 3d vehicle detection with two-scale 3d hypotheses and task priors. CoRR, abs/1901.03446, 2019.", "[29] Z. Qin, J. Wang, and Y. Lu. Monogrnet: A geometric reasoning network for 3d object localization. In (AAAI), 2019.", "[23] F. Manhardt, W. Kehl, and A. Gaidon. Roi-10d: Monocular lifting of 2d detection to 6d pose and metric shape. In (CVPR), 2019.", "[33] T. Roddick, A. Kendall, and R. Cipolla. Orthographic feature transform for monocular 3d object detection. CoRR, abs/1811.08188, 2018.", "[20] L. Liu, J. Lu, C. Xu, Q. Tian, and J. Zhou. Deep fitting degree scoring network for monocular 3d object detection. CoRR, abs/1904.12681, 2019."]}, {"table": "<table><tbody><tr><th></th><td colspan=\"4\">AP{}_{\\mbox{Car}}\\uparrow [%]</td><td colspan=\"3\">TP{}_{\\mbox{Car}}\\downarrow</td></tr><tr><th>Method</th><td>0.5m</td><td>1.0m</td><td>2.0m</td><td>4.0m</td><td>ATE [m]</td><td>ASE [1-IoU]</td><td>AOE [rad]</td></tr><tr><th>PointPillar</th><td>55.5</td><td>71.8</td><td>76.1</td><td>78.6</td><td>0.27</td><td>0.17</td><td>0.19</td></tr><tr><th>OFTNet</th><td>\u2013</td><td>\u2013</td><td>27.0</td><td>\u2013</td><td>0.65</td><td>0.16</td><td>0.18</td></tr><tr><th>MonoDIS</th><td>10.7</td><td>37.5</td><td>69.0</td><td>85.7</td><td>0.61</td><td>0.15</td><td>0.08</td></tr></tbody></table>", "caption": "Table 7: Performance comparison for results on category car in nuScenes dataset [2]. Top row: LiDAR-based PointPillar results (listed for completeness). Bottom: Available OFTNet results vs. MonoDIS.", "list_citation_info": ["[2] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, A. Krishnan, Y. Pan, G. Baldan, and O. Beijbom. nuScenes: A multimodal dataset for autonomous driving. CoRR, abs/1903.11027, 2019."]}]}