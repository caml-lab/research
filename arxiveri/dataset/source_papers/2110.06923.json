{"title": "Object DGCNN: 3D Object Detection Using Dynamic Graphs", "abstract": "3D object detection often involves complicated training and testing pipelines, which require substantial domain knowledge about individual datasets. Inspired by recent non-maximum suppression-free 2D object detection models, we propose a 3D object detection architecture on point clouds. Our method models 3D object detection as message passing on a dynamic graph, generalizing the DGCNN framework to predict a set of objects. In our construction, we remove the necessity of post-processing via object confidence aggregation or non-maximum suppression. To facilitate object detection from sparse point clouds, we also propose a set-to-set distillation approach customized to 3D detection. This approach aligns the outputs of the teacher model and the student model in a permutation-invariant fashion, significantly simplifying knowledge distillation for the 3D detection task. Our method achieves state-of-the-art performance on autonomous driving benchmarks. We also provide abundant analysis of the detection model and distillation framework.", "authors": ["Yue Wang", " Justin Solomon"], "pdf_url": "https://arxiv.org/abs/2110.06923", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Method</td><td>NDS \\uparrow</td><td>mAP \\uparrow</td><td>mATE \\downarrow</td><td>mASE \\downarrow</td><td>mAOE \\downarrow</td><td>mAVE \\downarrow</td><td>mAAE \\downarrow</td><td>NMS</td></tr><tr><td>PointPillars Lang_2019_CVPR </td><td>53.3</td><td>40.0</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>SSN zhu2020ssn </td><td>54.83</td><td>41.56</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>FreeAnchor zhang2019freeanchor </td><td>55.3</td><td>43.7</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>RegNetX-400MF-SECFPN radosavovic2020designing </td><td>55.2</td><td>41.2</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>Pillar-OD wang2020pillar </td><td>56.84</td><td>44.41</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>\u2713</td></tr><tr><td>CenterPoint (pillar) yin2021center  \\ast</td><td>59.56</td><td>47.48</td><td>31.27</td><td>25.81</td><td>33.78</td><td>32.25</td><td>20.20</td><td>\u2713</td></tr><tr><td>CenterPoint (pillar) yin2021center  \\ast</td><td>55.08</td><td>40.27</td><td>35.14</td><td>26.44</td><td>36.75</td><td>32.66</td><td>19.55</td><td></td></tr><tr><td>CenterPoint (voxel) yin2021center  {\\ddagger}</td><td>64.19</td><td>54.99</td><td>29.83</td><td>25.71</td><td>32.56</td><td>26.08</td><td>18.89</td><td>\u2713</td></tr><tr><td>CenterPoint (voxel) yin2021center  {\\ddagger}</td><td>57.00</td><td>45.32</td><td>31.66</td><td>27.14</td><td>40.47</td><td>37.23</td><td>20.14</td><td></td></tr><tr><td>Ours (pillar) \\ast</td><td>62.97</td><td>53.31</td><td>34.62</td><td>26.56</td><td>31.61</td><td>26.02</td><td>18.71</td><td>\u2713</td></tr><tr><td>Ours (pillar) \\ast</td><td>62.80</td><td>53.20</td><td>34.62</td><td>26.56</td><td>31.62</td><td>26.07</td><td>19.10</td><td></td></tr><tr><td>Ours (voxel) {\\ddagger}</td><td>66.10</td><td>58.73</td><td>33.31</td><td>26.32</td><td>28.80</td><td>25.11</td><td>19.08</td><td>\u2713</td></tr><tr><td>Ours (voxel) {\\ddagger}</td><td>66.04</td><td>58.62</td><td>33.33</td><td>26.34</td><td>28.80</td><td>25.11</td><td>19.06</td><td></td></tr></tbody></table>", "caption": "Table 1: Comparisons to recent works. Our method is robust to whether to use NMS. \\ast: implementations with the same PointPillars backbone. {\\ddagger}: implementations with the same SparseConv backbone.", "list_citation_info": ["[65] Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Designing network design spaces. 2020.", "[64] Xiaosong Zhang, Fang Wan, Chang Liu, Rongrong Ji, and Qixiang Ye. FreeAnchor: Learning to match anchors for visual object detection. In Neural Information Processing Systems, 2019.", "[6] Tianwei Yin, Xingyi Zhou, and Philipp Kr\u00e4henb\u00fchl. Center-based 3d object detection and tracking. CVPR, 2021.", "[63] Xinge Zhu, Yuexin Ma, Tai Wang, Yan Xu, Jianping Shi, and Dahua Lin. Ssn: Shape signature networks for multi-class object detection from point clouds. In Proceedings of the European Conference on Computer Vision, 2020.", "[4] Alex H. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2019.", "[5] Yue Wang, Alireza Fathi, Abhijit Kundu, David Ross, Caroline Pantofaru, Thomas Funkhouser, and Justin Solomon. Pillar-based object detection for autonomous driving. In The European Conference on Computer Vision, 2020."]}]}