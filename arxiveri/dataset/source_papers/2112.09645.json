{"title": "Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation", "abstract": "Supervised deep learning-based methods yield accurate results for medical image segmentation. However, they require large labeled datasets for this, and obtaining them is a laborious task that requires clinical expertise. Semi/self-supervised learning-based approaches address this limitation by exploiting unlabeled data along with limited annotated data. Recent self-supervised learning methods use contrastive loss to learn good global level representations from unlabeled images and achieve high performance in classification tasks on popular natural image datasets like ImageNet. In pixel-level prediction tasks such as segmentation, it is crucial to also learn good local level representations along with global representations to achieve better accuracy. However, the impact of the existing local contrastive loss-based methods remains limited for learning good local representations because similar and dissimilar local regions are defined based on random augmentations and spatial proximity; not based on the semantic label of local regions due to lack of large-scale expert annotations in the semi/self-supervised setting. In this paper, we propose a local contrastive loss to learn good pixel level features useful for segmentation by exploiting semantic label information obtained from pseudo-labels of unlabeled images alongside limited annotated images. In particular, we define the proposed loss to encourage similar representations for the pixels that have the same pseudo-label/ label while being dissimilar to the representation of pixels with different pseudo-label/label in the dataset. We perform pseudo-label based self-training and train the network by jointly optimizing the proposed contrastive loss on both labeled and unlabeled sets and segmentation loss on only the limited labeled set. We evaluated on three public cardiac and prostate datasets, and obtain high segmentation performance.", "authors": ["Krishna Chaitanya", " Ertunc Erdil", " Neerav Karani", " Ender Konukoglu"], "pdf_url": "https://arxiv.org/abs/2112.09645", "list_table_and_caption": [{"table": "<table><tbody><tr><th></th><td colspan=\"3\">ACDC</td><td colspan=\"3\">Prostate</td><td colspan=\"3\">MMWHS</td></tr><tr><th>Method</th><td><p>|X_{L}|=1</p></td><td><p>|X_{L}|=2</p></td><td><p>|X_{L}|=8</p></td><td><p>|X_{L}|=1</p></td><td><p>|X_{L}|=2</p></td><td><p>|X_{L}|=8</p></td><td><p>|X_{L}|=1</p></td><td><p>|X_{L}|=2</p></td><td><p>|X_{L}|=8</p></td></tr><tr><th colspan=\"10\">Baseline</th></tr><tr><th>Random init.</th><td><p>0.614</p></td><td><p>0.702</p></td><td><p>0.844</p></td><td><p>0.489</p></td><td><p>0.550</p></td><td><p>0.636</p></td><td><p>0.451</p></td><td><p>0.637</p></td><td><p>0.787</p></td></tr><tr><th colspan=\"10\">Semi-supervised Methods</th></tr><tr><th>Self-training [9]</th><td><p>0.690</p></td><td><p>0.749</p></td><td><p>0.860</p></td><td><p>0.551</p></td><td><p>0.598</p></td><td><p>0.680</p></td><td><p>0.563</p></td><td><p>0.691</p></td><td><p>0.801</p></td></tr><tr><th>Mixup [87]</th><td><p>0.695</p></td><td><p>0.785</p></td><td><p>0.863</p></td><td><p>0.543</p></td><td><p>0.593</p></td><td><p>0.661</p></td><td><p>0.561</p></td><td><p>0.690</p></td><td><p>0.796</p></td></tr><tr><th>Data Augment [14]</th><td><p>0.731</p></td><td><p>0.786</p></td><td><p>0.865</p></td><td><p>0.585</p></td><td><p>0.597</p></td><td><p>0.667</p></td><td><p>0.529</p></td><td><p>0.661</p></td><td><p>0.785</p></td></tr><tr><th>Adversarial Tr. [74]</th><td><p>0.536</p></td><td><p>0.654</p></td><td><p>0.791</p></td><td><p>0.487</p></td><td><p>0.544</p></td><td><p>0.586</p></td><td><p>0.482</p></td><td><p>0.655</p></td><td><p>0.779</p></td></tr><tr><th>Noisy Student [64]</th><td><p>0.632</p></td><td><p>0.737</p></td><td><p>0.836</p></td><td><p>0.556</p></td><td><p>0.601</p></td><td><p>0.668</p></td><td><p>0.593</p></td><td><p>0.685</p></td><td><p>0.780</p></td></tr><tr><th colspan=\"10\">Proposed Method</th></tr><tr><th>Pseudo-labels joint Tr. (intra)</th><td>0.761</td><td>0.845</td><td><p>0.881</p></td><td><p>0.571</p></td><td><p>0.613</p></td><td><p>0.693</p></td><td>0.599</td><td>0.721</td><td><p>0.803</p></td></tr><tr><th>Pseudo-labels joint Tr. (inter)</th><td><p>0.759</p></td><td><p>0.831</p></td><td>0.883</td><td>0.578</td><td>0.618</td><td>0.696</td><td><p>0.572</p></td><td><p>0.719</p></td><td><p>0.811</p></td></tr><tr><th colspan=\"10\">Benchmark</th></tr><tr><th>Training with large |X_{L}|</th><td colspan=\"3\">(|X_{L}|=78) 0.912</td><td colspan=\"3\">(|X_{L}|=20) 0.697</td><td colspan=\"3\">(|X_{L}|=8) 0.787</td></tr></tbody></table>", "caption": "TABLE I: Comparison of the proposed method with other semi-supervised learning, data augmentation methods and concurrent contrastive learning works. The proposed pseudo-label joint training provides better results than compared methods for all datasets and most |X_{tr}| values.In each column, best values among all methods are underlined.", "list_citation_info": ["[87] H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz, \u201cmixup: Beyond empirical risk minimization,\u201d arXiv preprint arXiv:1710.09412, 2017.", "[74] Y. Zhang, L. Yang, J. Chen, M. Fredericksen, D. P. Hughes, and D. Z. Chen, \u201cDeep adversarial networks for biomedical image segmentation utilizing unannotated images,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2017, pp. 408\u2013416.", "[14] K. Chaitanya, N. Karani, C. F. Baumgartner, A. Becker, O. Donati, and E. Konukoglu, \u201cSemi-supervised and task-driven data augmentation,\u201d in Information Processing in Medical Imaging, A. C. S. Chung, J. C. Gee, P. A. Yushkevich, and S. Bao, Eds. Cham: Springer International Publishing, 2019, pp. 29\u201341.", "[64] Q. Xie, M.-T. Luong, E. Hovy, and Q. V. Le, \u201cSelf-training with noisy student improves imagenet classification,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 10\u2009687\u201310\u2009698.", "[9] W. Bai, O. Oktay, M. Sinclair, H. Suzuki, M. Rajchl, G. Tarroni, B. Glocker, A. King, P. M. Matthews, and D. Rueckert, \u201cSemi-supervised learning for network-based cardiac mr image segmentation,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2017, pp. 253\u2013260."]}, {"table": "<table><thead><tr><th></th><th colspan=\"3\">ACDC</th><th colspan=\"3\">Prostate</th><th colspan=\"3\">MMWHS</th></tr><tr><th>Method</th><th><p>|X_{L}|=1</p></th><th><p>|X_{L}|=2</p></th><th><p>|X_{L}|=8</p></th><th><p>|X_{L}|=1</p></th><th><p>|X_{L}|=2</p></th><th><p>|X_{L}|=8</p></th><th><p>|X_{L}|=1</p></th><th><p>|X_{L}|=2</p></th><th><p>|X_{L}|=8</p></th></tr></thead><tbody><tr><th>Two step Tr. [26] (fully-sup)</th><td><p>0.568</p></td><td><p>0.717</p></td><td><p>0.841</p></td><td><p>0.561</p></td><td><p>0.596</p></td><td><p>0.686</p></td><td><p>0.509</p></td><td><p>0.661</p></td><td><p>0.795</p></td></tr><tr><th>Two step Tr. [26] (semi-sup)</th><td><p>0.622</p></td><td><p>0.747</p></td><td><p>0.843</p></td><td><p>0.568</p></td><td><p>0.606</p></td><td><p>0.688</p></td><td><p>0.559</p></td><td><p>0.704</p></td><td><p>0.804</p></td></tr><tr><th>Joint Tr. with pseudo-labels in seg. loss</th><td><p>0.420</p></td><td><p>0.603</p></td><td><p>0.749</p></td><td><p>0.435</p></td><td><p>0.495</p></td><td><p>0.545</p></td><td><p>0.470</p></td><td><p>0.510</p></td><td><p>0.638</p></td></tr><tr><th>Proposed joint Training (inter)</th><td>0.759</td><td>0.831</td><td>0.883</td><td>0.578</td><td>0.618</td><td>0.696</td><td>0.572</td><td>0.719</td><td><p>0.811</p></td></tr></tbody></table>", "caption": "TABLE II: We compare with some concurrent contrastive learning works. We observe proposed approach to give better results with the improvements being higher for ACDC dataset while them being relatively smaller for Prostate and MMWHS datasets.", "list_citation_info": ["[26] X. Zhao, R. Vemulapalli, P. Mansfield, B. Gong, B. Green, L. Shapira, and Y. Wu, \u201cContrastive learning for label-efficient semantic segmentation,\u201d arXiv preprint arXiv:2012.06985, 2020."]}, {"table": "<table><thead><tr><th></th><th colspan=\"3\">ACDC</th><th colspan=\"3\">Prostate</th><th colspan=\"3\">MMWHS</th></tr><tr><th>Method</th><th><p>|X_{L}|=1</p></th><th><p>|X_{L}|=2</p></th><th><p>|X_{L}|=8</p></th><th><p>|X_{L}|=1</p></th><th><p>|X_{L}|=2</p></th><th><p>|X_{L}|=8</p></th><th><p>|X_{L}|=1</p></th><th><p>|X_{L}|=2</p></th><th><p>|X_{L}|=8</p></th></tr></thead><tbody><tr><th>PI. + Baseline</th><td><p>0.725</p></td><td><p>0.789</p></td><td><p>0.872</p></td><td><p>0.579</p></td><td><p>0.619</p></td><td><p>0.684</p></td><td><p>0.569</p></td><td><p>0.694</p></td><td><p>0.794</p></td></tr><tr><th>PI. + Self-training( [9])</th><td><p>0.745</p></td><td><p>0.802</p></td><td><p>0.881</p></td><td><p>0.607</p></td><td><p>0.634</p></td><td>0.698</td><td><p>0.647</p></td><td><p>0.727</p></td><td><p>0.806</p></td></tr><tr><th>PI. + Proposed method (inter)</th><td>0.774</td><td>0.845</td><td>0.887</td><td>0.612</td><td>0.641</td><td><p>0.692</p></td><td>0.651</td><td>0.734</td><td>0.814</td></tr></tbody></table>", "caption": "TABLE III: We compare baseline, self-training, and proposed method trained over a pre-trained network initialization (PI.) instead of random initialization. This initialization was learnt via contrastive loss based pre-training as done in [10]. We see that both self-training and proposed methods benefit from better initialization and lead to higher gains with proposed approach yielding better improvements.", "list_citation_info": ["[10] K. Chaitanya, E. Erdil, N. Karani, and E. Konukoglu, \u201cContrastive learning of global and local features for medical image segmentation with limited annotations,\u201d Advances in Neural Information Processing Systems, vol. 33, 2020.", "[9] W. Bai, O. Oktay, M. Sinclair, H. Suzuki, M. Rajchl, G. Tarroni, B. Glocker, A. King, P. M. Matthews, and D. Rueckert, \u201cSemi-supervised learning for network-based cardiac mr image segmentation,\u201d in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2017, pp. 253\u2013260."]}]}