{"title": "Towards accurate binary convolutional neural network", "abstract": "We introduce a novel scheme to train binary convolutional neural networks (CNNs) -- CNNs with weights and activations constrained to {-1,+1} at run-time. It has been known that using binary weights and activations drastically reduce memory size and accesses, and can replace arithmetic operations with more efficient bitwise operations, leading to much faster test-time inference and lower power consumption. However, previous works on binarizing CNNs usually result in severe prediction accuracy degradation. In this paper, we address this issue with two major innovations: (1) approximating full-precision weights with the linear combination of multiple binary weight bases; (2) employing multiple binary activations to alleviate information loss. The implementation of the resulting binary CNN, denoted as ABC-Net, is shown to achieve much closer performance to its full-precision counterpart, and even reach the comparable prediction accuracy on ImageNet and forest trail datasets, given adequate binary weight bases and activations.", "authors": ["Xiaofan Lin", " Cong Zhao", " Wei Pan"], "pdf_url": "https://arxiv.org/abs/1711.11294", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Model</td><td>W</td><td>A</td><td>Top-1</td><td>Top-5</td></tr><tr><td>Full-Precision Resnet-18 [full-precision weights and activation]</td><td>32</td><td>32</td><td>69.3%</td><td>89.2%</td></tr><tr><td>BWN [full-precision activation] Rastegari et al. (2016)</td><td>1</td><td>32</td><td>60.8%</td><td>83.0%</td></tr><tr><td>DoReFa-Net [1-bit weight and 4-bit activation] Zhou et al. (2016)</td><td>1</td><td>4</td><td>59.2%</td><td>81.5%</td></tr><tr><td>XNOR-Net [binary weight and activation] Rastegari et al. (2016)</td><td>1</td><td>1</td><td>51.2%</td><td>73.2%</td></tr><tr><td>BNN [binary weight and activation] Courbariaux et al. (2016)</td><td>1</td><td>1</td><td>42.2%</td><td>67.1%</td></tr><tr><td>ABC-Net [5 binary weight bases, 5 binary activations]</td><td>1</td><td>1</td><td>65.0%</td><td>85.9%</td></tr><tr><td>ABC-Net [5 binary weight bases, full-precision activations]</td><td>1</td><td>32</td><td>68.3%</td><td>87.9%</td></tr></tbody></table>", "caption": "Table 3: Classification test accuracy of CNNs trained on ImageNet with Resnet-18 network topology. \u2018W\u2019 and \u2018A\u2019 refer to the weight and activation bitwidth respectively.", "list_citation_info": ["Rastegari et al. (2016) M. Rastegari, V. Ordonez, J. Redmon, and A. Farhadi. Xnor-net: Imagenet classification using binary convolutional neural networks. In European Conference on Computer Vision, pages 525\u2013542. Springer, 2016.", "Courbariaux et al. (2016) M. Courbariaux, I. Hubara, D. Soudry, R. El-Yaniv, and Y. Bengio. Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1. arXiv preprint arXiv:1602.02830, 2016.", "Zhou et al. (2016) S. Zhou, Y. Wu, Z. Ni, X. Zhou, H. Wen, and Y. Zou. Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients. arXiv preprint arXiv:1606.06160, 2016."]}]}