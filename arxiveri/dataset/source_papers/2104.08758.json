{"title": "Documenting large webtext corpora: A case study on the colossal clean crawled corpus", "abstract": "Large language models have led to remarkable progress on many NLP tasks, and researchers are turning to ever-larger text corpora to train them. Some of the largest corpora available are made by scraping significant portions of the internet, and are frequently introduced with only minimal documentation. In this work we provide some of the first documentation for the Colossal Clean Crawled Corpus (C4; Raffel et al., 2020), a dataset created by applying a set of filters to a single snapshot of Common Crawl. We begin by investigating where the data came from, and find a significant amount of text from unexpected sources like patents and US military websites. Then we explore the content of the text itself, and find machine-generated text (e.g., from machine translation systems) and evaluation examples from other benchmark NLP datasets. To understand the impact of the filters applied to create this dataset, we evaluate the text that was removed, and show that blocklist filtering disproportionately removes text from and about minority individuals. Finally, we conclude with some recommendations for how to created and document web-scale datasets from a scrape of the internet.", "authors": ["Jesse Dodge", " Maarten Sap", " Ana Marasovi\u0107", " William Agnew", " Gabriel Ilharco", " Dirk Groeneveld", " Margaret Mitchell", " Matt Gardner"], "pdf_url": "https://arxiv.org/abs/2104.08758", "list_table_and_caption": [{"table": "<table><thead><tr><th>Ethnicity</th><th>Positivity</th></tr></thead><tbody><tr><td>Jewish</td><td>67.1%</td></tr><tr><td>Asian</td><td>60.6%</td></tr><tr><td>Caucasian</td><td>60.5%</td></tr><tr><td>European</td><td>60.5%</td></tr><tr><td>White</td><td>56.5%</td></tr><tr><td>Alaskan</td><td>55.9%</td></tr><tr><td>Hispanic</td><td>50.8%</td></tr><tr><td>Native American</td><td>50.6%</td></tr><tr><td>South-American</td><td>44.4%</td></tr><tr><td>African-American</td><td>44.3%</td></tr><tr><td>Latino</td><td>43.1%</td></tr><tr><td>Middle-Eastern</td><td>42.6%</td></tr><tr><td>Black</td><td>39.3%</td></tr><tr><td>Arab</td><td>37.0%</td></tr><tr><td>African</td><td>36.6%</td></tr></tbody></table>", "caption": "Table 7: Proportion of times each ethnicity was associated with positive sentiment by UnifiedQA Khashabi et al. (2020), following the experimental setup of Li et al. (2020).", "list_citation_info": ["Li et al. (2020) Tao Li, Daniel Khashabi, Tushar Khot, Ashish Sabharwal, and Vivek Srikumar. 2020. UNQOVERing stereotyping biases via underspecified questions. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3475\u20133489, Online. Association for Computational Linguistics.", "Khashabi et al. (2020) Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Hannaneh Hajishirzi. 2020. UNIFIEDQA: Crossing format boundaries with a single QA system. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1896\u20131907, Online. Association for Computational Linguistics."]}]}