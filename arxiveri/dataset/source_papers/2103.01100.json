{"title": "Categorical depth distribution network for monocular 3D object detection", "abstract": "Monocular 3D object detection is a key problem for autonomous vehicles, as it provides a solution with simple configuration compared to typical multi-sensor systems. The main challenge in monocular 3D detection lies in accurately predicting object depth, which must be inferred from object and scene cues due to the lack of direct range measurement. Many methods attempt to directly estimate depth to assist in 3D detection, but show limited performance as a result of depth inaccuracy. Our proposed solution, Categorical Depth Distribution Network (CaDDN), uses a predicted categorical depth distribution for each pixel to project rich contextual feature information to the appropriate depth interval in 3D space. We then use the computationally efficient bird's-eye-view projection and single-stage detector to produce the final output bounding boxes. We design CaDDN as a fully differentiable end-to-end approach for joint depth estimation and object detection. We validate our approach on the KITTI 3D object detection benchmark, where we rank 1st among published monocular methods. We also provide the first monocular 3D detection results on the newly released Waymo Open Dataset. We provide a code release for CaDDN which is made available.", "authors": ["Cody Reading", " Ali Harakeh", " Julia Chae", " Steven L. Waslander"], "pdf_url": "https://arxiv.org/abs/2103.01100", "list_table_and_caption": [{"table": "<table><tbody><tr><th></th><th></th><td colspan=\"3\">Car (IOU = 0.7)</td><td colspan=\"3\">Pedestrian (IOU = 0.5)</td><td colspan=\"3\">Cyclist (IOU = 0.5)</td></tr><tr><th rowspan=\"-2\">Method</th><th rowspan=\"-2\">Frames</th><td><p>Easy</p></td><td>Mod.</td><td><p>Hard</p></td><td><p>Easy</p></td><td>Mod.</td><td><p>Hard</p></td><td><p>Easy</p></td><td>Mod.</td><td><p>Hard</p></td></tr><tr><th><p>Kinematic3D [4]</p></th><th>4</th><td><p>19.07</p></td><td><p>12.72</p></td><td><p>9.17</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>OFT [48]</p></th><th>1</th><td><p>1.61</p></td><td><p>1.32</p></td><td><p>1.00</p></td><td><p>0.63</p></td><td><p>0.36</p></td><td><p>0.35</p></td><td><p>0.14</p></td><td><p>0.06</p></td><td><p>0.07</p></td></tr><tr><th><p>ROI-10D [38]</p></th><th>1</th><td><p>4.32</p></td><td><p>2.02</p></td><td><p>1.46</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>MonoPSR [22]</p></th><th>1</th><td><p>10.76</p></td><td><p>7.25</p></td><td><p>5.85</p></td><td><p>6.12</p></td><td><p>4.00</p></td><td><p>3.30</p></td><td>8.37</td><td>4.74</td><td>3.68</td></tr><tr><th><p>Mono3D-PLiDAR [61]</p></th><th>1</th><td><p>10.76</p></td><td><p>7.50</p></td><td><p>6.10</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>MonoDIS [52]</p></th><th>1</th><td><p>10.37</p></td><td><p>7.94</p></td><td><p>6.40</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>UR3D [64]</p></th><th>1</th><td><p>15.58</p></td><td><p>8.61</p></td><td><p>6.00</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>M3D-RPN [3]</p></th><th>1</th><td><p>14.76</p></td><td><p>9.71</p></td><td><p>7.42</p></td><td><p>4.92</p></td><td><p>3.48</p></td><td><p>2.94</p></td><td><p>0.94</p></td><td><p>0.65</p></td><td><p>0.47</p></td></tr><tr><th><p>SMOKE [33]</p></th><th>1</th><td><p>14.03</p></td><td><p>9.76</p></td><td><p>7.84</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>MonoPair [12]</p></th><th>1</th><td><p>13.04</p></td><td><p>9.99</p></td><td><p>8.65</p></td><td>10.02</td><td>6.68</td><td>5.53</td><td><p>3.79</p></td><td><p>2.12</p></td><td><p>1.83</p></td></tr><tr><th><p>RTM3D [29]</p></th><th>1</th><td><p>14.41</p></td><td><p>10.34</p></td><td><p>8.77</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>AM3D [37]</p></th><th>1</th><td><p>16.50</p></td><td><p>10.74</p></td><td><p>9.52</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>MoVi-3D [53]</p></th><th>1</th><td><p>15.19</p></td><td><p>10.90</p></td><td><p>9.26</p></td><td><p>8.99</p></td><td><p>5.44</p></td><td><p>4.57</p></td><td><p>1.08</p></td><td><p>0.63</p></td><td><p>0.70</p></td></tr><tr><th><p>RAR-Net [32]</p></th><th>1</th><td><p>16.37</p></td><td><p>11.01</p></td><td><p>9.52</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>PatchNet [36]</p></th><th>1</th><td><p>15.68</p></td><td><p>11.12</p></td><td>10.17</td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>DA-3Ddet [65]</p></th><th>1</th><td>16.77</td><td><p>11.50</p></td><td><p>8.93</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>D4LCN [13]</p></th><th>1</th><td><p>16.65</p></td><td>11.72</td><td><p>9.51</p></td><td><p>4.55</p></td><td><p>3.42</p></td><td><p>2.83</p></td><td><p>2.45</p></td><td><p>1.67</p></td><td><p>1.36</p></td></tr><tr><th>CaDDN (ours)</th><th>1</th><td>19.17</td><td>13.41</td><td>11.46</td><td>12.87</td><td>8.14</td><td>6.76</td><td>7.00</td><td>3.41</td><td>3.30</td></tr><tr><th>Improvement</th><th>\u2013</th><td>+2.40</td><td>+1.69</td><td>+1.29</td><td>+2.85</td><td>+1.46</td><td>+1.23</td><td>-1.37</td><td>-1.33</td><td>-0.38</td></tr></tbody></table>", "caption": "Table 1: 3D detection results on the KITTI [16] test set. Results are shown using the \\mathrm{AP}|_{R_{40}} metric only for results that are readily available. We indicate the highest result with  red and the second highest with  blue. Full results for CaDDN can be accessed here.", "list_citation_info": ["[13] Mingyu Ding, Yuqi Huo, Hongwei Yi, Zhe Wang, Jianping Shi, Zhiwu Lu, and Ping Luo. Learning depth-guided convolutions for monocular 3d object detection. CVPR, 2020.", "[32] Lijie Liu, Chufan Wu, Jiwen Lu, Lingxi Xie, Jie Zhou, and Qi Tian. Reinforced axial refinement network for monocular 3d object detection. ECCV, 2020.", "[53] Andrea Simonelli, Samuel Rota Bul\u00f2, Lorenzo Porzi, Elisa Ricci, and Peter Kontschieder. Towards generalization across depth for monocular 3d object detection. ECCV, 2020.", "[33] Zechen Liu, Zizhang Wu, and Roland Toth. Smoke: Single-stage monocular 3d object detection via keypoint estimation. CVPRW, 2020.", "[3] Garrick Brazil and Xiaoming Liu. M3D-RPN: monocular 3D region proposal network for object detection. ICCV, 2019.", "[61] Xinshuo Weng and Kris Kitani. Monocular 3d object detection with pseudo-lidar point cloud. ICCVW, 2019.", "[12] Yongjian Chen, Lei Tai, Kai Sun, and Mingyang Li. Monopair: Monocular 3d object detection using pairwise spatial relationships. CVPR, 2020.", "[65] Xiaoqing Ye, Liang Du, Yifeng Shi, Yingying Li, Xiao Tan, Jianfeng Feng, Errui Ding, and Shilei Wen. Monocular 3d object detection via feature domain adaptation. ECCV, 2020.", "[16] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. CVPR, 2012.", "[48] Thomas Roddick, Alex Kendall, and Roberto Cipolla. Orthographic feature transform for monocular 3D object detection. BMVC, 2018.", "[64] Tae-Kyun Kim Xuepeng Shi, Zhixiang Chen. Distance-normalized unified representation for monocular 3d object detection. ECCV, 2020.", "[38] Fabian Manhardt, Wadim Kehl, and Adrien Gaidon. ROI-10D: monocular lifting of 2d detection to 6d pose and metric shape. CVPR, 2019.", "[36] Xinzhu Ma, Shinan Liu, Zhiyi Xia, Hongwen Zhang, Xingyu Zeng, and Wanli Ouyang. Rethinking pseudo-lidar representation. ECCV, 2020.", "[52] Andrea Simonelli, Samuel Rota Bul\u00f2, Lorenzo Porzi, Manuel L\u00f3pez-Antequera, and Peter Kontschieder. Disentangling monocular 3d object detection. ICCV, 2019.", "[4] Garrick Brazil, Gerard Pons-Moll, Xiaoming Liu, and Bernt Schiele. Kinematic 3d object detection in monocular video. ECCV, 2020.", "[29] Peixuan Li, Huaici Zhao, Pengfei Liu, and Feidao Cao. Rtm3d: Real-time monocular 3d detection from object keypoints for autonomous driving. ECCV, 2020.", "[37] Xinzhu Ma, Zhihui Wang, Haojie Li, Wanli Ouyang, and Pengbo Zhang. Accurate monocular 3D object detection via color-embedded 3D reconstruction for autonomous driving. ICCV, 2019.", "[22] Jason Ku, Alex D. Pon, and Steven L. Waslander. Monocular 3D object detection leveraging accurate proposals and shape reconstruction. CVPR, 2019."]}, {"table": "<table><thead><tr><th></th><th></th><th colspan=\"4\">3D mAP</th><th colspan=\"4\">3D mAPH</th></tr><tr><th rowspan=\"-2\">Difficulty</th><th rowspan=\"-2\">Method</th><th>Overall</th><th>0 - 30m</th><th>30 - 50m</th><th>50m - \\infty</th><th>Overall</th><th>0 - 30m</th><th>30 - 50m</th><th>50m - \\infty</th></tr></thead><tbody><tr><th></th><th>M3D-RPN [3]</th><td>0.35</td><td>1.12</td><td>0.18</td><td>0.02</td><td>0.34</td><td>1.10</td><td>0.18</td><td>0.02</td></tr><tr><th></th><th>CaDNN (Ours)</th><td>5.03</td><td>14.54</td><td>1.47</td><td>0.10</td><td>4.99</td><td>14.43</td><td>1.45</td><td>0.10</td></tr><tr><th rowspan=\"-3\">LEVEL_1(IOU = 0.7)</th><th>Improvement</th><td>+4.69</td><td>+13.43</td><td>+1.28</td><td>+0.08</td><td>+4.65</td><td>+13.33</td><td>+1.28</td><td>+0.08</td></tr><tr><th></th><th>M3D-RPN [3]</th><td>0.33</td><td>1.12</td><td>0.18</td><td>0.02</td><td>0.33</td><td>1.10</td><td>0.17</td><td>0.02</td></tr><tr><th></th><th>CaDNN (Ours)</th><td>4.49</td><td>14.50</td><td>1.42</td><td>0.09</td><td>4.45</td><td>14.38</td><td>1.41</td><td>0.09</td></tr><tr><th rowspan=\"-3\">LEVEL_2(IOU = 0.7)</th><th>Improvement</th><td>+4.15</td><td>+13.38</td><td>+1.24</td><td>+0.07</td><td>+4.12</td><td>+13.28</td><td>+1.24</td><td>+0.07</td></tr><tr><th></th><th>M3D-RPN [3]</th><td>3.79</td><td>11.14</td><td>2.16</td><td>0.26</td><td>3.63</td><td>10.70</td><td>2.09</td><td>0.21</td></tr><tr><th></th><th>CaDNN (Ours)</th><td>17.54</td><td>45.00</td><td>9.24</td><td>0.64</td><td>17.31</td><td>44.46</td><td>9.11</td><td>0.62</td></tr><tr><th rowspan=\"-3\">LEVEL_1(IOU = 0.5)</th><th>Improvement</th><td>+13.76</td><td>+33.86</td><td>+7.08</td><td>+0.39</td><td>+13.69</td><td>+33.77</td><td>+7.02</td><td>+0.41</td></tr><tr><th></th><th>M3D-RPN [3]</th><td>3.61</td><td>11.12</td><td>2.12</td><td>0.24</td><td>3.46</td><td>10.67</td><td>2.04</td><td>0.20</td></tr><tr><th></th><th>CaDNN (Ours)</th><td>16.51</td><td>44.87</td><td>8.99</td><td>0.58</td><td>16.28</td><td>44.33</td><td>8.86</td><td>0.55</td></tr><tr><th rowspan=\"-3\">LEVEL_2(IOU = 0.5)</th><th>Improvement</th><td>+12.89</td><td>+33.75</td><td>+6.87</td><td>+0.34</td><td>+12.82</td><td>+33.66</td><td>+6.81</td><td>+0.36</td></tr></tbody></table>", "caption": "Table 2: Results on the Waymo Open Dataset Validation Set on the Vehicle class. We evaluate M3D-RPN [3] as a baseline for comparison.", "list_citation_info": ["[3] Garrick Brazil and Xiaoming Liu. M3D-RPN: monocular 3D region proposal network for object detection. ICCV, 2019."]}, {"table": "<table><tbody><tr><th></th><th></th><td colspan=\"3\">Car (IOU = 0.7)</td><td colspan=\"3\">Pedestrian (IOU = 0.5)</td><td colspan=\"3\">Cyclist (IOU = 0.5)</td></tr><tr><th rowspan=\"-2\">Method</th><th rowspan=\"-2\">Frames</th><td><p>Easy</p></td><td>Mod.</td><td><p>Hard</p></td><td><p>Easy</p></td><td>Mod.</td><td><p>Hard</p></td><td><p>Easy</p></td><td>Mod.</td><td><p>Hard</p></td></tr><tr><th><p>Kinematic3D [4]</p></th><th>4</th><td><p>26.69</p></td><td><p>17.52</p></td><td><p>13.10</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>ROI-10D [38]</p></th><th>1</th><td><p>9.78</p></td><td><p>4.91</p></td><td><p>3.74</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>UR3D [64]</p></th><th>1</th><td><p>21.85</p></td><td><p>12.51</p></td><td><p>9.20</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>MonoPSR [22]</p></th><th>1</th><td><p>18.33</p></td><td><p>12.58</p></td><td><p>9.91</p></td><td><p>7.24</p></td><td><p>4.56</p></td><td><p>4.11</p></td><td>9.87</td><td>5.78</td><td>4.57</td></tr><tr><th><p>MonoDIS [52]</p></th><th>1</th><td><p>17.23</p></td><td><p>13.19</p></td><td><p>11.12</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>M3D-RPN [3]</p></th><th>1</th><td><p>21.02</p></td><td><p>13.67</p></td><td><p>10.23</p></td><td><p>5.65</p></td><td><p>4.05</p></td><td><p>3.29</p></td><td><p>1.25</p></td><td><p>0.81</p></td><td><p>0.78</p></td></tr><tr><th><p>Mono3D-PLiDAR [61]</p></th><th>1</th><td><p>21.27</p></td><td><p>13.92</p></td><td><p>11.25</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>RTM3D [29]</p></th><th>1</th><td><p>19.17</p></td><td><p>14.20</p></td><td><p>11.99</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>SMOKE [33]</p></th><th>1</th><td><p>20.83</p></td><td><p>14.49</p></td><td><p>12.75</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>MonoPair [12]</p></th><th>1</th><td><p>19.28</p></td><td><p>14.83</p></td><td><p>12.89</p></td><td>10.99</td><td>7.04</td><td>6.29</td><td><p>4.76</p></td><td><p>2.87</p></td><td><p>2.42</p></td></tr><tr><th><p>RAR-Net [32]</p></th><th>1</th><td><p>22.45</p></td><td><p>15.02</p></td><td><p>12.93</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>D4LCN [13]</p></th><th>1</th><td><p>22.51</p></td><td><p>16.02</p></td><td><p>12.55</p></td><td><p>5.06</p></td><td><p>3.86</p></td><td><p>3.59</p></td><td><p>2.72</p></td><td><p>1.82</p></td><td><p>1.79</p></td></tr><tr><th><p>PatchNet [36]</p></th><th>1</th><td><p>22.97</p></td><td><p>16.86</p></td><td>14.97</td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th><p>MoVi-3D [53]</p></th><th>1</th><td><p>22.76</p></td><td><p>17.03</p></td><td><p>14.85</p></td><td><p>10.08</p></td><td><p>6.29</p></td><td><p>5.37</p></td><td><p>1.45</p></td><td><p>0.91</p></td><td><p>0.93</p></td></tr><tr><th><p>AM3D [37]</p></th><th>1</th><td>25.03</td><td>17.32</td><td><p>14.91</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td><td><p>\u2013</p></td></tr><tr><th>CaDDN (ours)</th><th>1</th><td>27.94</td><td>18.91</td><td>17.19</td><td>14.72</td><td>9.41</td><td>8.17</td><td>9.67</td><td>5.38</td><td>4.75</td></tr><tr><th>Improvement</th><th>\u2013</th><td>+2.91</td><td>+1.59</td><td>+2.22</td><td>+3.73</td><td>+2.37</td><td>+1.88</td><td>-0.20</td><td>-0.40</td><td>+0.18</td></tr></tbody></table>", "caption": "Table 5: BEV detection results on the KITTI [16] test set. Results are shown using the \\mathrm{AP}|_{R_{40}} metric only for results that are readily available. We indicate the highest result with  red and the second highest with  blue. Full results for CaDDN can be accessed here.", "list_citation_info": ["[13] Mingyu Ding, Yuqi Huo, Hongwei Yi, Zhe Wang, Jianping Shi, Zhiwu Lu, and Ping Luo. Learning depth-guided convolutions for monocular 3d object detection. CVPR, 2020.", "[32] Lijie Liu, Chufan Wu, Jiwen Lu, Lingxi Xie, Jie Zhou, and Qi Tian. Reinforced axial refinement network for monocular 3d object detection. ECCV, 2020.", "[53] Andrea Simonelli, Samuel Rota Bul\u00f2, Lorenzo Porzi, Elisa Ricci, and Peter Kontschieder. Towards generalization across depth for monocular 3d object detection. ECCV, 2020.", "[33] Zechen Liu, Zizhang Wu, and Roland Toth. Smoke: Single-stage monocular 3d object detection via keypoint estimation. CVPRW, 2020.", "[3] Garrick Brazil and Xiaoming Liu. M3D-RPN: monocular 3D region proposal network for object detection. ICCV, 2019.", "[61] Xinshuo Weng and Kris Kitani. Monocular 3d object detection with pseudo-lidar point cloud. ICCVW, 2019.", "[12] Yongjian Chen, Lei Tai, Kai Sun, and Mingyang Li. Monopair: Monocular 3d object detection using pairwise spatial relationships. CVPR, 2020.", "[16] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. CVPR, 2012.", "[38] Fabian Manhardt, Wadim Kehl, and Adrien Gaidon. ROI-10D: monocular lifting of 2d detection to 6d pose and metric shape. CVPR, 2019.", "[36] Xinzhu Ma, Shinan Liu, Zhiyi Xia, Hongwen Zhang, Xingyu Zeng, and Wanli Ouyang. Rethinking pseudo-lidar representation. ECCV, 2020.", "[52] Andrea Simonelli, Samuel Rota Bul\u00f2, Lorenzo Porzi, Manuel L\u00f3pez-Antequera, and Peter Kontschieder. Disentangling monocular 3d object detection. ICCV, 2019.", "[4] Garrick Brazil, Gerard Pons-Moll, Xiaoming Liu, and Bernt Schiele. Kinematic 3d object detection in monocular video. ECCV, 2020.", "[64] Tae-Kyun Kim Xuepeng Shi, Zhixiang Chen. Distance-normalized unified representation for monocular 3d object detection. ECCV, 2020.", "[29] Peixuan Li, Huaici Zhao, Pengfei Liu, and Feidao Cao. Rtm3d: Real-time monocular 3d detection from object keypoints for autonomous driving. ECCV, 2020.", "[37] Xinzhu Ma, Zhihui Wang, Haojie Li, Wanli Ouyang, and Pengbo Zhang. Accurate monocular 3D object detection via color-embedded 3D reconstruction for autonomous driving. ICCV, 2019.", "[22] Jason Ku, Alex D. Pon, and Steven L. Waslander. Monocular 3D object detection leveraging accurate proposals and shape reconstruction. CVPR, 2019."]}]}