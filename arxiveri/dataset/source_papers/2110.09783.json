{"title": "Spatial-temporal transformer for 3d point cloud sequences", "abstract": "Effective learning of spatial-temporal information within a point cloud sequence is highly important for many down-stream tasks such as 4D semantic segmentation and 3D action recognition. In this paper, we propose a novel framework named Point Spatial-Temporal Transformer (PST2) to learn spatial-temporal representations from dynamic 3D point cloud sequences. Our PST2 consists of two major modules: a Spatio-Temporal Self-Attention (STSA) module and a Resolution Embedding (RE) module. Our STSA module is introduced to capture the spatial-temporal context information across adjacent frames, while the RE module is proposed to aggregate features across neighbors to enhance the resolution of feature maps. We test the effectiveness our PST2 with two different tasks on point cloud sequences, i.e., 4D semantic segmentation and 3D action recognition. Extensive experiments on three benchmarks show that our PST2 outperforms existing methods on all datasets. The effectiveness of our STSA and RE modules have also been justified with ablation experiments.", "authors": ["Yimin Wei", " Hao Liu", " Tingting Xie", " Qiuhong Ke", " Yulan Guo"], "pdf_url": "https://arxiv.org/abs/2110.09783", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Method</td><td>param (M)</td><td>nframe</td><td>mAcc</td><td>mIoU</td><td>Bldg</td><td>Road</td><td>Sdwlk</td><td>Fence</td><td>Vegitn</td><td>Pole</td><td>Car</td><td>T.Sign</td><td>Pdstr</td><td>Bicyc</td><td>Lane</td><td>T.light</td></tr><tr><td>3D MinkNet [5]</td><td>19.31</td><td>1</td><td>89.31</td><td>76.24</td><td>89.39</td><td>97.68</td><td>69.43</td><td>86.52</td><td>98.11</td><td>97.26</td><td>93.50</td><td>79.45</td><td>92.27</td><td>0.00</td><td>44.61</td><td>66.69</td></tr><tr><td>4D MinkNet [5]</td><td>23.72</td><td>3</td><td>88.01</td><td>77.46</td><td>90.13</td><td>98.26</td><td>73.47</td><td>87.19</td><td>99.10</td><td>97.50</td><td>94.01</td><td>79.04</td><td>92.62</td><td>0.00</td><td>50.01</td><td>68.14</td></tr><tr><td>Pointnet++ [24]</td><td>0.88</td><td>1</td><td>85.43</td><td>79.35</td><td>96.88</td><td>97.72</td><td>86.20</td><td>92.75</td><td>97.12</td><td>97.09</td><td>90.85</td><td>66.87</td><td>78.64</td><td>0.00</td><td>72.93</td><td>75.17</td></tr><tr><td>MeteorNet [20]</td><td>1.78</td><td>3</td><td>86.78</td><td>81.80</td><td>98.10</td><td>97.72</td><td>88.65</td><td>94.00</td><td>97.98</td><td>97.65</td><td>93.83</td><td>84.07</td><td>80.90</td><td>0.00</td><td>71.14</td><td>77.60</td></tr><tr><td>ASAP-Net [2]</td><td>1.84</td><td>3</td><td>87.02</td><td>82.73</td><td>97.67</td><td>98.15</td><td>89.85</td><td>95.50</td><td>97.12</td><td>97.59</td><td>94.90</td><td>80.97</td><td>86.08</td><td>0.00</td><td>74.66</td><td>77.51</td></tr><tr><td>PST^{2} (ours)</td><td>2.99</td><td>3</td><td>87.03</td><td>81.86</td><td>97.48</td><td>98.12</td><td>90.57</td><td>94.07</td><td>98.29</td><td>98.07</td><td>94.96</td><td>81.54</td><td>77.23</td><td>0.00</td><td>74.23</td><td>77.76</td></tr></tbody></table>", "caption": "Table 2: Semantic segmentation results on the Sythia dataset. Mean accuracy and mean IoU (%) are used as the evaluation metrics.", "list_citation_info": ["[20] Xingyu Liu, Mengyuan Yan, and Jeannette Bohg. MeteorNet: Deep learning on dynamic 3D point cloud sequences. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9246\u20139255, 2019.", "[5] Christopher Choy, JunYoung Gwak, and Silvio Savarese. 4D spatio-temporal convnets: Minkowski convolutional neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3075\u20133084, 2019.", "[24] Charles R Qi, Li Yi, Hao Su, and Leonidas J Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in Neural Information Processing Systems, pages 5099\u20135108, 2017.", "[2] Hanwen Cao, Yongyi Lu, Cewu Lu, Bo Pang, Gongshen Liu, and Alan Yuille. ASAP-Net: Attention and structure aware point cloud sequence segmentation. In BMVC British Machine Vision Conference, 2020."]}, {"table": "<table><tbody><tr><th>Method</th><th>nframe</th><th>mIoU</th><td>c1</td><td>c2</td><td>c3</td><td>c4</td><td>c5</td><td>c6</td><td>c7</td><td>c8</td><td>c9</td><td>c10</td><td>c11</td><td>c12</td><td>c13</td><td>c14</td><td>c15</td><td>c16</td><td>c17</td><td>c18</td><td>c19</td></tr><tr><th>PNv2 [24]</th><th>1</th><th>20.1</th><td>53.7</td><td>1.9</td><td>0.2</td><td>0.9</td><td>0.2</td><td>0.9</td><td>1.0</td><td>0.0</td><td>72.0</td><td>18.7</td><td>41.8</td><td>5.6</td><td>62.3</td><td>16.9</td><td>46.5</td><td>13.8</td><td>20.0</td><td>6.0</td><td>8.9</td></tr><tr><th>ASAP-Net [2]</th><th>3</th><th>33.3</th><td>84.1</td><td>11.6</td><td>7.5</td><td>3.2</td><td>11.4</td><td>7.8</td><td>18.5</td><td>3.0</td><td>81.8</td><td>28.1</td><td>53.1</td><td>7.8</td><td>74.9</td><td>37.6</td><td>64.4</td><td>27.2</td><td>51.7</td><td>22.8</td><td>30.8</td></tr><tr><th>PST^{2} (ours)</th><th>3</th><th>36.5</th><td>84.3</td><td>3.4</td><td>14.7</td><td>14.8</td><td>14.5</td><td>8.7</td><td>31.0</td><td>22.4</td><td>81.8</td><td>29.6</td><td>62.1</td><td>14.2</td><td>78.8</td><td>41.8</td><td>63.9</td><td>30.6</td><td>56.6</td><td>23.8</td><td>17.5</td></tr></tbody></table>", "caption": "Table 3: Semantic segmentation results on the SemanticKITTI dataset. Per-class and average IoU (%) are used as the evaluation metrics. c1-c19 represent the 19 categories provided in the SemanticKITTI dataset, namely, car (c1), bicycle (c2), motorcycle (c3), truck (c4), other-vehicle (c5), person (c6), bicyclist (c7), motorcyclist (c8), road (c9), parking (c10), sidewalk (c11), other-ground (c12), building (c13), fence (c14), vegetation (c15), trunk (c16), terrain (c17), pole (c18), and traffic-sign (c19).", "list_citation_info": ["[2] Hanwen Cao, Yongyi Lu, Cewu Lu, Bo Pang, Gongshen Liu, and Alan Yuille. ASAP-Net: Attention and structure aware point cloud sequence segmentation. In BMVC British Machine Vision Conference, 2020.", "[24] Charles R Qi, Li Yi, Hao Su, and Leonidas J Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in Neural Information Processing Systems, pages 5099\u20135108, 2017."]}, {"table": "<table><thead><tr><th>Method</th><th>param (M)</th><th>nframe</th><th>mIoU</th><th>c1</th><th>c2</th><th>c3</th><th>c4</th><th>c5</th><th>c6</th><th>c7</th><th>c8</th><th>c9</th><th>c10</th><th>c11</th><th>c12</th><th>c13</th><th>c14</th><th>c15</th><th>c16</th><th>c17</th><th>c18</th><th>c19</th></tr><tr><th>PNv2 [24]</th><th>3.62</th><th>1</th><th>20.1</th><th>53.7</th><th>1.9</th><th>0.2</th><th>0.9</th><th>0.2</th><th>0.9</th><th>1.0</th><th>0.0</th><th>72.0</th><th>18.7</th><th>41.8</th><th>5.6</th><th>62.3</th><th>16.9</th><th>46.5</th><th>13.8</th><th>20.0</th><th>6.0</th><th>8.9</th></tr></thead><tbody><tr><th>PNv2+RE</th><th>5.13</th><th>1</th><th>38.6</th><td>85.4</td><td>3.2</td><td>13.5</td><td>22.7</td><td>16.4</td><td>9.2</td><td>29.1</td><td>31.4</td><td>82.8</td><td>34.1</td><td>67.4</td><td>13.6</td><td>79.4</td><td>43.5</td><td>64.6</td><td>31.2</td><td>58.9</td><td>24.5</td><td>22.6</td></tr><tr><th>PNv2+STSA</th><th>3.87</th><th>3</th><th>32.4</th><td>83.4</td><td>3.3</td><td>7.3</td><td>6.4</td><td>11.0</td><td>6.7</td><td>25.9</td><td>13.6</td><td>78.0</td><td>19.1</td><td>59.1</td><td>9.7</td><td>69.1</td><td>38.2</td><td>59.8</td><td>27.0</td><td>56.5</td><td>23.5</td><td>17.4</td></tr><tr><th>PST^{2} (PNv2+STSA+RE)</th><th>5.63</th><th>3</th><th>36.5</th><td>84.3</td><td>3.4</td><td>14.7</td><td>14.8</td><td>14.5</td><td>8.7</td><td>31.0</td><td>22.4</td><td>81.8</td><td>29.6</td><td>62.1</td><td>14.2</td><td>78.8</td><td>41.8</td><td>63.9</td><td>30.6</td><td>56.6</td><td>23.8</td><td>17.5</td></tr></tbody></table>", "caption": "Table 5: Ablation results on the SemanticKITTI dataset. c1-c19 represent the 19 categories provided in the SemanticKITTI dataset, namely, car (c1), bicycle (c2), motorcycle (c3), truck (c4), other-vehicle (c5), person (c6), bicyclist (c7), motorcyclist (c8), road (c9), parking (c10), sidewalk (c11), other-ground (c12), building (c13), fence (c14), vegetation (c15), trunk (c16), terrain (c17), pole (c18), and traffic-sign (c19).", "list_citation_info": ["[24] Charles R Qi, Li Yi, Hao Su, and Leonidas J Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in Neural Information Processing Systems, pages 5099\u20135108, 2017."]}]}