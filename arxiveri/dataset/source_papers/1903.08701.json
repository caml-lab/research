{"title": "Lasernet: An efficient probabilistic 3d object detector for autonomous driving", "abstract": "In this paper, we present LaserNet, a computationally efficient method for 3D object detection from LiDAR data for autonomous driving. The efficiency results from processing LiDAR data in the native range view of the sensor, where the input data is naturally compact. Operating in the range view involves well known challenges for learning, including occlusion and scale variation, but it also provides contextual information based on how the sensor data was captured. Our approach uses a fully convolutional network to predict a multimodal distribution over 3D boxes for each point and then it efficiently fuses these distributions to generate a prediction for each object. Experiments show that modeling each detection as a distribution rather than a single deterministic box leads to better overall detection performance. Benchmark results show that this approach has significantly lower runtime than other recent detectors and that it achieves state-of-the-art performance when compared on a large dataset that has enough data to overcome the challenges of training on the range view.", "authors": ["Gregory P. Meyer", " Ankit Laddha", " Eric Kee", " Carlos Vallespi-Gonzalez", " Carl K. Wellington"], "pdf_url": "https://arxiv.org/abs/1903.08701", "list_table_and_caption": [{"table": "<table><thead><tr><th rowspan=\"2\">Method</th><th rowspan=\"2\">Input</th><th colspan=\"4\">Vehicle AP_{0.7}</th><th colspan=\"4\">Bike AP_{0.5}</th><th colspan=\"4\">Pedestrian AP_{0.5}</th></tr><tr><th>0-70m</th><th>0-30m</th><th>30-50m</th><th>50-70m</th><th>0-70m</th><th>0-30m</th><th>30-50m</th><th>50-70m</th><th>0-70m</th><th>0-30m</th><th>30-50m</th><th>50-70m</th></tr></thead><tbody><tr><th>LaserNet (Ours)</th><th>LiDAR</th><td>85.34</td><td>95.02</td><td>84.42</td><td>67.65</td><td>61.93</td><td>74.62</td><td>51.37</td><td>40.95</td><td>80.37</td><td>88.02</td><td>77.85</td><td>65.75</td></tr><tr><th>PIXOR  [28]</th><th>LiDAR</th><td>80.99</td><td>93.34</td><td>80.20</td><td>60.19</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>PIXOR++  [27]</th><th>LiDAR</th><td>82.63</td><td>93.80</td><td>82.34</td><td>63.42</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><th>ContFuse  [17]</th><th>LiDAR</th><td>83.13</td><td>93.08</td><td>82.48</td><td>65.53</td><td>57.27</td><td>68.08</td><td>48.83</td><td>38.26</td><td>73.51</td><td>80.60</td><td>71.68</td><td>59.12</td></tr><tr><th>ContFuse  [17]</th><th>LiDAR+RGB</th><td>85.17</td><td>93.86</td><td>84.41</td><td>69.83</td><td>61.13</td><td>72.01</td><td>52.60</td><td>43.03</td><td>76.84</td><td>82.97</td><td>75.54</td><td>64.19</td></tr></tbody></table>", "caption": "Table 1: BEV Object Detection Performance on ATG4D", "list_citation_info": ["[17] Ming Liang, Bin Yang, Shenlong Wang, and Raquel Urtasun. Deep continuous fusion for multi-sensor 3D object detection. In Proceedings of the European Conference on Computer Vision (ECCV), 2018.", "[27] Bin Yang, Ming Liang, and Raquel Urtasun. HDNET: Exploiting HD maps for 3d object detection. In Proceedings of the Conference on Robot Learning (CoRL), 2018.", "[28] Bin Yang, Wenjie Luo, and Raquel Urtasun. PIXOR: Real-time 3D object detection from point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018."]}, {"table": "<table><tbody><tr><th>Method</th><td>Forward Pass (ms)</td><td>Total (ms)</td></tr><tr><th>LaserNet (Ours)</th><td>12</td><td>30</td></tr><tr><th>PIXOR [28]</th><td>35</td><td>62</td></tr><tr><th>PIXOR++ [27]</th><td>35</td><td>62</td></tr><tr><th>VoxelNet [30]</th><td>190</td><td>225</td></tr><tr><th>MV3D [30]</th><td>-</td><td>360</td></tr><tr><th>AVOD [15]</th><td>80</td><td>100</td></tr><tr><th>F-PointNet [22]</th><td>-</td><td>170</td></tr><tr><th>ContFuse [17]</th><td>60</td><td>-</td></tr></tbody></table>", "caption": "Table 3: Runtime Performance on KITTI", "list_citation_info": ["[17] Ming Liang, Bin Yang, Shenlong Wang, and Raquel Urtasun. Deep continuous fusion for multi-sensor 3D object detection. In Proceedings of the European Conference on Computer Vision (ECCV), 2018.", "[27] Bin Yang, Ming Liang, and Raquel Urtasun. HDNET: Exploiting HD maps for 3d object detection. In Proceedings of the Conference on Robot Learning (CoRL), 2018.", "[22] Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas. Frustum pointnets for 3D object detection from RGB-D data. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.", "[30] Yin Zhou and Oncel Tuzel. Voxelnet: End-to-end learning for point cloud based 3D object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.", "[28] Bin Yang, Wenjie Luo, and Raquel Urtasun. PIXOR: Real-time 3D object detection from point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.", "[15] Jason Ku, Melissa Mozifian, Jungwook Lee, Ali Harakeh, and Steven L Waslander. Joint 3D proposal generation and object detection from view aggregation. In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2018."]}, {"table": "<table><thead><tr><th rowspan=\"2\">Method</th><th rowspan=\"2\">Input</th><th colspan=\"3\">Vehicle AP_{0.7}</th></tr><tr><th>Easy</th><th>Moderate</th><th>Hard</th></tr></thead><tbody><tr><th>LaserNet (Ours)</th><td>LiDAR</td><td>78.25</td><td>73.77</td><td>66.47</td></tr><tr><th>PIXOR [28]</th><td>LiDAR</td><td>81.70</td><td>77.05</td><td>72.95</td></tr><tr><th>PIXOR++ [27]</th><td>LiDAR</td><td>89.38</td><td>83.70</td><td>77.97</td></tr><tr><th>VoxelNet [30]</th><td>LiDAR</td><td>89.35</td><td>79.26</td><td>77.39</td></tr><tr><th>MV3D [5]</th><td>LiDAR+RGB</td><td>86.02</td><td>76.90</td><td>68.49</td></tr><tr><th>AVOD [15]</th><td>LiDAR+RGB</td><td>88.53</td><td>83.79</td><td>77.90</td></tr><tr><th>F-PointNet [22]</th><td>LiDAR+RGB</td><td>88.70</td><td>84.00</td><td>75.33</td></tr><tr><th>ContFuse [17]</th><td>LiDAR+RGB</td><td>88.81</td><td>85.83</td><td>77.33</td></tr></tbody></table>", "caption": "Table 4: BEV Object Detection Performance on KITTI", "list_citation_info": ["[17] Ming Liang, Bin Yang, Shenlong Wang, and Raquel Urtasun. Deep continuous fusion for multi-sensor 3D object detection. In Proceedings of the European Conference on Computer Vision (ECCV), 2018.", "[27] Bin Yang, Ming Liang, and Raquel Urtasun. HDNET: Exploiting HD maps for 3d object detection. In Proceedings of the Conference on Robot Learning (CoRL), 2018.", "[22] Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas. Frustum pointnets for 3D object detection from RGB-D data. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.", "[5] Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3D object detection network for autonomous driving. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.", "[30] Yin Zhou and Oncel Tuzel. Voxelnet: End-to-end learning for point cloud based 3D object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.", "[28] Bin Yang, Wenjie Luo, and Raquel Urtasun. PIXOR: Real-time 3D object detection from point clouds. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.", "[15] Jason Ku, Melissa Mozifian, Jungwook Lee, Ali Harakeh, and Steven L Waslander. Joint 3D proposal generation and object detection from view aggregation. In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2018."]}]}