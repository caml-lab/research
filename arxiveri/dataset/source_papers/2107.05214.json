{"title": "Split, embed and merge: An accurate table structure recognizer", "abstract": "Table structure recognition is an essential part for making machines understand tables. Its main task is to recognize the internal structure of a table. However, due to the complexity and diversity in their structure and style, it is very difficult to parse the tabular data into the structured format which machines can understand easily, especially for complex tables. In this paper, we introduce Split, Embed and Merge (SEM), an accurate table structure recognizer. Our model takes table images as input and can correctly recognize the structure of tables, whether they are simple or a complex tables. SEM is mainly composed of three parts, splitter, embedder and merger. In the first stage, we apply the splitter to predict the potential regions of the table row (column) separators, and obtain the fine grid structure of the table. In the second stage, by taking a full consideration of the textual information in the table, we fuse the output features for each table grid from both vision and language modalities. Moreover, we achieve a higher precision in our experiments through adding additional semantic features. Finally, we process the merging of these basic table grids in a self-regression manner. The correspondent merging results is learned through the attention mechanism. In our experiments, SEM achieves an average F1-Measure of 97.11% on the SciTSR dataset which outperforms other methods by a large margin. We also won the first place in the complex table and third place in all tables in ICDAR 2021 Competition on Scientific Literature Parsing, Task-B. Extensive experiments on other publicly available datasets demonstrate that our model achieves state-of-the-art.", "authors": ["Zhenrong Zhang", " Jianshu Zhang", " Jun Du"], "pdf_url": "https://arxiv.org/abs/2107.05214", "list_table_and_caption": [{"table": "<table><tbody><tr><td rowspan=\"2\">Method</td><td colspan=\"3\">SciTSR</td><td colspan=\"3\">SciTSR-COMP</td><td rowspan=\"2\">FPS</td></tr><tr><td>P</td><td>R</td><td>F1</td><td>P</td><td>R</td><td>F1</td></tr><tr><td>Adobe DeepDeSRT </td><td>82.9</td><td>79.6</td><td>81.2</td><td>79.6</td><td>73.7</td><td>76.5</td><td>-</td></tr><tr><td>TabbyPDF TabbyPDF </td><td>91.4</td><td>91.0</td><td>91.2</td><td>86.9</td><td>84.1</td><td>85.5</td><td>-</td></tr><tr><td>DeepDeSRT DeepDeSRT </td><td>89.8</td><td>89.7</td><td>89.7</td><td>81.1</td><td>81.3</td><td>81.2</td><td>20.88</td></tr><tr><td>GraphTSR GraphTSR </td><td>93.6</td><td>93.1</td><td>93.4</td><td>94.3</td><td>92.5</td><td>93.4</td><td>-</td></tr><tr><td>TabStruct-Net TabStructNet </td><td>92.7</td><td>91.3</td><td>92.0</td><td>90.9</td><td>88.2</td><td>89.5</td><td>0.77</td></tr><tr><td>T1</td><td>96.69</td><td>94.15</td><td>95.40</td><td>93.81</td><td>96.06</td><td>89.77</td><td>16.47</td></tr><tr><td>SEM</td><td>97.70</td><td>96.52</td><td>97.11</td><td>96.80</td><td>94.67</td><td>95.72</td><td>1.94</td></tr></tbody></table>", "caption": "Table 4: A performance comparison between our method and other state-of-the-art methods on the SciTSR and SciTSR-COMP datasets.", "list_citation_info": ["(6) S. Raja, A. Mondal, C. V. Jawahar, Table structure recognition using top-down and bottom-up cues, in: A. Vedaldi, H. Bischof, T. Brox, J.-M. Frahm (Eds.), Computer Vision \u2013 ECCV 2020, 2020, pp. 70\u201386.", "(10) Z. Chi, H. Huang, H.-D. Xu, H. Yu, W. Yin, X.-L. Mao, Complicated table structure recognition (2019).", "(50) A. Shigarov, A. Altaev, A. Mikhailov, V. Paramonov, E. Cherkashin, Tabbypdf: Web-based system for pdf table extraction, in: R. Dama\u0161evi\u010dius, G. Vasiljevien\u0117 (Eds.), Information and Software Technologies, 2018, pp. 257\u2013269.", "(3) S. Schreiber, S. Agne, I. Wolf, A. Dengel, S. Ahmed, Deepdesrt: Deep learning for detection and structure recognition of tables in document images, in: 2017 International Conference on Document Analysis and Recognition (ICDAR), Vol. 01, 2017, pp. 1162\u20131167. doi:10.1109/ICDAR.2017.192."]}]}