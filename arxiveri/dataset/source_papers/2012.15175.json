{"title": "Rethinking the Heatmap Regression for Bottom-up Human Pose Estimation", "abstract": "Heatmap regression has become the most prevalent choice for nowadays human pose estimation methods. The ground-truth heatmaps are usually constructed via covering all skeletal keypoints by 2D gaussian kernels. The standard deviations of these kernels are fixed. However, for bottom-up methods, which need to handle a large variance of human scales and labeling ambiguities, the current practice seems unreasonable. To better cope with these problems, we propose the scale-adaptive heatmap regression (SAHR) method, which can adaptively adjust the standard deviation for each keypoint. In this way, SAHR is more tolerant of various human scales and labeling ambiguities. However, SAHR may aggravate the imbalance between fore-background samples, which potentially hurts the improvement of SAHR. Thus, we further introduce the weight-adaptive heatmap regression (WAHR) to help balance the fore-background samples. Extensive experiments show that SAHR together with WAHR largely improves the accuracy of bottom-up human pose estimation. As a result, we finally outperform the state-of-the-art model by +1.5AP and achieve 72.0AP on COCO test-dev2017, which is com-arable with the performances of most top-down methods. Source codes are available at https://github.com/greatlog/SWAHR-HumanPose.", "authors": ["Zhengxiong Luo", " Zhicheng Wang", " Yan Huang", " Tieniu Tan", " Erjin Zhou"], "pdf_url": "https://arxiv.org/abs/2012.15175", "list_table_and_caption": [{"table": "<table><tbody><tr><td>Methods</td><td>Backbone</td><td>Input Size</td><td>#Params</td><td>GFLOPs</td><td>AP</td><td>AP^{50}</td><td>AP^{75}</td><td>AP^{M}</td><td>AP^{L}</td></tr><tr><td colspan=\"10\">w/o mutli-scale test</td></tr><tr><td>OpenPose [4]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>61.8</td><td>84.9</td><td>67.5</td><td>57.1</td><td>68.2</td></tr><tr><td>Hourglass [25]</td><td>Hourglass</td><td>512</td><td>277.8</td><td>206.9</td><td>56.6</td><td>81.8</td><td>61.8</td><td>49.8</td><td>67</td></tr><tr><td>PersonLab [27]</td><td>ResNet-152</td><td>1401</td><td>68.7</td><td>405.5</td><td>66.5</td><td>88.0</td><td>72.6</td><td>62.4</td><td>72.3</td></tr><tr><td>PifPaf [17]</td><td>-</td><td>-</td><td>-</td><td>-</td><td>66.7</td><td></td><td></td><td>62.4</td><td>72.9</td></tr><tr><td>HrHRNet [7]</td><td>HRNet-W32</td><td>512</td><td>28.5</td><td>47.9</td><td>66.4</td><td>87.5</td><td>72.8</td><td>61.2</td><td>74.2</td></tr><tr><td>HrHRNet [7] + SWAHR</td><td>HRNet-W32</td><td>512</td><td>28.6</td><td>48.0</td><td>67.9</td><td>88.9</td><td>74.5</td><td>62.4</td><td>75.5</td></tr><tr><td>HrHRNet [7]</td><td>HRNet-W48</td><td>640</td><td>63.8</td><td>154.3</td><td>68.4</td><td>88.2</td><td>75.1</td><td>64.4</td><td>74.2</td></tr><tr><td>HrHRNet [7] + SWAHR</td><td>HRNet-W48</td><td>640</td><td>63.8</td><td>154.6</td><td>\\mathbf{70.2}</td><td>\\mathbf{89.9}</td><td>\\mathbf{76.9}</td><td>\\mathbf{65.2}</td><td>\\mathbf{77.0}</td></tr><tr><td colspan=\"10\">w/ mutli-scale test</td></tr><tr><td>Hourglass [25]</td><td>-</td><td>512</td><td>277.8</td><td>206.9</td><td>63.0</td><td>85.7</td><td>68.9</td><td>58.0</td><td>70.4</td></tr><tr><td>PersonLab [27]</td><td>-</td><td>1401</td><td>68.7</td><td>405.5</td><td>65.5</td><td>86.8</td><td>72.3</td><td>60.6</td><td>72.6</td></tr><tr><td>HrHRNet [7]</td><td>HRNet-W48</td><td>640</td><td>63.8</td><td>154.3</td><td>70.5</td><td>89.3</td><td>77.2</td><td>66.6</td><td>75.8</td></tr><tr><td>HrHRNet [7] + SWAHR</td><td>HRNet-W48</td><td>640</td><td>63.8</td><td>154.6</td><td>\\mathbf{72.0}</td><td>\\mathbf{90.7}</td><td>\\mathbf{78.8}</td><td>\\mathbf{67.8}</td><td>\\mathbf{77.7}</td></tr></tbody></table>", "caption": "Table 1: Results on COCO test-dev2017. Top: without multi-scale test. Bottom: with multi-sale test (scale factors are 0.5, 1.0, and 1.5).", "list_citation_info": ["[27] G. Papandreou, Tyler Lixuan Zhu, Liang-Chieh Chen, Spyros Gidaris, J. Tompson, and Kevin Murphy. Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model. In ECCV, 2018.", "[4] Zhe Cao, Gines Hidalgo Martinez, Tomas Simon, Shih-En Wei, and Yaser Sheikh. Openpose: Realtime multi-person 2d pose estimation using part affinity fields. IEEE transactions on pattern analysis and machine intelligence, 2019.", "[25] Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks for human pose estimation. In European conference on computer vision, pages 483\u2013499. Springer, 2016.", "[17] S. Kreiss, L. Bertoni, and Alexandre Alahi. Pifpaf: Composite fields for human pose estimation. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 11969\u201311978, 2019.", "[7] Bowen Cheng, Bin Xiao, J. Wang, Humphrey Shi, T. Huang, and Lei Zhang. Bottom-up higher-resolution networks for multi-person pose estimation. ArXiv, abs/1908.10357, 2019."]}, {"table": "<table><tbody><tr><th>Methods</th><td>AP</td><td>AP^{50}</td><td>AP^{75}</td><td>AP^{M}</td><td>AP^{L}</td></tr><tr><th colspan=\"6\">Top-down methods</th></tr><tr><th>Mask-RCNN [12]</th><td>63.1</td><td>87.3</td><td>68.7</td><td>57.8</td><td>71.4</td></tr><tr><th>G-RMI [28]</th><td>64.9</td><td>85.5</td><td>71.3</td><td>62.3</td><td>70.0</td></tr><tr><th>Sun et al. [34]</th><td>67.8</td><td>88.2</td><td>74.8</td><td>63.9</td><td>74.0</td></tr><tr><th>G-RMI [28] + extra data</th><td>68.5</td><td>87.1</td><td>75.5</td><td>65.8</td><td>73.3</td></tr><tr><th>CPN [6]</th><td>72.1</td><td>91.4</td><td>80.0</td><td>68.7</td><td>77.2</td></tr><tr><th>RMEPE [9]</th><td>72.3</td><td>89.2</td><td>79.1</td><td>68.0</td><td>78.6</td></tr><tr><th>CFN [14]</th><td>72.6</td><td>86.1</td><td>69.7</td><td>78.3</td><td>64.1</td></tr><tr><th>CPN(ensemble) [6]</th><td>73.0</td><td>91.7</td><td>80.9</td><td>69.5</td><td>78.1</td></tr><tr><th>SimpleBaseline [37]</th><td>73.7</td><td>91.9</td><td>81.1</td><td>70.3</td><td>80.0</td></tr><tr><th>HRNet-W48 [33]</th><td>75.5</td><td>92.5</td><td>83.3</td><td>71.9</td><td>81.5</td></tr><tr><th colspan=\"6\">Bottom-up methods</th></tr><tr><th>OpenPose [4]</th><td>61.8</td><td>84.9</td><td>67.5</td><td>57.1</td><td>68.2</td></tr><tr><th>Hourglass [25]</th><td>65.5</td><td>86.8</td><td>72.3</td><td>60.6</td><td>72.6</td></tr><tr><th>PifPaf [17]</th><td>66.7</td><td>-</td><td>-</td><td>62.4</td><td>72.9</td></tr><tr><th>SPM [26]</th><td>66.9</td><td>88.5</td><td>72.9</td><td>62.6</td><td>73.1</td></tr><tr><th>PersonLab [27]</th><td>68.7</td><td>89.0</td><td>75.4</td><td>64.1</td><td>75.5</td></tr><tr><th>HrHRNet-W48 [7]</th><td>70.5</td><td>89.3</td><td>77.2</td><td>66.6</td><td>75.8</td></tr><tr><th>HrHRNet-W48 [7] + SWAHR</th><td>\\mathbf{72.0}</td><td>\\mathbf{90.7}</td><td>\\mathbf{78.8}</td><td>\\mathbf{67.8}</td><td>\\mathbf{77.7}</td></tr></tbody></table>", "caption": "Table 2: Results on COCO test-dev2017. Top: top-down methods. Bottom: bottom-up methods (with multi-scale test).", "list_citation_info": ["[9] Haoshu Fang, S. Xie, Yu-Wing Tai, and Cewu Lu. Rmpe: Regional multi-person pose estimation. 2017 IEEE International Conference on Computer Vision (ICCV), pages 2353\u20132362, 2017.", "[12] Kaiming He, Georgia Gkioxari, P. Doll\u00e1r, and Ross B. Girshick. Mask r-cnn. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42:386\u2013397, 2020.", "[14] Shaoli Huang, M. Gong, and D. Tao. A coarse-fine network for keypoint localization. 2017 IEEE International Conference on Computer Vision (ICCV), pages 3047\u20133056, 2017.", "[34] Xiao Sun, Bin Xiao, S. Liang, and Y. Wei. Integral human pose regression. In ECCV, 2018.", "[26] Xuecheng Nie, J. Zhang, S. Yan, and Jiashi Feng. Single-stage multi-person pose machines. 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pages 6950\u20136959, 2019.", "[33] Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang. Deep high-resolution representation learning for human pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5693\u20135703, 2019.", "[27] G. Papandreou, Tyler Lixuan Zhu, Liang-Chieh Chen, Spyros Gidaris, J. Tompson, and Kevin Murphy. Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model. In ECCV, 2018.", "[4] Zhe Cao, Gines Hidalgo Martinez, Tomas Simon, Shih-En Wei, and Yaser Sheikh. Openpose: Realtime multi-person 2d pose estimation using part affinity fields. IEEE transactions on pattern analysis and machine intelligence, 2019.", "[28] G. Papandreou, Tyler Lixuan Zhu, Nori Kanazawa, A. Toshev, J. Tompson, C. Bregler, and Kevin Murphy. Towards accurate multi-person pose estimation in the wild. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3711\u20133719, 2017.", "[37] Bin Xiao, Haiping Wu, and Yichen Wei. Simple baselines for human pose estimation and tracking. In Proceedings of the European conference on computer vision (ECCV), pages 466\u2013481, 2018.", "[25] Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks for human pose estimation. In European conference on computer vision, pages 483\u2013499. Springer, 2016.", "[17] S. Kreiss, L. Bertoni, and Alexandre Alahi. Pifpaf: Composite fields for human pose estimation. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 11969\u201311978, 2019.", "[7] Bowen Cheng, Bin Xiao, J. Wang, Humphrey Shi, T. Huang, and Lei Zhang. Bottom-up higher-resolution networks for multi-person pose estimation. ArXiv, abs/1908.10357, 2019.", "[6] Yilun Chen, Zhicheng Wang, Yuxiang Peng, Zhiqiang Zhang, Gang Yu, and Jian Sun. Cascaded pyramid network for multi-person pose estimation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7103\u20137112, 2018."]}, {"table": "<table><tbody><tr><th>Methods</th><td>AP</td><td>AP^{50}</td><td>AP^{75}</td><td>AP^{E}</td><td>AP^{M}</td><td>AP^{H}</td></tr><tr><th colspan=\"7\">Top-down methods</th></tr><tr><th>Mask-RCNN [12]</th><td>57.2</td><td>83.5</td><td>60.3</td><td>69.4</td><td>57.9</td><td>45.8</td></tr><tr><th>AlphaPose [9]</th><td>61.0</td><td>81.3</td><td>66.0</td><td>71.2</td><td>61.4</td><td>51.1</td></tr><tr><th>SimpleBaseline [37]</th><td>60.8</td><td>84.2</td><td>71.5</td><td>71.4</td><td>61.2</td><td>51.2</td></tr><tr><th colspan=\"7\">Top-down with refinement</th></tr><tr><th>SPPE [20]</th><td>66.0</td><td>84.2</td><td>71.5</td><td>75.5</td><td>66.3</td><td>57.4</td></tr><tr><th colspan=\"7\">Bottom-up methods w/o multi-scale testt</th></tr><tr><th>OpenPose [4]</th><td>-</td><td>-</td><td>-</td><td>62.7</td><td>48.7</td><td>32.3</td></tr><tr><th>HrHRNet-W48 [7]</th><td>65.9</td><td>86.4</td><td>70.6</td><td>73.3</td><td>66.5</td><td>57.9</td></tr><tr><th>HrHRNet-W48 [7] + SWAHR</th><td>\\mathbf{71.6}</td><td>\\mathbf{88.5}</td><td>\\mathbf{77.6}</td><td>\\mathbf{78.9}</td><td>\\mathbf{72.4}</td><td>\\mathbf{63.0}</td></tr><tr><th colspan=\"7\">Bottom-up methods w/ multi-scale testt</th></tr><tr><th>HrHRNet-W48 [7]</th><td>67.6</td><td>87.4</td><td>72.6</td><td>75.8</td><td>68.1</td><td>58.9</td></tr><tr><th>HrHRNet-W48 [7] + SWAHR</th><td>\\mathbf{73.8}</td><td>\\mathbf{90.5}</td><td>\\mathbf{79.9}</td><td>\\mathbf{81.2}</td><td>\\mathbf{74.7}</td><td>\\mathbf{64.7}</td></tr></tbody></table>", "caption": "Table 9: Comparisons with top-down and bottom up methods on CrowPose test dataset.", "list_citation_info": ["[9] Haoshu Fang, S. Xie, Yu-Wing Tai, and Cewu Lu. Rmpe: Regional multi-person pose estimation. 2017 IEEE International Conference on Computer Vision (ICCV), pages 2353\u20132362, 2017.", "[12] Kaiming He, Georgia Gkioxari, P. Doll\u00e1r, and Ross B. Girshick. Mask r-cnn. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42:386\u2013397, 2020.", "[4] Zhe Cao, Gines Hidalgo Martinez, Tomas Simon, Shih-En Wei, and Yaser Sheikh. Openpose: Realtime multi-person 2d pose estimation using part affinity fields. IEEE transactions on pattern analysis and machine intelligence, 2019.", "[20] Jiefeng Li, Can Wang, Hao Zhu, Yihuan Mao, Hao-Shu Fang, and Cewu Lu. Crowdpose: Efficient crowded scenes pose estimation and a new benchmark. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 10863\u201310872, 2019.", "[37] Bin Xiao, Haiping Wu, and Yichen Wei. Simple baselines for human pose estimation and tracking. In Proceedings of the European conference on computer vision (ECCV), pages 466\u2013481, 2018.", "[7] Bowen Cheng, Bin Xiao, J. Wang, Humphrey Shi, T. Huang, and Lei Zhang. Bottom-up higher-resolution networks for multi-person pose estimation. ArXiv, abs/1908.10357, 2019."]}]}