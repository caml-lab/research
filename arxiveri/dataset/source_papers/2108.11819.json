{"title": "Mining contextual information beyond image for semantic segmentation", "abstract": "This paper studies the context aggregation problem in semantic image segmentation. The existing researches focus on improving the pixel representations by aggregating the contextual information within individual images. Though impressive, these methods neglect the significance of the representations of the pixels of the corresponding class beyond the input image. To address this, this paper proposes to mine the contextual information beyond individual images to further augment the pixel representations. We first set up a feature memory module, which is updated dynamically during training, to store the dataset-level representations of various categories. Then, we learn class probability distribution of each pixel representation under the supervision of the ground-truth segmentation. At last, the representation of each pixel is augmented by aggregating the dataset-level representations based on the corresponding class probability distribution. Furthermore, by utilizing the stored dataset-level representations, we also propose a representation consistent learning strategy to make the classification head better address intra-class compactness and inter-class dispersion. The proposed method could be effortlessly incorporated into existing segmentation frameworks (e.g., FCN, PSPNet, OCRNet and DeepLabV3) and brings consistent performance improvements. Mining contextual information beyond image allows us to report state-of-the-art performance on various benchmarks: ADE20K, LIP, Cityscapes and COCO-Stuff.", "authors": ["Zhenchao Jin", " Tao Gong", " Dongdong Yu", " Qi Chu", " Jian Wang", " Changhu Wang", " Jie Shao"], "pdf_url": "https://arxiv.org/abs/2108.11819", "list_table_and_caption": [{"table": "<table><thead><tr><th>Method</th><th>Backbone</th><th>\\mathscr{F}</th><th>mIoU</th></tr><tr><th>Baseline</th><th>ResNet-50</th><th>-</th><th>36.96</th></tr></thead><tbody><tr><td>Baseline+MCIBI (ours)</td><td>ResNet-50</td><td>add</td><td>40.99</td></tr><tr><td>Baseline+MCIBI (ours)</td><td>ResNet-50</td><td>weighted add</td><td>41.17</td></tr><tr><td>Baseline+MCIBI (ours)</td><td>ResNet-50</td><td>concatenation</td><td>42.18</td></tr></tbody></table>", "caption": "Table 1: Ablation study on the validation set of ADE20K about the form of the transform function in Equation 4.FCN [32] is adopted as the Baseline framework.", "list_citation_info": ["[32] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431\u20133440, 2015."]}, {"table": "<table><tbody><tr><th>Method</th><td>Parameters</td><td>FLOPs</td><td>Time</td></tr><tr><th>ASPP [6] (our impl.)</th><td>42.21M</td><td>674.47G</td><td>101.44ms</td></tr><tr><th>PPM [50] (our impl.)</th><td>23.07M</td><td>309.45G</td><td>29.57ms</td></tr><tr><th>CCNet [22] (our impl.)</th><td>23.92M</td><td>397.38G</td><td>56.90ms</td></tr><tr><th>DANet [15] (our impl.)</th><td>23.92M</td><td>392.02G</td><td>62.64ms</td></tr><tr><th>ANN [57] (our impl.)</th><td>20.32M</td><td>335.24G</td><td>49.66ms</td></tr><tr><th>DNL [43] (our impl.)</th><td>24.12M</td><td>395.25G</td><td>68.62ms</td></tr><tr><th>APCNet [20] (our impl.)</th><td>30.46M</td><td>413.12G</td><td>54.20ms</td></tr><tr><th>DCA (ours)</th><td>14.82M</td><td>242.80G</td><td>47.64ms</td></tr><tr><th>ASPP+DCA (ours)</th><td>45.63M</td><td>730.56G</td><td>125.03ms</td></tr></tbody></table>", "caption": "Table 3: Complexity comparison with existing context schemes.The feature map of size [1\\times 2048\\times 128\\times 128] is used to evaluate their complexity during inference.All the numbers are obtained on a single NVIDIA Tesla V100 GPU with CUDA 11.0 and the smaller, the better.", "list_citation_info": ["[20] Junjun He, Zhongying Deng, Lei Zhou, Yali Wang, and Yu Qiao. Adaptive pyramid context network for semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7519\u20137528, 2019.", "[22] Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, and Wenyu Liu. Ccnet: Criss-cross attention for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 603\u2013612, 2019.", "[15] Jun Fu, Jing Liu, Haijie Tian, Yong Li, Yongjun Bao, Zhiwei Fang, and Hanqing Lu. Dual attention network for scene segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3146\u20133154, 2019.", "[57] Zhen Zhu, Mengde Xu, Song Bai, Tengteng Huang, and Xiang Bai. Asymmetric non-local neural networks for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 593\u2013602, 2019.", "[43] Minghao Yin, Zhuliang Yao, Yue Cao, Xiu Li, Zheng Zhang, Stephen Lin, and Han Hu. Disentangled non-local neural networks. In European Conference on Computer Vision, pages 191\u2013207. Springer, 2020.", "[6] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017.", "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017."]}, {"table": "<table><tbody><tr><th>Method</th><td>Train Set</td><td>Test Set</td><td>mIoU</td></tr><tr><th>FCN [32]</th><td>LIP train set</td><td>LIP val set</td><td>48.63</td></tr><tr><th>DeepLabV3 [6]</th><td>LIP train set</td><td>LIP val set</td><td>52.35</td></tr><tr><th>FCN [32]</th><td>LIP train set</td><td>CIHP val set</td><td>27.20</td></tr><tr><th>DeepLabV3 [6]</th><td>LIP train set</td><td>CIHP val set</td><td>27.02</td></tr><tr><th>FCN+MCIBI (ours)</th><td>LIP train set</td><td>LIP val set</td><td>51.07</td></tr><tr><th>DeepLabV3+MCIBI (ours)</th><td>LIP train set</td><td>LIP val set</td><td>53.52</td></tr><tr><th>FCN+MCIBI (ours)</th><td>LIP train set</td><td>CIHP val set</td><td>27.57</td></tr><tr><th>DeepLabV3+MCIBI (ours)</th><td>LIP train set</td><td>CIHP val set</td><td>27.89</td></tr></tbody></table>", "caption": "Table 4: Generalization ability of our feature memory module.", "list_citation_info": ["[6] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017.", "[32] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431\u20133440, 2015."]}, {"table": "<table><thead><tr><th>Method</th><th>Backbone</th><th>Stride</th><th>ADE20K (train/val)</th><th>Cityscapes (train/val)</th><th>LIP (train/val)</th><th>COCO-Stuff (train/val)</th></tr></thead><tbody><tr><th>FCN [32]</th><th>ResNet-50</th><th>8\\times</th><td>36.96</td><td>75.16</td><td>48.63</td><td>35.11</td></tr><tr><th>FCN+MCIBI (ours)</th><th>ResNet-50</th><th>8\\times</th><td>42.84</td><td>78.50</td><td>51.07</td><td>39.95</td></tr><tr><th>PSPNet [50]</th><th>ResNet-50</th><th>8\\times</th><td>42.64</td><td>79.05</td><td>51.94</td><td>41.01</td></tr><tr><th>PSPNet+MCIBI (ours)</th><th>ResNet-50</th><th>8\\times</th><td>43.77</td><td>79.90</td><td>52.84</td><td>41.80</td></tr><tr><th>OCRNet [45]</th><th>ResNet-50</th><th>8\\times</th><td>42.47</td><td>79.40</td><td>52.25</td><td>40.57</td></tr><tr><th>OCRNet+MCIBI (ours)</th><th>ResNet-50</th><th>8\\times</th><td>43.34</td><td>79.98</td><td>52.80</td><td>41.10</td></tr><tr><th>DeepLabV3 [6]</th><th>ResNet-50</th><th>8\\times</th><td>43.19</td><td>80.57</td><td>52.35</td><td>41.86</td></tr><tr><th>DeepLabV3+MCIBI (ours)</th><th>ResNet-50</th><th>8\\times</th><td>44.34</td><td>81.14</td><td>53.52</td><td>42.08</td></tr></tbody></table>", "caption": "Table 5: The improvements of segmentation performance achieved on different benchmarks when integrating the proposed mining contextual information beyond image (MCIBI)into the existing segmentation frameworks. All the results here are obtained under single-scale testing without any tricks.", "list_citation_info": ["[45] Yuhui Yuan, Xilin Chen, and Jingdong Wang. Object-contextual representations for semantic segmentation. arXiv preprint arXiv:1909.11065, 2019.", "[32] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431\u20133440, 2015.", "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017.", "[6] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017."]}, {"table": "<table><tbody><tr><td>Method</td><td>Backbone</td><td>Stride</td><td>mIoU</td></tr><tr><td>CCNet [22]</td><td>ResNet-101</td><td>8\\times</td><td>45.76</td></tr><tr><td>OCNet [46]</td><td>ResNet-101</td><td>8\\times</td><td>45.45</td></tr><tr><td>ACNet [16]</td><td>ResNet-101</td><td>8\\times</td><td>45.90</td></tr><tr><td>DMNet [19]</td><td>ResNet-101</td><td>8\\times</td><td>45.50</td></tr><tr><td>EncNet [48]</td><td>ResNet-101</td><td>8\\times</td><td>44.65</td></tr><tr><td>PSPNet [50]</td><td>ResNet-101</td><td>8\\times</td><td>43.29</td></tr><tr><td>PSANet [51]</td><td>ResNet-101</td><td>8\\times</td><td>43.77</td></tr><tr><td>APCNet [20]</td><td>ResNet-101</td><td>8\\times</td><td>45.38</td></tr><tr><td>OCRNet [45]</td><td>ResNet-101</td><td>8\\times</td><td>45.28</td></tr><tr><td>PSPNet [50]</td><td>ResNet-269</td><td>8\\times</td><td>44.94</td></tr><tr><td>OCRNet [45]</td><td>HRNetV2-W48</td><td>4\\times</td><td>45.66</td></tr><tr><td>DeepLabV3 [6]</td><td>ResNeSt-50</td><td>8\\times</td><td>45.12</td></tr><tr><td>DeepLabV3 [6]</td><td>ResNeSt-101</td><td>8\\times</td><td>46.91</td></tr><tr><td>SETR-MLA [54]</td><td>ViT-Large</td><td>16\\times</td><td>50.28</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-50</td><td>8\\times</td><td>45.95</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-101</td><td>8\\times</td><td>47.22</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNeSt-101</td><td>8\\times</td><td>47.36</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ViT-Large</td><td>16\\times</td><td>50.80</td></tr></tbody></table>", "caption": "Table 6: Comparison with the state-of-the-art on ADE20K (val).Multi-scale and flipping testing is adopted for fair comparison.", "list_citation_info": ["[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017.", "[45] Yuhui Yuan, Xilin Chen, and Jingdong Wang. Object-contextual representations for semantic segmentation. arXiv preprint arXiv:1909.11065, 2019.", "[48] Hang Zhang, Kristin Dana, Jianping Shi, Zhongyue Zhang, Xiaogang Wang, Ambrish Tyagi, and Amit Agrawal. Context encoding for semantic segmentation. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 7151\u20137160, 2018.", "[19] Junjun He, Zhongying Deng, and Yu Qiao. Dynamic multi-scale filters for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3562\u20133572, 2019.", "[20] Junjun He, Zhongying Deng, Lei Zhou, Yali Wang, and Yu Qiao. Adaptive pyramid context network for semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7519\u20137528, 2019.", "[22] Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, and Wenyu Liu. Ccnet: Criss-cross attention for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 603\u2013612, 2019.", "[51] Hengshuang Zhao, Yi Zhang, Shu Liu, Jianping Shi, Chen Change Loy, Dahua Lin, and Jiaya Jia. Psanet: Point-wise spatial attention network for scene parsing. In Proceedings of the European Conference on Computer Vision (ECCV), pages 267\u2013283, 2018.", "[6] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017.", "[46] Yuhui Yuan and Jingdong Wang. Ocnet: Object context network for scene parsing. arXiv preprint arXiv:1809.00916, 2018.", "[54] Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip HS Torr, et al. Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6881\u20136890, 2021.", "[16] Jun Fu, Jing Liu, Yuhang Wang, Yong Li, Yongjun Bao, Jinhui Tang, and Hanqing Lu. Adaptive context network for scene parsing. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6748\u20136757, 2019."]}, {"table": "<table><tbody><tr><td>Method</td><td>Backbone</td><td>Stride</td><td>mIoU</td></tr><tr><td>DeepLab [5]</td><td>ResNet-101</td><td>-</td><td>44.80</td></tr><tr><td>CE2P [35]</td><td>ResNet-101</td><td>16\\times</td><td>53.10</td></tr><tr><td>DeepLabV3 [6]</td><td>ResNet-101</td><td>8\\times</td><td>54.58</td></tr><tr><td>OCNet [46]</td><td>ResNet-101</td><td>8\\times</td><td>54.72</td></tr><tr><td>CCNet [22]</td><td>ResNet-101</td><td>8\\times</td><td>55.47</td></tr><tr><td>OCRNet [45]</td><td>ResNet-101</td><td>8\\times</td><td>55.60</td></tr><tr><td>HRNet [38]</td><td>HRNetV2-W48</td><td>4\\times</td><td>55.90</td></tr><tr><td>OCRNet [45]</td><td>HRNetV2-W48</td><td>4\\times</td><td>56.65</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-50</td><td>8\\times</td><td>54.08</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-101</td><td>8\\times</td><td>55.42</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNeSt-101</td><td>8\\times</td><td>56.34</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>HRNetV2-W48</td><td>4\\times</td><td>56.99</td></tr></tbody></table>", "caption": "Table 7: Segmentation results on the validation set of LIP.Flipping testing is leveraged for fair comparison.", "list_citation_info": ["[38] Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, et al. Deep high-resolution representation learning for visual recognition. IEEE transactions on pattern analysis and machine intelligence, 2020.", "[45] Yuhui Yuan, Xilin Chen, and Jingdong Wang. Object-contextual representations for semantic segmentation. arXiv preprint arXiv:1909.11065, 2019.", "[46] Yuhui Yuan and Jingdong Wang. Ocnet: Object context network for scene parsing. arXiv preprint arXiv:1809.00916, 2018.", "[22] Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, and Wenyu Liu. Ccnet: Criss-cross attention for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 603\u2013612, 2019.", "[5] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence, 40(4):834\u2013848, 2017.", "[6] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017.", "[35] Tao Ruan, Ting Liu, Zilong Huang, Yunchao Wei, Shikui Wei, and Yao Zhao. Devil in the details: Towards accurate single and multiple human parsing. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 4814\u20134821, 2019."]}, {"table": "<table><tbody><tr><td>Method</td><td>Backbone</td><td>Stride</td><td>mIoU</td></tr><tr><td>CCNet [22]</td><td>ResNet-101</td><td>8\\times</td><td>81.90</td></tr><tr><td>PSPNet [50]</td><td>ResNet-101</td><td>8\\times</td><td>78.40</td></tr><tr><td>PSANet [51]</td><td>ResNet-101</td><td>8\\times</td><td>80.10</td></tr><tr><td>OCNet [46]</td><td>ResNet-101</td><td>8\\times</td><td>80.10</td></tr><tr><td>OCRNet [45]</td><td>ResNet-101</td><td>8\\times</td><td>81.80</td></tr><tr><td>DANet [15]</td><td>ResNet-101</td><td>8\\times</td><td>81.50</td></tr><tr><td>ACFNet [47]</td><td>ResNet-101</td><td>8\\times</td><td>81.80</td></tr><tr><td>ANNet [57]</td><td>ResNet-101</td><td>8\\times</td><td>81.30</td></tr><tr><td>ACNet [16]</td><td>ResNet-101</td><td>8\\times</td><td>82.30</td></tr><tr><td>HRNet [38]</td><td>HRNetV2-W48</td><td>4\\times</td><td>81.60</td></tr><tr><td>OCRNet [45]</td><td>HRNetV2-W48</td><td>4\\times</td><td>82.40</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-50</td><td>8\\times</td><td>79.90</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-101</td><td>8\\times</td><td>82.03</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNeSt-101</td><td>8\\times</td><td>81.59</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>HRNetV2-W48</td><td>4\\times</td><td>82.55</td></tr></tbody></table>", "caption": "Table 8: Comparison of performance on the test set of Cityscapes with state-of-the-art (trained on trainval set).Multi-scale and flipping testing is used for fair comparison.", "list_citation_info": ["[38] Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, et al. Deep high-resolution representation learning for visual recognition. IEEE transactions on pattern analysis and machine intelligence, 2020.", "[45] Yuhui Yuan, Xilin Chen, and Jingdong Wang. Object-contextual representations for semantic segmentation. arXiv preprint arXiv:1909.11065, 2019.", "[22] Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, and Wenyu Liu. Ccnet: Criss-cross attention for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 603\u2013612, 2019.", "[51] Hengshuang Zhao, Yi Zhang, Shu Liu, Jianping Shi, Chen Change Loy, Dahua Lin, and Jiaya Jia. Psanet: Point-wise spatial attention network for scene parsing. In Proceedings of the European Conference on Computer Vision (ECCV), pages 267\u2013283, 2018.", "[15] Jun Fu, Jing Liu, Haijie Tian, Yong Li, Yongjun Bao, Zhiwei Fang, and Hanqing Lu. Dual attention network for scene segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3146\u20133154, 2019.", "[57] Zhen Zhu, Mengde Xu, Song Bai, Tengteng Huang, and Xiang Bai. Asymmetric non-local neural networks for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 593\u2013602, 2019.", "[47] Fan Zhang, Yanqin Chen, Zhihang Li, Zhibin Hong, Jingtuo Liu, Feifei Ma, Junyu Han, and Errui Ding. Acfnet: Attentional class feature network for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6798\u20136807, 2019.", "[46] Yuhui Yuan and Jingdong Wang. Ocnet: Object context network for scene parsing. arXiv preprint arXiv:1809.00916, 2018.", "[16] Jun Fu, Jing Liu, Yuhang Wang, Yong Li, Yongjun Bao, Jinhui Tang, and Hanqing Lu. Adaptive context network for scene parsing. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6748\u20136757, 2019.", "[50] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2881\u20132890, 2017."]}, {"table": "<table><tbody><tr><td>Method</td><td>Backbone</td><td>Stride</td><td>mIoU</td></tr><tr><td>DANet [15]</td><td>ResNet-101</td><td>8\\times</td><td>39.70</td></tr><tr><td>OCRNet [45]</td><td>ResNet-101</td><td>8\\times</td><td>39.50</td></tr><tr><td>SVCNet [14]</td><td>ResNet-101</td><td>8\\times</td><td>39.60</td></tr><tr><td>EMANet [26]</td><td>ResNet-101</td><td>8\\times</td><td>39.90</td></tr><tr><td>ACNet [16]</td><td>ResNet-101</td><td>8\\times</td><td>40.10</td></tr><tr><td>OCRNet [45]</td><td>HRNetV2-W48</td><td>4\\times</td><td>40.50</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-50</td><td>8\\times</td><td>39.68</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-101</td><td>8\\times</td><td>41.49</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNeSt-101</td><td>8\\times</td><td>42.15</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ViT-Large</td><td>16\\times</td><td>44.89</td></tr></tbody></table>", "caption": "Table 9: Segmentation results on the test set of COCO-Stuff-10K.Multi-scale and flipping testing is employed for fair comparison.", "list_citation_info": ["[14] Henghui Ding, Xudong Jiang, Bing Shuai, Ai Qun Liu, and Gang Wang. Semantic correlation promoted shape-variant context for segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8885\u20138894, 2019.", "[45] Yuhui Yuan, Xilin Chen, and Jingdong Wang. Object-contextual representations for semantic segmentation. arXiv preprint arXiv:1909.11065, 2019.", "[26] Xia Li, Zhisheng Zhong, Jianlong Wu, Yibo Yang, Zhouchen Lin, and Hong Liu. Expectation-maximization attention networks for semantic segmentation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9167\u20139176, 2019.", "[15] Jun Fu, Jing Liu, Haijie Tian, Yong Li, Yongjun Bao, Zhiwei Fang, and Hanqing Lu. Dual attention network for scene segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3146\u20133154, 2019.", "[16] Jun Fu, Jing Liu, Yuhang Wang, Yong Li, Yongjun Bao, Jinhui Tang, and Hanqing Lu. Adaptive context network for scene parsing. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6748\u20136757, 2019."]}]}