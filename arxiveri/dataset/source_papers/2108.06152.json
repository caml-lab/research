{"title": "Conditional DETR for Fast Training Convergence", "abstract": "The recently-developed DETR approach applies the transformer encoder and decoder architecture to object detection and achieves promising performance. In this paper, we handle the critical issue, slow training convergence, and present a conditional cross-attention mechanism for fast DETR training. Our approach is motivated by that the cross-attention in DETR relies highly on the content embeddings for localizing the four extremities and predicting the box, which increases the need for high-quality content embeddings and thus the training difficulty. Our approach, named conditional DETR, learns a conditional spatial query from the decoder embedding for decoder multi-head cross-attention. The benefit is that through the conditional spatial query, each cross-attention head is able to attend to a band containing a distinct region, e.g., one object extremity or a region inside the object box. This narrows down the spatial range for localizing the distinct regions for object classification and box regression, thus relaxing the dependence on the content embeddings and easing the training. Empirical results show that conditional DETR converges 6.7x faster for the backbones R50 and R101 and 10x faster for stronger backbones DC5-R50 and DC5-R101. Code is available at https://github.com/Atten4Vis/ConditionalDETR.", "authors": ["Depu Meng", " Xiaokang Chen", " Zejia Fan", " Gang Zeng", " Houqiang Li", " Yuhui Yuan", " Lei Sun", " Jingdong Wang"], "pdf_url": "https://arxiv.org/abs/2108.06152", "list_table_and_caption": [{"table": "<table><thead><tr><th>Model</th><th>#epochs</th><th>GFLOPs</th><th>#params (M)</th><th>AP</th><th>AP{}_{50}</th><th>AP{}_{75}</th><th>AP{}_{S}</th><th>AP{}_{M}</th><th>AP{}_{L}</th></tr></thead><tbody><tr><td>DETR-R50</td><td>500</td><td>86</td><td>41</td><td>42.0</td><td>62.4</td><td>44.2</td><td>20.5</td><td>45.8</td><td>61.1</td></tr><tr><td>DETR-R50</td><td>50</td><td>86</td><td>41</td><td>34.9</td><td>55.5</td><td>36.0</td><td>14.4</td><td>37.2</td><td>54.5</td></tr><tr><td>Conditional DETR-R50</td><td>50</td><td>90</td><td>44</td><td>40.9</td><td>61.8</td><td>43.3</td><td>20.8</td><td>44.6</td><td>59.2</td></tr><tr><td>Conditional DETR-R50</td><td>75</td><td>90</td><td>44</td><td>42.1</td><td>62.9</td><td>44.8</td><td>21.6</td><td>45.4</td><td>60.2</td></tr><tr><td>Conditional DETR-R50</td><td>108</td><td>90</td><td>44</td><td>43.0</td><td>64.0</td><td>45.7</td><td>22.7</td><td>46.7</td><td>61.5</td></tr><tr><td>DETR-DC5-R50</td><td>500</td><td>187</td><td>41</td><td>43.3</td><td>63.1</td><td>45.9</td><td>22.5</td><td>47.3</td><td>61.1</td></tr><tr><td>DETR-DC5-R50</td><td>50</td><td>187</td><td>41</td><td>36.7</td><td>57.6</td><td>38.2</td><td>15.4</td><td>39.8</td><td>56.3</td></tr><tr><td>Conditional DETR-DC5-R50</td><td>50</td><td>195</td><td>44</td><td>43.8</td><td>64.4</td><td>46.7</td><td>24.0</td><td>47.6</td><td>60.7</td></tr><tr><td>Conditional DETR-DC5-R50</td><td>75</td><td>195</td><td>44</td><td>44.5</td><td>65.2</td><td>47.3</td><td>24.4</td><td>48.1</td><td>62.1</td></tr><tr><td>Conditional DETR-DC5-R50</td><td>108</td><td>195</td><td>44</td><td>45.1</td><td>65.4</td><td>48.5</td><td>25.3</td><td>49.0</td><td>62.2</td></tr><tr><td>DETR-R101</td><td>500</td><td>152</td><td>60</td><td>43.5</td><td>63.8</td><td>46.4</td><td>21.9</td><td>48.0</td><td>61.8</td></tr><tr><td>DETR-R101</td><td>50</td><td>152</td><td>60</td><td>36.9</td><td>57.8</td><td>38.6</td><td>15.5</td><td>40.6</td><td>55.6</td></tr><tr><td>Conditional DETR-R101</td><td>50</td><td>156</td><td>63</td><td>42.8</td><td>63.7</td><td>46.0</td><td>21.7</td><td>46.6</td><td>60.9</td></tr><tr><td>Conditional DETR-R101</td><td>75</td><td>156</td><td>63</td><td>43.7</td><td>64.9</td><td>46.8</td><td>23.3</td><td>48.0</td><td>61.7</td></tr><tr><td>Conditional DETR-R101</td><td>108</td><td>156</td><td>63</td><td>44.5</td><td>65.6</td><td>47.5</td><td>23.6</td><td>48.4</td><td>63.6</td></tr><tr><td>DETR-DC5-R101</td><td>500</td><td>253</td><td>60</td><td>{44.9}</td><td>{64.7}</td><td>47.7</td><td>23.7</td><td>{49.5}</td><td>{62.3}</td></tr><tr><td>DETR-DC5-R101</td><td>50</td><td>253</td><td>60</td><td>38.6</td><td>59.7</td><td>40.7</td><td>17.2</td><td>42.2</td><td>57.4</td></tr><tr><td>Conditional DETR-DC5-R101</td><td>50</td><td>262</td><td>63</td><td>45.0</td><td>65.5</td><td>48.4</td><td>26.1</td><td>48.9</td><td>62.8</td></tr><tr><td>Conditional DETR-DC5-R101</td><td>75</td><td>262</td><td>63</td><td>45.6</td><td>66.5</td><td>48.8</td><td>25.5</td><td>49.7</td><td>63.3</td></tr><tr><td>Conditional DETR-DC5-R101</td><td>108</td><td>262</td><td>63</td><td>45.9</td><td>66.8</td><td>49.5</td><td>27.2</td><td>50.3</td><td>63.3</td></tr><tr><td>Other single-scale DETR variants</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Deformable DETR-R50-SS{}^{*}</td><td>50</td><td>78</td><td>34</td><td>39.4</td><td>59.6</td><td>42.3</td><td>20.6</td><td>43.0</td><td>55.5</td></tr><tr><td>UP-DETR-R50 [5]</td><td>150</td><td>86</td><td>41</td><td>40.5</td><td>60.8</td><td>42.6</td><td>19.0</td><td>44.4</td><td>60.0</td></tr><tr><td>UP-DETR-R50 [5]</td><td>300</td><td>86</td><td>41</td><td>42.8</td><td>63.0</td><td>45.3</td><td>20.8</td><td>47.1</td><td>61.7</td></tr><tr><td>Deformable DETR-DC5-R50-SS{}^{*}</td><td>50</td><td>128</td><td>34</td><td>41.5</td><td>61.8</td><td>44.9</td><td>24.1</td><td>45.3</td><td>56.0</td></tr></tbody></table>", "caption": "Table 1: Comparison of conditional DETR with DETR on COCO 2017 val.Our conditional DETR approach for high-resolution backbones DC5-R50and DC5-R101 is 10\\times faster than the original DETR,and for low-resolution backbonesR50 and R1016.67\\times faster.Conditional DETR is empirically superior toother two single-scale DETR variants.{}^{*}The results of deformable DETR arefrom the GitHub repositoryprovided by the authors of deformable DETR [53].", "list_citation_info": ["[5] Zhigang Dai, Bolun Cai, Yugeng Lin, and Junying Chen. UP-DETR: unsupervised pre-training for object detection with transformers. CoRR, abs/2011.09094, 2020.", "[53] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai. Deformable DETR: deformable transformers for end-to-end object detection. CoRR, abs/2010.04159, 2020."]}, {"table": "<table><tbody><tr><td>Model</td><td>#epochs</td><td>GFLOPs</td><td>#params (M)</td><td>AP</td><td>AP{}_{50}</td><td>AP{}_{75}</td><td>AP{}_{S}</td><td>AP{}_{M}</td><td>AP{}_{L}</td></tr><tr><td>Faster RCNN-FPN-R50 [33]</td><td>36</td><td>180</td><td>42</td><td>40.2</td><td>61.0</td><td>43.8</td><td>24.2</td><td>43.5</td><td>52.0</td></tr><tr><td>Faster RCNN-FPN-R50 [33]</td><td>108</td><td>180</td><td>42</td><td>42.0</td><td>62.1</td><td>45.5</td><td>26.6</td><td>45.5</td><td>53.4</td></tr><tr><td>Deformable DETR-R50 [53]</td><td>50</td><td>173</td><td>40</td><td>43.8</td><td>62.6</td><td>47.7</td><td>26.4</td><td>47.1</td><td>58.0</td></tr><tr><td>TSP-FCOS-R50 [37]</td><td>36</td><td>189</td><td>-</td><td>43.1</td><td>62.3</td><td>47.0</td><td>26.6</td><td>46.8</td><td>55.9</td></tr><tr><td>TSP-RCNN-R50 [37]</td><td>36</td><td>188</td><td>-</td><td>43.8</td><td>63.3</td><td>48.3</td><td>28.6</td><td>46.9</td><td>55.7</td></tr><tr><td>TSP-RCNN-R50 [37]</td><td>96</td><td>188</td><td>-</td><td>45.0</td><td>64.5</td><td>49.6</td><td>29.7</td><td>47.7</td><td>58.0</td></tr><tr><td>Conditional DETR-DC5-R50</td><td>50</td><td>195</td><td>44</td><td>43.8</td><td>64.4</td><td>46.7</td><td>24.0</td><td>47.6</td><td>60.7</td></tr><tr><td>Conditional DETR-DC5-R50</td><td>108</td><td>195</td><td>44</td><td>45.1</td><td>65.4</td><td>48.5</td><td>25.3</td><td>49.0</td><td>62.2</td></tr><tr><td>Faster RCNN-FPN-R101 [33]</td><td>36</td><td>246</td><td>60</td><td>42.0</td><td>62.5</td><td>45.9</td><td>25.2</td><td>45.6</td><td>54.6</td></tr><tr><td>Faster RCNN-FPN-R101 [33]</td><td>108</td><td>246</td><td>60</td><td>44.0</td><td>63.9</td><td>47.8</td><td>27.2</td><td>48.1</td><td>56.0</td></tr><tr><td>TSP-FCOS-R101 [37]</td><td>36</td><td>255</td><td>-</td><td>44.4</td><td>63.8</td><td>48.2</td><td>27.7</td><td>48.6</td><td>57.3</td></tr><tr><td>TSP-RCNN-R101 [37]</td><td>36</td><td>254</td><td>-</td><td>44.8</td><td>63.8</td><td>49.2</td><td>29.0</td><td>47.9</td><td>57.1</td></tr><tr><td>TSP-RCNN-R101 [37]</td><td>96</td><td>254</td><td>-</td><td>46.5</td><td>66.0</td><td>51.2</td><td>29.9</td><td>49.7</td><td>59.2</td></tr><tr><td>Conditional DETR-DC5-R101</td><td>50</td><td>262</td><td>63</td><td>45.0</td><td>65.5</td><td>48.4</td><td>26.1</td><td>48.9</td><td>62.8</td></tr><tr><td>Conditional DETR-DC5-R101</td><td>108</td><td>262</td><td>63</td><td>45.9</td><td>66.8</td><td>49.5</td><td>27.2</td><td>50.3</td><td>63.3</td></tr></tbody></table>", "caption": "Table 2: Results for multi-scale and higher-resolution DETR variants.We do not expect that our approach performs on paras our approach (single-scale, 16\\times resolution) does not use a strong multi-scale or 8\\times resolution encoder.Surprisingly,the AP scores of our approach with DC5-R50and DC5-R101are close to the two multi-scale and higher-resolution DETR variants.", "list_citation_info": ["[53] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai. Deformable DETR: deformable transformers for end-to-end object detection. CoRR, abs/2010.04159, 2020.", "[37] Zhiqing Sun, Shengcao Cao, Yiming Yang, and Kris Kitani. Rethinking transformer-based set prediction for object detection. CoRR, abs/2011.10881, 2020.", "[33] Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. Faster R-CNN: towards real-time object detection with region proposal networks. TPAMI, 2017."]}]}