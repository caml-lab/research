{"title": "TransUNet: Transformers make strong encoders for medical image segmentation", "abstract": "Medical image segmentation is an essential prerequisite for developing healthcare systems, especially for disease diagnosis and treatment planning. On various medical image segmentation tasks, the u-shaped architecture, also known as U-Net, has become the de-facto standard and achieved tremendous success. However, due to the intrinsic locality of convolution operations, U-Net generally demonstrates limitations in explicitly modeling long-range dependency. Transformers, designed for sequence-to-sequence prediction, have emerged as alternative architectures with innate global self-attention mechanisms, but can result in limited localization abilities due to insufficient low-level details. In this paper, we propose TransUNet, which merits both Transformers and U-Net, as a strong alternative for medical image segmentation. On one hand, the Transformer encodes tokenized image patches from a convolution neural network (CNN) feature map as the input sequence for extracting global contexts. On the other hand, the decoder upsamples the encoded features which are then combined with the high-resolution CNN feature maps to enable precise localization.\n  We argue that Transformers can serve as strong encoders for medical image segmentation tasks, with the combination of U-Net to enhance finer details by recovering localized spatial information. TransUNet achieves superior performances to various competing methods on different medical applications including multi-organ segmentation and cardiac segmentation. Code and models are available at https://github.com/Beckschen/TransUNet.", "authors": ["Jieneng Chen", " Yongyi Lu", " Qihang Yu", " Xiangde Luo", " Ehsan Adeli", " Yan Wang", " Le Lu", " Alan L. Yuille", " Yuyin Zhou"], "pdf_url": "https://arxiv.org/abs/2102.04306", "list_table_and_caption": [{"table": "<table><thead><tr><th colspan=\"2\">Framework</th><th colspan=\"2\">Average</th><th rowspan=\"2\">Aorta</th><th rowspan=\"2\">Gallbladder</th><th rowspan=\"2\">Kidney (L)</th><th rowspan=\"2\">Kidney (R)</th><th rowspan=\"2\">Liver</th><th rowspan=\"2\">Pancreas</th><th rowspan=\"2\">Spleen</th><th rowspan=\"2\">Stomach</th></tr><tr><th>Encoder</th><th>Decoder</th><th>DSC \\uparrow</th><th>HD \\downarrow</th></tr></thead><tbody><tr><td colspan=\"2\">V-Net [9]</td><td>68.81</td><td>-</td><td>75.34</td><td>51.87</td><td>77.10</td><td>80.75</td><td>87.84</td><td>40.05</td><td>80.56</td><td>56.98</td></tr><tr><td colspan=\"2\">DARR [5]</td><td>69.77</td><td>-</td><td>74.74</td><td>53.77</td><td>72.31</td><td>73.24</td><td>94.08</td><td>54.18</td><td>89.90</td><td>45.96</td></tr><tr><td>R50</td><td>U-Net [12]</td><td>74.68</td><td>36.87</td><td>84.18</td><td>62.84</td><td>79.19</td><td>71.29</td><td>93.35</td><td>48.23</td><td>84.41</td><td>73.92</td></tr><tr><td>R50</td><td>AttnUNet [13]</td><td>75.57</td><td>36.97</td><td>55.92</td><td>63.91</td><td>79.20</td><td>72.71</td><td>93.56</td><td>49.37</td><td>87.19</td><td>74.95</td></tr><tr><td>ViT [4]</td><td>None</td><td>61.50</td><td>39.61</td><td>44.38</td><td>39.59</td><td>67.46</td><td>62.94</td><td>89.21</td><td>43.14</td><td>75.45</td><td>69.78</td></tr><tr><td>ViT [4]</td><td>CUP</td><td>67.86</td><td>36.11</td><td>70.19</td><td>45.10</td><td>74.70</td><td>67.40</td><td>91.32</td><td>42.00</td><td>81.75</td><td>70.44</td></tr><tr><td>R50-ViT [4]</td><td>CUP</td><td>71.29</td><td>32.87</td><td>73.73</td><td>55.13</td><td>75.80</td><td>72.20</td><td>91.51</td><td>45.99</td><td>81.99</td><td>73.95</td></tr><tr><td colspan=\"2\">TransUNet</td><td>77.48</td><td>31.69</td><td>87.23</td><td>63.13</td><td>81.87</td><td>77.02</td><td>94.08</td><td>55.86</td><td>85.08</td><td>75.62</td></tr></tbody></table>", "caption": "Table 1: Comparison on the Synapse multi-organ CT dataset (average dice score % and average hausdorff distance in mm, and dice score % for each organ).", "list_citation_info": ["[12] Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: International Conference on Medical image computing and computer-assisted intervention. pp. 234\u2013241. Springer (2015)", "[13] Schlemper, J., Oktay, O., Schaap, M., Heinrich, M., Kainz, B., Glocker, B., Rueckert, D.: Attention gated networks: Learning to leverage salient regions in medical images. Medical image analysis 53, 197\u2013207 (2019)", "[5] Fu, S., Lu, Y., Wang, Y., Zhou, Y., Shen, W., Fishman, E., Yuille, A.: Domain adaptive relational reasoning for 3d multi-organ segmentation. In: International Conference on Medical Image Computing and Computer-Assisted Intervention. pp. 656\u2013666. Springer (2020)", "[4] Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et al.: An image is worth 16x16 words: Transformers for image recognition at scale. In: ICLR (2021)", "[9] Milletari, F., Navab, N., Ahmadi, S.A.: V-net: Fully convolutional neural networks for volumetric medical image segmentation. In: 3DV (2016)"]}]}