{"title": "Attention U-Net: Learning Where to Look for the Pancreas", "abstract": "We propose a novel attention gate (AG) model for medical imaging that automatically learns to focus on target structures of varying shapes and sizes. Models trained with AGs implicitly learn to suppress irrelevant regions in an input image while highlighting salient features useful for a specific task. This enables us to eliminate the necessity of using explicit external tissue/organ localisation modules of cascaded convolutional neural networks (CNNs). AGs can be easily integrated into standard CNN architectures such as the U-Net model with minimal computational overhead while increasing the model sensitivity and prediction accuracy. The proposed Attention U-Net architecture is evaluated on two large CT abdominal datasets for multi-class image segmentation. Experimental results show that AGs consistently improve the prediction performance of U-Net across different datasets and training sizes while preserving computational efficiency. The code for the proposed architecture is publicly available.", "authors": ["Ozan Oktay", " Jo Schlemper", " Loic Le Folgoc", " Matthew Lee", " Mattias Heinrich", " Kazunari Misawa", " Kensaku Mori", " Steven McDonagh", " Nils Y Hammerla", " Bernhard Kainz", " Ben Glocker", " Daniel Rueckert"], "pdf_url": "https://arxiv.org/abs/1804.03999", "list_table_and_caption": [{"table": "<br/><table><thead><tr><th>Method</th><th>Dataset</th><th>Pancreas DSC</th><th>Train/Test</th><th># Folds</th></tr></thead><tbody><tr><td>Hierarchical 3D FCN roth2017hierarchical </td><td>CT-150</td><td>82.2\\pm 10.2</td><td>Ext/150</td><td>-</td></tr><tr><td>Dense-Dilated FCN gibson2017towards </td><td>CT-82 &amp; Synapse<sup>3</sup><sup>3</sup>3https://www.synapse.org/Synapse:syn3193805</td><td>66.0\\pm 10.0</td><td>63/9</td><td>5-CV</td></tr><tr><td>2D U-Net heinrich2018ternarynet </td><td>CT-82</td><td>75.7\\pm 9.0</td><td>66/16</td><td>5-CV</td></tr><tr><td>Holistically Nested 2D FCN Stage-1roth2018media </td><td>CT-82</td><td>76.8\\pm 11.1</td><td>62/20</td><td>4-CV</td></tr><tr><td>Holistically Nested 2D FCN Stage-2roth2018media </td><td>CT-82</td><td>81.2\\pm 7.3</td><td>62/20</td><td>4-CV</td></tr><tr><td>2D FCN cai2017improving </td><td>CT-82</td><td>80.3\\pm 9.0</td><td>62/20</td><td>4-CV</td></tr><tr><td>2D FCN + Recurrent Network cai2017improving </td><td>CT-82</td><td>82.3\\pm 6.7</td><td>62/20</td><td>4-CV</td></tr><tr><td>Single Model 2D FCN zhou2017fixed </td><td>CT-82</td><td>75.7\\pm 10.5</td><td>62/20</td><td>4-CV</td></tr><tr><td>Multi-Model 2D FCN zhou2017fixed </td><td>CT-82</td><td>82.2\\pm 5.7</td><td>62/20</td><td>4-CV</td></tr></tbody></table>", "caption": "Table 4: State-of-the-art CT pancreas segmentation methods that are based on single and multiple CNN models. The listed segmentation frameworks are evaluated on the same public benchmark (CT-82) using different number of training and testing images. Similarly, the FCN approach proposed in roth2017hierarchical  is benchmarked on CT-150 although it is trained on an external dataset (Ext).", "list_citation_info": ["(4) Cai, J., Lu, L., Xie, Y., Xing, F., Yang, L.: Improving deep pancreas segmentation in CT and MRI images via recurrent neural contextual learning and direct loss function. In: MICCAI (2017)", "(27) Roth, H.R., Oda, H., Hayashi, Y., Oda, M., Shimizu, N., Fujiwara, M., Misawa, K., Mori, K.: Hierarchical 3D fully convolutional networks for multi-organ segmentation. arXiv preprint arXiv:1704.06382 (2017)", "(38) Zhou, Y., Xie, L., Shen, W., Wang, Y., Fishman, E.K., Yuille, A.L.: A fixed-point model for pancreas segmentation in abdominal CT scans. In: MICCAI. pp. 693\u2013701. Springer (2017)", "(6) Gibson, E., Giganti, F., Hu, Y., Bonmati, E., Bandula, S., Gurusamy, K., Davidson, B.R., Pereira, S.P., Clarkson, M.J., Barratt, D.C.: Towards image-guided pancreas and biliary endoscopy: Automatic multi-organ segmentation on abdominal CT with dense dilated networks. In: MICCAI. pp. 728\u2013736. Springer (2017)", "(8) Heinrich, M.P., Blendowski, M., Oktay, O.: TernaryNet: Faster deep model inference without GPUs for medical 3D segmentation using sparse and binary convolutions. arXiv preprint arXiv:1801.09449 (2018)", "(26) Roth, H.R., Lu, L., Lay, N., Harrison, A.P., Farag, A., Sohn, A., Summers, R.M.: Spatial aggregation of holistically-nested convolutional neural networks for automated pancreas localization and segmentation. Medical Image Analysis 45, 94 \u2013 107 (2018)"]}]}