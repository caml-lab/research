{"title": "Podnet: Pooled outputs distillation for small-tasks incremental learning", "abstract": "Lifelong learning has attracted much attention, but existing works still struggle to fight catastrophic forgetting and accumulate knowledge over long stretches of incremental learning. In this work, we propose PODNet, a model inspired by representation learning. By carefully balancing the compromise between remembering the old classes and learning new ones, PODNet fights catastrophic forgetting, even over very long runs of small incremental tasks --a setting so far unexplored by current works. PODNet innovates on existing art with an efficient spatial-based distillation-loss applied throughout the model and a representation comprising multiple proxy vectors for each class. We validate those innovations thoroughly, comparing PODNet with three state-of-the-art models on three datasets: CIFAR100, ImageNet100, and ImageNet1000. Our results showcase a significant advantage of PODNet over existing art, with accuracy gains of 12.10, 6.51, and 2.85 percentage points, respectively. Code is available at https://github.com/arthurdouillard/incremental_learning.pytorch", "authors": ["Arthur Douillard", " Matthieu Cord", " Charles Ollion", " Thomas Robert", " Eduardo Valle"], "pdf_url": "https://arxiv.org/abs/2004.13513", "list_table_and_caption": [{"table": "<table><thead><tr><th></th><th colspan=\"4\">CIFAR100</th></tr><tr><th></th><th>50 steps</th><th>25 steps</th><th>10 steps</th><th>5 steps</th></tr><tr><th>New classes per step</th><th>1</th><th>2</th><th>5</th><th>10</th></tr></thead><tbody><tr><th>iCaRL* [33]</th><td>\u2014</td><td>\u2014</td><td>52.57</td><td>57.17</td></tr><tr><th>iCaRL</th><td>44.20\u2009\\pm\u20090.98</td><td>50.60\u2009\\pm\u20091.06</td><td>53.78\u2009\\pm\u20091.16</td><td>58.08\u2009\\pm\u20090.59</td></tr><tr><th>BiC [38]</th><td>47.09\u2009\\pm\u20091.48</td><td>48.96\u2009\\pm\u20091.03</td><td>53.21\u2009\\pm\u20091.01</td><td>56.86\u2009\\pm\u20090.46</td></tr><tr><th>UCIR\u2009(NME)* [14]</th><td>\u2014</td><td>\u2014</td><td>60.12</td><td>63.12</td></tr><tr><th>UCIR\u2009(NME) [14]</th><td>48.57\u2009\\pm\u20090.37</td><td>56.82\u2009\\pm\u20090.19</td><td>60.83\u2009\\pm\u20090.70</td><td>63.63\u2009\\pm\u20090.87</td></tr><tr><th>UCIR\u2009(CNN)* [14]</th><td>\u2014</td><td>\u2014</td><td>60.18</td><td>63.42</td></tr><tr><th>UCIR\u2009(CNN) [14]</th><td>49.30\u2009\\pm\u20090.32</td><td>57.57\u2009\\pm\u20090.23</td><td>61.22\u2009\\pm\u20090.69</td><td>64.01\u2009\\pm\u20090.91</td></tr><tr><th>PODNet\u2009(NME)</th><td>61.40\u2009\\pm\u20090.68</td><td>62.71\u2009\\pm\u20091.26</td><td>64.03\u2009\\pm\u20091.30</td><td>64.48\u2009\\pm\u20091.32</td></tr><tr><th>PODNet\u2009(CNN)</th><td>57.98\u2009\\pm\u20090.46</td><td>60.72\u2009\\pm\u20091.36</td><td>63.19\u2009\\pm\u20091.16</td><td>64.83\u2009\\pm\u20090.98</td></tr></tbody></table>", "caption": "Table 1: Average incremental accuracy for PODNet vs. state of the art. We run experiments three times (random class orders) on CIFAR100 and report averages\u2009\\pm\u2009standard deviations. Models with an asterisk * are reported directly from Hou et al [14]", "list_citation_info": ["[38] Wu, Y., Chen, Y., Wang, L., Ye, Y., Liu, Z., Guo, Y., Fu, Y.: Large scale incremental learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)", "[33] Rebuffi, S.A., Kolesnikov, A., Sperl, G., Lampert, C.H.: icarl: Incremental classifier and representation learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)", "[14] Hou, S., Pan, X., Change Loy, C., Wang, Z., Lin, D.: Learning a unified classifier incrementally via rebalancing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)"]}, {"table": "<table><thead><tr><th></th><th colspan=\"4\">ImageNet100</th><th colspan=\"2\">Imagenet1000</th></tr><tr><th></th><th>50 steps</th><th>25 steps</th><th>10 steps</th><th>5 steps</th><th>10 steps</th><th>5 steps</th></tr><tr><th>New classes per step</th><th>1</th><th>2</th><th>5</th><th>10</th><th>50</th><th>100</th></tr></thead><tbody><tr><td>iCaRL* [33]</td><td>\u2014</td><td>\u2014</td><td>59.53</td><td>65.04</td><td>46.72</td><td>51.36</td></tr><tr><td>iCaRL [33]</td><td>54.97</td><td>54.56</td><td>60.90</td><td>65.56</td><td>\u2014</td><td>\u2014</td></tr><tr><td>BiC [38]</td><td>46.49</td><td>59.65</td><td>65.14</td><td>68.97</td><td>44.31</td><td>45.72</td></tr><tr><td>UCIR\u2009(NME)* [14]</td><td>\u2014</td><td>\u2014</td><td>66.16</td><td>68.43</td><td>59.92</td><td>61.56</td></tr><tr><td>UCIR\u2009(NME) [14]</td><td>55.44</td><td>60.81</td><td>65.83</td><td>69.07</td><td>\u2014</td><td>\u2014</td></tr><tr><td>UCIR\u2009(CNN)* [14]</td><td>\u2014</td><td>\u2014</td><td>68.09</td><td>70.47</td><td>61.28</td><td>64.34</td></tr><tr><td>UCIR\u2009(CNN) [14]</td><td>57.25</td><td>62.94</td><td>67.82</td><td>71.04</td><td>\u2014</td><td>\u2014</td></tr><tr><td>PODNet\u2009(CNN)</td><td>62.48</td><td>68.31</td><td>74.33</td><td>75.54</td><td>64.13</td><td>66.95</td></tr><tr><td></td><td>\\pm 0.59</td><td>\\pm 2.45</td><td>\\pm 0.93</td><td>\\pm 0.26</td><td></td><td></td></tr></tbody></table>", "caption": "Table 2: Average incremental accuracy, PODNet vs. state of the art. Models with an asterisk * are reported directly from Hou et al. [14]", "list_citation_info": ["[38] Wu, Y., Chen, Y., Wang, L., Ye, Y., Liu, Z., Guo, Y., Fu, Y.: Large scale incremental learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)", "[33] Rebuffi, S.A., Kolesnikov, A., Sperl, G., Lampert, C.H.: icarl: Incremental classifier and representation learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)", "[14] Hou, S., Pan, X., Change Loy, C., Wang, Z., Lin, D.: Learning a unified classifier incrementally via rebalancing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)"]}, {"table": "<table><thead><tr><th>M_{per}</th><th>5</th><th>10</th><th>20</th><th>50</th><th>100</th><th>200</th></tr></thead><tbody><tr><th>iCaRL [33]</th><td>16.44</td><td>28.57</td><td>44.20</td><td>48.29</td><td>54.10</td><td>57.82</td></tr><tr><th>BiC [38]</th><td>20.84</td><td>21.97</td><td>47.09</td><td>55.01</td><td>62.23</td><td>67.47</td></tr><tr><th>UCIR\u2009(NME) [14]</th><td>21.81</td><td>41.92</td><td>48.57</td><td>56.09</td><td>60.31</td><td>64.24</td></tr><tr><th>UCIR\u2009(CNN) [14]</th><td>22.17</td><td>42.70</td><td>49.30</td><td>57.02</td><td>61.37</td><td>65.99</td></tr><tr><th>PODNet\u2009(NME)</th><td>48.37</td><td>57.20</td><td>61.40</td><td>62.27</td><td>63.14</td><td>63.63</td></tr><tr><th>PODNet\u2009(CNN)</th><td>35.59</td><td>48.54</td><td>57.98</td><td>63.69</td><td>66.48</td><td>67.62</td></tr></tbody></table>", "caption": "Table 4: Effect of the memory size per class M_{per} on the models performance. Results from CIFAR100 with 50 steps, we report the average incremental accuracy", "list_citation_info": ["[33] Rebuffi, S.A., Kolesnikov, A., Sperl, G., Lampert, C.H.: icarl: Incremental classifier and representation learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)", "[38] Wu, Y., Chen, Y., Wang, L., Ye, Y., Liu, Z., Guo, Y., Fu, Y.: Large scale incremental learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)", "[14] Hou, S., Pan, X., Change Loy, C., Wang, Z., Lin, D.: Learning a unified classifier incrementally via rebalancing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)"]}, {"table": "<table><thead><tr><th>Loss</th><th>NME</th><th>CNN</th></tr></thead><tbody><tr><th>None</th><td>41.56</td><td>40.76</td></tr><tr><th>POD-pixels</th><td>42.21</td><td>40.81</td></tr><tr><th>POD-channels</th><td>55.91</td><td>50.34</td></tr><tr><th>POD-gap</th><td>57.25</td><td>53.87</td></tr><tr><th>POD-width</th><td>61.25</td><td>57.51</td></tr><tr><th>POD-height</th><td>61.24</td><td>57.50</td></tr><tr><th>POD-spatial</th><td>61.42</td><td>57.64</td></tr><tr><th>\\hdashlineGradCam [5]</th><td>41.89</td><td>42.07</td></tr><tr><th>Perceptual Style [16]</th><td>41.74</td><td>40.80</td></tr></tbody></table>", "caption": "Table 6: Comparison of distillation losses based on intermediary features. All losses evaluated without POD-flat.", "list_citation_info": ["[16] Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution. In: Proceedings of the IEEE European Conference on Computer Vision (ECCV) (2016)", "[5] Dhar, P., Singh, R.V., Peng, K.C., Wu, Z., Chellappa, R.: Learning without memorizing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2019)"]}]}