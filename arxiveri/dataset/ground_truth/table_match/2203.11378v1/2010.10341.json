{
    "target_title": "HyperShot: Few-Shot Learning by Kernel HyperNetworks",
    "target_table": "<table><tr><td>Method</td><td>CUB</td><td>mini-ImageNet</td></tr><tr><td>ML-LSTM (Ravi &amp; Larochelle, 2017)</td><td>\u2013</td><td>60.60\\pm 0.71</td></tr><tr><td>SNAIL (Mishra et al., 2018)</td><td>\u2013</td><td>55.20</td></tr><tr><td>VERSA (Gordon et al., 2018)</td><td>\u2013</td><td>67.37\\pm 0.86</td></tr><tr><td>Amortized VI (Gordon et al., 2018)</td><td>\u2013</td><td>55.68\\pm 0.91</td></tr><tr><td>Meta-Mixture (Jerfel et al., 2019)</td><td>\u2013</td><td>64.60\\pm 0.92</td></tr><tr><td>SimpleShot (Wang et al., 2019)</td><td>\u2013</td><td>66.92\\pm 0.17</td></tr><tr><td>Feature Transfer</td><td>68.40\\pm 0.79</td><td>60.51\\pm 0.55</td></tr><tr><td>Baseline++ (Chen et al., 2019)</td><td>78.51\\pm 0.59</td><td>66.18\\pm 0.18</td></tr><tr><td>MatchingNet (Vinyals et al., 2016)</td><td>75.11\\pm 0.35</td><td>62.71\\pm 0.44</td></tr><tr><td>ProtoNet (Snell et al., 2017)</td><td>75.93\\pm 0.46</td><td>64.07\\pm 0.65</td></tr><tr><td>MAML (Finn et al., 2017)</td><td>74.84\\pm 0.62</td><td>61.58\\pm 0.53</td></tr><tr><td>RelationNet (Sung et al., 2018)</td><td>78.22\\pm 0.07</td><td>64.20\\pm 0.28</td></tr><tr><td>DKT + CosSim (Patacchiola et al., 2020)</td><td>77.73\\pm 0.26</td><td>62.85\\pm 0.37</td></tr><tr><td>DKT + BNCosSim (Patacchiola et al., 2020)</td><td>77.76\\pm 0.62</td><td>64.00\\pm 0.09</td></tr><tr><td>GPLDLA (Kim &amp; Hospedales, 2021)</td><td>78.86\\pm 0.35</td><td>\u2013</td></tr><tr><td>amortized Bayesianprototype meta-learning (Sun et al., 2021) </td><td>\\mathbf{80.94\\pm 0.62}</td><td>\\mathbf{70.44\\pm 0.72}</td></tr><tr><td>VAMPIRE (Nguyen et al., 2020)</td><td>\u2013</td><td>64.31\\pm 0.74</td></tr><tr><td>ABML (Ravi &amp; Beatson, 2018)</td><td>68.94\\pm 0.16</td><td>\u2013</td></tr><tr><td>Bayesian MAML (Yoon et al., 2018)</td><td>\u2013</td><td>64.23\\pm 0.69</td></tr><tr><td>OVE PG GP + Cosine (ML) (Snell &amp; Zemel, 2020)</td><td>77.44\\pm 0.18</td><td>64.58\\pm 0.31</td></tr><tr><td>OVE PG GP + Cosine (PL) (Snell &amp; Zemel, 2020)</td><td>79.07\\pm 0.05</td><td>67.14\\pm 0.23</td></tr><tr><td>Reptile (Nichol et al., 2018)</td><td>\u2013</td><td>65.99\\pm 0.58</td></tr><tr><td>R2-D2 (Bertinetto et al., 2018)</td><td>\u2013</td><td>65.50\\pm 0.60</td></tr><tr><td>VSM (Zhen et al., 2020)</td><td>\u2013</td><td>68.01\\pm 0.90</td></tr><tr><td>HyperShot</td><td>79.80\\pm 0.16</td><td>68.78\\pm 0.29</td></tr><tr><td>HyperShot + finetuning</td><td>\\mathit{80.07\\pm 0.22}</td><td>\\mathit{69.62\\pm 0.28}</td></tr></table>",
    "target_caption": "Table 2: The classification accuracy results for the inference tasks on CUB and mini-ImageNet datasets in the 5-shot setting. The highest results are bold and second-highest in italic (the larger, the better). ",
    "source_title": "Learning to learn variational semantic memory",
    "source_table": "",
    "source_caption": ""
}