{"target_title": "Fast-MoCo: Boost Momentum-based Contrastive Learning with Combinatorial Patches", "target_table": "<table><tbody><tr><td><p>Method</p></td><td><p>100 ep.</p></td><td><p>200 ep.</p></td><td><p>400 ep.</p></td><td><p>800 ep.</p></td><td><p>1000 ep.</p></td></tr><tr><td><p>\\hlineB2.5SimCLR [6]</p></td><td><p>64.8</p></td><td><p>67.0</p></td><td><p>68.3</p></td><td><p>69.1</p></td><td><p>-</p></td></tr><tr><td><p>MoCo v2 [7]</p></td><td><p>-</p></td><td><p>67.5</p></td><td><p>-</p></td><td><p>71.1</p></td><td><p>-</p></td></tr><tr><td><p>BYOL [15]</p></td><td><p>66.5</p></td><td><p>70.6</p></td><td><p>73.2</p></td><td><p>-</p></td><td><p>74.3</p></td></tr><tr><td><p>SwAV [3]</p></td><td><p>-</p></td><td><p>-</p></td><td><p>70.1</p></td><td><p>-</p></td><td><p>-</p></td></tr><tr><td><p>BarlowTwins [33]</p></td><td><p>-</p></td><td><p>-</p></td><td><p>-</p></td><td><p>-</p></td><td><p>73.2</p></td></tr><tr><td><p>SimSiam [8]</p></td><td><p>68.1</p></td><td><p>70.0</p></td><td><p>70.8</p></td><td><p>71.3</p></td><td><p>-</p></td></tr><tr><td><p>MoCo v3 [9]</p></td><td><p>-</p></td><td><p>-</p></td><td><p>-</p></td><td><p>73.8</p></td><td><p>-</p></td></tr><tr><td><p>NNCLR [11]</p></td><td><p>69.4</p></td><td><p>70.7</p></td><td><p>74.2</p></td><td><p>74.9</p></td><td><p>75.4</p></td></tr><tr><td><p>OBoW [13]</p></td><td><p>-</p></td><td><p>73.8</p></td><td><p>-</p></td><td><p>-</p></td><td><p>-</p></td></tr><tr><td>Fast-MoCo</td><td>73.5</td><td>75.1</td><td>75.5</td><td><p>-</p></td><td><p>-</p></td></tr><tr><td><p>SwAV [3] (w/ multi-crop)</p></td><td><p>72.1</p></td><td><p>73.9</p></td><td><p>-</p></td><td><p>75.3</p></td><td><p>-</p></td></tr><tr><td><p>DINO [4] (w/ multi-crop)</p></td><td><p>-</p></td><td><p>-</p></td><td><p>-</p></td><td><p>75.3</p></td><td><p>-</p></td></tr><tr><td><p>NNCLR [11] (w/ multi-crop)</p></td><td><p>-</p></td><td><p>-</p></td><td><p>-</p></td><td>75.6</td><td><p>-</p></td></tr></tbody></table>", "target_caption": "Table 1: ImageNet-1k linear evaluation results for existing methods and our Fast-MoCo using ResNet-50. Best results are in bold. Fast-MoCo can achieve similar performance as MoCo v3 with only 100 epochs. When trained for 200 epochs, Fast-MoCo performances better than MoCo v3 trained for 800 epochs and is comparable with state-of-the-arts (multi-crop is not used in Fast-MoCo for a fair comparison).", "source_title": "Emerging properties in self-supervised vision transformers", "source_table": "<table><tbody><tr><td>Method</td><td>Arch.</td><td>Param.</td><td>im/s</td><td>Linear</td><td>k-NN</td></tr><tr><td>Supervised</td><td>RN50</td><td>23</td><td>1237</td><td>79.3</td><td>79.3</td></tr><tr><td>SCLR [12]</td><td>RN50</td><td>23</td><td>1237</td><td>69.1</td><td>60.7</td></tr><tr><td>MoCov2 [15]</td><td>RN50</td><td>23</td><td>1237</td><td>71.1</td><td>61.9</td></tr><tr><td>InfoMin [67]</td><td>RN50</td><td>23</td><td>1237</td><td>73.0</td><td>65.3</td></tr><tr><td>BarlowT [81]</td><td>RN50</td><td>23</td><td>1237</td><td>73.2</td><td>66.0</td></tr><tr><td>OBoW [27]</td><td>RN50</td><td>23</td><td>1237</td><td>73.8</td><td>61.9</td></tr><tr><td>BYOL [30]</td><td>RN50</td><td>23</td><td>1237</td><td>74.4</td><td>64.8</td></tr><tr><td>DCv2 [10]</td><td>RN50</td><td>23</td><td>1237</td><td>75.2</td><td>67.1</td></tr><tr><td>SwAV [10]</td><td>RN50</td><td>23</td><td>1237</td><td>75.3</td><td>65.7</td></tr><tr><td>DINO</td><td>RN50</td><td>23</td><td>1237</td><td>75.3</td><td>67.5</td></tr><tr><td>Supervised</td><td>ViT-S</td><td>21</td><td>1007</td><td>79.8</td><td>79.8</td></tr><tr><td>BYOL{}^{*} [30]</td><td>ViT-S</td><td>21</td><td>1007</td><td>71.4</td><td>66.6</td></tr><tr><td>MoCov2{}^{*} [15]</td><td>ViT-S</td><td>21</td><td>1007</td><td>72.7</td><td>64.4</td></tr><tr><td>SwAV{}^{*} [10]</td><td>ViT-S</td><td>21</td><td>1007</td><td>73.5</td><td>66.3</td></tr><tr><td>DINO</td><td>ViT-S</td><td>21</td><td>1007</td><td>77.0</td><td>74.5</td></tr><tr><td colspan=\"5\">Comparison across architectures</td><td></td></tr><tr><td>SCLR [12]</td><td>RN50w4</td><td>375</td><td>117</td><td>76.8</td><td>69.3</td></tr><tr><td>SwAV [10]</td><td>RN50w2</td><td>93</td><td>384</td><td>77.3</td><td>67.3</td></tr><tr><td>BYOL [30]</td><td>RN50w2</td><td>93</td><td>384</td><td>77.4</td><td>\u2013</td></tr><tr><td>DINO</td><td>ViT-B/16</td><td>85</td><td>312</td><td>78.2</td><td>76.1</td></tr><tr><td>SwAV [10]</td><td>RN50w5</td><td>586</td><td>76</td><td>78.5</td><td>67.1</td></tr><tr><td>BYOL [30]</td><td>RN50w4</td><td>375</td><td>117</td><td>78.6</td><td>\u2013</td></tr><tr><td>BYOL [30]</td><td>RN200w2</td><td>250</td><td>123</td><td>79.6</td><td>73.9</td></tr><tr><td>DINO</td><td>ViT-S/8</td><td>21</td><td>180</td><td>79.7</td><td>78.3</td></tr><tr><td>SCLRv2 [13]</td><td>RN152w3+SK</td><td>794</td><td>46</td><td>79.8</td><td>73.1</td></tr><tr><td>DINO</td><td>ViT-B/8</td><td>85</td><td>63</td><td>80.1</td><td>77.4</td></tr></tbody></table>", "source_caption": "Table 2: Linear and k-NN classification on ImageNet.We report top-1 accuracy for linear and k-NN evaluations on the validation set of ImageNet for different self-supervised methods.We focus on ResNet-50 and ViT-small architectures, but also report the best results obtained across architectures.{}^{*} are run by us.We run the k-NN evaluation for models with official released weights.The throughput (im/s) is calculated on a NVIDIA V100 GPU with 128 samples per forward.Parameters (M) are of the feature extractor."}