{
    "target_title": "Students taught by multimodal teachers are superior action recognizers",
    "target_table": "<table><tbody><tr><td></td><td></td><td colspan=\"2\">Something-Something</td><td colspan=\"2\">Something-Else</td></tr><tr><td>Method</td><td>Modalities at inference</td><td>Top 1</td><td>Top 5</td><td>Top 1</td><td>Top 5</td></tr><tr><td>Baseline [1]</td><td>RGB frames</td><td>59.6</td><td>85.6</td><td>51.7</td><td>78.1</td></tr><tr><td>Baseline [15]</td><td>Obj. detections</td><td>44.2</td><td>73.6</td><td>39.5</td><td>66.3</td></tr><tr><td>Baseline [1]</td><td>Optical flow</td><td>50.2</td><td>79.6</td><td>49.7</td><td>78.3</td></tr><tr><td>Teacher [1, 15]</td><td>RGB Frames &amp; Obj. detections</td><td>62.6</td><td>87.6</td><td>57.2</td><td>82.7</td></tr><tr><td>Student</td><td>RGB frames</td><td>62.1<sub>+2.5</sub></td><td>88.0<sub>+2.4</sub></td><td>57.2<sub>+5.5</sub></td><td>83.5<sub>+5.4</sub></td></tr><tr><td>Teacher [1]</td><td>RGB Frames &amp; Optical flow</td><td>64.0</td><td>89.0</td><td>61.5</td><td>86.2</td></tr><tr><td>Student</td><td>RGB frames</td><td>62.3<sub>+2.7</sub></td><td>88.8<sub>+3.2</sub></td><td>57.6<sub>+5.9</sub></td><td>84.1<sub>+6.0</sub></td></tr><tr><td>Teacher [1, 15]</td><td>RGB Frames &amp; Optical flow &amp; Obj. detections</td><td>65.7</td><td>90.2</td><td>63.2</td><td>87.3</td></tr><tr><td>Omnivore [1, 6]</td><td>RGB frames</td><td>62.5</td><td>88.1</td><td>56.8</td><td>83.3</td></tr><tr><td>Student</td><td>RGB frames</td><td>63.9<sub>+4.3</sub></td><td>89.2<sub>+3.6</sub></td><td>59.4<sub>+7.7</sub></td><td>85.4<sub>+7.3</sub></td></tr></tbody></table>",
    "target_caption": "Table 1: Something-Something [7] &amp; Something-Else [13] (compositional split) action recognition accuracy. Improvement over RGB frames baseline [1] in red.",
    "source_title": "Revisiting spatio-temporal layouts for compositional action recognition",
    "source_table": "",
    "source_caption": ""
}