{"target_title": "TinyViT: Fast Pretraining Distillation for Small Vision Transformers", "target_table": "<table><tr><td></td><td rowspan=\"2\">Model</td><td>Top-1</td><td>Top-5</td><td>#Params</td><td>MACs</td><td>Throughput</td><td rowspan=\"2\">Input</td><td rowspan=\"2\">Arch.</td></tr><tr><td></td><td>(%)</td><td>(%)</td><td>(M)</td><td>(G)</td><td>(images/s)</td></tr><tr><td rowspan=\"7\">5-10M #Params</td><td>MoblieViT-S [46]</td><td>78.4</td><td>-</td><td>6</td><td>1.8</td><td>2,661</td><td>256</td><td>Hybrid</td></tr><tr><td>ViTAS-DeiT-A [60]</td><td>75.5</td><td>92.4</td><td>6</td><td>1.3</td><td>3,504</td><td>224</td><td>Trans</td></tr><tr><td>GLiT-Tiny [9]</td><td>76.3</td><td>-</td><td>7</td><td>1.5</td><td>3,262</td><td>224</td><td>Trans</td></tr><tr><td>Mobile-Former-214M [14]</td><td>76.7</td><td>-</td><td>9</td><td>0.2</td><td>3,105</td><td>224</td><td>Hybrid</td></tr><tr><td>CrossViT-9 [10]</td><td>77.1</td><td>-</td><td>9</td><td>2.0</td><td>2,659</td><td>224</td><td>Trans</td></tr><tr><td>TinyViT-5M (ours)</td><td>79.1</td><td>94.8</td><td>5.4</td><td>1.3</td><td>3,060</td><td>224</td><td>Hybrid</td></tr><tr><td>TinyViT-5M<img/> (ours)</td><td>80.7</td><td>95.6</td><td>5.4</td><td>1.3</td><td>3,060</td><td>224</td><td>Hybrid</td></tr><tr><td rowspan=\"7\">11-20M</td><td>ResNet-18 [28]</td><td>70.3</td><td>86.7</td><td>12</td><td>1.8</td><td>8,714</td><td>224</td><td>CNN</td></tr><tr><td>PVT-Tiny [66]</td><td>75.1</td><td>-</td><td>13</td><td>1.9</td><td>2,791</td><td>224</td><td>Trans</td></tr><tr><td>ResT-Small [81]</td><td>79.6</td><td>94.9</td><td>14</td><td>2.1</td><td>2,037</td><td>224</td><td>Trans</td></tr><tr><td>LeViT-256 [24]</td><td>81.6</td><td>-</td><td>19</td><td>1.1</td><td>7,386</td><td>224</td><td>Hybrid</td></tr><tr><td>CoaT-Lite Small [71]</td><td>81.9</td><td>95.6</td><td>20</td><td>4.0</td><td>1,138</td><td>224</td><td>Trans</td></tr><tr><td>TinyViT-11M (ours)</td><td>81.5</td><td>95.8</td><td>11</td><td>2.0</td><td>2,468</td><td>224</td><td>Hybrid</td></tr><tr><td>TinyViT-11M<img/> (ours)</td><td>83.2</td><td>96.5</td><td>11</td><td>2.0</td><td>2,468</td><td>224</td><td>Hybrid</td></tr><tr><td rowspan=\"7\">&gt;20M</td><td>DeiT-S [64]</td><td>79.9</td><td>95.0</td><td>22</td><td>4.6</td><td>2,276</td><td>224</td><td>Trans</td></tr><tr><td>T2T-ViT-14 [74]</td><td>81.5</td><td>95.7</td><td>21</td><td>4.8</td><td>1,557</td><td>224</td><td>Trans</td></tr><tr><td>AutoFormer-S [11]</td><td>81.7</td><td>95.7</td><td>23</td><td>5.1</td><td>1,341</td><td>224</td><td>Trans</td></tr><tr><td>Swin-T [43]</td><td>81.2</td><td>95.5</td><td>28</td><td>4.5</td><td>1,393</td><td>224</td><td>Trans</td></tr><tr><td>CrossViT-15 [10]</td><td>82.3</td><td>-</td><td>28</td><td>6.1</td><td>1,306</td><td>224</td><td>Trans</td></tr><tr><td>EffNet-B5 [62]</td><td>83.6</td><td>96.7</td><td>30</td><td>9.9</td><td>330</td><td>456</td><td>CNN</td></tr><tr><td>TinyViT-21M (ours)</td><td>83.1</td><td>96.5</td><td>21</td><td>4.3</td><td>1,571</td><td>224</td><td>Hybrid</td></tr><tr><td></td><td>TinyViT-21M<img/> (ours)</td><td>84.8</td><td>97.3</td><td>21</td><td>4.3</td><td>1,571</td><td>224</td><td>Hybrid</td></tr><tr><td></td><td>TinyViT-21M<img/> \\uparrow384 (ours)</td><td>86.2</td><td>97.8</td><td>21</td><td>13.8</td><td>394</td><td>384</td><td>Hybrid</td></tr><tr><td></td><td>TinyViT-21M<img/> \\uparrow512 (ours)</td><td>86.5</td><td>97.9</td><td>21</td><td>27.0</td><td>167</td><td>512</td><td>Hybrid</td></tr></table>", "target_caption": "Table 4: TinyViT performance on IN-1k [18] with comparisons to state-of-the-art models. MACs (multiply\u2013accumulate operations) and Throughput are measured using the GitHub repository of [1, 24] and a V100 GPU. <img/>: pretrain on IN-21k with the proposed fast distillation; \\uparrow: finetune with higher resolution.", "source_title": "Rest: An efficient transformer for visual recognition", "source_table": "<table><tbody><tr><td>Model</td><td>#Params (M)</td><td>FLOPs (G)</td><td>Throughput</td><td>Top-1 (%)</td><td>Top-5 (%)</td></tr><tr><td colspan=\"6\">ConvNet</td></tr><tr><td>ResNet-18 DBLP:conf/cvpr/HeZRS16 </td><td>11.7</td><td>1.8</td><td>1852</td><td>69.7</td><td>89.1</td></tr><tr><td>ResNet-50 DBLP:conf/cvpr/HeZRS16 </td><td>25.6</td><td>4.1</td><td>871</td><td>79.0</td><td>94.4</td></tr><tr><td>ResNet-101 DBLP:conf/cvpr/HeZRS16 </td><td>44.7</td><td>7.9</td><td>635</td><td>80.3</td><td>95.2</td></tr><tr><td>RegNetY-4G DBLP:conf/cvpr/RadosavovicKGHD20 </td><td>20.6</td><td>4.0</td><td>1156</td><td>79.4</td><td>94.7</td></tr><tr><td>RegNetY-8G DBLP:conf/cvpr/RadosavovicKGHD20 </td><td>39.2</td><td>8.0</td><td>591</td><td>79.9</td><td>94.9</td></tr><tr><td>RegNetY-16G DBLP:conf/cvpr/RadosavovicKGHD20 </td><td>83.6</td><td>15.9</td><td>334</td><td>80.4</td><td>95.1</td></tr><tr><td colspan=\"6\">Transformer</td></tr><tr><td>DeiT-S DBLP:journals/corr/abs-2012-12877 </td><td>22.1</td><td>4.6</td><td>940</td><td>79.8</td><td>94.9</td></tr><tr><td>DeiT-B DBLP:journals/corr/abs-2012-12877 </td><td>86.6</td><td>17.6</td><td>292</td><td>81.8</td><td>95.6</td></tr><tr><td>PVT-T wang2021pyramid </td><td>13.2</td><td>1.9</td><td>1038</td><td>75.1</td><td>92.4</td></tr><tr><td>PVT-S wang2021pyramid </td><td>24.5</td><td>3.7</td><td>820</td><td>79.8</td><td>94.9</td></tr><tr><td>PVT-M wang2021pyramid </td><td>44.2</td><td>6.4</td><td>526</td><td>81.2</td><td>95.6</td></tr><tr><td>PVT-L wang2021pyramid </td><td>61.4</td><td>9.5</td><td>367</td><td>81.7</td><td>95.9</td></tr><tr><td>Swin-T DBLP:journals/corr/abs-2103-14030 </td><td>28.29</td><td>4.5</td><td>755</td><td>81.3</td><td>95.5</td></tr><tr><td>Swin-S DBLP:journals/corr/abs-2103-14030 </td><td>49.61</td><td>8.7</td><td>437</td><td>83.3</td><td>96.2</td></tr><tr><td>Swin-B DBLP:journals/corr/abs-2103-14030 </td><td>87.77</td><td>15.4</td><td>278</td><td>83.5</td><td>96.5</td></tr><tr><td>ResT-Lite (Ours)</td><td>10.49</td><td>1.4</td><td>1246</td><td>77.2 (\\uparrow 7.5)</td><td>93.7 (\\uparrow 4.6)</td></tr><tr><td>ResT-Small (Ours)</td><td>13.66</td><td>1.9</td><td>1043</td><td>79.6 (\\uparrow 9.9)</td><td>94.9 (\\uparrow 5.8)</td></tr><tr><td>ResT-Base (Ours)</td><td>30.28</td><td>4.3</td><td>673</td><td>81.6 (\\uparrow 2.6)</td><td>95.7 (\\uparrow 1.3)</td></tr><tr><td>ResT-Large (Ours)</td><td>51.63</td><td>7.9</td><td>429</td><td>83.6 (\\uparrow 3.3)</td><td>96.3 (\\uparrow 1.1)</td></tr></tbody></table>", "source_caption": "Table 2: Comparison with state-of-the-art backbones on ImageNet-1k benchmark. Throughput (images / s) is measured on a single V100 GPU, following  DBLP:journals/corr/abs-2012-12877 . All models are trained and evaluated on 224\\times224 resolution. The best records and the improvements over bench-marked ResNets are marked in bold and blue, respectively."}