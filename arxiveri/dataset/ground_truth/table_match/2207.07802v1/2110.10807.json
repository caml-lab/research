{"target_title": "Learning Granularity-Unified Representations for Text-to-Image Person Re-identification", "target_table": "<table><tbody><tr><td colspan=\"2\">Methods</td><td>Rank-1</td><td>Rank-5</td><td>Rank-10</td></tr><tr><td rowspan=\"19\">ResNet-50</td><td>Dual Path (Zheng et al., 2020b)</td><td>44.40</td><td>66.26</td><td>75.07</td></tr><tr><td>CMPM/C (Zhang and Lu, 2018)</td><td>49.37</td><td>-</td><td>79.27</td></tr><tr><td>MIA (Niu et al., 2020b)</td><td>53.10</td><td>75.00</td><td>82.90</td></tr><tr><td>A-GANet (Liu et al., 2019)</td><td>53.14</td><td>74.03</td><td>82.95</td></tr><tr><td>GALM (Jing et al., 2020)</td><td>54.12</td><td>75.45</td><td>82.97</td></tr><tr><td>TIMAM (Sarafianos et al., 2019)</td><td>54.51</td><td>77.56</td><td>84.78</td></tr><tr><td>TDE (Niu et al., 2020a)</td><td>55.25</td><td>77.46</td><td>84.56</td></tr><tr><td>VTA (Ge et al., 2019)</td><td>55.32</td><td>77.00</td><td>84.26</td></tr><tr><td>SCAN (Lee et al., 2018)</td><td>55.86</td><td>75.97</td><td>83.69</td></tr><tr><td>ViTAA (Wang et al., 2020)</td><td>55.97</td><td>75.84</td><td>83.52</td></tr><tr><td>CMAAM (Aggarwal et al., 2020)</td><td>56.68</td><td>77.18</td><td>84.86</td></tr><tr><td>HGAN (Zheng et al., 2020a)</td><td>59.00</td><td>79.49</td><td>86.62</td></tr><tr><td>NAFS (Gao et al., 2021)</td><td>59.94</td><td>79.86</td><td>86.70</td></tr><tr><td>DSSL (Zhu et al., 2021)</td><td>59.98</td><td>80.41</td><td>87.56</td></tr><tr><td>MGEL (Wang et al., 2021a)</td><td>60.27</td><td>80.01</td><td>86.74</td></tr><tr><td>SSAN (Ding et al., 2021)</td><td>61.37</td><td>80.15</td><td>86.73</td></tr><tr><td>Han et al. (Han et al., 2021)</td><td>61.65</td><td>80.98</td><td>86.78</td></tr><tr><td>LapsCore (Wu et al., 2021)</td><td>63.40</td><td>-</td><td>87.80</td></tr><tr><td>LGUR</td><td>64.21</td><td>81.94</td><td>87.93</td></tr><tr><td colspan=\"2\">LGUR ( DeiT-Small)</td><td>65.25</td><td>83.12</td><td>89.00</td></tr></tbody></table>", "target_caption": "Table 1. Performance comparisons on CUHK-PEDES.", "source_title": "Text-Based Person Search with Limited Data", "source_table": "<table><tbody><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">Arch.</td><td rowspan=\"2\">Dim.</td><td colspan=\"4\">Text to Image w/o Rerank</td><td colspan=\"4\">Image to Text w/o Rerank</td></tr><tr><td>Rank-1</td><td>Rank-5</td><td>Rank-10</td><td>mAP</td><td>Rank-1</td><td>Rank-5</td><td>Rank-10</td><td>mAP</td></tr><tr><td>GNA-RNN Li et al.(2017)Li, Xiao, Li, Zhou, Yue, and Wang</td><td>S</td><td>512</td><td>19.05</td><td>-</td><td>53.64</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>Dual Path Zheng et al.(2020b)Zheng, Zheng, Garrett, Yang, Xu, andShen</td><td>S</td><td>2048</td><td>44.40</td><td>66.26</td><td>75.07</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>CMPM/C\\dagger Zhang and Lu(2018)</td><td>S</td><td>512</td><td>49.37</td><td>71.69</td><td>79.27</td><td>-</td><td>60.96</td><td>84.42</td><td>90.83</td><td>-</td></tr><tr><td>MIA Niu et al.(2020)Niu, Huang, Ouyang, and Wang</td><td>M</td><td>1024</td><td>53.10</td><td>75.00</td><td>82.90</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>PMA Jing et al.(2020)Jing, Si, Wang, Wang, Wang, and Tan</td><td>M</td><td>1024</td><td>54.12</td><td>75.45</td><td>82.97</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>TIMAM\\dagger Sarafianos et al.(2019)Sarafianos, Xu, andKakadiaris</td><td>S</td><td>512</td><td>54.51</td><td>77.56</td><td>84.78</td><td>-</td><td>67.40</td><td>88.65</td><td>93.91</td><td>-</td></tr><tr><td>CKMA Chen et al.(2021a)Chen, Huang, Chang, Tan, Xue, andMa</td><td>S</td><td>512</td><td>54.69</td><td>73.65</td><td>81.86</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>ViTAA\\ddagger Wang et al.(2020a)Wang, Fang, Wang, andYang</td><td>M</td><td>256</td><td>54.92</td><td>75.18</td><td>82.90</td><td>51.60</td><td>65.71</td><td>88.68</td><td>93.75</td><td>45.75</td></tr><tr><td>CMAAM Aggarwal et al.(2020)Aggarwal, Babu, andChakraborty</td><td>M</td><td>512</td><td>56.68</td><td>77.18</td><td>84.86</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>HGAN\\dagger Zheng et al.(2020a)Zheng, Liu, Liu, Zha, andMei</td><td>M</td><td>512</td><td>59.00</td><td>79.49</td><td>86.62</td><td>-</td><td>71.16</td><td>90.05</td><td>95.06</td><td>-</td></tr><tr><td>NAFS (G)\\ddagger Gao et al.(2021)Gao, Cai, Jiang, Zheng, Zhang, Gong, Peng, Guo, andSun</td><td>M</td><td>768</td><td>59.36</td><td>79.13</td><td>86.00</td><td>54.07</td><td>71.89</td><td>90.99</td><td>95.28</td><td>50.16</td></tr><tr><td>MGEL Wang et al.(2021)Wang, Luo, Lin, and Li</td><td>M</td><td>512</td><td>60.27</td><td>80.01</td><td>86.74</td><td>-</td><td>71.87</td><td>91.38</td><td>95.42</td><td>-</td></tr><tr><td>AXM-Net Farooq et al.(2021)Farooq, Awais, Kittler, and Khalid</td><td>M</td><td>512</td><td>61.90</td><td>79.41</td><td>85.75</td><td>57.38</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>TIPCB\\ddagger Chen et al.(2021b)Chen, Zhang, Lu, Wang, Zheng, andWang</td><td>M</td><td>2048</td><td>63.63</td><td>82.82</td><td>89.01</td><td>56.78</td><td>73.55</td><td>92.26</td><td>96.03</td><td>51.78</td></tr><tr><td>Ours (ResNet50)</td><td>S</td><td>256</td><td>61.65</td><td>80.98</td><td>86.78</td><td>58.29</td><td>75.96</td><td>93.40</td><td>96.55</td><td>55.05</td></tr><tr><td>Ours (ResNet101)</td><td>S</td><td>256</td><td>64.08</td><td>81.73</td><td>88.19</td><td>60.08</td><td>78.99</td><td>95.02</td><td>97.17</td><td>56.78</td></tr><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">Arch.</td><td rowspan=\"2\">Dim.</td><td colspan=\"4\">Text to Image w/ Rerank</td><td colspan=\"4\">Image to Text w/ Rerank</td></tr><tr><td>Rank-1</td><td>Rank-5</td><td>Rank-10</td><td>mAP</td><td>Rank-1</td><td>Rank-5</td><td>Rank-10</td><td>mAP</td></tr><tr><td>ViTAA\\ddagger Wang et al.(2020a)Wang, Fang, Wang, andYang</td><td>M</td><td>256</td><td>54.92</td><td>74.77</td><td>82.49</td><td>52.60</td><td>66.17</td><td>88.61</td><td>93.56</td><td>46.39</td></tr><tr><td>NAFS (G)\\ddagger Gao et al.(2021)Gao, Cai, Jiang, Zheng, Zhang, Gong, Peng, Guo, andSun</td><td>M</td><td>768</td><td>59.62</td><td>78.90</td><td>85.72</td><td>55.02</td><td>72.67</td><td>90.92</td><td>95.12</td><td>50.92</td></tr><tr><td>TIPCB\\ddagger Chen et al.(2021b)Chen, Zhang, Lu, Wang, Zheng, andWang</td><td>M</td><td>2048</td><td>63.37</td><td>81.56</td><td>87.57</td><td>60.02</td><td>74.04</td><td>92.06</td><td>95.61</td><td>53.78</td></tr><tr><td>Ours (ResNet50)</td><td>S</td><td>256</td><td>61.94</td><td>80.52</td><td>86.45</td><td>59.45</td><td>76.26</td><td>93.46</td><td>96.58</td><td>55.67</td></tr><tr><td>Ours (ResNet101)</td><td>S</td><td>256</td><td>64.40</td><td>81.27</td><td>87.96</td><td>61.19</td><td>78.99</td><td>95.02</td><td>97.23</td><td>57.31</td></tr></tbody></table>", "source_caption": "Table 1: Comparisons with previous methods on the CUHK-PEDES. Only global features are used during inference for our reproduced NAFS Gao et al.(2021)Gao, Cai, Jiang, Zheng, Zhang, Gong, Peng, Guo, andSun. \"Arch.\"/\"Dim.\" is the abbreviation for architecture/feature dimension. S/M stands for the methods designed in single-/multi-scale architecture, and all single-scale methods are highlighted with gray background. \\dagger stands for the results from HGAN Zheng et al.(2020a)Zheng, Liu, Liu, Zha, andMei. \\ddagger stands for the results reproduced with public codes/checkpoints released by their authors. Overall 1^{st}/2^{nd} best in red/blue."}