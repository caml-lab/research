{"target_title": "Attention Swin U-Net: Cross-Contextual Attention Mechanism for Skin Lesion Segmentation", "target_table": "<table><thead><tr><td rowspan=\"2\">Methods</td><td colspan=\"4\">ISIC 2017</td><td colspan=\"4\">ISIC 2018</td><td colspan=\"4\">PH{}^{2}</td></tr><tr><td>DSC</td><td>SE</td><td>SP</td><td>ACC</td><td>DSC</td><td>SE</td><td>SP</td><td>ACC</td><td>DSC</td><td>SE</td><td>SP</td><td>ACC</td></tr></thead><tbody><tr><td>U-Net [3]</td><td>0.8159</td><td>0.8172</td><td>0.9680</td><td>0.9164</td><td>0.8545</td><td>0.8800</td><td>0.9697</td><td>0.9404</td><td>0.8936</td><td>0.9125</td><td>0.9588</td><td>0.9233</td></tr><tr><td>Att U-Net [13]</td><td>0.8082</td><td>0.7998</td><td>0.9776</td><td>0.9145</td><td>0.8566</td><td>0.8674</td><td>0.9863</td><td>0.9376</td><td>0.9003</td><td>0.9205</td><td>0.9640</td><td>0.9276</td></tr><tr><td>TransUNet [14]</td><td>0.8123</td><td>0.8263</td><td>0.9577</td><td>0.9207</td><td>0.8499</td><td>0.8578</td><td>0.9653</td><td>0.9452</td><td>0.8840</td><td>0.9063</td><td>0.9427</td><td>0.9200</td></tr><tr><td>MCGU-Net [24]</td><td>0.8927</td><td>0.8502</td><td>0.9855</td><td>0.9570</td><td>0.895</td><td>0.848</td><td>0.986</td><td>0.955</td><td>0.9263</td><td>0.8322</td><td>0.9714</td><td>0.9537</td></tr><tr><td>MedT [25]</td><td>0.8037</td><td>0.8064</td><td>0.9546</td><td>0.9090</td><td>0.8389</td><td>0.8252</td><td>0.9637</td><td>0.9358</td><td>0.9122</td><td>0.8472</td><td>0.9657</td><td>0.9416</td></tr><tr><td>FAT-Net [26]</td><td>0.8500</td><td>0.8392</td><td>0.9725</td><td>0.9326</td><td>0.8903</td><td>0.9100</td><td>0.9699</td><td>0.9578</td><td>0.9440</td><td>0.9441</td><td>0.9741</td><td>0.9703</td></tr><tr><td>TMU-Net [18]</td><td>0.9164</td><td>0.9128</td><td>0.9789</td><td>0.9660</td><td>0.9059</td><td>0.9038</td><td>0.9746</td><td>0.9603</td><td>0.9414</td><td>0.9395</td><td>0.9756</td><td>0.9647</td></tr><tr><td>Swin\u2009U-Net [16]</td><td>0.9183</td><td>0.9142</td><td>0.9798</td><td>0.9701</td><td>0.8946</td><td>0.9056</td><td>0.9798</td><td>0.9645</td><td>0.9449</td><td>0.9410</td><td>0.9564</td><td>0.9678</td></tr><tr><td>TransNorm [15]</td><td>0.8933</td><td>0.8532</td><td>0.9859</td><td>0.9582</td><td>0.8951</td><td>0.8750</td><td>0.9790</td><td>0.9580</td><td>0.9437</td><td>0.9438</td><td>0.9810</td><td>0.9723</td></tr><tr><td>Proposed Method</td><td>0.9240</td><td>0.9246</td><td>0.9794</td><td>0.9656</td><td>0.9105</td><td>0.9089</td><td>0.9807</td><td>0.9668</td><td>0.9504</td><td>0.9439</td><td>0.9576</td><td>0.9685</td></tr></tbody></table>", "target_caption": "Table 1: Performance comparison of the proposed method against the SOTA approaches on skin lesion segmentation task.", "source_title": "Transnorm: Transformer provides a strong spatial normalization mechanism for a deep segmentation model", "source_table": "<table><thead><tr><td>Methods</td><td>DSC</td><td>SE</td><td>SP</td><td>ACC</td></tr></thead><tbody><tr><td>U-Net [14]</td><td>0.8545</td><td>0.8800</td><td>0.9697</td><td>0.9404</td></tr><tr><td>Att U-Net [28]</td><td>0.8566</td><td>0.8674</td><td>0.9863</td><td>0.9376</td></tr><tr><td>DAGAN [48]</td><td>0.8807</td><td>0.9072</td><td>0.9588</td><td>0.9324</td></tr><tr><td>TransUNet [4]</td><td>0.8499</td><td>0.8578</td><td>0.9653</td><td>0.9452</td></tr><tr><td>MCGU-Net [49]</td><td>0.895</td><td>0.848</td><td>0.986</td><td>0.955</td></tr><tr><td>MedT [50]</td><td>0.8389</td><td>0.8252</td><td>0.9637</td><td>0.9358</td></tr><tr><td>FAT-Net [37]</td><td>0.8903</td><td>0.9100</td><td>0.9699</td><td>0.9578</td></tr><tr><td>Proposed Method</td><td>0.8951</td><td>0.8750</td><td>0.9790</td><td>0.9580</td></tr></tbody></table>", "source_caption": "TABLE III: Performance comparison of the suggested network against the SOTA counterparts for skin lesion segmentation on the ISIC 2018 dataset."}