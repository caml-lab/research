{"target_title": "Controllable and Guided Face Synthesis for Unconstrained Face Recognition", "target_table": "<table><tbody><tr><td rowspan=\"2\">Method</td><td rowspan=\"2\">Train Data, #labeled(+#unlabeled)</td><td rowspan=\"2\">Backbone</td><td colspan=\"3\">Verification</td><td colspan=\"2\">Identification</td></tr><tr><td>1e-5</td><td>1e-4</td><td>1e-3</td><td>Rank1</td><td>Rank5</td></tr><tr><td>VGGFace2 [7]</td><td>VGGFace2, 3.3M</td><td>SE-ResNet-50</td><td>70.50</td><td>83.10</td><td>90.80</td><td>90.20</td><td>94.6</td></tr><tr><td>AFRN [35]</td><td>VGGFace2-*, 3.1M</td><td>ResNet-101</td><td>77.10</td><td>88.50</td><td>94.90</td><td>97.30</td><td>97.60</td></tr><tr><td>ArcFace [12]</td><td>MS1MV2, 5.8M</td><td>ResNet-50</td><td>84.28</td><td>91.66</td><td>94.81</td><td>92.95</td><td>95.60</td></tr><tr><td>MagFace [53]</td><td>MS1MV2, 5.8M</td><td>ResNet-50</td><td>83.87</td><td>91.47</td><td>94.67</td><td>-</td><td>-</td></tr><tr><td>Shi et al. [69]</td><td>cleaned MS1MV2, 3.9M(+70K)</td><td>ResNet-50</td><td>88.19</td><td>92.78</td><td>95.86</td><td>95.86</td><td>96.72</td></tr><tr><td>ArcFace</td><td>cleaned MS1MV2, 3.9M</td><td>ResNet-50</td><td>87.26</td><td>94.01</td><td>95.95</td><td>94.61</td><td>96.52</td></tr><tr><td>ArcFace+Ours</td><td>cleaned MS1MV2, 3.9M(+70K)</td><td>ResNet-50</td><td>90.95</td><td>94.61</td><td>96.21</td><td>94.96</td><td>96.84</td></tr></tbody></table>", "target_caption": "Table 1:  Comparison with state-of-the-art methods on the IJB-B benchmark. \u2003\u2003\u2003\u2018*\u2019 denotes a subset of data selected by the authors.", "source_title": "VGGface2: A dataset for recognising faces across pose and age", "source_table": "<table><tbody><tr><td>Training dataset</td><td>Arch.</td><td colspan=\"4\">1:1 Verification TAR</td><td colspan=\"5\">1:N Identification TPIR</td></tr><tr><td></td><td></td><td>FAR=1E-5</td><td>FAR=1E-4</td><td>FAR=1E-3</td><td>FAR=1E-2</td><td>FPIR=0.01</td><td>FPIR=0.1</td><td>Rank-1</td><td>Rank-5</td><td>Rank-10</td></tr><tr><td>VGGFace [17]</td><td>ResNet-50</td><td>0.342</td><td>0.535</td><td>0.711</td><td>0.850</td><td>0.429\\pm 0.024</td><td>0.635\\pm 0.015</td><td>0.752\\pm 0.038</td><td>0.843\\pm 0.032</td><td>0.874\\pm 0.026</td></tr><tr><td>MS1M [7]</td><td>ResNet-50</td><td>0.548</td><td>0.743</td><td>0.857</td><td>0.935</td><td>0.662\\pm 0.036</td><td>0.810\\pm 0.028</td><td>0.865\\pm 0.053</td><td>0.917\\pm 0.032</td><td>0.936\\pm 0.024</td></tr><tr><td>VGGFace2</td><td>ResNet-50</td><td>0.647</td><td>0.784</td><td>0.878</td><td>0.938</td><td>0.701\\pm 0.038</td><td>0.824\\pm 0.034</td><td>0.886\\pm 0.032</td><td>0.936\\pm 0.019</td><td>0.953\\pm 0.013</td></tr><tr><td>VGGFace2_ft</td><td>ResNet-50</td><td>0.671</td><td>0.804</td><td>0.891</td><td>0.947</td><td>0.702\\pm 0.041</td><td>0.843\\pm 0.032</td><td>0.894\\pm 0.039</td><td>0.940\\pm 0.022</td><td>0.954\\pm 0.016</td></tr><tr><td>VGGFace2</td><td>SENet</td><td>0.671</td><td>0.800</td><td>0.888</td><td>0.949</td><td>0.706\\pm 0.047</td><td>0.839\\pm 0.035</td><td>0.901\\pm 0.030</td><td>0.945\\pm 0.016</td><td>0.958\\pm 0.010</td></tr><tr><td>VGGFace2_ft</td><td>SENet</td><td>\\mathbf{0.705}</td><td>\\mathbf{0.831}</td><td>\\mathbf{0.908}</td><td>\\mathbf{0.956}</td><td>\\mathbf{0.743\\pm 0.037}</td><td>\\mathbf{0.863\\pm 0.032}</td><td>\\mathbf{0.902\\pm 0.036}</td><td>\\mathbf{0.946\\pm 0.022}</td><td>\\mathbf{0.959\\pm 0.015}</td></tr><tr><td>Whitelam et al. [23]</td><td>-</td><td>0.350</td><td>0.540</td><td>0.700</td><td>0.840</td><td>0.420</td><td>0.640</td><td>0.790</td><td>0.850</td><td>0.900</td></tr></tbody></table>", "source_caption": "TABLE VII: Performance evaluation on the IJB-B dataset. A higher value isbetter. The results of [23] are read from thecurves reported in the paper. Note, [23] has a differentevaluation for the verification protocol where pairsgenerated from different galleries are evaluated separately andaveraged to get the final results."}