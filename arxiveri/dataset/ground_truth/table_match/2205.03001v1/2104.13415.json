{"target_title": "Revisiting Pretraining for Semi-Supervised Learning in the Low-Label Regime", "target_table": "<table><tbody><tr><td></td><td></td><td></td><td colspan=\"3\">PascalVOC</td><td colspan=\"2\">CityScapes</td></tr><tr><td>Pretrain</td><td>Trg.Pre.</td><td>SSL</td><td>1%</td><td>2%</td><td>5%</td><td>#100</td><td>#372</td></tr><tr><td>IN Sup</td><td>-</td><td>CutMix [7]</td><td>53.79</td><td>64.81</td><td>66.48</td><td>57.89</td><td>65.64</td></tr><tr><td>IN Sup</td><td>-</td><td>ClassMix [24]</td><td>40.64</td><td>52.84</td><td>59.82</td><td>-</td><td>-</td></tr><tr><td>IN Sup</td><td>-</td><td>CLMB [25]</td><td>-</td><td>63.40</td><td>69.10</td><td>64.90</td><td>70.00</td></tr><tr><td>IN PixPro</td><td>-</td><td>-</td><td>38.20</td><td>49.95</td><td>60.35</td><td>52.99</td><td>63.05</td></tr><tr><td>IN PixPro</td><td>PixPro</td><td>-</td><td>41.35</td><td>52.97</td><td>63.11</td><td>53.26</td><td>63.26</td></tr><tr><td>IN PixPro</td><td>-</td><td>CutMix</td><td>49.58</td><td>61.63</td><td>67.61</td><td>58.30</td><td>68.21</td></tr><tr><td>IN PixPro</td><td>PixPro</td><td>CutMix</td><td>52.20</td><td>61.25</td><td>68.59</td><td>59.20</td><td>68.02</td></tr></tbody></table>", "target_caption": "TABLE II: Evaluation of Semi-supervised finetuning with different model initial weights. IN PixPro indicates weights pretrained with PixPro on ImageNet.", "source_title": "Semi-supervised semantic segmentation with pixel-level contrastive learning from a class-wise memory bank", "source_table": "<table><tbody><tr><td>method</td><td>1/50</td><td>1/20</td><td>1/8</td><td>FS</td></tr><tr><td colspan=\"5\">Architecture: Deeplabv2 with ResNet-101 backbone</td></tr><tr><td>Adversarial [17]+</td><td>57.2 (-17.7)</td><td>64.7 (-10.2)</td><td>69.5 (-5.4)</td><td>74.9</td></tr><tr><td>s4GAN [27]+</td><td>63.3 (-10.3)</td><td>67.2 (-6.4)</td><td>71.4 (-2.2)</td><td>73.6</td></tr><tr><td>French et al. [11]*</td><td>64.8 (-7.7)</td><td>66.5 (-6.0)</td><td>67.6 (-4.9)</td><td>72.5</td></tr><tr><td>CBC [9]+</td><td>65.5 (-8.1)</td><td>69.3 (-4.3)</td><td>70.7 (-2.9)</td><td>73.6</td></tr><tr><td>ClassMix [29]+</td><td>66.2 (-7.9)</td><td>67.8 (-6.3)</td><td>71.0 (-3.1)</td><td>74.1</td></tr><tr><td>DMT [10]*+</td><td>67.2 (-7.6)</td><td>69.9 (-4.9)</td><td>72.7 (-2.1)</td><td>74.8</td></tr><tr><td>Ours*</td><td>65.6 (-7.0)</td><td>67.8 (-4.8)</td><td>69.9 (-2.7)</td><td>72.6</td></tr><tr><td>Ours+</td><td>68.2 (-5.9)</td><td>70.1 (-4.0)</td><td>71.8 (-2.3)</td><td>74.1</td></tr><tr><td colspan=\"5\">Architecture: Deeplabv3+ with ResNet-50 backbone</td></tr><tr><td>Error-corr [26]*</td><td>\u2014</td><td>\u2014</td><td>70.2 (-6.1)</td><td>76.3</td></tr><tr><td>Lai et al. [21]*</td><td>\u2014</td><td>\u2014</td><td>72.4 (-4.1)</td><td>76.5</td></tr><tr><td>Ours*</td><td>63.4 (-12.5)</td><td>69.1 (-6.8)</td><td>72.0\\textbf{ (-3.9)}</td><td>75.9</td></tr></tbody></table><p>* ImageNet pre-training, + COCO pre-training</p>", "source_caption": "Table 3: Performance (Mean IoU) for the Pascal VOC val set for different labeled-unlabeled ratios and, in parentheses, the difference w.r.t. the corresponding fully supervised (FS) result."}