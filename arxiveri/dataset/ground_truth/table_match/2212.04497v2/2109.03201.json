{"target_title": "UNETR++: Delving into Efficient and Accurate 3D Medical Image Segmentation", "target_table": "<table><thead><tr><td rowspan=\"2\">Methods</td><td rowspan=\"2\">Params</td><td rowspan=\"2\">FLOPs</td><td rowspan=\"2\">Spl</td><td rowspan=\"2\">RKid</td><td rowspan=\"2\">LKid</td><td rowspan=\"2\">Gal</td><td rowspan=\"2\">Liv</td><td rowspan=\"2\">Sto</td><td rowspan=\"2\">Aor</td><td rowspan=\"2\">Pan</td><td colspan=\"2\">Average</td></tr><tr><td>HD95 \\downarrow</td><td>DSC \\uparrow</td></tr></thead><tbody><tr><td>U-Net [27]</td><td>-</td><td>-</td><td>86.67</td><td>68.60</td><td>77.77</td><td>69.72</td><td>93.43</td><td>75.58</td><td>89.07</td><td>53.98</td><td>-</td><td>76.85</td></tr><tr><td>TransUNet [5]</td><td>96.07</td><td>88.91</td><td>85.08</td><td>77.02</td><td>81.87</td><td>63.16</td><td>94.08</td><td>75.62</td><td>87.23</td><td>55.86</td><td>31.69</td><td>77.49</td></tr><tr><td>Swin-UNet [3]</td><td>-</td><td>-</td><td>90.66</td><td>79.61</td><td>83.28</td><td>66.53</td><td>94.29</td><td>76.60</td><td>85.47</td><td>56.58</td><td>21.55</td><td>79.13</td></tr><tr><td>UNETR [13]</td><td>92.49</td><td>75.76</td><td>85.00</td><td>84.52</td><td>85.60</td><td>56.30</td><td>94.57</td><td>70.46</td><td>89.80</td><td>60.47</td><td>18.59</td><td>78.35</td></tr><tr><td>MISSFormer [15]</td><td>-</td><td>-</td><td>91.92</td><td>82.00</td><td>85.21</td><td>68.65</td><td>94.41</td><td>80.81</td><td>86.99</td><td>65.67</td><td>18.20</td><td>81.96</td></tr><tr><td>Swin-UNETR [12]</td><td>62.83</td><td>384.2</td><td>95.37</td><td>86.26</td><td>86.99</td><td>66.54</td><td>95.72</td><td>77.01</td><td>91.12</td><td>68.80</td><td>10.55</td><td>83.48</td></tr><tr><td>nnFormer [34]</td><td>150.5</td><td>213.4</td><td>90.51</td><td>86.25</td><td>86.57</td><td>70.17</td><td>96.84</td><td>86.83</td><td>92.04</td><td>83.35</td><td>10.63</td><td>86.57</td></tr><tr><td>UNETR++</td><td>42.96</td><td>47.98</td><td>95.77</td><td>87.18</td><td>87.54</td><td>71.25</td><td>96.42</td><td>86.01</td><td>92.52</td><td>81.10</td><td>7.53</td><td>87.22</td></tr></tbody></table>", "target_caption": "Table 1: State-of-the-art comparison on the abdominal multi-organ Synapse dataset. We report both the segmentation performance (DSC, HD95) and model complexity (parameters and FLOPs).Our proposed UNETR++ achieves favorable segmentation performance against existing methods, while being considerably reducing the model complexity. Best results are in bold. Abbreviations stand for: Spl: spleen, RKid: right kidney, LKid: left kidney, Gal: gallbladder, Liv: liver, Sto: stomach, Aor: aorta, Pan: pancreas. Best results are in bold.", "source_title": "nnformer: Interleaved transformer for volumetric segmentation", "source_table": "<table><tr><td rowspan=\"2\">Methods</td><td colspan=\"2\">Average</td><td rowspan=\"2\">Aotra</td><td rowspan=\"2\">Gallbladder</td><td rowspan=\"2\">Kidney (Left)</td><td rowspan=\"2\">Kidney (Right)</td><td rowspan=\"2\">Liver</td><td rowspan=\"2\">Pancreas</td><td rowspan=\"2\">Spleen</td><td rowspan=\"2\">Stomach</td></tr><tr><td>HD95 \\downarrow</td><td>DSC \\uparrow</td></tr><tr><td>ViT [2] + CUP [11]</td><td>36.11</td><td>67.86</td><td>70.19</td><td>45.10</td><td>74.70</td><td>67.40</td><td>91.32</td><td>42.00</td><td>81.75</td><td>70.44</td></tr><tr><td>R50-ViT [2] + CUP [11]</td><td>32.87</td><td>71.29</td><td>73.73</td><td>55.13</td><td>75.80</td><td>72.20</td><td>91.51</td><td>45.99</td><td>81.99</td><td>73.95</td></tr><tr><td>TransUNet [11]</td><td>31.69</td><td>77.48</td><td>87.23</td><td>63.16</td><td>81.87</td><td>77.02</td><td>94.08</td><td>55.86</td><td>85.08</td><td>75.62</td></tr><tr><td>TransUNet{}^{\\bigtriangledown} [11]</td><td>-</td><td>84.36</td><td>90.68</td><td>71.99</td><td>86.04</td><td>83.71</td><td>95.54</td><td>73.96</td><td>88.80</td><td>84.20</td></tr><tr><td>SwinUNet [18]</td><td>21.55</td><td>79.13</td><td>85.47</td><td>66.53</td><td>83.28</td><td>79.61</td><td>94.29</td><td>56.58</td><td>90.66</td><td>76.60</td></tr><tr><td>TransClaw U-Net [15]</td><td>26.38</td><td>78.09</td><td>85.87</td><td>61.38</td><td>84.83</td><td>79.36</td><td>94.28</td><td>57.65</td><td>87.74</td><td>73.55</td></tr><tr><td>LeVit-UNet-384s [22]</td><td>16.84</td><td>78.53</td><td>87.33</td><td>62.23</td><td>84.61</td><td>80.25</td><td>93.11</td><td>59.07</td><td>88.86</td><td>72.76</td></tr><tr><td>MISSFormer [35]</td><td>18.20</td><td>81.96</td><td>86.99</td><td>68.65</td><td>85.21</td><td>82.00</td><td>94.41</td><td>65.67</td><td>91.92</td><td>80.81</td></tr><tr><td>UNETR [34]</td><td>22.97</td><td>79.56</td><td>89.99</td><td>60.56</td><td>85.66</td><td>84.80</td><td>94.46</td><td>59.25</td><td>87.81</td><td>73.99</td></tr><tr><td>Our nnFormer</td><td>10.63</td><td>86.57</td><td>92.04</td><td>70.17</td><td>86.57</td><td>86.25</td><td>96.84</td><td>83.35</td><td>90.51</td><td>86.83</td></tr><tr><td>P-values</td><td colspan=\"10\">&lt; 1e-2 (HD95), &lt; 1e-2 (DSC)</td></tr></table>", "source_caption": "Table 3: Comparison with transformer-based models on multi-organ segmentation (Synapse). The evaluation metrics are HD95 (mm) and DSC in (%). Best results are bolded while second best are underlined. \\bigtriangledown denotes TransUNet uses larger inputs, whose size is 512\\times512. The p-values are calculated based on the average performance of our nnFormer and the best performing baseline in both metrics."}