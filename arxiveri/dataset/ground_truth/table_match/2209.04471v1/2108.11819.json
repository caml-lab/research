{"target_title": "MCIBI++: Soft Mining Contextual Information Beyond Image for Semantic Segmentation", "target_table": "<table><tbody><tr><td>Method</td><td>Backbone</td><td>Stride</td><td>mIoU (\\%)</td></tr><tr><td>CCNet [28]</td><td>ResNet-101</td><td>8\\times</td><td>45.76</td></tr><tr><td>OCNet [27]</td><td>ResNet-101</td><td>8\\times</td><td>45.45</td></tr><tr><td>ACNet [24]</td><td>ResNet-101</td><td>8\\times</td><td>45.90</td></tr><tr><td>DMNet [84]</td><td>ResNet-101</td><td>8\\times</td><td>45.50</td></tr><tr><td>EncNet [85]</td><td>ResNet-101</td><td>8\\times</td><td>44.65</td></tr><tr><td>PSPNet [4]</td><td>ResNet-101</td><td>8\\times</td><td>43.29</td></tr><tr><td>PSANet [59]</td><td>ResNet-101</td><td>8\\times</td><td>43.77</td></tr><tr><td>APCNet [86]</td><td>ResNet-101</td><td>8\\times</td><td>45.38</td></tr><tr><td>OCRNet [26]</td><td>ResNet-101</td><td>8\\times</td><td>45.28</td></tr><tr><td>UperNet [35]</td><td>ResNet-101</td><td>8\\times</td><td>44.85</td></tr><tr><td>CPNet [25]</td><td>ResNet-101</td><td>8\\times</td><td>46.27</td></tr><tr><td>ISNet [23]</td><td>ResNet-101</td><td>8\\times</td><td>47.31</td></tr><tr><td>MaskFormer [22]</td><td>ResNet-101</td><td>8\\times</td><td>47.20</td></tr><tr><td>PSPNet [4]</td><td>ResNet-269</td><td>8\\times</td><td>44.94</td></tr><tr><td>OCRNet [26]</td><td>HRNetV2-W48</td><td>4\\times</td><td>45.66</td></tr><tr><td>ISNet [23]</td><td>ResNeSt-101</td><td>8\\times</td><td>47.55</td></tr><tr><td>DeepLabV3 [6]</td><td>ResNeSt-101</td><td>8\\times</td><td>46.91</td></tr><tr><td>DeepLabV3 [6]</td><td>ResNeSt-200</td><td>8\\times</td><td>48.36</td></tr><tr><td>SETR-MLA [21]</td><td>ViT-Large</td><td>16\\times</td><td>50.28</td></tr><tr><td>UperNet [20]</td><td>Swin-Large</td><td>32\\times</td><td>53.50</td></tr><tr><td>DeepLabV3+MCIBI [44]</td><td>ResNet-101</td><td>8\\times</td><td>47.22</td></tr><tr><td>DeepLabV3+MCIBI [44]</td><td>ResNeSt-101</td><td>8\\times</td><td>47.36</td></tr><tr><td>DeepLabV3+MCIBI [44]</td><td>ViT-Large</td><td>16\\times</td><td>50.80</td></tr><tr><td>UperNet+MCIBI++ (ours)</td><td>ResNet-101</td><td>8\\times</td><td>47.93</td></tr><tr><td>UperNet+MCIBI++ (ours)</td><td>ResNeSt-101</td><td>8\\times</td><td>48.56</td></tr><tr><td>UperNet+MCIBI++ (ours)</td><td>Swin-Large</td><td>32\\times</td><td>54.52</td></tr></tbody></table>", "target_caption": "TABLE X: The comparison with the state-of-the-art methods on ADE20K (val).Multi-scale and flipping testing are adopted for fair comparison.Bold denotes the best score.", "source_title": "Mining contextual information beyond image for semantic segmentation", "source_table": "<table><tbody><tr><td>Method</td><td>Backbone</td><td>Stride</td><td>mIoU</td></tr><tr><td>CCNet [22]</td><td>ResNet-101</td><td>8\\times</td><td>45.76</td></tr><tr><td>OCNet [46]</td><td>ResNet-101</td><td>8\\times</td><td>45.45</td></tr><tr><td>ACNet [16]</td><td>ResNet-101</td><td>8\\times</td><td>45.90</td></tr><tr><td>DMNet [19]</td><td>ResNet-101</td><td>8\\times</td><td>45.50</td></tr><tr><td>EncNet [48]</td><td>ResNet-101</td><td>8\\times</td><td>44.65</td></tr><tr><td>PSPNet [50]</td><td>ResNet-101</td><td>8\\times</td><td>43.29</td></tr><tr><td>PSANet [51]</td><td>ResNet-101</td><td>8\\times</td><td>43.77</td></tr><tr><td>APCNet [20]</td><td>ResNet-101</td><td>8\\times</td><td>45.38</td></tr><tr><td>OCRNet [45]</td><td>ResNet-101</td><td>8\\times</td><td>45.28</td></tr><tr><td>PSPNet [50]</td><td>ResNet-269</td><td>8\\times</td><td>44.94</td></tr><tr><td>OCRNet [45]</td><td>HRNetV2-W48</td><td>4\\times</td><td>45.66</td></tr><tr><td>DeepLabV3 [6]</td><td>ResNeSt-50</td><td>8\\times</td><td>45.12</td></tr><tr><td>DeepLabV3 [6]</td><td>ResNeSt-101</td><td>8\\times</td><td>46.91</td></tr><tr><td>SETR-MLA [54]</td><td>ViT-Large</td><td>16\\times</td><td>50.28</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-50</td><td>8\\times</td><td>45.95</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNet-101</td><td>8\\times</td><td>47.22</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ResNeSt-101</td><td>8\\times</td><td>47.36</td></tr><tr><td>DeepLabV3+MCIBI (ours)</td><td>ViT-Large</td><td>16\\times</td><td>50.80</td></tr></tbody></table>", "source_caption": "Table 6: Comparison with the state-of-the-art on ADE20K (val).Multi-scale and flipping testing is adopted for fair comparison."}