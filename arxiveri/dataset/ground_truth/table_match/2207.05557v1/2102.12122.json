{"target_title": "LightViT: Towards Light-Weight Convolution-Free Vision Transformers", "target_table": "<table><tr><td rowspan=\"2\">Backbone</td><td>Params</td><td>FLOPs</td><td colspan=\"6\">Mask R-CNN 1x schedule</td><td colspan=\"6\">Mask R-CNN 3x + MS schedule</td></tr><tr><td>(M)</td><td>(G)</td><td>AP{}^{b}</td><td>AP{}_{50}^{b}</td><td>AP{}_{75}^{b}</td><td>AP{}^{m}</td><td>AP{}_{50}^{m}</td><td>AP{}_{75}^{m}</td><td>AP{}^{b}</td><td>AP{}_{50}^{b}</td><td>AP{}_{75}^{b}</td><td>AP{}^{m}</td><td>AP{}_{50}^{m}</td><td>AP{}_{75}^{m}</td></tr><tr><td>ResNet-18 [8]</td><td>31</td><td>207</td><td>34.0</td><td>54.0</td><td>36.7</td><td>31.2</td><td>51.0</td><td>32.7</td><td>36.9</td><td>57.1</td><td>40.0</td><td>33.6</td><td>53.9</td><td>35.7</td></tr><tr><td>ResNet-50 [8]</td><td>44</td><td>260</td><td>38.0</td><td>58.6</td><td>41.4</td><td>34.4</td><td>55.1</td><td>36.7</td><td>41.0</td><td>61.7</td><td>44.9</td><td>37.1</td><td>58.4</td><td>40.1</td></tr><tr><td>ResNet-101 [8]</td><td>101</td><td>493</td><td>40.4</td><td>61.1</td><td>44.2</td><td>36.4</td><td>57.7</td><td>38.8</td><td>42.8</td><td>63.2</td><td>47.1</td><td>38.5</td><td>60.1</td><td>41.3</td></tr><tr><td>PVT-T [30]</td><td>33</td><td>208</td><td>36.7</td><td>59.2</td><td>39.3</td><td>35.1</td><td>56.7</td><td>37.3</td><td>39.8</td><td>62.2</td><td>43.0</td><td>37.4</td><td>59.3</td><td>39.9</td></tr><tr><td>PVT-S [30]</td><td>44</td><td>245</td><td>40.4</td><td>62.9</td><td>43.8</td><td>37.8</td><td>60.1</td><td>40.3</td><td>43.0</td><td>65.3</td><td>46.9</td><td>39.9</td><td>62.5</td><td>42.8</td></tr><tr><td>PVT-M [30]</td><td>64</td><td>302</td><td>42.0</td><td>64.4</td><td>45.6</td><td>39.0</td><td>61.6</td><td>42.1</td><td>44.2</td><td>66.0</td><td>48.2</td><td>40.5</td><td>63.1</td><td>43.5</td></tr><tr><td>LightViT-T</td><td>28</td><td>187</td><td>37.8</td><td>60.7</td><td>40.4</td><td>35.9</td><td>57.8</td><td>38.0</td><td>41.5</td><td>64.4</td><td>45.1</td><td>38.4</td><td>61.2</td><td>40.8</td></tr><tr><td>LightViT-S</td><td>38</td><td>204</td><td>40.0</td><td>62.9</td><td>42.6</td><td>37.4</td><td>60.0</td><td>39.3</td><td>43.2</td><td>66.0</td><td>47.4</td><td>39.9</td><td>63.0</td><td>42.7</td></tr><tr><td>LightViT-B</td><td>54</td><td>240</td><td>41.7</td><td>64.5</td><td>45.1</td><td>38.8</td><td>61.4</td><td>41.4</td><td>45.0</td><td>67.9</td><td>48.8</td><td>41.2</td><td>64.8</td><td>44.2</td></tr></table>", "target_caption": "Table 4: Object detection and instance segmentation performance on COCO val2017. The FLOPs are measured on 800\\times 1280. All the models are pretrained on ImageNet-1K.", "source_title": "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions", "source_table": "<table><tr><td rowspan=\"2\">Backbone</td><td rowspan=\"2\">#Param(M)</td><td colspan=\"6\">Mask R-CNN 1x</td><td colspan=\"6\">Mask R-CNN 3x + MS</td></tr><tr><td>AP{}^{\\rm b}</td><td>AP{}_{50}^{\\rm b}</td><td>AP{}_{75}^{\\rm b}</td><td>AP{}^{\\rm m}</td><td>AP{}_{50}^{\\rm m}</td><td>AP{}_{75}^{\\rm m}</td><td>AP{}^{\\rm b}</td><td>AP{}_{50}^{\\rm b}</td><td>AP{}_{75}^{\\rm b}</td><td>AP{}^{\\rm m}</td><td>AP{}_{50}^{\\rm m}</td><td>AP{}_{75}^{\\rm m}</td></tr><tr><td>ResNet18 [22]</td><td>31.2</td><td>34.0</td><td>54.0</td><td>36.7</td><td>31.2</td><td>51.0</td><td>32.7</td><td>36.9</td><td>57.1</td><td>40.0</td><td>33.6</td><td>53.9</td><td>35.7</td></tr><tr><td>PVT-Tiny (ours)</td><td>32.9</td><td>36.7(+2.7)</td><td>59.2</td><td>39.3</td><td>35.1(+3.9)</td><td>56.7</td><td>37.3</td><td>39.8(+2.9)</td><td>62.2</td><td>43.0</td><td>37.4(+3.8)</td><td>59.3</td><td>39.9</td></tr><tr><td>ResNet50 [22]</td><td>44.2</td><td>38.0</td><td>58.6</td><td>41.4</td><td>34.4</td><td>55.1</td><td>36.7</td><td>41.0</td><td>61.7</td><td>44.9</td><td>37.1</td><td>58.4</td><td>40.1</td></tr><tr><td>PVT-Small (ours)</td><td>44.1</td><td>40.4(+2.4)</td><td>62.9</td><td>43.8</td><td>37.8(+3.4)</td><td>60.1</td><td>40.3</td><td>43.0(+2.0)</td><td>65.3</td><td>46.9</td><td>39.9(+2.8)</td><td>62.5</td><td>42.8</td></tr><tr><td>ResNet101 [22]</td><td>63.2</td><td>40.4</td><td>61.1</td><td>44.2</td><td>36.4</td><td>57.7</td><td>38.8</td><td>42.8</td><td>63.2</td><td>47.1</td><td>38.5</td><td>60.1</td><td>41.3</td></tr><tr><td>ResNeXt101-32x4d [73]</td><td>62.8</td><td>41.9(+1.5)</td><td>62.5</td><td>45.9</td><td>37.5(+1.1)</td><td>59.4</td><td>40.2</td><td>44.0(+1.2)</td><td>64.4</td><td>48.0</td><td>39.2(+0.7)</td><td>61.4</td><td>41.9</td></tr><tr><td>PVT-Medium (ours)</td><td>63.9</td><td>42.0(+1.6)</td><td>64.4</td><td>45.6</td><td>39.0(+2.6)</td><td>61.6</td><td>42.1</td><td>44.2(+1.4)</td><td>66.0</td><td>48.2</td><td>40.5(+2.0)</td><td>63.1</td><td>43.5</td></tr><tr><td>ResNeXt101-64x4d [73]</td><td>101.9</td><td>42.8</td><td>63.8</td><td>47.3</td><td>38.4</td><td>60.6</td><td>41.3</td><td>44.4</td><td>64.9</td><td>48.8</td><td>39.7</td><td>61.9</td><td>42.6</td></tr><tr><td>PVT-Large (ours)</td><td>81.0</td><td>42.9(+0.1)</td><td>65.0</td><td>46.6</td><td>39.5(+1.1)</td><td>61.9</td><td>42.5</td><td>44.5(+0.1)</td><td>66.0</td><td>48.3</td><td>40.7(+1.0)</td><td>63.4</td><td>43.7</td></tr></table><p>.</p>", "source_caption": "Table 4: Object detection and instance segmentation performance on COCO val2017.AP{}^{\\rm b} and AP{}^{\\rm m} denote bounding box AP and mask AP, respectively."}