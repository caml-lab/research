{"target_title": "SceneComposer: Any-Level Semantic Image Synthesis", "target_table": "<table><thead><tr><td>Method</td><td>FID \\downarrow</td><td>zero-shot FID\\downarrow</td></tr></thead><tbody><tr><td>SSA-GAN [31]</td><td>19.37</td><td>-</td></tr><tr><td>VQ-Diffusion [15]</td><td>13.86</td><td>-</td></tr><tr><td>DF-GAN [55]</td><td>19.32</td><td>-</td></tr><tr><td>GLIDE [37]</td><td>-</td><td>12.89</td></tr><tr><td>SD [45, 1]</td><td>-</td><td>9.89</td></tr><tr><td>DALLE-2 [41]</td><td>-</td><td>10.87</td></tr><tr><td>Ours</td><td>8.55</td><td>9.47</td></tr></tbody></table>", "target_caption": "Table 3: Quantitative comparison with T2I methods on COCO. ", "source_title": "Hierarchical text-conditional image generation with clip latents", "source_table": "<table><tr><td>Model</td><td>FID</td><td>Zero-shot FID</td><td>Zero-shot FID (filt)</td></tr><tr><td>AttnGAN (Xu et al., 2017)</td><td>35.49</td><td></td><td></td></tr><tr><td>DM-GAN (Zhu et al., 2019)</td><td>32.64</td><td></td><td></td></tr><tr><td>DF-GAN (Tao et al., 2020)</td><td>21.42</td><td></td><td></td></tr><tr><td>DM-GAN + CL (Ye et al., 2021)</td><td>20.79</td><td></td><td></td></tr><tr><td>XMC-GAN (Zhang et al., 2021a)</td><td>9.33</td><td></td><td></td></tr><tr><td>LAFITE (Zhou et al., 2021)</td><td>8.12</td><td></td><td></td></tr><tr><td>Make-A-Scene (Gafni et al., 2022)</td><td>7.55</td><td></td><td></td></tr><tr><td>DALL-E (Ramesh et al., 2021)</td><td></td><td>\\sim 28</td><td></td></tr><tr><td>LAFITE (Zhou et al., 2021)</td><td></td><td>26.94</td><td></td></tr><tr><td>GLIDE (Nichol et al., 2021)</td><td></td><td>12.24</td><td>12.89</td></tr><tr><td>Make-A-Scene (Gafni et al., 2022)</td><td></td><td></td><td>11.84</td></tr><tr><td>unCLIP (AR prior)</td><td></td><td>10.63</td><td>11.08</td></tr><tr><td>unCLIP (Diffusion prior)</td><td></td><td>10.39</td><td>10.87</td></tr></table>", "source_caption": "Table 2:  Comparison of FID on MS-COCO 256\\times 256. We use guidance scale 1.25 for the decoder for both the AR and diffusion prior, and achieve the best results using the diffusion prior."}