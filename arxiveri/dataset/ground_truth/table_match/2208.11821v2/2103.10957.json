{"target_title": "Refine and Represent: Region-to-Object Representation Learning", "target_table": "<table><tbody><tr><td></td><td colspan=\"2\">COCO 1\\times</td><td colspan=\"2\">COCO 2\\times</td></tr><tr><td>Method</td><td>AP<sup>bb</sup></td><td>AP<sup>mk</sup></td><td>AP<sup>bb</sup></td><td>AP<sup>mk</sup></td></tr><tr><td>Supervised</td><td>38.9</td><td>35.4</td><td>40.6</td><td>36.8</td></tr><tr><td>MoCo v2 [10]</td><td>38.9</td><td>35.4</td><td>40.9</td><td>37.0</td></tr><tr><td>BYOL<sup>\u2020</sup> [23]</td><td>40.6</td><td>37.5</td><td>42.0</td><td>38.7</td></tr><tr><td>DenseCL [56]</td><td>40.3</td><td>36.4</td><td>41.2</td><td>37.3</td></tr><tr><td>ReSim [60]</td><td>39.3</td><td>35.7</td><td>41.1</td><td>37.1</td></tr><tr><td>PixPro [63]</td><td>41.4</td><td>-</td><td>-</td><td>-</td></tr><tr><td>DetCon<sub>B</sub><sup>\u2020</sup> [28]</td><td>41.5</td><td>38.0</td><td>42.1</td><td>38.9</td></tr><tr><td>DetCo [61]</td><td>39.4</td><td>34.4</td><td>41.4</td><td>35.8</td></tr><tr><td>LEWEL [31]</td><td>41.3</td><td>37.4</td><td>42.2</td><td>38.2</td></tr><tr><td>R2O</td><td>41.7</td><td>38.3</td><td>42.3</td><td>39.0</td></tr></tbody></table>", "target_caption": "Table 1: Performance on COCO object detection and instance segmentation following ImageNet pretraining. All methods pretrained a ResNet-50 which later served as the backbone of a Mask R-CNN R50-FPN finetuned on train2017 for 12 epochs (1\\times schedule) or 24 epochs (2\\times schedule). We report Average Precision on bounding box (AP<sup>bb</sup>) and mask (AP<sup>mk</sup>) predictions for val2017. <sup>\u2020</sup>: Results from re-implementation.", "source_title": "Efficient visual pretraining with contrastive detection", "source_table": "<table><tbody><tr><td></td><td colspan=\"2\">Fine-tune 1\\times</td><td colspan=\"2\">Fine-tune 2\\times</td></tr><tr><td>method</td><td><p>AP{}^{\\text{bb}}_{\\text{~{}}}</p></td><td><p>AP{}^{\\text{mk}}_{\\text{~{}}}</p></td><td><p>AP{}^{\\text{bb}}_{\\text{~{}}}</p></td><td><p>AP{}^{\\text{mk}}_{\\text{~{}}}</p></td></tr><tr><td>Supervised</td><td><p>39.6</p></td><td><p>35.6</p></td><td><p>41.6</p></td><td><p>37.6</p></td></tr><tr><td>VADeR [48]</td><td><p>39.2</p></td><td><p>35.6</p></td><td><p>-</p></td><td><p>-</p></td></tr><tr><td>MoCo [24]</td><td><p>39.4</p></td><td><p>35.6</p></td><td><p>41.7</p></td><td><p>37.5</p></td></tr><tr><td>SimCLR [9]</td><td><p>39.7</p></td><td><p>35.8</p></td><td><p>41.6</p></td><td><p>37.4</p></td></tr><tr><td>MoCo v2 [11]</td><td><p>40.1</p></td><td><p>36.3</p></td><td><p>41.7</p></td><td><p>37.6</p></td></tr><tr><td>InfoMin [54]</td><td><p>40.6</p></td><td><p>36.7</p></td><td><p>42.5</p></td><td><p>38.4</p></td></tr><tr><td>PixPro [63]</td><td><p>41.4</p></td><td><p>-</p></td><td><p>-</p></td><td><p>-</p></td></tr><tr><td>BYOL [21]</td><td><p>41.6</p></td><td><p>37.2</p></td><td><p>42.4</p></td><td><p>38.0</p></td></tr><tr><td>SwAV [7]</td><td><p>41.6</p></td><td><p>37.8</p></td><td><p>-</p></td><td><p>-</p></td></tr><tr><td>DetCon{}_{S}</td><td><p>41.8</p></td><td><p>37.4</p></td><td><p>42.9</p></td><td><p>38.1</p></td></tr><tr><td>DetCon{}_{B}</td><td>42.7</td><td>38.2</td><td>43.4</td><td>38.7</td></tr></tbody></table>", "source_caption": "Table 2: Comparison to prior art: all methods are pretrained on ImageNet then fined-tuned on COCO for 12 epochs (1\\times  schedule) or 24 epochs (2\\times  schedule). "}