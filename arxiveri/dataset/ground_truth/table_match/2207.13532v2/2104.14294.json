{"target_title": "Contrastive Masked Autoencoders are Stronger Vision Learners", "target_table": "<table><tbody><tr><td>Method</td><td>Pre-training epochs</td><td>Params.(M)</td><td>Supervision</td><td>Accuracy</td></tr><tr><td>MoCo-v3 [10]</td><td>300</td><td>88</td><td>RGB</td><td>83.0</td></tr><tr><td>DINO [6]</td><td>1600</td><td>88</td><td>RGB</td><td>82.8</td></tr><tr><td>CIM [17]</td><td>300</td><td>88</td><td>RGB</td><td>83.1</td></tr><tr><td>BEiT [3]</td><td>800</td><td>88</td><td>DALLE</td><td>83.2</td></tr><tr><td>SimMIM [42]</td><td>800</td><td>88</td><td>RGB</td><td>83.8</td></tr><tr><td>PeCo [15]</td><td>800</td><td>88</td><td>Perceptual Codebook</td><td>84.5</td></tr><tr><td>MaskFeat [39]</td><td>1600</td><td>88</td><td>HOG</td><td>84.0</td></tr><tr><td>CAE [11]</td><td>1600</td><td>88</td><td>DALLE+RGB</td><td>83.8</td></tr><tr><td>iBOT [50]</td><td>1600</td><td>88</td><td>RGB</td><td>84.0</td></tr><tr><td>SIM [37]</td><td>1600</td><td>88</td><td>RGB</td><td>83.8</td></tr><tr><td>MAE [24]</td><td>800</td><td>88</td><td>RGB</td><td>83.1</td></tr><tr><td>MAE [24]</td><td>1600</td><td>88</td><td>RGB</td><td>83.6</td></tr><tr><td>CMAE (ours)</td><td>800</td><td>88</td><td>RGB</td><td>84.4</td></tr><tr><td>CMAE (ours)</td><td>1600</td><td>88</td><td>RGB</td><td>84.7</td></tr><tr><td>ConvMAE<sup>*</sup> [18]</td><td>800</td><td>88</td><td>RGB</td><td>84.6</td></tr><tr><td>ConvMAE<sup>*</sup> [18]</td><td>1600</td><td>88</td><td>RGB</td><td>84.6</td></tr><tr><td>CMAE<sup>*</sup> (ours)</td><td>800</td><td>88</td><td>RGB</td><td>85.0</td></tr><tr><td>CMAE<sup>*</sup> (ours)</td><td>1600</td><td>88</td><td>RGB</td><td>85.3</td></tr></tbody></table>", "target_caption": "Table 2: Comparison of our model with existing methods on ViT-B. We evaluate them with the top-1 accuracy on ImageNet. The symbol of <sup>*</sup> throughout experiments denotes using convolutions instead of linear transformation as the tokenizer for visual patches. ", "source_title": "Emerging properties in self-supervised vision transformers", "source_table": "<table><thead><tr><td></td><td>Cifar{}_{\\text{10}}</td><td>Cifar{}_{\\text{100}}</td><td>INat{}_{\\text{18}}</td><td>INat{}_{\\text{19}}</td><td>Flwrs</td><td>Cars</td><td>INet</td></tr></thead><tbody><tr><td>ViT-S/16</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Sup. [69]</td><td>99.0</td><td>89.5</td><td>70.7</td><td>76.6</td><td>98.2</td><td>92.1</td><td>79.9</td></tr><tr><td>DINO</td><td>99.0</td><td>90.5</td><td>72.0</td><td>78.2</td><td>98.5</td><td>93.0</td><td>81.5</td></tr><tr><td>ViT-B/16</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Sup. [69]</td><td>99.0</td><td>90.8</td><td>73.2</td><td>77.7</td><td>98.4</td><td>92.1</td><td>81.8</td></tr><tr><td>DINO</td><td>99.1</td><td>91.7</td><td>72.6</td><td>78.6</td><td>98.8</td><td>93.0</td><td>82.8</td></tr></tbody></table>", "source_caption": "Table 6: Transfer learning by finetuning pretrained models on different datasets.We report top-1 accuracy.Self-supervised pretraining with DINO transfers better than supervised pretraining."}