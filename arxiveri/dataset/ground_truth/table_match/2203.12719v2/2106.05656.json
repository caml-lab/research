{"target_title": "What to Hide from Your Students: Attention-Guided Masked Image Modeling", "target_table": "<table><thead><tr><td rowspan=\"2\">Method</td><td colspan=\"2\">(a) Full</td><td colspan=\"4\">(b) Few Examples</td></tr><tr><td>k-NN</td><td>Linear</td><td>\\nu=1</td><td>5</td><td>10</td><td>20</td></tr></thead><tbody><tr><td>SimCLR [9]</td><td>-</td><td>69.0</td><td></td><td></td><td></td><td></td></tr><tr><td>BYOL [23]</td><td>66.6</td><td>71.4</td><td></td><td></td><td></td><td></td></tr><tr><td>MoBY [71]</td><td>-</td><td>72.8</td><td></td><td></td><td></td><td></td></tr><tr><td>DINO [8]</td><td>72.8</td><td>76.1</td><td></td><td></td><td></td><td></td></tr><tr><td>MST [38]</td><td>75.0</td><td>76.9</td><td></td><td></td><td></td><td></td></tr><tr><td>iBOT [78]</td><td>74.6</td><td>77.4</td><td>38.9</td><td>54.1</td><td>58.5</td><td>61.9</td></tr><tr><td>iBOT+AttMask (Ours)</td><td>75.0</td><td>77.5</td><td>40.4</td><td>55.5</td><td>59.9</td><td>63.1</td></tr></tbody></table>", "target_caption": "Table A13: Top-1 accuracy on ImageNet validation set. (a) k-NN and linear probing using the full ImageNet training set; (b) k-NN using only \\nu\\in\\{1,5,10,20\\} examples per class. Pre-training on 100% ImageNet-1k for 300 epochs.", "source_title": "Mst: Masked self-supervised transformer for visual representation", "source_table": "<table><tr><td>Method</td><td>Architecture</td><td>Parameters</td><td>epoch</td><td>im/s</td><td>Linear</td><td>k-NN</td></tr><tr><td>Supervised</td><td rowspan=\"4\"> Res50[16] </td><td rowspan=\"4\"> 23 </td><td>100</td><td>1237</td><td>76.5</td><td>-</td></tr><tr><td>MoCov2 [6]</td><td>800</td><td>1237</td><td>71.1</td><td>61.9</td></tr><tr><td>BYOL [13]</td><td>1000</td><td>1237</td><td>74.4</td><td>64.8</td></tr><tr><td>SwAV [1]</td><td>800</td><td>1237</td><td>75.3</td><td>65.7</td></tr><tr><td>Supervised</td><td rowspan=\"15\"> DeiT-S[26] </td><td rowspan=\"15\"> 21 </td><td>300</td><td>1007</td><td>76.4</td><td>-</td></tr><tr><td>SwAV [1]</td><td>300</td><td>1007</td><td>67.1</td><td>-</td></tr><tr><td>SimCLR [4]</td><td>300</td><td>1007</td><td>69.0</td><td>-</td></tr><tr><td>BYOL [13]</td><td>300</td><td>1007</td><td>71.0</td><td>-</td></tr><tr><td>MoCov3 [7]</td><td>300</td><td>1007</td><td>72.5</td><td>-</td></tr><tr><td>MOBY [30]</td><td>300</td><td>1007</td><td>72.8</td><td>-</td></tr><tr><td>BYOL [13]</td><td>800</td><td>1007</td><td>71.4</td><td>66.6</td></tr><tr><td>MoCov2 [6]</td><td>800</td><td>1007</td><td>72.7</td><td>64.4</td></tr><tr><td>SwAV [1]</td><td>800</td><td>1007</td><td>73.5</td><td>66.3</td></tr><tr><td>DINO [2]</td><td>300</td><td>1007</td><td>75.2</td><td>72.8</td></tr><tr><td>DINO{}^{{\\dagger}} [2]</td><td>300</td><td>1007</td><td>75.9</td><td>72.8</td></tr><tr><td>DINO{}^{{\\dagger}} [2]</td><td>800</td><td>1007</td><td>77.0</td><td>74.5</td></tr><tr><td>Ours {}^{{\\dagger}}</td><td>100</td><td>1007</td><td>75.0</td><td>72.1</td></tr><tr><td>Ours</td><td>300</td><td>1007</td><td>76.3</td><td>75.0</td></tr><tr><td>Ours {}^{{\\dagger}}</td><td>300</td><td>1007</td><td>76.9</td><td>75.0</td></tr><tr><td>Supervised</td><td rowspan=\"3\"> Swin-T[20] </td><td rowspan=\"3\"> 28 </td><td>300</td><td>755</td><td>81.2</td><td>-</td></tr><tr><td>MoBY [30]</td><td>100</td><td>755</td><td>70.9</td><td>57.34</td></tr><tr><td>Ours</td><td>100</td><td>755</td><td>73.8</td><td>66.20</td></tr></table>", "source_caption": "Table 1:  Comparison of popular self-supervise learning methods on ImageNet.Throughput (im/s) is calculated on a single NVIDIA V100 GPU with batch size 128. {}^{{\\dagger}} adopts the linear probing of DINO."}